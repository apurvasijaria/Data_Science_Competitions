{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from string import digits \n",
    "import string\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data set\n",
    "# unzipping dataset\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"../dataset/fake-news.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"../dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading dataset\n",
    "train = pd.read_csv('../dataset/train.csv')\n",
    "test = pd.read_csv('../dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data\n",
    "\n",
    "Understanding Data Types and Missing Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5200 entries, 0 to 5199\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5200 non-null   int64 \n",
      " 1   title   5078 non-null   object\n",
      " 2   author  4697 non-null   object\n",
      " 3   text    5193 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 162.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20800.000000</td>\n",
       "      <td>20800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>0.500625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6004.587135</td>\n",
       "      <td>0.500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5199.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15599.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20799.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         label\n",
       "count  20800.000000  20800.000000\n",
       "mean   10399.500000      0.500625\n",
       "std     6004.587135      0.500012\n",
       "min        0.000000      0.000000\n",
       "25%     5199.750000      0.000000\n",
       "50%    10399.500000      1.000000\n",
       "75%    15599.250000      1.000000\n",
       "max    20799.000000      1.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check for missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Author column has more than 5% missing values - cannot drop all rows. \n",
    "Imputing with empty text_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title     122\n",
       "author    503\n",
       "text        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the structure of data\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing null columns with empty string\n",
    "train = train.replace(np.nan, '', regex=True)\n",
    "test = test.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5200 entries, 0 to 5199\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              5200 non-null   int64  \n",
      " 1   title           5200 non-null   object \n",
      " 2   author          5200 non-null   object \n",
      " 3   text            5200 non-null   object \n",
      " 4   original_text   5200 non-null   object \n",
      " 5   text_words      5200 non-null   object \n",
      " 6   text_digit_cnt  5200 non-null   int64  \n",
      " 7   clean_text_lem  5200 non-null   object \n",
      " 8   clean_text      5200 non-null   object \n",
      " 9   title_polarity  5200 non-null   float64\n",
      " 10  text_polarity   5200 non-null   float64\n",
      " 11  ttl_wrds        5200 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 487.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id        0\n",
      "title     0\n",
      "author    0\n",
      "text      0\n",
      "label     0\n",
      "dtype: int64\n",
      "id        0\n",
      "title     0\n",
      "author    0\n",
      "text      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Checking null values after imputing\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing and Cleaning\n",
    "\n",
    "**Hypothesis:** Fake news would have more polarizing words in article and title, and be longer and have less reliable citations\n",
    "\n",
    "### Feature Engineering \n",
    "\n",
    "To check above hypothesis, add following features:\n",
    "    - total words in article\n",
    "    - sentiment polarity of title\n",
    "    - sentiment polarity of article\n",
    "    - number of words in article with all digits\n",
    "\n",
    "---------------\n",
    "Steps:\n",
    "    1. cleaning and processing \n",
    "    2. remove stop words\n",
    "        cnt digits in columns\n",
    "    3. cnt words in all columns (3 features)\n",
    "    4. find action words\n",
    "    5. calculate sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting column names\n",
    "text_cols = train.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the orignal text column before modifications\n",
    "train['original_text'] = train['text']\n",
    "test['original_text'] = test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing colums to lowercase\n",
    "for col in text_cols:\n",
    "    train[col] = train.apply(lambda x: x[col].lower(),axis=1)\n",
    "    test[col] = test.apply(lambda x: x[col].lower(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing punctuations\n",
    "for col in text_cols:\n",
    "    train[col] = train.apply(lambda x: x[col].translate(str.maketrans('','',string.punctuation)),axis=1)\n",
    "    test[col] = test.apply(lambda x: x[col].translate(str.maketrans('','',string.punctuation)),axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word tokenization\n",
    "train['text_words'] = train.apply(lambda x: word_tokenize(x['text']),axis=1)\n",
    "test['text_words'] = test.apply(lambda x: word_tokenize(x['text']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new features \n",
    "## Number of digits ( to see if citations are made)\n",
    "\n",
    "def cnt_digits(sentence):\n",
    "    return sum(c.isdigit() for c in sentence)\n",
    "        \n",
    "train['text_digit_cnt'] = train.apply(lambda x: cnt_digits(x.text_words),axis=1)\n",
    "test['text_digit_cnt'] = test.apply(lambda x: cnt_digits(x.text_words),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing digits\n",
    "for col in text_cols:\n",
    "    train[col] = train.apply(lambda x: x[col].translate(str.maketrans('', '', digits)) ,axis=1)\n",
    "    test[col] = test.apply(lambda x: x[col].translate(str.maketrans('', '', digits) ) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenzize again after digits removal\n",
    "train['text_words'] = train.apply(lambda x: word_tokenize(x['text']),axis=1)\n",
    "test['text_words'] = test.apply(lambda x: word_tokenize(x['text']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lemmatize verbs and nouns\n",
    "## in final model only nouns have been lemmatize, verbs used to indicate polarity\n",
    "\n",
    "def lemmat_words(words,pos):\n",
    "    lemmated = [lemmatizer.lemmatize(word,pos) for word in words]\n",
    "    return lemmated\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train['clean_text_lem'] = train.apply(lambda x: lemmat_words(x['text_words'],pos = wordnet.NOUN),axis=1)\n",
    "test['clean_text_lem'] = test.apply(lambda x: lemmat_words(x['text_words'],pos = wordnet.NOUN),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove stopwords\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "## stop words from nltk module\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "def rm_stopwords(text_words):\n",
    "    stopped = [w for w in text_words if not w in stop_words]\n",
    "    return stopped\n",
    "\n",
    "train['clean_text'] = train.apply(lambda x: rm_stopwords(x['clean_text_lem']),axis=1)\n",
    "test['clean_text'] = test.apply(lambda x: rm_stopwords(x['clean_text_lem']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Sentiment\n",
    "def polarity(words):\n",
    "    text = ' '.join([w for w in words])\n",
    "    blob = TextBlob(text)\n",
    "    return(blob.polarity)\n",
    "\n",
    "train['title_polarity'] = train.apply(lambda x: polarity(x['title']),axis=1)\n",
    "train['text_polarity'] = train.apply(lambda x: polarity(x['clean_text']),axis=1)\n",
    "test['title_polarity'] = test.apply(lambda x: polarity(x['title']),axis=1)\n",
    "test['text_polarity'] = test.apply(lambda x: polarity(x['clean_text']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## length of article\n",
    "train['ttl_wrds'] = train.apply(lambda x: len(x.text_words),axis = 1)\n",
    "test['ttl_wrds'] = test.apply(lambda x: len(x.text_words),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>text_words</th>\n",
       "      <th>text_digit_cnt</th>\n",
       "      <th>clean_text_lem</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>text_polarity</th>\n",
       "      <th>ttl_wrds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>house dem aide we didn’t even see comey’s lett...</td>\n",
       "      <td>darrell lucus</td>\n",
       "      <td>house dem aide we didn’t even see comey’s lett...</td>\n",
       "      <td>1</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>[house, dem, aide, we, didn, ’, t, even, see, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[house, dem, aide, we, didn, ’, t, even, see, ...</td>\n",
       "      <td>[house, dem, aide, ’, even, see, comey, ’, let...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>flynn hillary clinton big woman on campus  bre...</td>\n",
       "      <td>daniel j flynn</td>\n",
       "      <td>ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>[ever, get, the, feeling, your, life, circles,...</td>\n",
       "      <td>9</td>\n",
       "      <td>[ever, get, the, feeling, your, life, circle, ...</td>\n",
       "      <td>[ever, get, feeling, life, circle, roundabout,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077613</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>why the truth might get you fired</td>\n",
       "      <td>consortiumnewscom</td>\n",
       "      <td>why the truth might get you fired october   \\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>[why, the, truth, might, get, you, fired, octo...</td>\n",
       "      <td>8</td>\n",
       "      <td>[why, the, truth, might, get, you, fired, octo...</td>\n",
       "      <td>[truth, might, get, fired, october, tension, i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083994</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>civilians killed in single us airstrike have ...</td>\n",
       "      <td>jessica purkiss</td>\n",
       "      <td>videos  civilians killed in single us airstrik...</td>\n",
       "      <td>1</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>[videos, civilians, killed, in, single, us, ai...</td>\n",
       "      <td>13</td>\n",
       "      <td>[video, civilian, killed, in, single, u, airst...</td>\n",
       "      <td>[video, civilian, killed, single, u, airstrike...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>howard portnoy</td>\n",
       "      <td>print \\nan iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>[print, an, iranian, woman, has, been, sentenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>[print, an, iranian, woman, ha, been, sentence...</td>\n",
       "      <td>[print, iranian, woman, ha, sentenced, six, ye...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047143</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title             author  \\\n",
       "0   0  house dem aide we didn’t even see comey’s lett...      darrell lucus   \n",
       "1   1  flynn hillary clinton big woman on campus  bre...     daniel j flynn   \n",
       "2   2                  why the truth might get you fired  consortiumnewscom   \n",
       "3   3   civilians killed in single us airstrike have ...    jessica purkiss   \n",
       "4   4  iranian woman jailed for fictional unpublished...     howard portnoy   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  house dem aide we didn’t even see comey’s lett...      1   \n",
       "1  ever get the feeling your life circles the rou...      0   \n",
       "2  why the truth might get you fired october   \\n...      1   \n",
       "3  videos  civilians killed in single us airstrik...      1   \n",
       "4  print \\nan iranian woman has been sentenced to...      1   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  Ever get the feeling your life circles the rou...   \n",
       "2  Why the Truth Might Get You Fired October 29, ...   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...   \n",
       "4  Print \\nAn Iranian woman has been sentenced to...   \n",
       "\n",
       "                                          text_words  text_digit_cnt  \\\n",
       "0  [house, dem, aide, we, didn, ’, t, even, see, ...               6   \n",
       "1  [ever, get, the, feeling, your, life, circles,...               9   \n",
       "2  [why, the, truth, might, get, you, fired, octo...               8   \n",
       "3  [videos, civilians, killed, in, single, us, ai...              13   \n",
       "4  [print, an, iranian, woman, has, been, sentenc...               2   \n",
       "\n",
       "                                      clean_text_lem  \\\n",
       "0  [house, dem, aide, we, didn, ’, t, even, see, ...   \n",
       "1  [ever, get, the, feeling, your, life, circle, ...   \n",
       "2  [why, the, truth, might, get, you, fired, octo...   \n",
       "3  [video, civilian, killed, in, single, u, airst...   \n",
       "4  [print, an, iranian, woman, ha, been, sentence...   \n",
       "\n",
       "                                          clean_text  title_polarity  \\\n",
       "0  [house, dem, aide, ’, even, see, comey, ’, let...             0.0   \n",
       "1  [ever, get, feeling, life, circle, roundabout,...             0.0   \n",
       "2  [truth, might, get, fired, october, tension, i...             0.0   \n",
       "3  [video, civilian, killed, single, u, airstrike...             0.0   \n",
       "4  [print, iranian, woman, ha, sentenced, six, ye...             0.0   \n",
       "\n",
       "   text_polarity  ttl_wrds  \n",
       "0       0.026726       857  \n",
       "1       0.077613       742  \n",
       "2       0.083994      1293  \n",
       "3       0.021485       555  \n",
       "4       0.047143       160  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Saving data\n",
    "train.to_csv('../dataset/train_cleaned.csv',index= False)\n",
    "test.to_csv('../dataset/test_cleaned.csv',index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
