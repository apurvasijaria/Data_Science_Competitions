{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0966f7",
   "metadata": {},
   "source": [
    "#### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3864a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641b8e90",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2862ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_to_model.csv')\n",
    "test = pd.read_csv('../data/test_to_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cbf320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Married</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>EMI</th>\n",
       "      <th>EMI_exp</th>\n",
       "      <th>loan_avg</th>\n",
       "      <th>Long_Term_Loan</th>\n",
       "      <th>Medium_Term_Loan</th>\n",
       "      <th>Short_term_Loan</th>\n",
       "      <th>Credit_History_Bad</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Semiurban</th>\n",
       "      <th>Urban</th>\n",
       "      <th>Male</th>\n",
       "      <th>Graduate</th>\n",
       "      <th>self_employed_No</th>\n",
       "      <th>self_employed_Unknown</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.653094</td>\n",
       "      <td>4.290129</td>\n",
       "      <td>0.687296</td>\n",
       "      <td>15733.997337</td>\n",
       "      <td>2.547716</td>\n",
       "      <td>78134.975570</td>\n",
       "      <td>0.027687</td>\n",
       "      <td>0.083062</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.166124</td>\n",
       "      <td>0.291531</td>\n",
       "      <td>0.379479</td>\n",
       "      <td>0.328990</td>\n",
       "      <td>0.817590</td>\n",
       "      <td>0.781759</td>\n",
       "      <td>0.814332</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.166124</td>\n",
       "      <td>0.164495</td>\n",
       "      <td>0.083062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.476373</td>\n",
       "      <td>3.875873</td>\n",
       "      <td>0.463973</td>\n",
       "      <td>9856.363082</td>\n",
       "      <td>1.008359</td>\n",
       "      <td>61391.397533</td>\n",
       "      <td>0.164209</td>\n",
       "      <td>0.276201</td>\n",
       "      <td>0.089945</td>\n",
       "      <td>0.372495</td>\n",
       "      <td>0.454838</td>\n",
       "      <td>0.485653</td>\n",
       "      <td>0.470229</td>\n",
       "      <td>0.386497</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>0.389155</td>\n",
       "      <td>0.222445</td>\n",
       "      <td>0.372495</td>\n",
       "      <td>0.371027</td>\n",
       "      <td>0.276201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>0.246030</td>\n",
       "      <td>4250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10117.500466</td>\n",
       "      <td>1.980634</td>\n",
       "      <td>42083.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.081125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13050.000000</td>\n",
       "      <td>2.507289</td>\n",
       "      <td>62750.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.739897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18700.000000</td>\n",
       "      <td>3.016086</td>\n",
       "      <td>93500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.637489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78000.000022</td>\n",
       "      <td>9.098281</td>\n",
       "      <td>650000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Married  CoapplicantIncome  Loan_Status           EMI     EMI_exp  \\\n",
       "count  614.000000         614.000000   614.000000    614.000000  614.000000   \n",
       "mean     0.653094           4.290129     0.687296  15733.997337    2.547716   \n",
       "std      0.476373           3.875873     0.463973   9856.363082    1.008359   \n",
       "min      0.000000           0.000000     0.000000    900.000000    0.246030   \n",
       "25%      0.000000           0.000000     0.000000  10117.500466    1.980634   \n",
       "50%      1.000000           7.081125     1.000000  13050.000000    2.507289   \n",
       "75%      1.000000           7.739897     1.000000  18700.000000    3.016086   \n",
       "max      1.000000          10.637489     1.000000  78000.000022    9.098281   \n",
       "\n",
       "            loan_avg  Long_Term_Loan  Medium_Term_Loan  Short_term_Loan  \\\n",
       "count     614.000000      614.000000        614.000000       614.000000   \n",
       "mean    78134.975570        0.027687          0.083062         0.008143   \n",
       "std     61391.397533        0.164209          0.276201         0.089945   \n",
       "min      4250.000000        0.000000          0.000000         0.000000   \n",
       "25%     42083.333333        0.000000          0.000000         0.000000   \n",
       "50%     62750.000000        0.000000          0.000000         0.000000   \n",
       "75%     93500.000000        0.000000          0.000000         0.000000   \n",
       "max    650000.000000        1.000000          1.000000         1.000000   \n",
       "\n",
       "       Credit_History_Bad       Rural   Semiurban       Urban        Male  \\\n",
       "count          614.000000  614.000000  614.000000  614.000000  614.000000   \n",
       "mean             0.166124    0.291531    0.379479    0.328990    0.817590   \n",
       "std              0.372495    0.454838    0.485653    0.470229    0.386497   \n",
       "min              0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%              0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "50%              0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "75%              0.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max              1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Graduate  self_employed_No  self_employed_Unknown           1  \\\n",
       "count  614.000000        614.000000             614.000000  614.000000   \n",
       "mean     0.781759          0.814332               0.052117    0.166124   \n",
       "std      0.413389          0.389155               0.222445    0.372495   \n",
       "min      0.000000          0.000000               0.000000    0.000000   \n",
       "25%      1.000000          1.000000               0.000000    0.000000   \n",
       "50%      1.000000          1.000000               0.000000    0.000000   \n",
       "75%      1.000000          1.000000               0.000000    0.000000   \n",
       "max      1.000000          1.000000               1.000000    1.000000   \n",
       "\n",
       "                2           3  \n",
       "count  614.000000  614.000000  \n",
       "mean     0.164495    0.083062  \n",
       "std      0.371027    0.276201  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    0.000000  \n",
       "75%      0.000000    0.000000  \n",
       "max      1.000000    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c75adaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Married</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>EMI</th>\n",
       "      <th>EMI_exp</th>\n",
       "      <th>loan_avg</th>\n",
       "      <th>Long_Term_Loan</th>\n",
       "      <th>Medium_Term_Loan</th>\n",
       "      <th>Short_term_Loan</th>\n",
       "      <th>...</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Semiurban</th>\n",
       "      <th>Urban</th>\n",
       "      <th>Male</th>\n",
       "      <th>Graduate</th>\n",
       "      <th>self_employed_No</th>\n",
       "      <th>self_employed_Unknown</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>13450.0</td>\n",
       "      <td>2.299538</td>\n",
       "      <td>134500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>1</td>\n",
       "      <td>7.319202</td>\n",
       "      <td>0</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>2.101461</td>\n",
       "      <td>42666.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>66000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>1</td>\n",
       "      <td>7.765993</td>\n",
       "      <td>1</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>2.428658</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>14100.0</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>141000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID  Married  CoapplicantIncome  Loan_Status      EMI   EMI_exp  \\\n",
       "0  LP001002        0           0.000000            1  13450.0  2.299538   \n",
       "1  LP001003        1           7.319202            0  12800.0  2.101461   \n",
       "2  LP001005        1           0.000000            1   5940.0  1.980000   \n",
       "3  LP001006        1           7.765993            1  12000.0  2.428658   \n",
       "4  LP001008        0           0.000000            1  14100.0  2.350000   \n",
       "\n",
       "        loan_avg  Long_Term_Loan  Medium_Term_Loan  Short_term_Loan  ...  \\\n",
       "0  134500.000000             0.0               0.0              0.0  ...   \n",
       "1   42666.666667             0.0               0.0              0.0  ...   \n",
       "2   66000.000000             0.0               0.0              0.0  ...   \n",
       "3   60000.000000             0.0               0.0              0.0  ...   \n",
       "4  141000.000000             0.0               0.0              0.0  ...   \n",
       "\n",
       "   Rural  Semiurban  Urban  Male  Graduate  self_employed_No  \\\n",
       "0    0.0        0.0    1.0   1.0       1.0               1.0   \n",
       "1    1.0        0.0    0.0   1.0       1.0               1.0   \n",
       "2    0.0        0.0    1.0   1.0       1.0               0.0   \n",
       "3    0.0        0.0    1.0   1.0       0.0               1.0   \n",
       "4    0.0        0.0    1.0   1.0       1.0               1.0   \n",
       "\n",
       "   self_employed_Unknown    1    2    3  \n",
       "0                    0.0  0.0  0.0  0.0  \n",
       "1                    0.0  1.0  0.0  0.0  \n",
       "2                    0.0  0.0  0.0  0.0  \n",
       "3                    0.0  0.0  0.0  0.0  \n",
       "4                    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4c17c",
   "metadata": {},
   "source": [
    "#### Create data for modelling\n",
    "\n",
    "- Drop id columne\n",
    "- separate label and features in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939f2199",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Loan_ID',axis = 1,inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c8933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.Loan_Status\n",
    "train= train.drop('Loan_Status',axis = 1,inplace = False )\n",
    "\n",
    "test_id = test.Loan_ID\n",
    "test.drop('Loan_ID',axis = 1,inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3725f7c6",
   "metadata": {},
   "source": [
    "#### Scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2297758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train = pd.DataFrame(MinMaxScaler().fit_transform(train),columns = train.columns)\n",
    "test = pd.DataFrame(MinMaxScaler().fit_transform(test),columns = test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33de7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(MinMaxScaler().fit(train), open('../models/scaler.pkl', 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bef69f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Married</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>EMI</th>\n",
       "      <th>EMI_exp</th>\n",
       "      <th>loan_avg</th>\n",
       "      <th>Long_Term_Loan</th>\n",
       "      <th>Medium_Term_Loan</th>\n",
       "      <th>Short_term_Loan</th>\n",
       "      <th>Credit_History_Bad</th>\n",
       "      <th>Rural</th>\n",
       "      <th>Semiurban</th>\n",
       "      <th>Urban</th>\n",
       "      <th>Male</th>\n",
       "      <th>Graduate</th>\n",
       "      <th>self_employed_No</th>\n",
       "      <th>self_employed_Unknown</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.653094</td>\n",
       "      <td>0.403303</td>\n",
       "      <td>0.192399</td>\n",
       "      <td>0.260011</td>\n",
       "      <td>0.114417</td>\n",
       "      <td>0.027687</td>\n",
       "      <td>0.083062</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.166124</td>\n",
       "      <td>0.291531</td>\n",
       "      <td>0.379479</td>\n",
       "      <td>0.328990</td>\n",
       "      <td>0.817590</td>\n",
       "      <td>0.781759</td>\n",
       "      <td>0.814332</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.166124</td>\n",
       "      <td>0.164495</td>\n",
       "      <td>0.083062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.476373</td>\n",
       "      <td>0.364360</td>\n",
       "      <td>0.127839</td>\n",
       "      <td>0.113910</td>\n",
       "      <td>0.095070</td>\n",
       "      <td>0.164209</td>\n",
       "      <td>0.276201</td>\n",
       "      <td>0.089945</td>\n",
       "      <td>0.372495</td>\n",
       "      <td>0.454838</td>\n",
       "      <td>0.485653</td>\n",
       "      <td>0.470229</td>\n",
       "      <td>0.386497</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>0.389155</td>\n",
       "      <td>0.222445</td>\n",
       "      <td>0.372495</td>\n",
       "      <td>0.371027</td>\n",
       "      <td>0.276201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119553</td>\n",
       "      <td>0.195951</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665676</td>\n",
       "      <td>0.157588</td>\n",
       "      <td>0.255445</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727606</td>\n",
       "      <td>0.230869</td>\n",
       "      <td>0.312921</td>\n",
       "      <td>0.138211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Married  CoapplicantIncome         EMI     EMI_exp    loan_avg  \\\n",
       "count  614.000000         614.000000  614.000000  614.000000  614.000000   \n",
       "mean     0.653094           0.403303    0.192399    0.260011    0.114417   \n",
       "std      0.476373           0.364360    0.127839    0.113910    0.095070   \n",
       "min      0.000000           0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000           0.000000    0.119553    0.195951    0.058588   \n",
       "50%      1.000000           0.665676    0.157588    0.255445    0.090592   \n",
       "75%      1.000000           0.727606    0.230869    0.312921    0.138211   \n",
       "max      1.000000           1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       Long_Term_Loan  Medium_Term_Loan  Short_term_Loan  Credit_History_Bad  \\\n",
       "count      614.000000        614.000000       614.000000          614.000000   \n",
       "mean         0.027687          0.083062         0.008143            0.166124   \n",
       "std          0.164209          0.276201         0.089945            0.372495   \n",
       "min          0.000000          0.000000         0.000000            0.000000   \n",
       "25%          0.000000          0.000000         0.000000            0.000000   \n",
       "50%          0.000000          0.000000         0.000000            0.000000   \n",
       "75%          0.000000          0.000000         0.000000            0.000000   \n",
       "max          1.000000          1.000000         1.000000            1.000000   \n",
       "\n",
       "            Rural   Semiurban       Urban        Male    Graduate  \\\n",
       "count  614.000000  614.000000  614.000000  614.000000  614.000000   \n",
       "mean     0.291531    0.379479    0.328990    0.817590    0.781759   \n",
       "std      0.454838    0.485653    0.470229    0.386497    0.413389   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    1.000000    1.000000   \n",
       "50%      0.000000    0.000000    0.000000    1.000000    1.000000   \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       self_employed_No  self_employed_Unknown           1           2  \\\n",
       "count        614.000000             614.000000  614.000000  614.000000   \n",
       "mean           0.814332               0.052117    0.166124    0.164495   \n",
       "std            0.389155               0.222445    0.372495    0.371027   \n",
       "min            0.000000               0.000000    0.000000    0.000000   \n",
       "25%            1.000000               0.000000    0.000000    0.000000   \n",
       "50%            1.000000               0.000000    0.000000    0.000000   \n",
       "75%            1.000000               0.000000    0.000000    0.000000   \n",
       "max            1.000000               1.000000    1.000000    1.000000   \n",
       "\n",
       "                3  \n",
       "count  614.000000  \n",
       "mean     0.083062  \n",
       "std      0.276201  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      0.000000  \n",
       "max      1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b523c",
   "metadata": {},
   "source": [
    "#### Splitting the training data into train and validation sets\n",
    "\n",
    "maintain a 75:25 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "873706ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train,train_y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c8b58",
   "metadata": {},
   "source": [
    "#### Defining Accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6a8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,confusion_matrix\n",
    "\n",
    "def accuracy_cal(act,pred):\n",
    "    print('confusion matrix: ',confusion_matrix(act,pred))\n",
    "    print('Accuracy Score: ',accuracy_score(act,pred))\n",
    "    print('F1 Score: ',f1_score(act,pred))\n",
    "    print('Recall Score: ',recall_score(act,pred))\n",
    "    print('Precision Score: ',precision_score(act,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2b5e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used in below models to visualize the precision recall tradeoff and auc score and roc curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve (fpr, tpr, label = None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Posiitve Rate\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_prt_roc(tr,scores):\n",
    "    precisions,recalls,thresholds = precision_recall_curve(tr,scores)\n",
    "    plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "    fpr, tpr, threshold = roc_curve(tr,scores)\n",
    "    plot_roc_curve(fpr,tpr)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f92c099",
   "metadata": {},
   "source": [
    "#### Load model libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e02927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7c20a",
   "metadata": {},
   "source": [
    "#### Trying a bunch of classifiers using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad069763",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'SGDClassifier':SGDClassifier(),\n",
    "          'RandomForestClassifier': RandomForestClassifier(),\n",
    "          'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "          'LogisticRegression': LogisticRegression(),\n",
    "          'AdaBoostClassifier':AdaBoostClassifier(),\n",
    "          'XGBClassifier':XGBClassifier(),\n",
    "          'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "          'HistGradientBoostingClassifier':HistGradientBoostingClassifier(),\n",
    "          'SVC': SVC()\n",
    "         }\n",
    "\n",
    "\n",
    "def Fit_Score(models, X_train, y_train, X_test, y_test, train, train_y):\n",
    "    np.random.seed(77)\n",
    "    model_scores = {}\n",
    "    for name, model in models.items():\n",
    "        print(name)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        model_scores[name] = {\"cv_acc\": np.mean(cross_val_score(model, train, train_y, cv=5, scoring=\"accuracy\")),\n",
    "                              \"confusion matrix\": confusion_matrix(y_test,y_pred),\n",
    "                              \"Accuracy Score\": accuracy_score(y_test,y_pred),\n",
    "                              \"F1 Score\": f1_score(y_test,y_pred),\n",
    "                              \"Recall Score\": recall_score(y_test,y_pred),\n",
    "                              \"Precision Score\": precision_score(y_test,y_pred)}\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dee9a693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier\n",
      "RandomForestClassifier\n",
      "DecisionTreeClassifier\n",
      "LogisticRegression\n",
      "AdaBoostClassifier\n",
      "XGBClassifier\n",
      "[10:59:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:59:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:59:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:59:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:59:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:59:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "GradientBoostingClassifier\n",
      "HistGradientBoostingClassifier\n",
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_acc</th>\n",
       "      <th>confusion matrix</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.757417</td>\n",
       "      <td>[[27, 27], [2, 98]]</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.871111</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.825776</td>\n",
       "      <td>[[31, 23], [6, 94]]</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.803419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.701933</td>\n",
       "      <td>[[32, 22], [26, 74]]</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.829028</td>\n",
       "      <td>[[27, 27], [2, 98]]</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.871111</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.806238</td>\n",
       "      <td>[[30, 24], [11, 89]]</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.835681</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.787611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.786605</td>\n",
       "      <td>[[35, 19], [12, 88]]</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.850242</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.822430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.806171</td>\n",
       "      <td>[[32, 22], [8, 92]]</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.807018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier</th>\n",
       "      <td>0.806198</td>\n",
       "      <td>[[32, 22], [11, 89]]</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.843602</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.801802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.830654</td>\n",
       "      <td>[[27, 27], [2, 98]]</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.871111</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.784000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  cv_acc      confusion matrix  \\\n",
       "SGDClassifier                   0.757417   [[27, 27], [2, 98]]   \n",
       "RandomForestClassifier          0.825776   [[31, 23], [6, 94]]   \n",
       "DecisionTreeClassifier          0.701933  [[32, 22], [26, 74]]   \n",
       "LogisticRegression              0.829028   [[27, 27], [2, 98]]   \n",
       "AdaBoostClassifier              0.806238  [[30, 24], [11, 89]]   \n",
       "XGBClassifier                   0.786605  [[35, 19], [12, 88]]   \n",
       "GradientBoostingClassifier      0.806171   [[32, 22], [8, 92]]   \n",
       "HistGradientBoostingClassifier  0.806198  [[32, 22], [11, 89]]   \n",
       "SVC                             0.830654   [[27, 27], [2, 98]]   \n",
       "\n",
       "                                Accuracy Score  F1 Score  Recall Score  \\\n",
       "SGDClassifier                         0.811688  0.871111          0.98   \n",
       "RandomForestClassifier                0.811688  0.866359          0.94   \n",
       "DecisionTreeClassifier                0.688312  0.755102          0.74   \n",
       "LogisticRegression                    0.811688  0.871111          0.98   \n",
       "AdaBoostClassifier                    0.772727  0.835681          0.89   \n",
       "XGBClassifier                         0.798701  0.850242          0.88   \n",
       "GradientBoostingClassifier            0.805195  0.859813          0.92   \n",
       "HistGradientBoostingClassifier        0.785714  0.843602          0.89   \n",
       "SVC                                   0.811688  0.871111          0.98   \n",
       "\n",
       "                                Precision Score  \n",
       "SGDClassifier                          0.784000  \n",
       "RandomForestClassifier                 0.803419  \n",
       "DecisionTreeClassifier                 0.770833  \n",
       "LogisticRegression                     0.784000  \n",
       "AdaBoostClassifier                     0.787611  \n",
       "XGBClassifier                          0.822430  \n",
       "GradientBoostingClassifier             0.807018  \n",
       "HistGradientBoostingClassifier         0.801802  \n",
       "SVC                                    0.784000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores = Fit_Score(models=models, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,train=train,train_y=train_y)\n",
    "pd.DataFrame(Scores.values(), Scores.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7e47b",
   "metadata": {},
   "source": [
    "#### Pick top 5 algorithm for hypertuning and ensemble based on f1 snd recall\n",
    "- SVC\n",
    "- gradient boosting classifier\n",
    "- SGD Classifier\n",
    "- logistic\n",
    "- random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "394de95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_acc</th>\n",
       "      <th>confusion matrix</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.757417</td>\n",
       "      <td>[[27, 27], [2, 98]]</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.871111</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.825776</td>\n",
       "      <td>[[31, 23], [6, 94]]</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.803419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.829028</td>\n",
       "      <td>[[27, 27], [2, 98]]</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.871111</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.830654</td>\n",
       "      <td>[[27, 27], [2, 98]]</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.871111</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.806171</td>\n",
       "      <td>[[32, 22], [8, 92]]</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.807018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.786605</td>\n",
       "      <td>[[35, 19], [12, 88]]</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.850242</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.822430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier</th>\n",
       "      <td>0.806198</td>\n",
       "      <td>[[32, 22], [11, 89]]</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.843602</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.801802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.806238</td>\n",
       "      <td>[[30, 24], [11, 89]]</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.835681</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.787611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.701933</td>\n",
       "      <td>[[32, 22], [26, 74]]</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.770833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  cv_acc      confusion matrix  \\\n",
       "SGDClassifier                   0.757417   [[27, 27], [2, 98]]   \n",
       "RandomForestClassifier          0.825776   [[31, 23], [6, 94]]   \n",
       "LogisticRegression              0.829028   [[27, 27], [2, 98]]   \n",
       "SVC                             0.830654   [[27, 27], [2, 98]]   \n",
       "GradientBoostingClassifier      0.806171   [[32, 22], [8, 92]]   \n",
       "XGBClassifier                   0.786605  [[35, 19], [12, 88]]   \n",
       "HistGradientBoostingClassifier  0.806198  [[32, 22], [11, 89]]   \n",
       "AdaBoostClassifier              0.806238  [[30, 24], [11, 89]]   \n",
       "DecisionTreeClassifier          0.701933  [[32, 22], [26, 74]]   \n",
       "\n",
       "                                Accuracy Score  F1 Score  Recall Score  \\\n",
       "SGDClassifier                         0.811688  0.871111          0.98   \n",
       "RandomForestClassifier                0.811688  0.866359          0.94   \n",
       "LogisticRegression                    0.811688  0.871111          0.98   \n",
       "SVC                                   0.811688  0.871111          0.98   \n",
       "GradientBoostingClassifier            0.805195  0.859813          0.92   \n",
       "XGBClassifier                         0.798701  0.850242          0.88   \n",
       "HistGradientBoostingClassifier        0.785714  0.843602          0.89   \n",
       "AdaBoostClassifier                    0.772727  0.835681          0.89   \n",
       "DecisionTreeClassifier                0.688312  0.755102          0.74   \n",
       "\n",
       "                                Precision Score  \n",
       "SGDClassifier                          0.784000  \n",
       "RandomForestClassifier                 0.803419  \n",
       "LogisticRegression                     0.784000  \n",
       "SVC                                    0.784000  \n",
       "GradientBoostingClassifier             0.807018  \n",
       "XGBClassifier                          0.822430  \n",
       "HistGradientBoostingClassifier         0.801802  \n",
       "AdaBoostClassifier                     0.787611  \n",
       "DecisionTreeClassifier                 0.770833  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Scores.values(), Scores.keys()).sort_values('Accuracy Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddd30e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'RandomForestClassifier': RandomForestClassifier(),\n",
    "          'LogisticRegression': LogisticRegression(),\n",
    "          'SGDClassifier':SGDClassifier(),\n",
    "          'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "          'SVC': SVC()\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514382d",
   "metadata": {},
   "source": [
    "#### Tuning these top 5 models using gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "acf187d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46624aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_fit(name, classifier, params):\n",
    "    grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=params,\n",
    "                           cv=5,\n",
    "                           n_jobs=1,\n",
    "                           verbose=True, refit=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    pickle.dump(grid_search, open(''.join(['../models/',name,'_gridsearch_1.pkl']), 'wb')) \n",
    "    best_parameters = grid_search.best_params_\n",
    "    best_accuracy = grid_search.best_score_\n",
    "    print(best_parameters)\n",
    "    print(best_accuracy)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67e553",
   "metadata": {},
   "source": [
    "#### Tuning Random Forest Classifier \n",
    "\n",
    "Improves from 81% to 84%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84fc6255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31ab44c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 12, 'n_estimators': 100}\n",
      "0.8434782608695652\n"
     ]
    }
   ],
   "source": [
    "##grid search on random forest\n",
    "n_est = [100,200,300,400,600,800,1000,1500]\n",
    "params = {\"n_estimators\": n_est,\n",
    "       \"max_depth\": [5, 10],\n",
    "       \"min_samples_split\": [10,12],\n",
    "       \"min_samples_leaf\": [2, 5, 12]}\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "gridsearch_fit(name= 'RandomForestClassifier', classifier = classifier, params = params) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a48e5",
   "metadata": {},
   "source": [
    "#### Tuning Logistic Regression Classifier \n",
    "\n",
    "Improves from 81% to 84%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "055916e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##grid search on logistic regresson\n",
    "LogisticRegression().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "254ac27d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'solver': 'newton-cg'}\n",
      "0.8347826086956524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.83478261 0.83478261 0.83478261 0.83478261 0.83478261 0.82826087\n",
      "        nan        nan 0.83478261 0.7        0.7        0.82608696\n",
      " 0.83478261 0.83478261 0.83043478]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = [{'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
    "              {'penalty':['none', 'elasticnet', 'l1', 'l2']},\n",
    "              {'C':[0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "gridsearch_fit(name= 'LogisticRegression', classifier = classifier, params = params) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c603d1",
   "metadata": {},
   "source": [
    "#### Tuning SGD Classifier \n",
    "\n",
    "Improves from 81% to 83.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b604d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##grid search on ada boost classifier\n",
    "SGDClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b1cd59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "{'alpha': 0.01, 'loss': 'hinge', 'max_iter': 500, 'penalty': 'l1', 'warm_start': 'True'}\n",
      "0.8369565217391305\n"
     ]
    }
   ],
   "source": [
    "params = {\"alpha\" : [0.001, 0.01, 0.1, 1, 10],\n",
    "          \"warm_start\" : ['True','False'],\n",
    "          \"loss\":['hinge',  'squared_hinge','squared_error'],\n",
    "          \"max_iter\": [500,1000],\n",
    "          \"penalty\": ['l1','l2']}\n",
    "\n",
    "classifier = SGDClassifier(early_stopping=True)\n",
    "gridsearch_fit(name= 'SGDClassifier', classifier = classifier, params = params) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70290af",
   "metadata": {},
   "source": [
    "#### Tuning Gradient Boosting Classifier \n",
    "\n",
    "Improves from 81% to 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1efb02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'criterion', 'init', 'learning_rate', 'loss', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_iter_no_change', 'random_state', 'subsample', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1392ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 12, 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}\n",
      "0.8456521739130436\n"
     ]
    }
   ],
   "source": [
    "##grid search on gradient boosting classifier\n",
    "n_est = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 100)]\n",
    "params = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"min_samples_split\": [8,12],\n",
    "    \"min_samples_leaf\": [2,5],\n",
    "    \"max_depth\":[10,12],\n",
    "    \"n_estimators\":[200,400,600,800,100]\n",
    "    }\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "gridsearch_fit(name= 'GradientBoostingClassifier', classifier = classifier, params = params) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775365ca",
   "metadata": {},
   "source": [
    "#### Tuning Support Vector Classifier \n",
    "\n",
    "Improves from 81% to 83.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d6c8a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##grid search on SVC\n",
    "SVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9a60524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "{'C': 0.5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.8369565217391305\n"
     ]
    }
   ],
   "source": [
    "##grid search on gradient boosting classifier\n",
    "params = {'C': [0.1,0.5,0.6,1], 'gamma': [1,0.1,0.2,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "classifier = SVC()\n",
    "gridsearch_fit(name= 'SVC', classifier = classifier, params = params) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8d387",
   "metadata": {},
   "source": [
    "#### Predicting on the validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fbc5bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "confusion matrix:  [[30 24]\n",
      " [ 4 96]]\n",
      "Accuracy Score:  0.8181818181818182\n",
      "F1 Score:  0.8727272727272728\n",
      "Recall Score:  0.96\n",
      "Precision Score:  0.8\n",
      "-----------------------------------------------------\n",
      "LogisticRegression\n",
      "confusion matrix:  [[27 27]\n",
      " [ 2 98]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8711111111111111\n",
      "Recall Score:  0.98\n",
      "Precision Score:  0.784\n",
      "-----------------------------------------------------\n",
      "SGDClassifier\n",
      "confusion matrix:  [[27 27]\n",
      " [ 2 98]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8711111111111111\n",
      "Recall Score:  0.98\n",
      "Precision Score:  0.784\n",
      "-----------------------------------------------------\n",
      "GradientBoostingClassifier\n",
      "confusion matrix:  [[31 23]\n",
      " [ 6 94]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8663594470046083\n",
      "Recall Score:  0.94\n",
      "Precision Score:  0.8034188034188035\n",
      "-----------------------------------------------------\n",
      "SVC\n",
      "confusion matrix:  [[27 27]\n",
      " [ 2 98]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8711111111111111\n",
      "Recall Score:  0.98\n",
      "Precision Score:  0.784\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = ['RandomForestClassifier','LogisticRegression','SGDClassifier','GradientBoostingClassifier','SVC']\n",
    "final = pd.DataFrame({'y_final':y_test}).reset_index()\n",
    "\n",
    "for name in models:\n",
    "    model = pickle.load(open(''.join(['../models/',name,'_gridsearch_1.pkl']),'rb'))\n",
    "    y_pred = model.predict(X_test)\n",
    "    temp = pd.DataFrame({'Actual':y_test,name:y_pred}).reset_index()\n",
    "    print(name)\n",
    "    accuracy_cal(temp['Actual'],temp[name])\n",
    "    print('-----------------------------------------------------')\n",
    "    #print(temp.head())\n",
    "    final = pd.merge(final,temp[[name]],how = 'left',left_index = True, right_index = True)\n",
    "    #print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92e568d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y_final</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>609</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  y_final  RandomForestClassifier  LogisticRegression  SGDClassifier  \\\n",
       "0    350        1                       1                   1              1   \n",
       "1    377        1                       1                   1              1   \n",
       "2    163        1                       1                   1              1   \n",
       "3    609        1                       1                   1              1   \n",
       "4    132        1                       1                   1              1   \n",
       "\n",
       "   GradientBoostingClassifier  SVC  \n",
       "0                           1    1  \n",
       "1                           1    1  \n",
       "2                           1    1  \n",
       "3                           1    1  \n",
       "4                           1    1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03c03d",
   "metadata": {},
   "source": [
    "#### Creating Ensemble models on top of the 5 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "935ecac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##hard voting \n",
    "from statistics import mode\n",
    "final['HardVoting_5'] = final.apply(lambda x: mode(x[2:6]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d3c21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['HardVoting_4'] = final.apply(lambda x: int(mode(x[i] for i in [2,3,5,6])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a333736",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['HardVoting_3'] = final.apply(lambda x: int(mode(x[i] for i in [2,3,4])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d057e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y_final</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>HardVoting_5</th>\n",
       "      <th>HardVoting_4</th>\n",
       "      <th>HardVoting_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>609</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  y_final  RandomForestClassifier  LogisticRegression  SGDClassifier  \\\n",
       "0    350        1                       1                   1              1   \n",
       "1    377        1                       1                   1              1   \n",
       "2    163        1                       1                   1              1   \n",
       "3    609        1                       1                   1              1   \n",
       "4    132        1                       1                   1              1   \n",
       "\n",
       "   GradientBoostingClassifier  SVC  HardVoting_5  HardVoting_4  HardVoting_3  \n",
       "0                           1    1             1             1             1  \n",
       "1                           1    1             1             1             1  \n",
       "2                           1    1             1             1             1  \n",
       "3                           1    1             1             1             1  \n",
       "4                           1    1             1             1             1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dad6e5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(final.corr(), annot = True,fmt='.1g', cbar_kws= {'orientation': 'horizontal'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5d67a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = ['y_final','HardVoting_5','HardVoting_4','HardVoting_3','index']\n",
    "cols2 = ['y_final','index']\n",
    "cols3 = ['index','y_final','HardVoting_5']\n",
    "cols4 = ['index','y_final','HardVoting_5','HardVoting_4','HardVoting_3','GradientBoostingClassifier','SVC']\n",
    "cols5 = ['index','y_final','HardVoting_5','HardVoting_4','HardVoting_3','SGDClassifier','GradientBoostingClassifier','SVC']\n",
    "cols6 = ['index','y_final','SGDClassifier','GradientBoostingClassifier','SVC']\n",
    "cols7 = ['index','y_final','SGDClassifier','GradientBoostingClassifier','SVC','RandomForestClassifier','LogisticRegression']\n",
    "\n",
    "##cols2\n",
    "#{'solver': 'newton-cg'}\n",
    "#0.8049462365591398\n",
    "\n",
    "##cols1\n",
    "#{'solver': 'liblinear'}\n",
    "#0.8113978494623655\n",
    "\n",
    "##cols4\n",
    "#{'solver': 'newton-cg'}\n",
    "#00.8178494623655913\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9d697",
   "metadata": {},
   "source": [
    "#### Creating ML based ensemble score on top of 5 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b6fe8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final.y_final\n",
    "x = final.drop(cols4,axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "327417f3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "{'penalty': 'none'}\n",
      "0.8178494623655913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/apurvasij/anaconda3/envs/loan_pred/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.80494624 0.80494624 0.80494624 0.80494624 0.80494624 0.81784946\n",
      "        nan        nan 0.80494624 0.64946237 0.64946237 0.64946237]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = [{'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
    "              {'penalty':['none', 'elasticnet', 'l1', 'l2']},\n",
    "              {'C':[0.001, 0.0001,0.00001]}]\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=params,\n",
    "                           cv=5,\n",
    "                           n_jobs=1,\n",
    "                           verbose=True, refit=True)\n",
    "grid_search.fit(x, y)\n",
    "pickle.dump(grid_search, open(''.join(['../models/','LogisticRegression','_gridsearch_2.pkl']), 'wb')) \n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(best_parameters)\n",
    "print(best_accuracy)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a9973b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "{'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.8113978494623655\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_est = [100,200,500,700,1000]\n",
    "params = {\"n_estimators\": n_est,\n",
    "       \"max_depth\": [5, 10],\n",
    "       \"min_samples_split\": [10,12],\n",
    "       \"min_samples_leaf\": [2, 5, 12]}\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=params,\n",
    "                           cv=5,\n",
    "                           n_jobs=1,\n",
    "                           verbose=True, refit=True)\n",
    "grid_search.fit(x, y)\n",
    "pickle.dump(grid_search, open(''.join(['../models/','RandomForestClassifier','_gridsearch_2.pkl']), 'wb')) \n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(best_parameters)\n",
    "print(best_accuracy)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1ebce",
   "metadata": {},
   "source": [
    "#### Comparing final accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db267278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "confusion matrix:  [[30 24]\n",
      " [ 4 96]]\n",
      "Accuracy Score:  0.8181818181818182\n",
      "F1 Score:  0.8727272727272728\n",
      "Recall Score:  0.96\n",
      "Precision Score:  0.8\n",
      "-----------------------------------------------------\n",
      "LogisticRegression\n",
      "confusion matrix:  [[27 27]\n",
      " [ 2 98]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8711111111111111\n",
      "Recall Score:  0.98\n",
      "Precision Score:  0.784\n",
      "-----------------------------------------------------\n",
      "SGDClassifier\n",
      "confusion matrix:  [[27 27]\n",
      " [ 2 98]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8711111111111111\n",
      "Recall Score:  0.98\n",
      "Precision Score:  0.784\n",
      "-----------------------------------------------------\n",
      "GradientBoostingClassifier\n",
      "confusion matrix:  [[31 23]\n",
      " [ 6 94]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8663594470046083\n",
      "Recall Score:  0.94\n",
      "Precision Score:  0.8034188034188035\n",
      "-----------------------------------------------------\n",
      "SVC\n",
      "confusion matrix:  [[27 27]\n",
      " [ 2 98]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8711111111111111\n",
      "Recall Score:  0.98\n",
      "Precision Score:  0.784\n",
      "-----------------------------------------------------\n",
      "HardVoting_5\n",
      "confusion matrix:  [[29 25]\n",
      " [ 4 96]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8687782805429863\n",
      "Recall Score:  0.96\n",
      "Precision Score:  0.7933884297520661\n",
      "-----------------------------------------------------\n",
      "HardVoting_4\n",
      "confusion matrix:  [[29 25]\n",
      " [ 4 96]]\n",
      "Accuracy Score:  0.8116883116883117\n",
      "F1 Score:  0.8687782805429863\n",
      "Recall Score:  0.96\n",
      "Precision Score:  0.7933884297520661\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,9):\n",
    "    print(final.columns[i])\n",
    "    accuracy_cal(final[final.columns[1]],final[final.columns[i]])\n",
    "    print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fedb64",
   "metadata": {},
   "source": [
    "They all perform similarly on the validation dataset - this might be due to less number of dataset to be trained on.\n",
    "\n",
    "\n",
    "#### Predicting values for the final test file and creating individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b4697fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "LogisticRegression\n",
      "SGDClassifier\n",
      "GradientBoostingClassifier\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "models = ['RandomForestClassifier','LogisticRegression','SGDClassifier','GradientBoostingClassifier','SVC']\n",
    "final = pd.DataFrame({'Loan_ID':test_id})\n",
    "\n",
    "for name in models:\n",
    "    model = pickle.load(open(''.join(['../models/',name,'_gridsearch_1.pkl']),'rb'))\n",
    "    y_pred = model.predict(test)\n",
    "    temp = pd.DataFrame({'Loan_ID':test_id,name:y_pred}).reset_index()\n",
    "    final = pd.merge(final,temp[[name]],how = 'left',left_index = True, right_index = True)\n",
    "    print(name)\n",
    "    \n",
    "final['HardVoting_5'] = final.apply(lambda x: mode(x[1:5]), axis=1)\n",
    "final['HardVoting_4'] = final.apply(lambda x: int(mode(x[i] for i in [1,2,4,5])), axis=1)\n",
    "final['HardVoting_3'] = final.apply(lambda x: int(mode(x[i] for i in [1,2,3])), axis=1)\n",
    "final['HardVoting_3_1'] = final.apply(lambda x: int(mode(x[i] for i in [2,3,4])), axis=1)\n",
    "final['HardVoting_2'] = final.apply(lambda x: int(max(x[i] for i in [2,4])), axis=1)\n",
    "\n",
    "models = ['RandomForestClassifier','LogisticRegression']\n",
    "cols4 = ['Loan_ID','HardVoting_5','HardVoting_4','HardVoting_3','GradientBoostingClassifier','SVC','HardVoting_3_1','HardVoting_2']\n",
    "\n",
    "x = final.drop(cols4,axis = 1, inplace = False)\n",
    "for name in models:\n",
    "    model = pickle.load(open(''.join(['../models/',name,'_gridsearch_2.pkl']),'rb'))\n",
    "    y_pred = model.predict(x)\n",
    "    temp = pd.DataFrame({'Loan_ID':test_id,''.join([name,'_ens']):y_pred}).reset_index()\n",
    "    final = pd.merge(final,temp[[''.join([name,'_ens'])]],how = 'left',left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0946edf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>HardVoting_5</th>\n",
       "      <th>HardVoting_4</th>\n",
       "      <th>HardVoting_3</th>\n",
       "      <th>HardVoting_3_1</th>\n",
       "      <th>HardVoting_2</th>\n",
       "      <th>RandomForestClassifier_ens</th>\n",
       "      <th>LogisticRegression_ens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID  RandomForestClassifier  LogisticRegression  SGDClassifier  \\\n",
       "0  LP001015                       1                   1              1   \n",
       "1  LP001022                       1                   1              1   \n",
       "2  LP001031                       1                   1              1   \n",
       "3  LP001035                       1                   1              1   \n",
       "4  LP001051                       1                   1              1   \n",
       "\n",
       "   GradientBoostingClassifier  SVC  HardVoting_5  HardVoting_4  HardVoting_3  \\\n",
       "0                           1    1             1             1             1   \n",
       "1                           1    1             1             1             1   \n",
       "2                           1    1             1             1             1   \n",
       "3                           1    1             1             1             1   \n",
       "4                           1    1             1             1             1   \n",
       "\n",
       "   HardVoting_3_1  HardVoting_2  RandomForestClassifier_ens  \\\n",
       "0               1             1                           1   \n",
       "1               1             1                           1   \n",
       "2               1             1                           1   \n",
       "3               1             1                           1   \n",
       "4               1             1                           1   \n",
       "\n",
       "   LogisticRegression_ens  \n",
       "0                       1  \n",
       "1                       1  \n",
       "2                       1  \n",
       "3                       1  \n",
       "4                       1  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db36271",
   "metadata": {},
   "source": [
    "#### Recode the loan status to Y and N for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "718f2d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "LogisticRegression\n",
      "SGDClassifier\n",
      "GradientBoostingClassifier\n",
      "SVC\n",
      "HardVoting_5\n",
      "HardVoting_4\n",
      "HardVoting_3\n",
      "HardVoting_3_1\n",
      "HardVoting_2\n",
      "RandomForestClassifier_ens\n",
      "LogisticRegression_ens\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    print(final.columns[i])\n",
    "    submit = pd.DataFrame({'Loan_ID':final[final.columns[0]],'Loan_Status':final[final.columns[i]]})\n",
    "    submit.Loan_Status = np.where(submit['Loan_Status'] == 1,'Y','N')\n",
    "    submit.to_csv(''.join([\"../submissions/\",final.columns[i],\"_iter3.csv\"]),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cdfb45",
   "metadata": {},
   "source": [
    "#### Final Output on Public Leaderboard\n",
    "\n",
    "- Gradient Boosting Classifier outperforms with 79.9 % accuracy\n",
    "- Logistic Regression performs second best with 78.6% accuracy\n",
    "- Rest other classifiers and ensemble models range between 77.7% - 78.1% accuracy\n",
    "- Adaboost and DecisionTree perform worst with 61% accuracy\n",
    "\n",
    "#### Final Ranking\n",
    "\n",
    "- Rank 404/74541 (top 0.5%) on public leaderboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan_pred",
   "language": "python",
   "name": "loan_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
