ID,Title,Domain,original_title,text_words,text_digit_cnt,clean_text_lem,clean_text_wrds,clean_text,title_polarity,text_polarity,ttl_wrds,char_count,word_density,punctuation_count,title_word_count,upper_case_word_count,noun_count,verb_count,adj_count,adv_count,pron_count
1,what is good in a decision tree a large or a small leaf size,Techniques,what is good in a decision tree a large or a small leaf size,"['what', 'is', 'good', 'in', 'a', 'decision', 'tree', 'a', 'large', 'or', 'a', 'small', 'leaf', 'size']",0,"['what', 'is', 'good', 'in', 'a', 'decision', 'tree', 'a', 'large', 'or', 'a', 'small', 'leaf', 'size']","['good', 'decision', 'tree', 'large', 'small', 'leaf', 'size']",good decision tree large small leaf size,0.2214285714285714,0.2214285714285714,14,40,2.6666666666666665,0,0,0,0,0,0,0,0
2,training data only contains single positive label,Techniques,training data only contains single positive label,"['training', 'data', 'only', 'contains', 'single', 'positive', 'label']",0,"['training', 'data', 'only', 'contains', 'single', 'positive', 'label']","['training', 'data', 'contains', 'single', 'positive', 'label']",training data contains single positive label,0.0519480519480519,0.0779220779220779,7,44,5.5,0,0,0,0,0,0,0,0
3,calculating percentage contribution of a negative component,Techniques,calculating percentage contribution of a negative component,"['calculating', 'percentage', 'contribution', 'of', 'a', 'negative', 'component']",0,"['calculating', 'percentage', 'contribution', 'of', 'a', 'negative', 'component']","['calculating', 'percentage', 'contribution', 'negative', 'component']",calculating percentage contribution negative component,-0.3,-0.3,7,54,6.75,0,0,0,0,0,0,0,0
4,unable to open solution checker,Hackathons,unable to open solution checker,"['unable', 'to', 'open', 'solution', 'checker']",0,"['unable', 'to', 'open', 'solution', 'checker']","['unable', 'open', 'solution', 'checker']",unable open solution checker,-0.25,-0.25,5,28,4.666666666666667,0,0,0,0,0,0,0,0
5,user name change,Misc,user name change,"['user', 'name', 'change']",0,"['user', 'name', 'change']","['user', 'name', 'change']",user name change,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
6,how to decide which curve to fit to our model,Techniques,how to decide which curve to fit to our model,"['how', 'to', 'decide', 'which', 'curve', 'to', 'fit', 'to', 'our', 'model']",0,"['how', 'to', 'decide', 'which', 'curve', 'to', 'fit', 'to', 'our', 'model']","['decide', 'curve', 'fit', 'model']",decide curve fit model,0.4,0.4,10,22,2.0,0,0,0,0,0,0,0,0
7,epochs in neural network,Techniques,epochs in neural network,"['epochs', 'in', 'neural', 'network']",0,"['epoch', 'in', 'neural', 'network']","['epoch', 'neural', 'network']",epoch neural network,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
8,chatbot to give answersometimes inferred from repository,Techniques,chatbot to give answersometimes inferred from repository,"['chatbot', 'to', 'give', 'answersometimes', 'inferred', 'from', 'repository']",0,"['chatbot', 'to', 'give', 'answersometimes', 'inferred', 'from', 'repository']","['chatbot', 'give', 'answersometimes', 'inferred', 'repository']",chatbot give answersometimes inferred repository,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
9,plot on google maps in python,Tools,plot on google maps in python,"['plot', 'on', 'google', 'maps', 'in', 'python']",0,"['plot', 'on', 'google', 'map', 'in', 'python']","['plot', 'google', 'map', 'python']",plot google map python,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
10,which algorithm to choose when the response is weak,Techniques,which algorithm to choose when the response is weak,"['which', 'algorithm', 'to', 'choose', 'when', 'the', 'response', 'is', 'weak']",0,"['which', 'algorithm', 'to', 'choose', 'when', 'the', 'response', 'is', 'weak']","['algorithm', 'choose', 'response', 'weak']",algorithm choose response weak,-0.375,-0.375,9,30,3.0,0,0,0,0,0,0,0,0
11,r code throws the error error in trial  nonnumeric argument to binary operator called from reduce trial,Tools,r code throws the error error in trial  nonnumeric argument to binary operator called from reduce trial,"['r', 'code', 'throws', 'the', 'error', 'error', 'in', 'trial', 'nonnumeric', 'argument', 'to', 'binary', 'operator', 'called', 'from', 'reduce', 'trial']",0,"['r', 'code', 'throw', 'the', 'error', 'error', 'in', 'trial', 'nonnumeric', 'argument', 'to', 'binary', 'operator', 'called', 'from', 'reduce', 'trial']","['r', 'code', 'throw', 'error', 'error', 'trial', 'nonnumeric', 'argument', 'binary', 'operator', 'called', 'reduce', 'trial']",r code throw error error trial nonnumeric argument binary operator called reduce trial,0.0,0.0,17,86,4.777777777777778,0,0,0,0,0,0,0,0
12,learning path to pick to become a data scientist,Career,learning path to pick to become a data scientist,"['learning', 'path', 'to', 'pick', 'to', 'become', 'a', 'data', 'scientist']",0,"['learning', 'path', 'to', 'pick', 'to', 'become', 'a', 'data', 'scientist']","['learning', 'path', 'pick', 'become', 'data', 'scientist']",learning path pick become data scientist,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
13,build highquality training data for computer vision and nlp applications,Techniques,build highquality training data for computer vision and nlp applications,"['build', 'highquality', 'training', 'data', 'for', 'computer', 'vision', 'and', 'nlp', 'applications']",0,"['build', 'highquality', 'training', 'data', 'for', 'computer', 'vision', 'and', 'nlp', 'application']","['build', 'highquality', 'training', 'data', 'computer', 'vision', 'nlp', 'application']",build highquality training data computer vision nlp application,0.0,0.0,10,63,5.7272727272727275,0,0,0,0,0,0,0,0
14,your score for this submission is your leaderboard score is ,Hackathons,your score for this submission is your leaderboard score is ,"['your', 'score', 'for', 'this', 'submission', 'is', 'your', 'leaderboard', 'score', 'is']",1,"['your', 'score', 'for', 'this', 'submission', 'is', 'your', 'leaderboard', 'score', 'is']","['score', 'submission', 'leaderboard', 'score']",score submission leaderboard score,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
15,which one is better to master python r or sas i want to be data scientist,Career,which one is better to master python r or sas i want to be data scientist,"['which', 'one', 'is', 'better', 'to', 'master', 'python', 'r', 'or', 'sas', 'i', 'want', 'to', 'be', 'data', 'scientist']",0,"['which', 'one', 'is', 'better', 'to', 'master', 'python', 'r', 'or', 'sa', 'i', 'want', 'to', 'be', 'data', 'scientist']","['one', 'better', 'master', 'python', 'r', 'sa', 'want', 'data', 'scientist']",one better master python r sa want data scientist,0.5,0.5,16,49,2.8823529411764706,0,0,0,0,0,0,0,0
16,what is the default threshold when applying logistic regression in sklearn,Techniques,what is the default threshold when applying logistic regression in sklearn,"['what', 'is', 'the', 'default', 'threshold', 'when', 'applying', 'logistic', 'regression', 'in', 'sklearn']",0,"['what', 'is', 'the', 'default', 'threshold', 'when', 'applying', 'logistic', 'regression', 'in', 'sklearn']","['default', 'threshold', 'applying', 'logistic', 'regression', 'sklearn']",default threshold applying logistic regression sklearn,0.0,0.0,11,54,4.5,0,0,0,0,0,0,0,0
17,need help  where do i go from here  how do i deep dive,Techniques,need help  where do i go from here  how do i deep dive,"['need', 'help', 'where', 'do', 'i', 'go', 'from', 'here', 'how', 'do', 'i', 'deep', 'dive']",0,"['need', 'help', 'where', 'do', 'i', 'go', 'from', 'here', 'how', 'do', 'i', 'deep', 'dive']","['need', 'help', 'go', 'deep', 'dive']",need help go deep dive,0.0,0.0,13,22,1.5714285714285714,0,0,0,0,0,0,0,0
18,please guide me if pgpbabi course from greatlakes will be good for me or not,Career,please guide me if pgpbabi course from greatlakes will be good for me or not,"['please', 'guide', 'me', 'if', 'pgpbabi', 'course', 'from', 'greatlakes', 'will', 'be', 'good', 'for', 'me', 'or', 'not']",0,"['please', 'guide', 'me', 'if', 'pgpbabi', 'course', 'from', 'greatlakes', 'will', 'be', 'good', 'for', 'me', 'or', 'not']","['please', 'guide', 'pgpbabi', 'course', 'greatlakes', 'good']",please guide pgpbabi course greatlakes good,0.7,0.7,15,43,2.6875,0,0,0,0,0,0,0,0
19,how to do group by in r,Tools,how to do group by in r,"['how', 'to', 'do', 'group', 'by', 'in', 'r']",0,"['how', 'to', 'do', 'group', 'by', 'in', 'r']","['group', 'r']",group r,0.0,0.0,7,7,0.875,0,0,0,0,0,0,0,0
20,python h http  server error,Techniques,python h http  server error,"['python', 'h', 'http', 'server', 'error']",1,"['python', 'h', 'http', 'server', 'error']","['python', 'h', 'http', 'server', 'error']",python h http server error,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
21,how to select records containing certain names in the column in r,Tools,how to select records containing certain names in the column in r,"['how', 'to', 'select', 'records', 'containing', 'certain', 'names', 'in', 'the', 'column', 'in', 'r']",0,"['how', 'to', 'select', 'record', 'containing', 'certain', 'name', 'in', 'the', 'column', 'in', 'r']","['select', 'record', 'containing', 'certain', 'name', 'column', 'r']",select record containing certain name column r,0.2142857142857142,0.2142857142857142,12,46,3.5384615384615383,0,0,0,0,0,0,0,0
22,what kind of plot will be helpful for total count group data  data grouped by month and year ,Techniques,what kind of plot will be helpful for total count group data  data grouped by month and year ,"['what', 'kind', 'of', 'plot', 'will', 'be', 'helpful', 'for', 'total', 'count', 'group', 'data', 'data', 'grouped', 'by', 'month', 'and', 'year']",0,"['what', 'kind', 'of', 'plot', 'will', 'be', 'helpful', 'for', 'total', 'count', 'group', 'data', 'data', 'grouped', 'by', 'month', 'and', 'year']","['kind', 'plot', 'helpful', 'total', 'count', 'group', 'data', 'data', 'grouped', 'month', 'year']",kind plot helpful total count group data data grouped month year,0.3,0.3,18,64,3.3684210526315788,0,0,0,0,0,0,0,0
23,problem  “datewise” for next week in future forecast for the “customer numbers” expected to have alarm,Techniques,problem  “datewise” for next week in future forecast for the “customer numbers” expected to have alarm,"['problem', '“', 'datewise', '”', 'for', 'next', 'week', 'in', 'future', 'forecast', 'for', 'the', '“', 'customer', 'numbers', '”', 'expected', 'to', 'have', 'alarm']",0,"['problem', '“', 'datewise', '”', 'for', 'next', 'week', 'in', 'future', 'forecast', 'for', 'the', '“', 'customer', 'number', '”', 'expected', 'to', 'have', 'alarm']","['problem', '“', 'datewise', '”', 'next', 'week', 'future', 'forecast', '“', 'customer', 'number', '”', 'expected', 'alarm']",problem “ datewise ” next week future forecast “ customer number ” expected alarm,-0.0333333333333333,-0.0333333333333333,20,81,3.857142857142857,0,0,0,0,0,0,0,0
24,example of xgboost using julia on the wisconsin breast cancer data,Tools,example of xgboost using julia on the wisconsin breast cancer data,"['example', 'of', 'xgboost', 'using', 'julia', 'on', 'the', 'wisconsin', 'breast', 'cancer', 'data']",0,"['example', 'of', 'xgboost', 'using', 'julia', 'on', 'the', 'wisconsin', 'breast', 'cancer', 'data']","['example', 'xgboost', 'using', 'julia', 'wisconsin', 'breast', 'cancer', 'data']",example xgboost using julia wisconsin breast cancer data,0.0,0.0,11,56,4.666666666666667,0,0,0,0,0,0,0,0
25,attributeerror can only use dt accessor with datetimelike values,Tools,attributeerror can only use dt accessor with datetimelike values,"['attributeerror', 'can', 'only', 'use', 'dt', 'accessor', 'with', 'datetimelike', 'values']",0,"['attributeerror', 'can', 'only', 'use', 'dt', 'accessor', 'with', 'datetimelike', 'value']","['attributeerror', 'use', 'dt', 'accessor', 'datetimelike', 'value']",attributeerror use dt accessor datetimelike value,0.0,0.0,9,49,4.9,0,0,0,0,0,0,0,0
26,recommended desktoplaptop specs for data science,Misc,recommended desktoplaptop specs for data science,"['recommended', 'desktoplaptop', 'specs', 'for', 'data', 'science']",0,"['recommended', 'desktoplaptop', 'spec', 'for', 'data', 'science']","['recommended', 'desktoplaptop', 'spec', 'data', 'science']",recommended desktoplaptop spec data science,0.0,0.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
27,what is the difference between the qplot function and the ggplot function from the ggplot package in r,Tools,what is the difference between the qplot function and the ggplot function from the ggplot package in r,"['what', 'is', 'the', 'difference', 'between', 'the', 'qplot', 'function', 'and', 'the', 'ggplot', 'function', 'from', 'the', 'ggplot', 'package', 'in', 'r']",0,"['what', 'is', 'the', 'difference', 'between', 'the', 'qplot', 'function', 'and', 'the', 'ggplot', 'function', 'from', 'the', 'ggplot', 'package', 'in', 'r']","['difference', 'qplot', 'function', 'ggplot', 'function', 'ggplot', 'package', 'r']",difference qplot function ggplot function ggplot package r,0.0,0.0,18,58,3.0526315789473686,0,0,0,0,0,0,0,0
28,price optimization in r,Techniques,price optimization in r,"['price', 'optimization', 'in', 'r']",0,"['price', 'optimization', 'in', 'r']","['price', 'optimization', 'r']",price optimization r,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
29,how to find dependent variable in test dataset by using train dataset,Techniques,how to find dependent variable in test dataset by using train dataset,"['how', 'to', 'find', 'dependent', 'variable', 'in', 'test', 'dataset', 'by', 'using', 'train', 'dataset']",0,"['how', 'to', 'find', 'dependent', 'variable', 'in', 'test', 'dataset', 'by', 'using', 'train', 'dataset']","['find', 'dependent', 'variable', 'test', 'dataset', 'using', 'train', 'dataset']",find dependent variable test dataset using train dataset,0.0,0.0,12,56,4.3076923076923075,0,0,0,0,0,0,0,0
30,datafest  is back,Hackathons,datafest  is back,"['datafest', 'is', 'back']",1,"['datafest', 'is', 'back']","['datafest', 'back']",datafest back,0.0,0.0,3,13,3.25,0,0,0,0,0,0,0,0
31,sample data for analysis in retail  consumer  footwear industry,Misc,sample data for analysis in retail  consumer  footwear industry,"['sample', 'data', 'for', 'analysis', 'in', 'retail', 'consumer', 'footwear', 'industry']",0,"['sample', 'data', 'for', 'analysis', 'in', 'retail', 'consumer', 'footwear', 'industry']","['sample', 'data', 'analysis', 'retail', 'consumer', 'footwear', 'industry']",sample data analysis retail consumer footwear industry,0.0,0.0,9,54,5.4,0,0,0,0,0,0,0,0
32,how to group similar college name in one group,Hackathons,how to group similar college name in one group,"['how', 'to', 'group', 'similar', 'college', 'name', 'in', 'one', 'group']",0,"['how', 'to', 'group', 'similar', 'college', 'name', 'in', 'one', 'group']","['group', 'similar', 'college', 'name', 'one', 'group']",group similar college name one group,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
33,best practices for machine leaning and deep learnings implementations,Resources,best practices for machine leaning and deep learnings implementations,"['best', 'practices', 'for', 'machine', 'leaning', 'and', 'deep', 'learnings', 'implementations']",0,"['best', 'practice', 'for', 'machine', 'leaning', 'and', 'deep', 'learning', 'implementation']","['best', 'practice', 'machine', 'leaning', 'deep', 'learning', 'implementation']",best practice machine leaning deep learning implementation,0.5,0.5,9,58,5.8,0,0,0,0,0,0,0,0
34,optimize qlikview document,Tools,optimize qlikview document,"['optimize', 'qlikview', 'document']",0,"['optimize', 'qlikview', 'document']","['optimize', 'qlikview', 'document']",optimize qlikview document,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
35,does high redundancy mean high correlation,Techniques,does high redundancy mean high correlation,"['does', 'high', 'redundancy', 'mean', 'high', 'correlation']",0,"['doe', 'high', 'redundancy', 'mean', 'high', 'correlation']","['doe', 'high', 'redundancy', 'mean', 'high', 'correlation']",doe high redundancy mean high correlation,0.0025,0.0025,6,41,5.857142857142857,0,0,0,0,0,0,0,0
36,why do we subtract  from the sample size to calculate degree of freedom,Techniques,why do we subtract  from the sample size to calculate degree of freedom,"['why', 'do', 'we', 'subtract', 'from', 'the', 'sample', 'size', 'to', 'calculate', 'degree', 'of', 'freedom']",1,"['why', 'do', 'we', 'subtract', 'from', 'the', 'sample', 'size', 'to', 'calculate', 'degree', 'of', 'freedom']","['subtract', 'sample', 'size', 'calculate', 'degree', 'freedom']",subtract sample size calculate degree freedom,0.0,0.0,13,45,3.2142857142857144,0,0,0,0,0,0,0,0
37,awesome ipython notebooks for data science,Tools,awesome ipython notebooks for data science,"['awesome', 'ipython', 'notebooks', 'for', 'data', 'science']",0,"['awesome', 'ipython', 'notebook', 'for', 'data', 'science']","['awesome', 'ipython', 'notebook', 'data', 'science']",awesome ipython notebook data science,1.0,1.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
38,dummy encoding for ordered categorical data,Techniques,dummy encoding for ordered categorical data,"['dummy', 'encoding', 'for', 'ordered', 'categorical', 'data']",0,"['dummy', 'encoding', 'for', 'ordered', 'categorical', 'data']","['dummy', 'encoding', 'ordered', 'categorical', 'data']",dummy encoding ordered categorical data,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
39,practice dataset for knn algorithm,Resources,practice dataset for knn algorithm,"['practice', 'dataset', 'for', 'knn', 'algorithm']",0,"['practice', 'dataset', 'for', 'knn', 'algorithm']","['practice', 'dataset', 'knn', 'algorithm']",practice dataset knn algorithm,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
40,regarding masters in business analytics,Career,regarding masters in business analytics,"['regarding', 'masters', 'in', 'business', 'analytics']",0,"['regarding', 'master', 'in', 'business', 'analytics']","['regarding', 'master', 'business', 'analytics']",regarding master business analytics,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
41,churn model data set and technique,Techniques,churn model data set and technique,"['churn', 'model', 'data', 'set', 'and', 'technique']",0,"['churn', 'model', 'data', 'set', 'and', 'technique']","['churn', 'model', 'data', 'set', 'technique']",churn model data set technique,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
42,web scraping in r,Techniques,web scraping in r,"['web', 'scraping', 'in', 'r']",0,"['web', 'scraping', 'in', 'r']","['web', 'scraping', 'r']",web scraping r,0.0,0.0,4,14,2.8,0,0,0,0,0,0,0,0
43,how does bootstrap sampling work during boosting,Techniques,how does bootstrap sampling work during boosting,"['how', 'does', 'bootstrap', 'sampling', 'work', 'during', 'boosting']",0,"['how', 'doe', 'bootstrap', 'sampling', 'work', 'during', 'boosting']","['doe', 'bootstrap', 'sampling', 'work', 'boosting']",doe bootstrap sampling work boosting,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
44,how to access specific parts of a list in r,Tools,how to access specific parts of a list in r,"['how', 'to', 'access', 'specific', 'parts', 'of', 'a', 'list', 'in', 'r']",0,"['how', 'to', 'access', 'specific', 'part', 'of', 'a', 'list', 'in', 'r']","['access', 'specific', 'part', 'list', 'r']",access specific part list r,0.0,0.0,10,27,2.4545454545454546,0,0,0,0,0,0,0,0
45,unable to fill missing value,Hackathons,unable to fill missing value,"['unable', 'to', 'fill', 'missing', 'value']",0,"['unable', 'to', 'fill', 'missing', 'value']","['unable', 'fill', 'missing', 'value']",unable fill missing value,-0.35,-0.35,5,25,4.166666666666667,0,0,0,0,0,0,0,0
46,how to reduce too many if conditions in r,Tools,how to reduce too many if conditions in r,"['how', 'to', 'reduce', 'too', 'many', 'if', 'conditions', 'in', 'r']",0,"['how', 'to', 'reduce', 'too', 'many', 'if', 'condition', 'in', 'r']","['reduce', 'many', 'condition', 'r']",reduce many condition r,0.5,0.5,9,23,2.3,0,0,0,0,0,0,0,0
47,filling missing values with ,Techniques,filling missing values with ,"['filling', 'missing', 'values', 'with']",1,"['filling', 'missing', 'value', 'with']","['filling', 'missing', 'value']",filling missing value,-0.2,-0.2,4,21,4.2,0,0,0,0,0,0,0,0
48,what to do when hosmer lemeshow test fails during logistic regression,Techniques,what to do when hosmer lemeshow test fails during logistic regression,"['what', 'to', 'do', 'when', 'hosmer', 'lemeshow', 'test', 'fails', 'during', 'logistic', 'regression']",0,"['what', 'to', 'do', 'when', 'hosmer', 'lemeshow', 'test', 'fails', 'during', 'logistic', 'regression']","['hosmer', 'lemeshow', 'test', 'fails', 'logistic', 'regression']",hosmer lemeshow test fails logistic regression,-0.5,-0.5,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
49,is it a good practice to remove observations with very less frequency from the data,Techniques,is it a good practice to remove observations with very less frequency from the data,"['is', 'it', 'a', 'good', 'practice', 'to', 'remove', 'observations', 'with', 'very', 'less', 'frequency', 'from', 'the', 'data']",0,"['is', 'it', 'a', 'good', 'practice', 'to', 'remove', 'observation', 'with', 'very', 'le', 'frequency', 'from', 'the', 'data']","['good', 'practice', 'remove', 'observation', 'le', 'frequency', 'data']",good practice remove observation le frequency data,0.2416666666666666,0.7,15,50,3.125,0,0,0,0,0,0,0,0
50,what is the effect of cross validation on model complexity,Techniques,what is the effect of cross validation on model complexity,"['what', 'is', 'the', 'effect', 'of', 'cross', 'validation', 'on', 'model', 'complexity']",0,"['what', 'is', 'the', 'effect', 'of', 'cross', 'validation', 'on', 'model', 'complexity']","['effect', 'cross', 'validation', 'model', 'complexity']",effect cross validation model complexity,0.0,0.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
51,what can a business analyst offer for movie ticket booking websites,Other,what can a business analyst offer for movie ticket booking websites,"['what', 'can', 'a', 'business', 'analyst', 'offer', 'for', 'movie', 'ticket', 'booking', 'websites']",0,"['what', 'can', 'a', 'business', 'analyst', 'offer', 'for', 'movie', 'ticket', 'booking', 'website']","['business', 'analyst', 'offer', 'movie', 'ticket', 'booking', 'website']",business analyst offer movie ticket booking website,0.0,0.0,11,51,4.25,0,0,0,0,0,0,0,0
52,xgboost unstable output,Other,xgboost unstable output,"['xgboost', 'unstable', 'output']",0,"['xgboost', 'unstable', 'output']","['xgboost', 'unstable', 'output']",xgboost unstable output,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
53,what is your environment  tool set  libraries to perform data analysis in python,Tools,what is your environment  tool set  libraries to perform data analysis in python,"['what', 'is', 'your', 'environment', 'tool', 'set', 'libraries', 'to', 'perform', 'data', 'analysis', 'in', 'python']",0,"['what', 'is', 'your', 'environment', 'tool', 'set', 'library', 'to', 'perform', 'data', 'analysis', 'in', 'python']","['environment', 'tool', 'set', 'library', 'perform', 'data', 'analysis', 'python']",environment tool set library perform data analysis python,0.0,0.0,13,57,4.071428571428571,0,0,0,0,0,0,0,0
54,what should one learn after working on tableau,Career,what should one learn after working on tableau,"['what', 'should', 'one', 'learn', 'after', 'working', 'on', 'tableau']",0,"['what', 'should', 'one', 'learn', 'after', 'working', 'on', 'tableau']","['one', 'learn', 'working', 'tableau']",one learn working tableau,0.0,0.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
55,dataset with size more than  tb available for download  click prediction,Techniques,dataset with size more than  tb available for download  click prediction,"['dataset', 'with', 'size', 'more', 'than', 'tb', 'available', 'for', 'download', 'click', 'prediction']",1,"['dataset', 'with', 'size', 'more', 'than', 'tb', 'available', 'for', 'download', 'click', 'prediction']","['dataset', 'size', 'tb', 'available', 'download', 'click', 'prediction']",dataset size tb available download click prediction,0.45,0.4,11,51,4.25,0,0,0,0,0,0,0,0
56,what is retain statement in sas,Tools,what is retain statement in sas,"['what', 'is', 'retain', 'statement', 'in', 'sas']",0,"['what', 'is', 'retain', 'statement', 'in', 'sa']","['retain', 'statement', 'sa']",retain statement sa,0.0,0.0,6,19,2.7142857142857144,0,0,0,0,0,0,0,0
57,skills expected from a person changing career to analytics feild,Career,skills expected from a person changing career to analytics feild,"['skills', 'expected', 'from', 'a', 'person', 'changing', 'career', 'to', 'analytics', 'feild']",0,"['skill', 'expected', 'from', 'a', 'person', 'changing', 'career', 'to', 'analytics', 'feild']","['skill', 'expected', 'person', 'changing', 'career', 'analytics', 'feild']",skill expected person changing career analytics feild,-0.1,-0.1,10,53,4.818181818181818,0,0,0,0,0,0,0,0
58,gridsearchcv and cross valdation in python,Techniques,gridsearchcv and cross valdation in python,"['gridsearchcv', 'and', 'cross', 'valdation', 'in', 'python']",0,"['gridsearchcv', 'and', 'cross', 'valdation', 'in', 'python']","['gridsearchcv', 'cross', 'valdation', 'python']",gridsearchcv cross valdation python,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
59,how can build expression based on wild card in qlikview,Tools,how can build expression based on wild card in qlikview,"['how', 'can', 'build', 'expression', 'based', 'on', 'wild', 'card', 'in', 'qlikview']",0,"['how', 'can', 'build', 'expression', 'based', 'on', 'wild', 'card', 'in', 'qlikview']","['build', 'expression', 'based', 'wild', 'card', 'qlikview']",build expression based wild card qlikview,0.1,0.1,10,41,3.727272727272727,0,0,0,0,0,0,0,0
60,approaches for do you know whos a megastar,Hackathons,approaches for do you know whos a megastar,"['approaches', 'for', 'do', 'you', 'know', 'whos', 'a', 'megastar']",0,"['approach', 'for', 'do', 'you', 'know', 'who', 'a', 'megastar']","['approach', 'know', 'megastar']",approach know megastar,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
61,convert continous variables into categoriccal using decision trees,Techniques,convert continous variables into categoriccal using decision trees,"['convert', 'continous', 'variables', 'into', 'categoriccal', 'using', 'decision', 'trees']",0,"['convert', 'continous', 'variable', 'into', 'categoriccal', 'using', 'decision', 'tree']","['convert', 'continous', 'variable', 'categoriccal', 'using', 'decision', 'tree']",convert continous variable categoriccal using decision tree,0.0,0.0,8,59,6.555555555555555,0,0,0,0,0,0,0,0
62,cpbae course by iiml,Career,cpbae course by iiml,"['cpbae', 'course', 'by', 'iiml']",0,"['cpbae', 'course', 'by', 'iiml']","['cpbae', 'course', 'iiml']",cpbae course iiml,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
63,how to replace missing values in a particular column using knnimpute,Tools,how to replace missing values in a particular column using knnimpute,"['how', 'to', 'replace', 'missing', 'values', 'in', 'a', 'particular', 'column', 'using', 'knnimpute']",0,"['how', 'to', 'replace', 'missing', 'value', 'in', 'a', 'particular', 'column', 'using', 'knnimpute']","['replace', 'missing', 'value', 'particular', 'column', 'using', 'knnimpute']",replace missing value particular column using knnimpute,-0.0166666666666666,-0.0166666666666666,11,55,4.583333333333333,0,0,0,0,0,0,0,0
64,apriori and fpgrowth algorithms,Techniques,apriori and fpgrowth algorithms,"['apriori', 'and', 'fpgrowth', 'algorithms']",0,"['apriori', 'and', 'fpgrowth', 'algorithm']","['apriori', 'fpgrowth', 'algorithm']",apriori fpgrowth algorithm,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
65,reading date time information using r,Tools,reading date time information using r,"['reading', 'date', 'time', 'information', 'using', 'r']",0,"['reading', 'date', 'time', 'information', 'using', 'r']","['reading', 'date', 'time', 'information', 'using', 'r']",reading date time information using r,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
66,parsing in sas for a keyword,Tools,parsing in sas for a keyword,"['parsing', 'in', 'sas', 'for', 'a', 'keyword']",0,"['parsing', 'in', 'sa', 'for', 'a', 'keyword']","['parsing', 'sa', 'keyword']",parsing sa keyword,0.0,0.0,6,18,2.5714285714285716,0,0,0,0,0,0,0,0
67,using customer relationships to create groups,Techniques,using customer relationships to create groups,"['using', 'customer', 'relationships', 'to', 'create', 'groups']",0,"['using', 'customer', 'relationship', 'to', 'create', 'group']","['using', 'customer', 'relationship', 'create', 'group']",using customer relationship create group,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
68,how to disable the index of series to matplotlib for plotting on the xaxis,Tools,how to disable the index of series to matplotlib for plotting on the xaxis,"['how', 'to', 'disable', 'the', 'index', 'of', 'series', 'to', 'matplotlib', 'for', 'plotting', 'on', 'the', 'xaxis']",0,"['how', 'to', 'disable', 'the', 'index', 'of', 'series', 'to', 'matplotlib', 'for', 'plotting', 'on', 'the', 'xaxis']","['disable', 'index', 'series', 'matplotlib', 'plotting', 'xaxis']",disable index series matplotlib plotting xaxis,0.0,0.0,14,46,3.066666666666667,0,0,0,0,0,0,0,0
69,training multiple models in same gpu simultaneously and how to setup ai lab,Tools,training multiple models in same gpu simultaneously and how to setup ai lab,"['training', 'multiple', 'models', 'in', 'same', 'gpu', 'simultaneously', 'and', 'how', 'to', 'setup', 'ai', 'lab']",0,"['training', 'multiple', 'model', 'in', 'same', 'gpu', 'simultaneously', 'and', 'how', 'to', 'setup', 'ai', 'lab']","['training', 'multiple', 'model', 'gpu', 'simultaneously', 'setup', 'ai', 'lab']",training multiple model gpu simultaneously setup ai lab,0.0,0.0,13,55,3.9285714285714284,0,0,0,0,0,0,0,0
70,how to read zip file directly in python,Tools,how to read zip file directly in python,"['how', 'to', 'read', 'zip', 'file', 'directly', 'in', 'python']",0,"['how', 'to', 'read', 'zip', 'file', 'directly', 'in', 'python']","['read', 'zip', 'file', 'directly', 'python']",read zip file directly python,0.1,0.1,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
71,post  years of experience chances of switching career to analytics,Career,post  years of experience chances of switching career to analytics,"['post', 'years', 'of', 'experience', 'chances', 'of', 'switching', 'career', 'to', 'analytics']",1,"['post', 'year', 'of', 'experience', 'chance', 'of', 'switching', 'career', 'to', 'analytics']","['post', 'year', 'experience', 'chance', 'switching', 'career', 'analytics']",post year experience chance switching career analytics,0.0,0.0,10,54,4.909090909090909,0,0,0,0,0,0,0,0
72,i want to learn r is there any free course for beginners,Resources,i want to learn r is there any free course for beginners,"['i', 'want', 'to', 'learn', 'r', 'is', 'there', 'any', 'free', 'course', 'for', 'beginners']",0,"['i', 'want', 'to', 'learn', 'r', 'is', 'there', 'any', 'free', 'course', 'for', 'beginner']","['want', 'learn', 'r', 'free', 'course', 'beginner']",want learn r free course beginner,0.4,0.4,12,33,2.5384615384615383,0,0,0,0,0,0,0,0
73,k means vs density based clustering,Techniques,k means vs density based clustering,"['k', 'means', 'vs', 'density', 'based', 'clustering']",0,"['k', 'mean', 'v', 'density', 'based', 'clustering']","['k', 'mean', 'v', 'density', 'based', 'clustering']",k mean v density based clustering,0.0,-0.3125,6,33,4.714285714285714,0,0,0,0,0,0,0,0
74,why are numerical fields dropped and just a present or not indicator flag used in their place,Techniques,why are numerical fields dropped and just a present or not indicator flag used in their place,"['why', 'are', 'numerical', 'fields', 'dropped', 'and', 'just', 'a', 'present', 'or', 'not', 'indicator', 'flag', 'used', 'in', 'their', 'place']",0,"['why', 'are', 'numerical', 'field', 'dropped', 'and', 'just', 'a', 'present', 'or', 'not', 'indicator', 'flag', 'used', 'in', 'their', 'place']","['numerical', 'field', 'dropped', 'present', 'indicator', 'flag', 'used', 'place']",numerical field dropped present indicator flag used place,0.0,0.0,17,57,3.1666666666666665,0,0,0,0,0,0,0,0
75,understaing the significance test,Resources,understaing the significance test,"['understaing', 'the', 'significance', 'test']",0,"['understaing', 'the', 'significance', 'test']","['understaing', 'significance', 'test']",understaing significance test,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
76,why cant we use roc curve to compare two models,Misc,why cant we use roc curve to compare two models,"['why', 'cant', 'we', 'use', 'roc', 'curve', 'to', 'compare', 'two', 'models']",0,"['why', 'cant', 'we', 'use', 'roc', 'curve', 'to', 'compare', 'two', 'model']","['cant', 'use', 'roc', 'curve', 'compare', 'two', 'model']",cant use roc curve compare two model,0.0,0.0,10,36,3.272727272727273,0,0,0,0,0,0,0,0
77,meaning of the plots obtained in lm in r,Techniques,meaning of the plots obtained in lm in r,"['meaning', 'of', 'the', 'plots', 'obtained', 'in', 'lm', 'in', 'r']",0,"['meaning', 'of', 'the', 'plot', 'obtained', 'in', 'lm', 'in', 'r']","['meaning', 'plot', 'obtained', 'lm', 'r']",meaning plot obtained lm r,0.0,0.0,9,26,2.6,0,0,0,0,0,0,0,0
78,i m new in data science what can be error plz help,Hackathons,i m new in data science what can be error plz help,"['i', 'm', 'new', 'in', 'data', 'science', 'what', 'can', 'be', 'error', 'plz', 'help']",0,"['i', 'm', 'new', 'in', 'data', 'science', 'what', 'can', 'be', 'error', 'plz', 'help']","['new', 'data', 'science', 'error', 'plz', 'help']",new data science error plz help,0.1363636363636363,0.1363636363636363,12,31,2.3846153846153846,0,0,0,0,0,0,0,0
79,download  free tutorial to learn data science in r from scratch,Resources,download  free tutorial to learn data science in r from scratch,"['download', 'free', 'tutorial', 'to', 'learn', 'data', 'science', 'in', 'r', 'from', 'scratch']",0,"['download', 'free', 'tutorial', 'to', 'learn', 'data', 'science', 'in', 'r', 'from', 'scratch']","['download', 'free', 'tutorial', 'learn', 'data', 'science', 'r', 'scratch']",download free tutorial learn data science r scratch,0.4,0.4,11,51,4.25,0,0,0,0,0,0,0,0
80,interpret result of logistic regression in terms of percentage increase or decrease,Techniques,interpret result of logistic regression in terms of percentage increase or decrease,"['interpret', 'result', 'of', 'logistic', 'regression', 'in', 'terms', 'of', 'percentage', 'increase', 'or', 'decrease']",0,"['interpret', 'result', 'of', 'logistic', 'regression', 'in', 'term', 'of', 'percentage', 'increase', 'or', 'decrease']","['interpret', 'result', 'logistic', 'regression', 'term', 'percentage', 'increase', 'decrease']",interpret result logistic regression term percentage increase decrease,0.0,0.0,12,70,5.384615384615385,0,0,0,0,0,0,0,0
81,how to declare irregular time series data into time series,Tools,how to declare irregular time series data into time series,"['how', 'to', 'declare', 'irregular', 'time', 'series', 'data', 'into', 'time', 'series']",0,"['how', 'to', 'declare', 'irregular', 'time', 'series', 'data', 'into', 'time', 'series']","['declare', 'irregular', 'time', 'series', 'data', 'time', 'series']",declare irregular time series data time series,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
82,microsofts introduction to r course on edx,Resources,microsofts introduction to r course on edx,"['microsofts', 'introduction', 'to', 'r', 'course', 'on', 'edx']",0,"['microsofts', 'introduction', 'to', 'r', 'course', 'on', 'edx']","['microsofts', 'introduction', 'r', 'course', 'edx']",microsofts introduction r course edx,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
83,dont we get any points for participating in skilltest,Misc,dont we get any points for participating in skilltest,"['dont', 'we', 'get', 'any', 'points', 'for', 'participating', 'in', 'skilltest']",0,"['dont', 'we', 'get', 'any', 'point', 'for', 'participating', 'in', 'skilltest']","['dont', 'get', 'point', 'participating', 'skilltest']",dont get point participating skilltest,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
84,how to rename the file in r,Tools,how to rename the file in r,"['how', 'to', 'rename', 'the', 'file', 'in', 'r']",0,"['how', 'to', 'rename', 'the', 'file', 'in', 'r']","['rename', 'file', 'r']",rename file r,0.0,0.0,7,13,1.625,0,0,0,0,0,0,0,0
85,regression analysis using polynomials,Techniques,regression analysis using polynomials,"['regression', 'analysis', 'using', 'polynomials']",0,"['regression', 'analysis', 'using', 'polynomial']","['regression', 'analysis', 'using', 'polynomial']",regression analysis using polynomial,0.0,0.0,4,36,7.2,0,0,0,0,0,0,0,0
86,can we use stock market time series table data in form of d matrix as input to capsule neural network,Techniques,can we use stock market time series table data in form of d matrix as input to capsule neural network,"['can', 'we', 'use', 'stock', 'market', 'time', 'series', 'table', 'data', 'in', 'form', 'of', 'd', 'matrix', 'as', 'input', 'to', 'capsule', 'neural', 'network']",0,"['can', 'we', 'use', 'stock', 'market', 'time', 'series', 'table', 'data', 'in', 'form', 'of', 'd', 'matrix', 'a', 'input', 'to', 'capsule', 'neural', 'network']","['use', 'stock', 'market', 'time', 'series', 'table', 'data', 'form', 'matrix', 'input', 'capsule', 'neural', 'network']",use stock market time series table data form matrix input capsule neural network,0.0,0.0,20,80,3.8095238095238093,0,0,0,0,0,0,0,0
87,when do we split the data into train and test data,Techniques,when do we split the data into train and test data,"['when', 'do', 'we', 'split', 'the', 'data', 'into', 'train', 'and', 'test', 'data']",0,"['when', 'do', 'we', 'split', 'the', 'data', 'into', 'train', 'and', 'test', 'data']","['split', 'data', 'train', 'test', 'data']",split data train test data,0.0,0.0,11,26,2.1666666666666665,0,0,0,0,0,0,0,0
88,how to perform element wise multiplication in ipython notebook,Tools,how to perform element wise multiplication in ipython notebook,"['how', 'to', 'perform', 'element', 'wise', 'multiplication', 'in', 'ipython', 'notebook']",0,"['how', 'to', 'perform', 'element', 'wise', 'multiplication', 'in', 'ipython', 'notebook']","['perform', 'element', 'wise', 'multiplication', 'ipython', 'notebook']",perform element wise multiplication ipython notebook,0.7,0.7,9,52,5.2,0,0,0,0,0,0,0,0
89,dependent list creation using shiny,Tools,dependent list creation using shiny,"['dependent', 'list', 'creation', 'using', 'shiny']",0,"['dependent', 'list', 'creation', 'using', 'shiny']","['dependent', 'list', 'creation', 'using', 'shiny']",dependent list creation using shiny,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
90,should i start exploring big data technology,Career,should i start exploring big data technology,"['should', 'i', 'start', 'exploring', 'big', 'data', 'technology']",0,"['should', 'i', 'start', 'exploring', 'big', 'data', 'technology']","['start', 'exploring', 'big', 'data', 'technology']",start exploring big data technology,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
91,how sapply simplifies the result in r,Tools,how sapply simplifies the result in r,"['how', 'sapply', 'simplifies', 'the', 'result', 'in', 'r']",0,"['how', 'sapply', 'simplifies', 'the', 'result', 'in', 'r']","['sapply', 'simplifies', 'result', 'r']",sapply simplifies result r,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
92,career in business analytics for freshers,Career,career in business analytics for freshers,"['career', 'in', 'business', 'analytics', 'for', 'freshers']",0,"['career', 'in', 'business', 'analytics', 'for', 'fresher']","['career', 'business', 'analytics', 'fresher']",career business analytics fresher,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
93,how to convert the factor into integer in r,Tools,how to convert the factor into integer in r,"['how', 'to', 'convert', 'the', 'factor', 'into', 'integer', 'in', 'r']",0,"['how', 'to', 'convert', 'the', 'factor', 'into', 'integer', 'in', 'r']","['convert', 'factor', 'integer', 'r']",convert factor integer r,0.0,0.0,9,24,2.4,0,0,0,0,0,0,0,0
94,what do the values from varimp for a randomforest indicate,Techniques,what do the values from varimp for a randomforest indicate,"['what', 'do', 'the', 'values', 'from', 'varimp', 'for', 'a', 'randomforest', 'indicate']",0,"['what', 'do', 'the', 'value', 'from', 'varimp', 'for', 'a', 'randomforest', 'indicate']","['value', 'varimp', 'randomforest', 'indicate']",value varimp randomforest indicate,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
95,predictive modelling on large data set,Tools,predictive modelling on large data set,"['predictive', 'modelling', 'on', 'large', 'data', 'set']",0,"['predictive', 'modelling', 'on', 'large', 'data', 'set']","['predictive', 'modelling', 'large', 'data', 'set']",predictive modelling large data set,0.2142857142857142,0.2142857142857142,6,35,5.0,0,0,0,0,0,0,0,0
96,chrn prediction in a time frame,Techniques,chrn prediction in a time frame,"['chrn', 'prediction', 'in', 'a', 'time', 'frame']",0,"['chrn', 'prediction', 'in', 'a', 'time', 'frame']","['chrn', 'prediction', 'time', 'frame']",chrn prediction time frame,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
97,box detection using opencv,Techniques,box detection using opencv,"['box', 'detection', 'using', 'opencv']",0,"['box', 'detection', 'using', 'opencv']","['box', 'detection', 'using', 'opencv']",box detection using opencv,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
98,career shift to big data analytics from mainframes,Career,career shift to big data analytics from mainframes,"['career', 'shift', 'to', 'big', 'data', 'analytics', 'from', 'mainframes']",0,"['career', 'shift', 'to', 'big', 'data', 'analytics', 'from', 'mainframe']","['career', 'shift', 'big', 'data', 'analytics', 'mainframe']",career shift big data analytics mainframe,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
99,mlp  number of neurons input layer,Techniques,mlp  number of neurons input layer,"['mlp', 'number', 'of', 'neurons', 'input', 'layer']",0,"['mlp', 'number', 'of', 'neuron', 'input', 'layer']","['mlp', 'number', 'neuron', 'input', 'layer']",mlp number neuron input layer,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
100,extracting twitter data and storing it,Techniques,extracting twitter data and storing it,"['extracting', 'twitter', 'data', 'and', 'storing', 'it']",0,"['extracting', 'twitter', 'data', 'and', 'storing', 'it']","['extracting', 'twitter', 'data', 'storing']",extracting twitter data storing,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
101,explain backup node in hadoopbigdata hadoop,Tools,explain backup node in hadoopbigdata hadoop,"['explain', 'backup', 'node', 'in', 'hadoopbigdata', 'hadoop']",0,"['explain', 'backup', 'node', 'in', 'hadoopbigdata', 'hadoop']","['explain', 'backup', 'node', 'hadoopbigdata', 'hadoop']",explain backup node hadoopbigdata hadoop,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
102,mckinsey analytics hackathon  healthcare analytics th april ,Hackathons,mckinsey analytics hackathon  healthcare analytics th april ,"['mckinsey', 'analytics', 'hackathon', 'healthcare', 'analytics', 'th', 'april']",1,"['mckinsey', 'analytics', 'hackathon', 'healthcare', 'analytics', 'th', 'april']","['mckinsey', 'analytics', 'hackathon', 'healthcare', 'analytics', 'th', 'april']",mckinsey analytics hackathon healthcare analytics th april,0.0,0.0,7,58,7.25,0,0,0,0,0,0,0,0
103,best universitites for masters in data science,Career,best universitites for masters in data science,"['best', 'universitites', 'for', 'masters', 'in', 'data', 'science']",0,"['best', 'universitites', 'for', 'master', 'in', 'data', 'science']","['best', 'universitites', 'master', 'data', 'science']",best universitites master data science,1.0,1.0,7,38,4.75,0,0,0,0,0,0,0,0
104,loan prediction,Hackathons,loan prediction,"['loan', 'prediction']",0,"['loan', 'prediction']","['loan', 'prediction']",loan prediction,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
105,what are your thoughts on this article  data scientists are dead,Misc,what are your thoughts on this article  data scientists are dead,"['what', 'are', 'your', 'thoughts', 'on', 'this', 'article', 'data', 'scientists', 'are', 'dead']",0,"['what', 'are', 'your', 'thought', 'on', 'this', 'article', 'data', 'scientist', 'are', 'dead']","['thought', 'article', 'data', 'scientist', 'dead']",thought article data scientist dead,-0.2,-0.2,11,35,2.9166666666666665,0,0,0,0,0,0,0,0
106,how to read raw data with more than one delimiters in sas,Tools,how to read raw data with more than one delimiters in sas,"['how', 'to', 'read', 'raw', 'data', 'with', 'more', 'than', 'one', 'delimiters', 'in', 'sas']",0,"['how', 'to', 'read', 'raw', 'data', 'with', 'more', 'than', 'one', 'delimiters', 'in', 'sa']","['read', 'raw', 'data', 'one', 'delimiters', 'sa']",read raw data one delimiters sa,0.1346153846153846,-0.2307692307692307,12,31,2.3846153846153846,0,0,0,0,0,0,0,0
107,which technique can be used for catering order by multiple stores,Techniques,which technique can be used for catering order by multiple stores,"['which', 'technique', 'can', 'be', 'used', 'for', 'catering', 'order', 'by', 'multiple', 'stores']",0,"['which', 'technique', 'can', 'be', 'used', 'for', 'catering', 'order', 'by', 'multiple', 'store']","['technique', 'used', 'catering', 'order', 'multiple', 'store']",technique used catering order multiple store,0.0,0.0,11,44,3.6666666666666665,0,0,0,0,0,0,0,0
108,what should be the frequency when creating time series object in r for a value which occurs once in a week,Tools,what should be the frequency when creating time series object in r for a value which occurs once in a week,"['what', 'should', 'be', 'the', 'frequency', 'when', 'creating', 'time', 'series', 'object', 'in', 'r', 'for', 'a', 'value', 'which', 'occurs', 'once', 'in', 'a', 'week']",0,"['what', 'should', 'be', 'the', 'frequency', 'when', 'creating', 'time', 'series', 'object', 'in', 'r', 'for', 'a', 'value', 'which', 'occurs', 'once', 'in', 'a', 'week']","['frequency', 'creating', 'time', 'series', 'object', 'r', 'value', 'occurs', 'week']",frequency creating time series object r value occurs week,0.0,0.0,21,57,2.590909090909091,0,0,0,0,0,0,0,0
109,resources  frameworks for media mix modelling,Other,resources  frameworks for media mix modelling,"['resources', 'frameworks', 'for', 'media', 'mix', 'modelling']",0,"['resource', 'framework', 'for', 'medium', 'mix', 'modelling']","['resource', 'framework', 'medium', 'mix', 'modelling']",resource framework medium mix modelling,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
110,lasso regression to shrink the dimensions by using penalty function,Techniques,lasso regression to shrink the dimensions by using penalty function,"['lasso', 'regression', 'to', 'shrink', 'the', 'dimensions', 'by', 'using', 'penalty', 'function']",0,"['lasso', 'regression', 'to', 'shrink', 'the', 'dimension', 'by', 'using', 'penalty', 'function']","['lasso', 'regression', 'shrink', 'dimension', 'using', 'penalty', 'function']",lasso regression shrink dimension using penalty function,0.0,0.0,10,56,5.090909090909091,0,0,0,0,0,0,0,0
111,customer segmentation approach your thoughts please,Techniques,customer segmentation approach your thoughts please,"['customer', 'segmentation', 'approach', 'your', 'thoughts', 'please']",0,"['customer', 'segmentation', 'approach', 'your', 'thought', 'please']","['customer', 'segmentation', 'approach', 'thought', 'please']",customer segmentation approach thought please,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
112,multi label classification,Techniques,multi label classification,"['multi', 'label', 'classification']",0,"['multi', 'label', 'classification']","['multi', 'label', 'classification']",multi label classification,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
113,how to convert date into year and month and while analyzing a time series problem in r,Techniques,how to convert date into year and month and while analyzing a time series problem in r,"['how', 'to', 'convert', 'date', 'into', 'year', 'and', 'month', 'and', 'while', 'analyzing', 'a', 'time', 'series', 'problem', 'in', 'r']",0,"['how', 'to', 'convert', 'date', 'into', 'year', 'and', 'month', 'and', 'while', 'analyzing', 'a', 'time', 'series', 'problem', 'in', 'r']","['convert', 'date', 'year', 'month', 'analyzing', 'time', 'series', 'problem', 'r']",convert date year month analyzing time series problem r,0.0,0.0,17,55,3.0555555555555554,0,0,0,0,0,0,0,0
114,use of different formulas to calculate the zscore,Techniques,use of different formulas to calculate the zscore,"['use', 'of', 'different', 'formulas', 'to', 'calculate', 'the', 'zscore']",0,"['use', 'of', 'different', 'formula', 'to', 'calculate', 'the', 'zscore']","['use', 'different', 'formula', 'calculate', 'zscore']",use different formula calculate zscore,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
115,i have to predict cosine similarity between    column into rd column how to approach this problem in r,Techniques,i have to predict cosine similarity between    column into rd column how to approach this problem in r,"['i', 'have', 'to', 'predict', 'cosine', 'similarity', 'between', 'column', 'into', 'rd', 'column', 'how', 'to', 'approach', 'this', 'problem', 'in', 'r']",2,"['i', 'have', 'to', 'predict', 'cosine', 'similarity', 'between', 'column', 'into', 'rd', 'column', 'how', 'to', 'approach', 'this', 'problem', 'in', 'r']","['predict', 'cosine', 'similarity', 'column', 'rd', 'column', 'approach', 'problem', 'r']",predict cosine similarity column rd column approach problem r,0.0,0.0,18,61,3.210526315789474,0,0,0,0,0,0,0,0
116,multiple instances of r studio getting opened,Tools,multiple instances of r studio getting opened,"['multiple', 'instances', 'of', 'r', 'studio', 'getting', 'opened']",0,"['multiple', 'instance', 'of', 'r', 'studio', 'getting', 'opened']","['multiple', 'instance', 'r', 'studio', 'getting', 'opened']",multiple instance r studio getting opened,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
117,negative adjusted r squared,Techniques,negative adjusted r squared,"['negative', 'adjusted', 'r', 'squared']",0,"['negative', 'adjusted', 'r', 'squared']","['negative', 'adjusted', 'r', 'squared']",negative adjusted r squared,-0.3,-0.3,4,27,5.4,0,0,0,0,0,0,0,0
118,selecting variables and transferring into new datasets in sas,Tools,selecting variables and transferring into new datasets in sas,"['selecting', 'variables', 'and', 'transferring', 'into', 'new', 'datasets', 'in', 'sas']",0,"['selecting', 'variable', 'and', 'transferring', 'into', 'new', 'datasets', 'in', 'sa']","['selecting', 'variable', 'transferring', 'new', 'datasets', 'sa']",selecting variable transferring new datasets sa,0.1363636363636363,0.1363636363636363,9,47,4.7,0,0,0,0,0,0,0,0
119,selecting final submission for scoring,Hackathons,selecting final submission for scoring,"['selecting', 'final', 'submission', 'for', 'scoring']",0,"['selecting', 'final', 'submission', 'for', 'scoring']","['selecting', 'final', 'submission', 'scoring']",selecting final submission scoring,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
120,how to convert data from character to a standard date format in r,Tools,how to convert data from character to a standard date format in r,"['how', 'to', 'convert', 'data', 'from', 'character', 'to', 'a', 'standard', 'date', 'format', 'in', 'r']",0,"['how', 'to', 'convert', 'data', 'from', 'character', 'to', 'a', 'standard', 'date', 'format', 'in', 'r']","['convert', 'data', 'character', 'standard', 'date', 'format', 'r']",convert data character standard date format r,0.0,0.0,13,45,3.2142857142857144,0,0,0,0,0,0,0,0
121,ho model classification  confusion matrix vs auc,Techniques,ho model classification  confusion matrix vs auc,"['ho', 'model', 'classification', 'confusion', 'matrix', 'vs', 'auc']",0,"['ho', 'model', 'classification', 'confusion', 'matrix', 'v', 'auc']","['ho', 'model', 'classification', 'confusion', 'matrix', 'v', 'auc']",ho model classification confusion matrix v auc,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
122,how to convert a bunch of doc files into docx files,Tools,how to convert a bunch of doc files into docx files,"['how', 'to', 'convert', 'a', 'bunch', 'of', 'doc', 'files', 'into', 'docx', 'files']",0,"['how', 'to', 'convert', 'a', 'bunch', 'of', 'doc', 'file', 'into', 'docx', 'file']","['convert', 'bunch', 'doc', 'file', 'docx', 'file']",convert bunch doc file docx file,0.0,0.0,11,32,2.6666666666666665,0,0,0,0,0,0,0,0
123,ph d scholar requires review dataset for research purpose,Techniques,ph d scholar requires review dataset for research purpose,"['ph', 'd', 'scholar', 'requires', 'review', 'dataset', 'for', 'research', 'purpose']",0,"['ph', 'd', 'scholar', 'requires', 'review', 'dataset', 'for', 'research', 'purpose']","['ph', 'scholar', 'requires', 'review', 'dataset', 'research', 'purpose']",ph scholar requires review dataset research purpose,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
124,how can i implement decision tree in sas,Tools,how can i implement decision tree in sas,"['how', 'can', 'i', 'implement', 'decision', 'tree', 'in', 'sas']",0,"['how', 'can', 'i', 'implement', 'decision', 'tree', 'in', 'sa']","['implement', 'decision', 'tree', 'sa']",implement decision tree sa,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
125,how to apply a code for another  stocks ,Tools,how to apply a code for another  stocks ,"['how', 'to', 'apply', 'a', 'code', 'for', 'another', 'stocks']",1,"['how', 'to', 'apply', 'a', 'code', 'for', 'another', 'stock']","['apply', 'code', 'another', 'stock']",apply code another stock,0.0,0.0,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
126,data mining technique for count data,Techniques,data mining technique for count data,"['data', 'mining', 'technique', 'for', 'count', 'data']",0,"['data', 'mining', 'technique', 'for', 'count', 'data']","['data', 'mining', 'technique', 'count', 'data']",data mining technique count data,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
127,how cross validation helps in svm classification,Techniques,how cross validation helps in svm classification,"['how', 'cross', 'validation', 'helps', 'in', 'svm', 'classification']",0,"['how', 'cross', 'validation', 'help', 'in', 'svm', 'classification']","['cross', 'validation', 'help', 'svm', 'classification']",cross validation help svm classification,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
128,do we need to avoid a dummy variable trap for the naive bayes classifier technique,Techniques,do we need to avoid a dummy variable trap for the naive bayes classifier technique,"['do', 'we', 'need', 'to', 'avoid', 'a', 'dummy', 'variable', 'trap', 'for', 'the', 'naive', 'bayes', 'classifier', 'technique']",0,"['do', 'we', 'need', 'to', 'avoid', 'a', 'dummy', 'variable', 'trap', 'for', 'the', 'naive', 'bayes', 'classifier', 'technique']","['need', 'avoid', 'dummy', 'variable', 'trap', 'naive', 'bayes', 'classifier', 'technique']",need avoid dummy variable trap naive bayes classifier technique,-0.3,-0.3,15,63,3.9375,0,0,0,0,0,0,0,0
129,why univariate and bivariate analysis is required for machine learning,Hackathons,why univariate and bivariate analysis is required for machine learning,"['why', 'univariate', 'and', 'bivariate', 'analysis', 'is', 'required', 'for', 'machine', 'learning']",0,"['why', 'univariate', 'and', 'bivariate', 'analysis', 'is', 'required', 'for', 'machine', 'learning']","['univariate', 'bivariate', 'analysis', 'required', 'machine', 'learning']",univariate bivariate analysis required machine learning,0.0,0.0,10,55,5.0,0,0,0,0,0,0,0,0
130,pls help me with the code,Techniques,pls help me with the code,"['pls', 'help', 'me', 'with', 'the', 'code']",0,"['pls', 'help', 'me', 'with', 'the', 'code']","['pls', 'help', 'code']",pls help code,0.0,0.0,6,13,1.8571428571428572,0,0,0,0,0,0,0,0
131,derivate of sigmoid function in rnn implementation,Techniques,derivate of sigmoid function in rnn implementation,"['derivate', 'of', 'sigmoid', 'function', 'in', 'rnn', 'implementation']",0,"['derivate', 'of', 'sigmoid', 'function', 'in', 'rnn', 'implementation']","['derivate', 'sigmoid', 'function', 'rnn', 'implementation']",derivate sigmoid function rnn implementation,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
132,what does stemmer do in python nltk library,Tools,what does stemmer do in python nltk library,"['what', 'does', 'stemmer', 'do', 'in', 'python', 'nltk', 'library']",0,"['what', 'doe', 'stemmer', 'do', 'in', 'python', 'nltk', 'library']","['doe', 'stemmer', 'python', 'nltk', 'library']",doe stemmer python nltk library,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
133,why do we need to make our data stationary,Techniques,why do we need to make our data stationary,"['why', 'do', 'we', 'need', 'to', 'make', 'our', 'data', 'stationary']",0,"['why', 'do', 'we', 'need', 'to', 'make', 'our', 'data', 'stationary']","['need', 'make', 'data', 'stationary']",need make data stationary,0.0,0.0,9,25,2.5,0,0,0,0,0,0,0,0
134,what are the career options in machine learning and computer vision,Career,what are the career options in machine learning and computer vision,"['what', 'are', 'the', 'career', 'options', 'in', 'machine', 'learning', 'and', 'computer', 'vision']",0,"['what', 'are', 'the', 'career', 'option', 'in', 'machine', 'learning', 'and', 'computer', 'vision']","['career', 'option', 'machine', 'learning', 'computer', 'vision']",career option machine learning computer vision,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
135,machine learning model selection for time series problem,Techniques,machine learning model selection for time series problem,"['machine', 'learning', 'model', 'selection', 'for', 'time', 'series', 'problem']",0,"['machine', 'learning', 'model', 'selection', 'for', 'time', 'series', 'problem']","['machine', 'learning', 'model', 'selection', 'time', 'series', 'problem']",machine learning model selection time series problem,0.0,0.0,8,52,5.777777777777778,0,0,0,0,0,0,0,0
136,data analysis of unstructured data that have non linear key value position,Techniques,data analysis of unstructured data that have non linear key value position,"['data', 'analysis', 'of', 'unstructured', 'data', 'that', 'have', 'non', 'linear', 'key', 'value', 'position']",0,"['data', 'analysis', 'of', 'unstructured', 'data', 'that', 'have', 'non', 'linear', 'key', 'value', 'position']","['data', 'analysis', 'unstructured', 'data', 'non', 'linear', 'key', 'value', 'position']",data analysis unstructured data non linear key value position,0.0,0.0,12,61,4.6923076923076925,0,0,0,0,0,0,0,0
137,help me understand the questions of deep learning skilltest,Techniques,help me understand the questions of deep learning skilltest,"['help', 'me', 'understand', 'the', 'questions', 'of', 'deep', 'learning', 'skilltest']",0,"['help', 'me', 'understand', 'the', 'question', 'of', 'deep', 'learning', 'skilltest']","['help', 'understand', 'question', 'deep', 'learning', 'skilltest']",help understand question deep learning skilltest,0.0,0.0,9,48,4.8,0,0,0,0,0,0,0,0
138,nlp tasks  techniques,Techniques,nlp tasks  techniques,"['nlp', 'tasks', 'techniques']",0,"['nlp', 'task', 'technique']","['nlp', 'task', 'technique']",nlp task technique,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
139,speech to text conversion,Techniques,speech to text conversion,"['speech', 'to', 'text', 'conversion']",0,"['speech', 'to', 'text', 'conversion']","['speech', 'text', 'conversion']",speech text conversion,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
140,named entity recognition,Techniques,named entity recognition,"['named', 'entity', 'recognition']",0,"['named', 'entity', 'recognition']","['named', 'entity', 'recognition']",named entity recognition,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
141,measures of central tendency and dispersion  limitations,Techniques,measures of central tendency and dispersion  limitations,"['measures', 'of', 'central', 'tendency', 'and', 'dispersion', 'limitations']",0,"['measure', 'of', 'central', 'tendency', 'and', 'dispersion', 'limitation']","['measure', 'central', 'tendency', 'dispersion', 'limitation']",measure central tendency dispersion limitation,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
142,exploratory analysis on gb data,Techniques,exploratory analysis on gb data,"['exploratory', 'analysis', 'on', 'gb', 'data']",0,"['exploratory', 'analysis', 'on', 'gb', 'data']","['exploratory', 'analysis', 'gb', 'data']",exploratory analysis gb data,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
143,cv in random forest errorcv is ,Techniques,cv in random forest errorcv is ,"['cv', 'in', 'random', 'forest', 'errorcv', 'is']",1,"['cv', 'in', 'random', 'forest', 'errorcv', 'is']","['cv', 'random', 'forest', 'errorcv']",cv random forest errorcv,-0.5,-0.5,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
144,choosing number of trees in random forest,Techniques,choosing number of trees in random forest,"['choosing', 'number', 'of', 'trees', 'in', 'random', 'forest']",0,"['choosing', 'number', 'of', 'tree', 'in', 'random', 'forest']","['choosing', 'number', 'tree', 'random', 'forest']",choosing number tree random forest,-0.5,-0.5,7,34,4.25,0,0,0,0,0,0,0,0
145,banglore or ncr for data science career oppurtunities,Career,banglore or ncr for data science career oppurtunities,"['banglore', 'or', 'ncr', 'for', 'data', 'science', 'career', 'oppurtunities']",0,"['banglore', 'or', 'ncr', 'for', 'data', 'science', 'career', 'oppurtunities']","['banglore', 'ncr', 'data', 'science', 'career', 'oppurtunities']",banglore ncr data science career oppurtunities,0.0,0.0,8,46,5.111111111111111,0,0,0,0,0,0,0,0
146,mnist digit data,Techniques,mnist digit data,"['mnist', 'digit', 'data']",0,"['mnist', 'digit', 'data']","['mnist', 'digit', 'data']",mnist digit data,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
147,query regarding data normalization,Techniques,query regarding data normalization,"['query', 'regarding', 'data', 'normalization']",0,"['query', 'regarding', 'data', 'normalization']","['query', 'regarding', 'data', 'normalization']",query regarding data normalization,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
148,difference between gradient boosting and adaboost,Techniques,difference between gradient boosting and adaboost,"['difference', 'between', 'gradient', 'boosting', 'and', 'adaboost']",0,"['difference', 'between', 'gradient', 'boosting', 'and', 'adaboost']","['difference', 'gradient', 'boosting', 'adaboost']",difference gradient boosting adaboost,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
149,image classification for product,Techniques,image classification for product,"['image', 'classification', 'for', 'product']",0,"['image', 'classification', 'for', 'product']","['image', 'classification', 'product']",image classification product,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
150,unable to combine train and test data set in big mart sales problem,Hackathons,unable to combine train and test data set in big mart sales problem,"['unable', 'to', 'combine', 'train', 'and', 'test', 'data', 'set', 'in', 'big', 'mart', 'sales', 'problem']",0,"['unable', 'to', 'combine', 'train', 'and', 'test', 'data', 'set', 'in', 'big', 'mart', 'sale', 'problem']","['unable', 'combine', 'train', 'test', 'data', 'set', 'big', 'mart', 'sale', 'problem']",unable combine train test data set big mart sale problem,-0.25,-0.25,13,56,4.0,0,0,0,0,0,0,0,0
151,business analytics big data analytics interview case study,Techniques,business analytics big data analytics interview case study,"['business', 'analytics', 'big', 'data', 'analytics', 'interview', 'case', 'study']",0,"['business', 'analytics', 'big', 'data', 'analytics', 'interview', 'case', 'study']","['business', 'analytics', 'big', 'data', 'analytics', 'interview', 'case', 'study']",business analytics big data analytics interview case study,0.0,0.0,8,58,6.444444444444445,0,0,0,0,0,0,0,0
152,how to check best cost value in svm,Techniques,how to check best cost value in svm,"['how', 'to', 'check', 'best', 'cost', 'value', 'in', 'svm']",0,"['how', 'to', 'check', 'best', 'cost', 'value', 'in', 'svm']","['check', 'best', 'cost', 'value', 'svm']",check best cost value svm,1.0,1.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
153,difference in univariate time series  regression based forecasting,Techniques,difference in univariate time series  regression based forecasting,"['difference', 'in', 'univariate', 'time', 'series', 'regression', 'based', 'forecasting']",0,"['difference', 'in', 'univariate', 'time', 'series', 'regression', 'based', 'forecasting']","['difference', 'univariate', 'time', 'series', 'regression', 'based', 'forecasting']",difference univariate time series regression based forecasting,0.0,0.0,8,62,6.888888888888889,0,0,0,0,0,0,0,0
154,where to get sas for personal computer and best formal coaching institute for learning sas or r,Tools,where to get sas for personal computer and best formal coaching institute for learning sas or r,"['where', 'to', 'get', 'sas', 'for', 'personal', 'computer', 'and', 'best', 'formal', 'coaching', 'institute', 'for', 'learning', 'sas', 'or', 'r']",0,"['where', 'to', 'get', 'sa', 'for', 'personal', 'computer', 'and', 'best', 'formal', 'coaching', 'institute', 'for', 'learning', 'sa', 'or', 'r']","['get', 'sa', 'personal', 'computer', 'best', 'formal', 'coaching', 'institute', 'learning', 'sa', 'r']",get sa personal computer best formal coaching institute learning sa r,0.5,0.5,17,69,3.8333333333333335,0,0,0,0,0,0,0,0
155,what are the ways and techniques to become good in text analytics,Techniques,what are the ways and techniques to become good in text analytics,"['what', 'are', 'the', 'ways', 'and', 'techniques', 'to', 'become', 'good', 'in', 'text', 'analytics']",0,"['what', 'are', 'the', 'way', 'and', 'technique', 'to', 'become', 'good', 'in', 'text', 'analytics']","['way', 'technique', 'become', 'good', 'text', 'analytics']",way technique become good text analytics,0.7,0.7,12,40,3.076923076923077,0,0,0,0,0,0,0,0
156,face recognition accuracy,Techniques,face recognition accuracy,"['face', 'recognition', 'accuracy']",0,"['face', 'recognition', 'accuracy']","['face', 'recognition', 'accuracy']",face recognition accuracy,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
157,handle log variables in regression,Other,handle log variables in regression,"['handle', 'log', 'variables', 'in', 'regression']",0,"['handle', 'log', 'variable', 'in', 'regression']","['handle', 'log', 'variable', 'regression']",handle log variable regression,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
158,nlp tokenization,Techniques,nlp tokenization,"['nlp', 'tokenization']",0,"['nlp', 'tokenization']","['nlp', 'tokenization']",nlp tokenization,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
159,given list of labelled words finding sentiment,Techniques,given list of labelled words finding sentiment,"['given', 'list', 'of', 'labelled', 'words', 'finding', 'sentiment']",0,"['given', 'list', 'of', 'labelled', 'word', 'finding', 'sentiment']","['given', 'list', 'labelled', 'word', 'finding', 'sentiment']",given list labelled word finding sentiment,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
160,general query in r,Misc,general query in r,"['general', 'query', 'in', 'r']",0,"['general', 'query', 'in', 'r']","['general', 'query', 'r']",general query r,0.05,0.05,4,15,3.0,0,0,0,0,0,0,0,0
161,machine learning fundamentals on text mining multi label classification,Techniques,machine learning fundamentals on text mining multi label classification,"['machine', 'learning', 'fundamentals', 'on', 'text', 'mining', 'multi', 'label', 'classification']",0,"['machine', 'learning', 'fundamental', 'on', 'text', 'mining', 'multi', 'label', 'classification']","['machine', 'learning', 'fundamental', 'text', 'mining', 'multi', 'label', 'classification']",machine learning fundamental text mining multi label classification,0.0,0.0,9,67,6.7,0,0,0,0,0,0,0,0
162,how find patterns in categorical data with respect to time,Techniques,how find patterns in categorical data with respect to time,"['how', 'find', 'patterns', 'in', 'categorical', 'data', 'with', 'respect', 'to', 'time']",0,"['how', 'find', 'pattern', 'in', 'categorical', 'data', 'with', 'respect', 'to', 'time']","['find', 'pattern', 'categorical', 'data', 'respect', 'time']",find pattern categorical data respect time,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
163,analytics program choicecritical from placement perspective for bca graduate with  years of experience and other queries,Career,analytics program choicecritical from placement perspective for bca graduate with  years of experience and other queries,"['analytics', 'program', 'choicecritical', 'from', 'placement', 'perspective', 'for', 'bca', 'graduate', 'with', 'years', 'of', 'experience', 'and', 'other', 'queries']",1,"['analytics', 'program', 'choicecritical', 'from', 'placement', 'perspective', 'for', 'bca', 'graduate', 'with', 'year', 'of', 'experience', 'and', 'other', 'query']","['analytics', 'program', 'choicecritical', 'placement', 'perspective', 'bca', 'graduate', 'year', 'experience', 'query']",analytics program choicecritical placement perspective bca graduate year experience query,-0.125,0.0,16,89,5.235294117647059,0,0,0,0,0,0,0,0
164,predict the duration a vehicle takes to service,Techniques,predict the duration a vehicle takes to service,"['predict', 'the', 'duration', 'a', 'vehicle', 'takes', 'to', 'service']",0,"['predict', 'the', 'duration', 'a', 'vehicle', 'take', 'to', 'service']","['predict', 'duration', 'vehicle', 'take', 'service']",predict duration vehicle take service,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
165,when does the private lb gets published,Hackathons,when does the private lb gets published,"['when', 'does', 'the', 'private', 'lb', 'gets', 'published']",0,"['when', 'doe', 'the', 'private', 'lb', 'get', 'published']","['doe', 'private', 'lb', 'get', 'published']",doe private lb get published,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
166,anybody has the dataset for the kaggle drawbridge competition,Resources,anybody has the dataset for the kaggle drawbridge competition,"['anybody', 'has', 'the', 'dataset', 'for', 'the', 'kaggle', 'drawbridge', 'competition']",0,"['anybody', 'ha', 'the', 'dataset', 'for', 'the', 'kaggle', 'drawbridge', 'competition']","['anybody', 'ha', 'dataset', 'kaggle', 'drawbridge', 'competition']",anybody ha dataset kaggle drawbridge competition,0.0,0.0,9,48,4.8,0,0,0,0,0,0,0,0
167,while joining two datatables in r do we need to specify key in both or not,Tools,while joining two datatables in r do we need to specify key in both or not,"['while', 'joining', 'two', 'datatables', 'in', 'r', 'do', 'we', 'need', 'to', 'specify', 'key', 'in', 'both', 'or', 'not']",0,"['while', 'joining', 'two', 'datatables', 'in', 'r', 'do', 'we', 'need', 'to', 'specify', 'key', 'in', 'both', 'or', 'not']","['joining', 'two', 'datatables', 'r', 'need', 'specify', 'key']",joining two datatables r need specify key,0.0,0.0,16,41,2.411764705882353,0,0,0,0,0,0,0,0
168,how to impute categorical missing values in python,Tools,how to impute categorical missing values in python,"['how', 'to', 'impute', 'categorical', 'missing', 'values', 'in', 'python']",0,"['how', 'to', 'impute', 'categorical', 'missing', 'value', 'in', 'python']","['impute', 'categorical', 'missing', 'value', 'python']",impute categorical missing value python,-0.2,-0.2,8,39,4.333333333333333,0,0,0,0,0,0,0,0
169,highly imbalance dataset  auc of ,Techniques,highly imbalance dataset  auc of ,"['highly', 'imbalance', 'dataset', 'auc', 'of']",1,"['highly', 'imbalance', 'dataset', 'auc', 'of']","['highly', 'imbalance', 'dataset', 'auc']",highly imbalance dataset auc,0.16,0.16,5,28,4.666666666666667,0,0,0,0,0,0,0,0
170,solution to time seriespractise problem in r,Hackathons,solution to time seriespractise problem in r,"['solution', 'to', 'time', 'seriespractise', 'problem', 'in', 'r']",0,"['solution', 'to', 'time', 'seriespractise', 'problem', 'in', 'r']","['solution', 'time', 'seriespractise', 'problem', 'r']",solution time seriespractise problem r,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
171,how to improve the performance of random forest in r,Tools,how to improve the performance of random forest in r,"['how', 'to', 'improve', 'the', 'performance', 'of', 'random', 'forest', 'in', 'r']",0,"['how', 'to', 'improve', 'the', 'performance', 'of', 'random', 'forest', 'in', 'r']","['improve', 'performance', 'random', 'forest', 'r']",improve performance random forest r,-0.5,-0.5,10,35,3.1818181818181817,0,0,0,0,0,0,0,0
172,must read books on python,Resources,must read books on python,"['must', 'read', 'books', 'on', 'python']",0,"['must', 'read', 'book', 'on', 'python']","['must', 'read', 'book', 'python']",must read book python,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
173,how to realize dbscan algorithm in python without using any packages,Techniques,how to realize dbscan algorithm in python without using any packages,"['how', 'to', 'realize', 'dbscan', 'algorithm', 'in', 'python', 'without', 'using', 'any', 'packages']",0,"['how', 'to', 'realize', 'dbscan', 'algorithm', 'in', 'python', 'without', 'using', 'any', 'package']","['realize', 'dbscan', 'algorithm', 'python', 'without', 'using', 'package']",realize dbscan algorithm python without using package,0.0,0.0,11,53,4.416666666666667,0,0,0,0,0,0,0,0
174,how are you guys filling in the missing data  loan prediciton,Hackathons,how are you guys filling in the missing data  loan prediciton,"['how', 'are', 'you', 'guys', 'filling', 'in', 'the', 'missing', 'data', 'loan', 'prediciton']",0,"['how', 'are', 'you', 'guy', 'filling', 'in', 'the', 'missing', 'data', 'loan', 'prediciton']","['guy', 'filling', 'missing', 'data', 'loan', 'prediciton']",guy filling missing data loan prediciton,-0.2,-0.2,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
175,how to connect google analytics data to qlikview,Tools,how to connect google analytics data to qlikview,"['how', 'to', 'connect', 'google', 'analytics', 'data', 'to', 'qlikview']",0,"['how', 'to', 'connect', 'google', 'analytics', 'data', 'to', 'qlikview']","['connect', 'google', 'analytics', 'data', 'qlikview']",connect google analytics data qlikview,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
176,portfoliowide vs customer level lgd which is better and why,Techniques,portfoliowide vs customer level lgd which is better and why,"['portfoliowide', 'vs', 'customer', 'level', 'lgd', 'which', 'is', 'better', 'and', 'why']",0,"['portfoliowide', 'v', 'customer', 'level', 'lgd', 'which', 'is', 'better', 'and', 'why']","['portfoliowide', 'v', 'customer', 'level', 'lgd', 'better']",portfoliowide v customer level lgd better,0.5,0.5,10,41,3.727272727272727,0,0,0,0,0,0,0,0
177,retrieve embedding from fine tune bert for binary classification,Techniques,retrieve embedding from fine tune bert for binary classification,"['retrieve', 'embedding', 'from', 'fine', 'tune', 'bert', 'for', 'binary', 'classification']",0,"['retrieve', 'embedding', 'from', 'fine', 'tune', 'bert', 'for', 'binary', 'classification']","['retrieve', 'embedding', 'fine', 'tune', 'bert', 'binary', 'classification']",retrieve embedding fine tune bert binary classification,0.4166666666666667,0.4166666666666667,9,55,5.5,0,0,0,0,0,0,0,0
178,jobs for freshers in analytics,Career,jobs for freshers in analytics,"['jobs', 'for', 'freshers', 'in', 'analytics']",0,"['job', 'for', 'fresher', 'in', 'analytics']","['job', 'fresher', 'analytics']",job fresher analytics,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
179,sas working knowledge for reporting professionals,Tools,sas working knowledge for reporting professionals,"['sas', 'working', 'knowledge', 'for', 'reporting', 'professionals']",0,"['sa', 'working', 'knowledge', 'for', 'reporting', 'professional']","['sa', 'working', 'knowledge', 'reporting', 'professional']",sa working knowledge reporting professional,0.0,0.1,6,43,6.142857142857143,0,0,0,0,0,0,0,0
180,forecasting methods and techniques,Techniques,forecasting methods and techniques,"['forecasting', 'methods', 'and', 'techniques']",0,"['forecasting', 'method', 'and', 'technique']","['forecasting', 'method', 'technique']",forecasting method technique,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
181,error in sas code,Tools,error in sas code,"['error', 'in', 'sas', 'code']",0,"['error', 'in', 'sa', 'code']","['error', 'sa', 'code']",error sa code,0.0,0.0,4,13,2.6,0,0,0,0,0,0,0,0
182,how does bagging affect decision tree models,Techniques,how does bagging affect decision tree models,"['how', 'does', 'bagging', 'affect', 'decision', 'tree', 'models']",0,"['how', 'doe', 'bagging', 'affect', 'decision', 'tree', 'model']","['doe', 'bagging', 'affect', 'decision', 'tree', 'model']",doe bagging affect decision tree model,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
183,assigning weights to a variable to score a product,Techniques,assigning weights to a variable to score a product,"['assigning', 'weights', 'to', 'a', 'variable', 'to', 'score', 'a', 'product']",0,"['assigning', 'weight', 'to', 'a', 'variable', 'to', 'score', 'a', 'product']","['assigning', 'weight', 'variable', 'score', 'product']",assigning weight variable score product,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
184,record matching and clustering,Other,record matching and clustering,"['record', 'matching', 'and', 'clustering']",0,"['record', 'matching', 'and', 'clustering']","['record', 'matching', 'clustering']",record matching clustering,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
185,is machine learning a must have skill to become a data scientist,Career,is machine learning a must have skill to become a data scientist,"['is', 'machine', 'learning', 'a', 'must', 'have', 'skill', 'to', 'become', 'a', 'data', 'scientist']",0,"['is', 'machine', 'learning', 'a', 'must', 'have', 'skill', 'to', 'become', 'a', 'data', 'scientist']","['machine', 'learning', 'must', 'skill', 'become', 'data', 'scientist']",machine learning must skill become data scientist,0.0,0.0,12,49,3.769230769230769,0,0,0,0,0,0,0,0
186,data applications in the financial industry,Other,data applications in the financial industry,"['data', 'applications', 'in', 'the', 'financial', 'industry']",0,"['data', 'application', 'in', 'the', 'financial', 'industry']","['data', 'application', 'financial', 'industry']",data application financial industry,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
187,how can i make sample submission file,Hackathons,how can i make sample submission file,"['how', 'can', 'i', 'make', 'sample', 'submission', 'file']",0,"['how', 'can', 'i', 'make', 'sample', 'submission', 'file']","['make', 'sample', 'submission', 'file']",make sample submission file,0.0,0.0,7,27,3.375,0,0,0,0,0,0,0,0
188,model building help in excel,Other,model building help in excel,"['model', 'building', 'help', 'in', 'excel']",0,"['model', 'building', 'help', 'in', 'excel']","['model', 'building', 'help', 'excel']",model building help excel,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
189,need data source and social media data,Resources,need data source and social media data,"['need', 'data', 'source', 'and', 'social', 'media', 'data']",0,"['need', 'data', 'source', 'and', 'social', 'medium', 'data']","['need', 'data', 'source', 'social', 'medium', 'data']",need data source social medium data,0.0333333333333333,0.0333333333333333,7,35,4.375,0,0,0,0,0,0,0,0
190,calculate run time for sentiment analysis,Tools,calculate run time for sentiment analysis,"['calculate', 'run', 'time', 'for', 'sentiment', 'analysis']",0,"['calculate', 'run', 'time', 'for', 'sentiment', 'analysis']","['calculate', 'run', 'time', 'sentiment', 'analysis']",calculate run time sentiment analysis,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
191,relevant to bikeshare dataset why not split up the hours into  categories instead of ,Techniques,relevant to bikeshare dataset why not split up the hours into  categories instead of ,"['relevant', 'to', 'bikeshare', 'dataset', 'why', 'not', 'split', 'up', 'the', 'hours', 'into', 'categories', 'instead', 'of']",2,"['relevant', 'to', 'bikeshare', 'dataset', 'why', 'not', 'split', 'up', 'the', 'hour', 'into', 'category', 'instead', 'of']","['relevant', 'bikeshare', 'dataset', 'split', 'hour', 'category', 'instead']",relevant bikeshare dataset split hour category instead,0.4,0.4,14,54,3.6,0,0,0,0,0,0,0,0
192,extract words between symbols in r,Tools,extract words between symbols in r,"['extract', 'words', 'between', 'symbols', 'in', 'r']",0,"['extract', 'word', 'between', 'symbol', 'in', 'r']","['extract', 'word', 'symbol', 'r']",extract word symbol r,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
193,what are some good modelling techniques in machine learning,Techniques,what are some good modelling techniques in machine learning,"['what', 'are', 'some', 'good', 'modelling', 'techniques', 'in', 'machine', 'learning']",0,"['what', 'are', 'some', 'good', 'modelling', 'technique', 'in', 'machine', 'learning']","['good', 'modelling', 'technique', 'machine', 'learning']",good modelling technique machine learning,0.7,0.7,9,41,4.1,0,0,0,0,0,0,0,0
194,need dataset of mini datahack,Hackathons,need dataset of mini datahack,"['need', 'dataset', 'of', 'mini', 'datahack']",0,"['need', 'dataset', 'of', 'mini', 'datahack']","['need', 'dataset', 'mini', 'datahack']",need dataset mini datahack,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
195,countif function using fixed column range in r,Tools,countif function using fixed column range in r,"['countif', 'function', 'using', 'fixed', 'column', 'range', 'in', 'r']",0,"['countif', 'function', 'using', 'fixed', 'column', 'range', 'in', 'r']","['countif', 'function', 'using', 'fixed', 'column', 'range', 'r']",countif function using fixed column range r,0.1,0.1,8,43,4.777777777777778,0,0,0,0,0,0,0,0
196,how to treat inf values in r,Tools,how to treat inf values in r,"['how', 'to', 'treat', 'inf', 'values', 'in', 'r']",0,"['how', 'to', 'treat', 'inf', 'value', 'in', 'r']","['treat', 'inf', 'value', 'r']",treat inf value r,0.0,0.0,7,17,2.125,0,0,0,0,0,0,0,0
197, questions to test a data scientist on natural language processing solution skilltest – nlp  doubt on question ,Techniques, questions to test a data scientist on natural language processing solution skilltest – nlp  doubt on question ,"['questions', 'to', 'test', 'a', 'data', 'scientist', 'on', 'natural', 'language', 'processing', 'solution', 'skilltest', '–', 'nlp', 'doubt', 'on', 'question']",2,"['question', 'to', 'test', 'a', 'data', 'scientist', 'on', 'natural', 'language', 'processing', 'solution', 'skilltest', '–', 'nlp', 'doubt', 'on', 'question']","['question', 'test', 'data', 'scientist', 'natural', 'language', 'processing', 'solution', 'skilltest', '–', 'nlp', 'doubt', 'question']",question test data scientist natural language processing solution skilltest – nlp doubt question,0.1,0.1,17,96,5.333333333333333,0,0,0,0,0,0,0,0
198,webanalytics  bi,Career,webanalytics  bi,"['webanalytics', 'bi']",0,"['webanalytics', 'bi']","['webanalytics', 'bi']",webanalytics bi,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
199,analysis of power consumption by various equipments,Techniques,analysis of power consumption by various equipments,"['analysis', 'of', 'power', 'consumption', 'by', 'various', 'equipments']",0,"['analysis', 'of', 'power', 'consumption', 'by', 'various', 'equipment']","['analysis', 'power', 'consumption', 'various', 'equipment']",analysis power consumption various equipment,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
200,career move from mainframes to big data or data science,Career,career move from mainframes to big data or data science,"['career', 'move', 'from', 'mainframes', 'to', 'big', 'data', 'or', 'data', 'science']",0,"['career', 'move', 'from', 'mainframe', 'to', 'big', 'data', 'or', 'data', 'science']","['career', 'move', 'mainframe', 'big', 'data', 'data', 'science']",career move mainframe big data data science,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
201,medical image analysis in python,Tools,medical image analysis in python,"['medical', 'image', 'analysis', 'in', 'python']",0,"['medical', 'image', 'analysis', 'in', 'python']","['medical', 'image', 'analysis', 'python']",medical image analysis python,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
202,how can i make a chart static in qlikview,Tools,how can i make a chart static in qlikview,"['how', 'can', 'i', 'make', 'a', 'chart', 'static', 'in', 'qlikview']",0,"['how', 'can', 'i', 'make', 'a', 'chart', 'static', 'in', 'qlikview']","['make', 'chart', 'static', 'qlikview']",make chart static qlikview,0.5,0.5,9,26,2.6,0,0,0,0,0,0,0,0
203,use of lastplot and xlim in r,Tools,use of lastplot and xlim in r,"['use', 'of', 'lastplot', 'and', 'xlim', 'in', 'r']",0,"['use', 'of', 'lastplot', 'and', 'xlim', 'in', 'r']","['use', 'lastplot', 'xlim', 'r']",use lastplot xlim r,0.0,0.0,7,19,2.375,0,0,0,0,0,0,0,0
204,imputation using boosted trees in r gbmimpute imputation,Tools,imputation using boosted trees in r gbmimpute imputation,"['imputation', 'using', 'boosted', 'trees', 'in', 'r', 'gbmimpute', 'imputation']",0,"['imputation', 'using', 'boosted', 'tree', 'in', 'r', 'gbmimpute', 'imputation']","['imputation', 'using', 'boosted', 'tree', 'r', 'gbmimpute', 'imputation']",imputation using boosted tree r gbmimpute imputation,0.0,0.0,8,52,5.777777777777778,0,0,0,0,0,0,0,0
205,how to set missing values in r,Techniques,how to set missing values in r,"['how', 'to', 'set', 'missing', 'values', 'in', 'r']",0,"['how', 'to', 'set', 'missing', 'value', 'in', 'r']","['set', 'missing', 'value', 'r']",set missing value r,-0.2,-0.2,7,19,2.375,0,0,0,0,0,0,0,0
206,help with the list of must know classification algorithms,Techniques,help with the list of must know classification algorithms,"['help', 'with', 'the', 'list', 'of', 'must', 'know', 'classification', 'algorithms']",0,"['help', 'with', 'the', 'list', 'of', 'must', 'know', 'classification', 'algorithm']","['help', 'list', 'must', 'know', 'classification', 'algorithm']",help list must know classification algorithm,0.0,0.0,9,44,4.4,0,0,0,0,0,0,0,0
207,what are advantages of rbind and cbind over matrix in r,Tools,what are advantages of rbind and cbind over matrix in r,"['what', 'are', 'advantages', 'of', 'rbind', 'and', 'cbind', 'over', 'matrix', 'in', 'r']",0,"['what', 'are', 'advantage', 'of', 'rbind', 'and', 'cbind', 'over', 'matrix', 'in', 'r']","['advantage', 'rbind', 'cbind', 'matrix', 'r']",advantage rbind cbind matrix r,0.0,0.0,11,30,2.5,0,0,0,0,0,0,0,0
208,how to convert data in practice problem time series to ts format in r,Tools,how to convert data in practice problem time series to ts format in r,"['how', 'to', 'convert', 'data', 'in', 'practice', 'problem', 'time', 'series', 'to', 'ts', 'format', 'in', 'r']",0,"['how', 'to', 'convert', 'data', 'in', 'practice', 'problem', 'time', 'series', 'to', 't', 'format', 'in', 'r']","['convert', 'data', 'practice', 'problem', 'time', 'series', 'format', 'r']",convert data practice problem time series format r,0.0,0.0,14,50,3.3333333333333335,0,0,0,0,0,0,0,0
209,how to get started with machine learning,Misc,how to get started with machine learning,"['how', 'to', 'get', 'started', 'with', 'machine', 'learning']",0,"['how', 'to', 'get', 'started', 'with', 'machine', 'learning']","['get', 'started', 'machine', 'learning']",get started machine learning,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
210,what is the logic behind jitters commandgeomjitter   in r,Tools,what is the logic behind jitters commandgeomjitter   in r,"['what', 'is', 'the', 'logic', 'behind', 'jitters', 'commandgeomjitter', 'in', 'r']",0,"['what', 'is', 'the', 'logic', 'behind', 'jitter', 'commandgeomjitter', 'in', 'r']","['logic', 'behind', 'jitter', 'commandgeomjitter', 'r']",logic behind jitter commandgeomjitter r,-0.4,-0.4,9,39,3.9,0,0,0,0,0,0,0,0
211,install tensorflow on windows bit in anacondapython,Tools,install tensorflow on windows bit in anacondapython,"['install', 'tensorflow', 'on', 'windows', 'bit', 'in', 'anacondapython']",0,"['install', 'tensorflow', 'on', 'window', 'bit', 'in', 'anacondapython']","['install', 'tensorflow', 'window', 'bit', 'anacondapython']",install tensorflow window bit anacondapython,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
212,how to repeat whole vector in r,Tools,how to repeat whole vector in r,"['how', 'to', 'repeat', 'whole', 'vector', 'in', 'r']",0,"['how', 'to', 'repeat', 'whole', 'vector', 'in', 'r']","['repeat', 'whole', 'vector', 'r']",repeat whole vector r,0.2,0.2,7,21,2.625,0,0,0,0,0,0,0,0
213,how to interpret the outputs from a lasso regularization technique in r,Techniques,how to interpret the outputs from a lasso regularization technique in r,"['how', 'to', 'interpret', 'the', 'outputs', 'from', 'a', 'lasso', 'regularization', 'technique', 'in', 'r']",0,"['how', 'to', 'interpret', 'the', 'output', 'from', 'a', 'lasso', 'regularization', 'technique', 'in', 'r']","['interpret', 'output', 'lasso', 'regularization', 'technique', 'r']",interpret output lasso regularization technique r,0.0,0.0,12,49,3.769230769230769,0,0,0,0,0,0,0,0
214,question regarding overfitting and underfitting,Tools,question regarding overfitting and underfitting,"['question', 'regarding', 'overfitting', 'and', 'underfitting']",0,"['question', 'regarding', 'overfitting', 'and', 'underfitting']","['question', 'regarding', 'overfitting', 'underfitting']",question regarding overfitting underfitting,0.0,0.0,5,43,7.166666666666667,0,0,0,0,0,0,0,0
215,what is the signifies of eta and nthread in xgboost model,Techniques,what is the signifies of eta and nthread in xgboost model,"['what', 'is', 'the', 'signifies', 'of', 'eta', 'and', 'nthread', 'in', 'xgboost', 'model']",0,"['what', 'is', 'the', 'signifies', 'of', 'eta', 'and', 'nthread', 'in', 'xgboost', 'model']","['signifies', 'eta', 'nthread', 'xgboost', 'model']",signifies eta nthread xgboost model,0.0,0.0,11,35,2.9166666666666665,0,0,0,0,0,0,0,0
216,how to fill the missing value in the addition of data frame in python,Tools,how to fill the missing value in the addition of data frame in python,"['how', 'to', 'fill', 'the', 'missing', 'value', 'in', 'the', 'addition', 'of', 'data', 'frame', 'in', 'python']",0,"['how', 'to', 'fill', 'the', 'missing', 'value', 'in', 'the', 'addition', 'of', 'data', 'frame', 'in', 'python']","['fill', 'missing', 'value', 'addition', 'data', 'frame', 'python']",fill missing value addition data frame python,-0.2,-0.2,14,45,3.0,0,0,0,0,0,0,0,0
217,essential healthcare kpis and data visualizations,Resources,essential healthcare kpis and data visualizations,"['essential', 'healthcare', 'kpis', 'and', 'data', 'visualizations']",0,"['essential', 'healthcare', 'kpis', 'and', 'data', 'visualization']","['essential', 'healthcare', 'kpis', 'data', 'visualization']",essential healthcare kpis data visualization,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
218,random forest binary classification  predictproba values,Techniques,random forest binary classification  predictproba values,"['random', 'forest', 'binary', 'classification', 'predictproba', 'values']",0,"['random', 'forest', 'binary', 'classification', 'predictproba', 'value']","['random', 'forest', 'binary', 'classification', 'predictproba', 'value']",random forest binary classification predictproba value,-0.5,-0.5,6,54,7.714285714285714,0,0,0,0,0,0,0,0
219,best tableau training centre with placement assistance,Career,best tableau training centre with placement assistance,"['best', 'tableau', 'training', 'centre', 'with', 'placement', 'assistance']",0,"['best', 'tableau', 'training', 'centre', 'with', 'placement', 'assistance']","['best', 'tableau', 'training', 'centre', 'placement', 'assistance']",best tableau training centre placement assistance,1.0,1.0,7,49,6.125,0,0,0,0,0,0,0,0
220,how to convert the column of data frame to index of data frame in python,Tools,how to convert the column of data frame to index of data frame in python,"['how', 'to', 'convert', 'the', 'column', 'of', 'data', 'frame', 'to', 'index', 'of', 'data', 'frame', 'in', 'python']",0,"['how', 'to', 'convert', 'the', 'column', 'of', 'data', 'frame', 'to', 'index', 'of', 'data', 'frame', 'in', 'python']","['convert', 'column', 'data', 'frame', 'index', 'data', 'frame', 'python']",convert column data frame index data frame python,0.0,0.0,15,49,3.0625,0,0,0,0,0,0,0,0
221,how to get the percentage concordant and discordant values for a logistic regression model in r,Tools,how to get the percentage concordant and discordant values for a logistic regression model in r,"['how', 'to', 'get', 'the', 'percentage', 'concordant', 'and', 'discordant', 'values', 'for', 'a', 'logistic', 'regression', 'model', 'in', 'r']",0,"['how', 'to', 'get', 'the', 'percentage', 'concordant', 'and', 'discordant', 'value', 'for', 'a', 'logistic', 'regression', 'model', 'in', 'r']","['get', 'percentage', 'concordant', 'discordant', 'value', 'logistic', 'regression', 'model', 'r']",get percentage concordant discordant value logistic regression model r,0.0,0.0,16,70,4.117647058823529,0,0,0,0,0,0,0,0
222,over sampling mutli label data,Techniques,over sampling mutli label data,"['over', 'sampling', 'mutli', 'label', 'data']",0,"['over', 'sampling', 'mutli', 'label', 'data']","['sampling', 'mutli', 'label', 'data']",sampling mutli label data,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
223,load previous saved workspace image in rstudio,Tools,load previous saved workspace image in rstudio,"['load', 'previous', 'saved', 'workspace', 'image', 'in', 'rstudio']",0,"['load', 'previous', 'saved', 'workspace', 'image', 'in', 'rstudio']","['load', 'previous', 'saved', 'workspace', 'image', 'rstudio']",load previous saved workspace image rstudio,-0.1666666666666666,-0.1666666666666666,7,43,5.375,0,0,0,0,0,0,0,0
224,how data can be used to build a model,Techniques,how data can be used to build a model,"['how', 'data', 'can', 'be', 'used', 'to', 'build', 'a', 'model']",0,"['how', 'data', 'can', 'be', 'used', 'to', 'build', 'a', 'model']","['data', 'used', 'build', 'model']",data used build model,0.0,0.0,9,21,2.1,0,0,0,0,0,0,0,0
225,binary optimization,Techniques,binary optimization,"['binary', 'optimization']",0,"['binary', 'optimization']","['binary', 'optimization']",binary optimization,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
226,sample solution for old data hackathons,Hackathons,sample solution for old data hackathons,"['sample', 'solution', 'for', 'old', 'data', 'hackathons']",0,"['sample', 'solution', 'for', 'old', 'data', 'hackathons']","['sample', 'solution', 'old', 'data', 'hackathons']",sample solution old data hackathons,0.1,0.1,6,35,5.0,0,0,0,0,0,0,0,0
227,suitability of random forest methods for n  p classification problem,Techniques,suitability of random forest methods for n  p classification problem,"['suitability', 'of', 'random', 'forest', 'methods', 'for', 'n', 'p', 'classification', 'problem']",0,"['suitability', 'of', 'random', 'forest', 'method', 'for', 'n', 'p', 'classification', 'problem']","['suitability', 'random', 'forest', 'method', 'n', 'p', 'classification', 'problem']",suitability random forest method n p classification problem,-0.5,-0.5,10,59,5.363636363636363,0,0,0,0,0,0,0,0
228,warning argument is not numeric or logical returning na,Tools,warning argument is not numeric or logical returning na,"['warning', 'argument', 'is', 'not', 'numeric', 'or', 'logical', 'returning', 'na']",0,"['warning', 'argument', 'is', 'not', 'numeric', 'or', 'logical', 'returning', 'na']","['warning', 'argument', 'numeric', 'logical', 'returning', 'na']",warning argument numeric logical returning na,0.25,0.25,9,45,4.5,0,0,0,0,0,0,0,0
229,how to create self learning data product,Other,how to create self learning data product,"['how', 'to', 'create', 'self', 'learning', 'data', 'product']",0,"['how', 'to', 'create', 'self', 'learning', 'data', 'product']","['create', 'self', 'learning', 'data', 'product']",create self learning data product,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
230,what is default replication factor in hadoop bigdatahadoop,Career,what is default replication factor in hadoop bigdatahadoop,"['what', 'is', 'default', 'replication', 'factor', 'in', 'hadoop', 'bigdatahadoop']",0,"['what', 'is', 'default', 'replication', 'factor', 'in', 'hadoop', 'bigdatahadoop']","['default', 'replication', 'factor', 'hadoop', 'bigdatahadoop']",default replication factor hadoop bigdatahadoop,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
231,how to convert excel dashboards in tableau dashboards,Tools,how to convert excel dashboards in tableau dashboards,"['how', 'to', 'convert', 'excel', 'dashboards', 'in', 'tableau', 'dashboards']",0,"['how', 'to', 'convert', 'excel', 'dashboard', 'in', 'tableau', 'dashboard']","['convert', 'excel', 'dashboard', 'tableau', 'dashboard']",convert excel dashboard tableau dashboard,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
232,feature selection using boruta package in r,Techniques,feature selection using boruta package in r,"['feature', 'selection', 'using', 'boruta', 'package', 'in', 'r']",0,"['feature', 'selection', 'using', 'boruta', 'package', 'in', 'r']","['feature', 'selection', 'using', 'boruta', 'package', 'r']",feature selection using boruta package r,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
233,why it is necessary to use cross validation approach to find the tuning parameter,Techniques,why it is necessary to use cross validation approach to find the tuning parameter,"['why', 'it', 'is', 'necessary', 'to', 'use', 'cross', 'validation', 'approach', 'to', 'find', 'the', 'tuning', 'parameter']",0,"['why', 'it', 'is', 'necessary', 'to', 'use', 'cross', 'validation', 'approach', 'to', 'find', 'the', 'tuning', 'parameter']","['necessary', 'use', 'cross', 'validation', 'approach', 'find', 'tuning', 'parameter']",necessary use cross validation approach find tuning parameter,0.0,0.0,14,61,4.066666666666666,0,0,0,0,0,0,0,0
234,a look into the hackathon,Hackathons,a look into the hackathon,"['a', 'look', 'into', 'the', 'hackathon']",0,"['a', 'look', 'into', 'the', 'hackathon']","['look', 'hackathon']",look hackathon,0.0,0.0,5,14,2.3333333333333335,0,0,0,0,0,0,0,0
235,how to choose the value of k in knn algorithm,Techniques,how to choose the value of k in knn algorithm,"['how', 'to', 'choose', 'the', 'value', 'of', 'k', 'in', 'knn', 'algorithm']",0,"['how', 'to', 'choose', 'the', 'value', 'of', 'k', 'in', 'knn', 'algorithm']","['choose', 'value', 'k', 'knn', 'algorithm']",choose value k knn algorithm,0.0,0.0,10,28,2.5454545454545454,0,0,0,0,0,0,0,0
236,using r on ubuntu vs windows,Tools,using r on ubuntu vs windows,"['using', 'r', 'on', 'ubuntu', 'vs', 'windows']",0,"['using', 'r', 'on', 'ubuntu', 'v', 'window']","['using', 'r', 'ubuntu', 'v', 'window']",using r ubuntu v window,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
237,how to get residual in linear regression model in r,Techniques,how to get residual in linear regression model in r,"['how', 'to', 'get', 'residual', 'in', 'linear', 'regression', 'model', 'in', 'r']",0,"['how', 'to', 'get', 'residual', 'in', 'linear', 'regression', 'model', 'in', 'r']","['get', 'residual', 'linear', 'regression', 'model', 'r']",get residual linear regression model r,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
238,looking for people with some work in general ai,Career,looking for people with some work in general ai,"['looking', 'for', 'people', 'with', 'some', 'work', 'in', 'general', 'ai']",0,"['looking', 'for', 'people', 'with', 'some', 'work', 'in', 'general', 'ai']","['looking', 'people', 'work', 'general', 'ai']",looking people work general ai,0.05,0.05,9,30,3.0,0,0,0,0,0,0,0,0
239,ways to find outliers in sas,Tools,ways to find outliers in sas,"['ways', 'to', 'find', 'outliers', 'in', 'sas']",0,"['way', 'to', 'find', 'outlier', 'in', 'sa']","['way', 'find', 'outlier', 'sa']",way find outlier sa,0.0,0.0,6,19,2.7142857142857144,0,0,0,0,0,0,0,0
240,time series analysis with categorical values,Techniques,time series analysis with categorical values,"['time', 'series', 'analysis', 'with', 'categorical', 'values']",0,"['time', 'series', 'analysis', 'with', 'categorical', 'value']","['time', 'series', 'analysis', 'categorical', 'value']",time series analysis categorical value,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
241,python smlogit  getting linalgerror singular matrix when using modelfit function,Techniques,python smlogit  getting linalgerror singular matrix when using modelfit function,"['python', 'smlogit', 'getting', 'linalgerror', 'singular', 'matrix', 'when', 'using', 'modelfit', 'function']",0,"['python', 'smlogit', 'getting', 'linalgerror', 'singular', 'matrix', 'when', 'using', 'modelfit', 'function']","['python', 'smlogit', 'getting', 'linalgerror', 'singular', 'matrix', 'using', 'modelfit', 'function']",python smlogit getting linalgerror singular matrix using modelfit function,0.0,0.0,10,74,6.7272727272727275,0,0,0,0,0,0,0,0
242,how to start deep learning i have started with basic ml like regression and classification,Techniques,how to start deep learning i have started with basic ml like regression and classification,"['how', 'to', 'start', 'deep', 'learning', 'i', 'have', 'started', 'with', 'basic', 'ml', 'like', 'regression', 'and', 'classification']",0,"['how', 'to', 'start', 'deep', 'learning', 'i', 'have', 'started', 'with', 'basic', 'ml', 'like', 'regression', 'and', 'classification']","['start', 'deep', 'learning', 'started', 'basic', 'ml', 'like', 'regression', 'classification']",start deep learning started basic ml like regression classification,0.0,0.0,15,67,4.1875,0,0,0,0,0,0,0,0
243,which is better iit or isi or iisc for data science,Career,which is better iit or isi or iisc for data science,"['which', 'is', 'better', 'iit', 'or', 'isi', 'or', 'iisc', 'for', 'data', 'science']",0,"['which', 'is', 'better', 'iit', 'or', 'isi', 'or', 'iisc', 'for', 'data', 'science']","['better', 'iit', 'isi', 'iisc', 'data', 'science']",better iit isi iisc data science,0.5,0.5,11,32,2.6666666666666665,0,0,0,0,0,0,0,0
244,switching to proper analystics sas,Career,switching to proper analystics sas,"['switching', 'to', 'proper', 'analystics', 'sas']",0,"['switching', 'to', 'proper', 'analystics', 'sa']","['switching', 'proper', 'analystics', 'sa']",switching proper analystics sa,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
245,what is career growth as a data scientist,Career,what is career growth as a data scientist,"['what', 'is', 'career', 'growth', 'as', 'a', 'data', 'scientist']",0,"['what', 'is', 'career', 'growth', 'a', 'a', 'data', 'scientist']","['career', 'growth', 'data', 'scientist']",career growth data scientist,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
246,extract date and time from unix timestamp in r,Tools,extract date and time from unix timestamp in r,"['extract', 'date', 'and', 'time', 'from', 'unix', 'timestamp', 'in', 'r']",0,"['extract', 'date', 'and', 'time', 'from', 'unix', 'timestamp', 'in', 'r']","['extract', 'date', 'time', 'unix', 'timestamp', 'r']",extract date time unix timestamp r,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
247,looking for best bigdata approach for my project,Techniques,looking for best bigdata approach for my project,"['looking', 'for', 'best', 'bigdata', 'approach', 'for', 'my', 'project']",0,"['looking', 'for', 'best', 'bigdata', 'approach', 'for', 'my', 'project']","['looking', 'best', 'bigdata', 'approach', 'project']",looking best bigdata approach project,1.0,1.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
248,predict or forecast a value for next  days,Techniques,predict or forecast a value for next  days,"['predict', 'or', 'forecast', 'a', 'value', 'for', 'next', 'days']",1,"['predict', 'or', 'forecast', 'a', 'value', 'for', 'next', 'day']","['predict', 'forecast', 'value', 'next', 'day']",predict forecast value next day,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
249,problem statements on nsl kdd dataset,Resources,problem statements on nsl kdd dataset,"['problem', 'statements', 'on', 'nsl', 'kdd', 'dataset']",0,"['problem', 'statement', 'on', 'nsl', 'kdd', 'dataset']","['problem', 'statement', 'nsl', 'kdd', 'dataset']",problem statement nsl kdd dataset,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
250,how do i install python  on an aws ec instance,Tools,how do i install python  on an aws ec instance,"['how', 'do', 'i', 'install', 'python', 'on', 'an', 'aws', 'ec', 'instance']",1,"['how', 'do', 'i', 'install', 'python', 'on', 'an', 'aws', 'ec', 'instance']","['install', 'python', 'aws', 'ec', 'instance']",install python aws ec instance,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
251,video classification using deep learning,Techniques,video classification using deep learning,"['video', 'classification', 'using', 'deep', 'learning']",0,"['video', 'classification', 'using', 'deep', 'learning']","['video', 'classification', 'using', 'deep', 'learning']",video classification using deep learning,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
252,career guidance,Career,career guidance,"['career', 'guidance']",0,"['career', 'guidance']","['career', 'guidance']",career guidance,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
253,why do we say errors cannot be normally distributed in logistic regression,Techniques,why do we say errors cannot be normally distributed in logistic regression,"['why', 'do', 'we', 'say', 'errors', 'can', 'not', 'be', 'normally', 'distributed', 'in', 'logistic', 'regression']",0,"['why', 'do', 'we', 'say', 'error', 'can', 'not', 'be', 'normally', 'distributed', 'in', 'logistic', 'regression']","['say', 'error', 'normally', 'distributed', 'logistic', 'regression']",say error normally distributed logistic regression,0.15,0.15,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
254,crowd counting  building crowd counting model using python,Techniques,crowd counting  building crowd counting model using python,"['crowd', 'counting', 'building', 'crowd', 'counting', 'model', 'using', 'python']",0,"['crowd', 'counting', 'building', 'crowd', 'counting', 'model', 'using', 'python']","['crowd', 'counting', 'building', 'crowd', 'counting', 'model', 'using', 'python']",crowd counting building crowd counting model using python,0.0,0.0,8,57,6.333333333333333,0,0,0,0,0,0,0,0
255,micro market level analysis,Techniques,micro market level analysis,"['micro', 'market', 'level', 'analysis']",0,"['micro', 'market', 'level', 'analysis']","['micro', 'market', 'level', 'analysis']",micro market level analysis,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
256,sas vs sap functional as a career choice,Career,sas vs sap functional as a career choice,"['sas', 'vs', 'sap', 'functional', 'as', 'a', 'career', 'choice']",0,"['sa', 'v', 'sap', 'functional', 'a', 'a', 'career', 'choice']","['sa', 'v', 'sap', 'functional', 'career', 'choice']",sa v sap functional career choice,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
257,variable clustering in python,Techniques,variable clustering in python,"['variable', 'clustering', 'in', 'python']",0,"['variable', 'clustering', 'in', 'python']","['variable', 'clustering', 'python']",variable clustering python,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
258,necessary mathematical skills for machine learning and data analysis,Resources,necessary mathematical skills for machine learning and data analysis,"['necessary', 'mathematical', 'skills', 'for', 'machine', 'learning', 'and', 'data', 'analysis']",0,"['necessary', 'mathematical', 'skill', 'for', 'machine', 'learning', 'and', 'data', 'analysis']","['necessary', 'mathematical', 'skill', 'machine', 'learning', 'data', 'analysis']",necessary mathematical skill machine learning data analysis,0.0,0.0,9,59,5.9,0,0,0,0,0,0,0,0
259,why sorted data set gets processed faster in sas during data manipulation,Tools,why sorted data set gets processed faster in sas during data manipulation,"['why', 'sorted', 'data', 'set', 'gets', 'processed', 'faster', 'in', 'sas', 'during', 'data', 'manipulation']",0,"['why', 'sorted', 'data', 'set', 'get', 'processed', 'faster', 'in', 'sa', 'during', 'data', 'manipulation']","['sorted', 'data', 'set', 'get', 'processed', 'faster', 'sa', 'data', 'manipulation']",sorted data set get processed faster sa data manipulation,0.0,0.0,12,57,4.384615384615385,0,0,0,0,0,0,0,0
260,setting up rstudio server on the cloud,Tools,setting up rstudio server on the cloud,"['setting', 'up', 'rstudio', 'server', 'on', 'the', 'cloud']",0,"['setting', 'up', 'rstudio', 'server', 'on', 'the', 'cloud']","['setting', 'rstudio', 'server', 'cloud']",setting rstudio server cloud,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
261,how to create stack of bar plot in python,Tools,how to create stack of bar plot in python,"['how', 'to', 'create', 'stack', 'of', 'bar', 'plot', 'in', 'python']",0,"['how', 'to', 'create', 'stack', 'of', 'bar', 'plot', 'in', 'python']","['create', 'stack', 'bar', 'plot', 'python']",create stack bar plot python,0.0,0.0,9,28,2.8,0,0,0,0,0,0,0,0
262,i am facing issues with improving the models and score,Other,i am facing issues with improving the models and score,"['i', 'am', 'facing', 'issues', 'with', 'improving', 'the', 'models', 'and', 'score']",0,"['i', 'am', 'facing', 'issue', 'with', 'improving', 'the', 'model', 'and', 'score']","['facing', 'issue', 'improving', 'model', 'score']",facing issue improving model score,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
263,how to read sas data set in excel,Tools,how to read sas data set in excel,"['how', 'to', 'read', 'sas', 'data', 'set', 'in', 'excel']",0,"['how', 'to', 'read', 'sa', 'data', 'set', 'in', 'excel']","['read', 'sa', 'data', 'set', 'excel']",read sa data set excel,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
264,how to drop a variable in r,Tools,how to drop a variable in r,"['how', 'to', 'drop', 'a', 'variable', 'in', 'r']",0,"['how', 'to', 'drop', 'a', 'variable', 'in', 'r']","['drop', 'variable', 'r']",drop variable r,0.0,0.0,7,15,1.875,0,0,0,0,0,0,0,0
265,running multiple algorithms using caretlist caretensemble,Tools,running multiple algorithms using caretlist caretensemble,"['running', 'multiple', 'algorithms', 'using', 'caretlist', 'caretensemble']",0,"['running', 'multiple', 'algorithm', 'using', 'caretlist', 'caretensemble']","['running', 'multiple', 'algorithm', 'using', 'caretlist', 'caretensemble']",running multiple algorithm using caretlist caretensemble,0.0,0.0,6,56,8.0,0,0,0,0,0,0,0,0
266,dealing with large number of features in document term matrix in text mining,Techniques,dealing with large number of features in document term matrix in text mining,"['dealing', 'with', 'large', 'number', 'of', 'features', 'in', 'document', 'term', 'matrix', 'in', 'text', 'mining']",0,"['dealing', 'with', 'large', 'number', 'of', 'feature', 'in', 'document', 'term', 'matrix', 'in', 'text', 'mining']","['dealing', 'large', 'number', 'feature', 'document', 'term', 'matrix', 'text', 'mining']",dealing large number feature document term matrix text mining,0.2142857142857142,0.2142857142857142,13,61,4.357142857142857,0,0,0,0,0,0,0,0
267,syntax error in spyder  invalid character in identifier,Tools,syntax error in spyder  invalid character in identifier,"['syntax', 'error', 'in', 'spyder', 'invalid', 'character', 'in', 'identifier']",0,"['syntax', 'error', 'in', 'spyder', 'invalid', 'character', 'in', 'identifier']","['syntax', 'error', 'spyder', 'invalid', 'character', 'identifier']",syntax error spyder invalid character identifier,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
268,error in applying svm on image data,Tools,error in applying svm on image data,"['error', 'in', 'applying', 'svm', 'on', 'image', 'data']",0,"['error', 'in', 'applying', 'svm', 'on', 'image', 'data']","['error', 'applying', 'svm', 'image', 'data']",error applying svm image data,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
269,how to hide the default column numbers in r while showing output,Tools,how to hide the default column numbers in r while showing output,"['how', 'to', 'hide', 'the', 'default', 'column', 'numbers', 'in', 'r', 'while', 'showing', 'output']",0,"['how', 'to', 'hide', 'the', 'default', 'column', 'number', 'in', 'r', 'while', 'showing', 'output']","['hide', 'default', 'column', 'number', 'r', 'showing', 'output']",hide default column number r showing output,0.0,0.0,12,43,3.3076923076923075,0,0,0,0,0,0,0,0
270,predicting building fire alarms,Techniques,predicting building fire alarms,"['predicting', 'building', 'fire', 'alarms']",0,"['predicting', 'building', 'fire', 'alarm']","['predicting', 'building', 'fire', 'alarm']",predicting building fire alarm,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
271,how to make overlaid line distributions with and without using ggplot  in r,Tools,how to make overlaid line distributions with and without using ggplot  in r,"['how', 'to', 'make', 'overlaid', 'line', 'distributions', 'with', 'and', 'without', 'using', 'ggplot', 'in', 'r']",1,"['how', 'to', 'make', 'overlaid', 'line', 'distribution', 'with', 'and', 'without', 'using', 'ggplot', 'in', 'r']","['make', 'overlaid', 'line', 'distribution', 'without', 'using', 'ggplot', 'r']",make overlaid line distribution without using ggplot r,0.0,0.0,13,54,3.857142857142857,0,0,0,0,0,0,0,0
272,recommender systems tutorial,Techniques,recommender systems tutorial,"['recommender', 'systems', 'tutorial']",0,"['recommender', 'system', 'tutorial']","['recommender', 'system', 'tutorial']",recommender system tutorial,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
273,how to use naroughfix to remove missing value from data,Techniques,how to use naroughfix to remove missing value from data,"['how', 'to', 'use', 'naroughfix', 'to', 'remove', 'missing', 'value', 'from', 'data']",0,"['how', 'to', 'use', 'naroughfix', 'to', 'remove', 'missing', 'value', 'from', 'data']","['use', 'naroughfix', 'remove', 'missing', 'value', 'data']",use naroughfix remove missing value data,-0.2,-0.2,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
274,how to construct an ensemble from many different search points in r,Techniques,how to construct an ensemble from many different search points in r,"['how', 'to', 'construct', 'an', 'ensemble', 'from', 'many', 'different', 'search', 'points', 'in', 'r']",0,"['how', 'to', 'construct', 'an', 'ensemble', 'from', 'many', 'different', 'search', 'point', 'in', 'r']","['construct', 'ensemble', 'many', 'different', 'search', 'point', 'r']",construct ensemble many different search point r,0.25,0.25,12,48,3.6923076923076925,0,0,0,0,0,0,0,0
275,one query related to career transition,Career,one query related to career transition,"['one', 'query', 'related', 'to', 'career', 'transition']",0,"['one', 'query', 'related', 'to', 'career', 'transition']","['one', 'query', 'related', 'career', 'transition']",one query related career transition,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
276,feature engineering  eda best practices for a project with large number of attributes,Techniques,feature engineering  eda best practices for a project with large number of attributes,"['feature', 'engineering', 'eda', 'best', 'practices', 'for', 'a', 'project', 'with', 'large', 'number', 'of', 'attributes']",0,"['feature', 'engineering', 'eda', 'best', 'practice', 'for', 'a', 'project', 'with', 'large', 'number', 'of', 'attribute']","['feature', 'engineering', 'eda', 'best', 'practice', 'project', 'large', 'number', 'attribute']",feature engineering eda best practice project large number attribute,0.6071428571428571,0.6071428571428571,13,68,4.857142857142857,0,0,0,0,0,0,0,0
277,from which resources can i learn piwik web analytics,Resources,from which resources can i learn piwik web analytics,"['from', 'which', 'resources', 'can', 'i', 'learn', 'piwik', 'web', 'analytics']",0,"['from', 'which', 'resource', 'can', 'i', 'learn', 'piwik', 'web', 'analytics']","['resource', 'learn', 'piwik', 'web', 'analytics']",resource learn piwik web analytics,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
278,what is standardized distance in knn,Techniques,what is standardized distance in knn,"['what', 'is', 'standardized', 'distance', 'in', 'knn']",0,"['what', 'is', 'standardized', 'distance', 'in', 'knn']","['standardized', 'distance', 'knn']",standardized distance knn,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
279,how to swift nonit professional career to data analytics,Career,how to swift nonit professional career to data analytics,"['how', 'to', 'swift', 'nonit', 'professional', 'career', 'to', 'data', 'analytics']",0,"['how', 'to', 'swift', 'nonit', 'professional', 'career', 'to', 'data', 'analytics']","['swift', 'nonit', 'professional', 'career', 'data', 'analytics']",swift nonit professional career data analytics,0.1,0.1,9,46,4.6,0,0,0,0,0,0,0,0
280,why we need to convert numeric variable into categorical variable in model building,Techniques,why we need to convert numeric variable into categorical variable in model building,"['why', 'we', 'need', 'to', 'convert', 'numeric', 'variable', 'into', 'categorical', 'variable', 'in', 'model', 'building']",0,"['why', 'we', 'need', 'to', 'convert', 'numeric', 'variable', 'into', 'categorical', 'variable', 'in', 'model', 'building']","['need', 'convert', 'numeric', 'variable', 'categorical', 'variable', 'model', 'building']",need convert numeric variable categorical variable model building,0.0,0.0,13,65,4.642857142857143,0,0,0,0,0,0,0,0
281,when can the data contain  for amount and kgs,Techniques,when can the data contain  for amount and kgs,"['when', 'can', 'the', 'data', 'contain', 'for', 'amount', 'and', 'kgs']",1,"['when', 'can', 'the', 'data', 'contain', 'for', 'amount', 'and', 'kg']","['data', 'contain', 'amount', 'kg']",data contain amount kg,0.0,0.0,9,22,2.2,0,0,0,0,0,0,0,0
282,what is a feature mask,Techniques,what is a feature mask,"['what', 'is', 'a', 'feature', 'mask']",0,"['what', 'is', 'a', 'feature', 'mask']","['feature', 'mask']",feature mask,0.0,0.0,5,12,2.0,0,0,0,0,0,0,0,0
283,model fit  validation of a model,Techniques,model fit  validation of a model,"['model', 'fit', 'validation', 'of', 'a', 'model']",0,"['model', 'fit', 'validation', 'of', 'a', 'model']","['model', 'fit', 'validation', 'model']",model fit validation model,0.4,0.4,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
284,which algorithms are good for multi class classification problems,Techniques,which algorithms are good for multi class classification problems,"['which', 'algorithms', 'are', 'good', 'for', 'multi', 'class', 'classification', 'problems']",0,"['which', 'algorithm', 'are', 'good', 'for', 'multi', 'class', 'classification', 'problem']","['algorithm', 'good', 'multi', 'class', 'classification', 'problem']",algorithm good multi class classification problem,0.7,0.7,9,49,4.9,0,0,0,0,0,0,0,0
285,career change after having different experience,Career,career change after having different experience,"['career', 'change', 'after', 'having', 'different', 'experience']",0,"['career', 'change', 'after', 'having', 'different', 'experience']","['career', 'change', 'different', 'experience']",career change different experience,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
286,what is dynamic time warping algorithm,Techniques,what is dynamic time warping algorithm,"['what', 'is', 'dynamic', 'time', 'warping', 'algorithm']",0,"['what', 'is', 'dynamic', 'time', 'warping', 'algorithm']","['dynamic', 'time', 'warping', 'algorithm']",dynamic time warping algorithm,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
287,need help to solve this simple entrylevel problem,Techniques,need help to solve this simple entrylevel problem,"['need', 'help', 'to', 'solve', 'this', 'simple', 'entrylevel', 'problem']",0,"['need', 'help', 'to', 'solve', 'this', 'simple', 'entrylevel', 'problem']","['need', 'help', 'solve', 'simple', 'entrylevel', 'problem']",need help solve simple entrylevel problem,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
288,how to read the association rules to find clustered items,Techniques,how to read the association rules to find clustered items,"['how', 'to', 'read', 'the', 'association', 'rules', 'to', 'find', 'clustered', 'items']",0,"['how', 'to', 'read', 'the', 'association', 'rule', 'to', 'find', 'clustered', 'item']","['read', 'association', 'rule', 'find', 'clustered', 'item']",read association rule find clustered item,0.0,0.0,10,41,3.727272727272727,0,0,0,0,0,0,0,0
289,how to test a hypothesis python  customers with larger fares are more likely to travel alone,Techniques,how to test a hypothesis python  customers with larger fares are more likely to travel alone,"['how', 'to', 'test', 'a', 'hypothesis', 'python', 'customers', 'with', 'larger', 'fares', 'are', 'more', 'likely', 'to', 'travel', 'alone']",0,"['how', 'to', 'test', 'a', 'hypothesis', 'python', 'customer', 'with', 'larger', 'fare', 'are', 'more', 'likely', 'to', 'travel', 'alone']","['test', 'hypothesis', 'python', 'customer', 'larger', 'fare', 'likely', 'travel', 'alone']",test hypothesis python customer larger fare likely travel alone,0.1666666666666666,0.0,16,63,3.7058823529411766,0,0,0,0,0,0,0,0
290,how to interpret the factors in factor analysis,Techniques,how to interpret the factors in factor analysis,"['how', 'to', 'interpret', 'the', 'factors', 'in', 'factor', 'analysis']",0,"['how', 'to', 'interpret', 'the', 'factor', 'in', 'factor', 'analysis']","['interpret', 'factor', 'factor', 'analysis']",interpret factor factor analysis,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
291,feature hashing in r,Techniques,feature hashing in r,"['feature', 'hashing', 'in', 'r']",0,"['feature', 'hashing', 'in', 'r']","['feature', 'hashing', 'r']",feature hashing r,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
292,black friday solution,Hackathons,black friday solution,"['black', 'friday', 'solution']",0,"['black', 'friday', 'solution']","['black', 'friday', 'solution']",black friday solution,-0.1666666666666666,-0.1666666666666666,3,21,5.25,0,0,0,0,0,0,0,0
293,fulljoin function not working in r,Techniques,fulljoin function not working in r,"['fulljoin', 'function', 'not', 'working', 'in', 'r']",0,"['fulljoin', 'function', 'not', 'working', 'in', 'r']","['fulljoin', 'function', 'working', 'r']",fulljoin function working r,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
294,what should be the value of nround in xgboost model,Techniques,what should be the value of nround in xgboost model,"['what', 'should', 'be', 'the', 'value', 'of', 'nround', 'in', 'xgboost', 'model']",0,"['what', 'should', 'be', 'the', 'value', 'of', 'nround', 'in', 'xgboost', 'model']","['value', 'nround', 'xgboost', 'model']",value nround xgboost model,0.0,0.0,10,26,2.3636363636363638,0,0,0,0,0,0,0,0
295,pg diploma in data science from manipal global,Career,pg diploma in data science from manipal global,"['pg', 'diploma', 'in', 'data', 'science', 'from', 'manipal', 'global']",0,"['pg', 'diploma', 'in', 'data', 'science', 'from', 'manipal', 'global']","['pg', 'diploma', 'data', 'science', 'manipal', 'global']",pg diploma data science manipal global,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
296,data visualization – how to pick the right chart type,Other,data visualization – how to pick the right chart type,"['data', 'visualization', '–', 'how', 'to', 'pick', 'the', 'right', 'chart', 'type']",0,"['data', 'visualization', '–', 'how', 'to', 'pick', 'the', 'right', 'chart', 'type']","['data', 'visualization', '–', 'pick', 'right', 'chart', 'type']",data visualization – pick right chart type,0.2857142857142857,0.2857142857142857,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
297,why are features of steel washers normally distributed in a factory making them,Misc,why are features of steel washers normally distributed in a factory making them,"['why', 'are', 'features', 'of', 'steel', 'washers', 'normally', 'distributed', 'in', 'a', 'factory', 'making', 'them']",0,"['why', 'are', 'feature', 'of', 'steel', 'washer', 'normally', 'distributed', 'in', 'a', 'factory', 'making', 'them']","['feature', 'steel', 'washer', 'normally', 'distributed', 'factory', 'making']",feature steel washer normally distributed factory making,0.15,0.15,13,56,4.0,0,0,0,0,0,0,0,0
298,what is difference between bar graph and histogram,Techniques,what is difference between bar graph and histogram,"['what', 'is', 'difference', 'between', 'bar', 'graph', 'and', 'histogram']",0,"['what', 'is', 'difference', 'between', 'bar', 'graph', 'and', 'histogram']","['difference', 'bar', 'graph', 'histogram']",difference bar graph histogram,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
299,admission process for data science from praxis business school,Career,admission process for data science from praxis business school,"['admission', 'process', 'for', 'data', 'science', 'from', 'praxis', 'business', 'school']",0,"['admission', 'process', 'for', 'data', 'science', 'from', 'praxis', 'business', 'school']","['admission', 'process', 'data', 'science', 'praxis', 'business', 'school']",admission process data science praxis business school,0.0,0.0,9,53,5.3,0,0,0,0,0,0,0,0
300,how to compute new distribution in bagging,Techniques,how to compute new distribution in bagging,"['how', 'to', 'compute', 'new', 'distribution', 'in', 'bagging']",0,"['how', 'to', 'compute', 'new', 'distribution', 'in', 'bagging']","['compute', 'new', 'distribution', 'bagging']",compute new distribution bagging,0.1363636363636363,0.1363636363636363,7,32,4.0,0,0,0,0,0,0,0,0
301,how to print heading of fields on every page in excel,Tools,how to print heading of fields on every page in excel,"['how', 'to', 'print', 'heading', 'of', 'fields', 'on', 'every', 'page', 'in', 'excel']",0,"['how', 'to', 'print', 'heading', 'of', 'field', 'on', 'every', 'page', 'in', 'excel']","['print', 'heading', 'field', 'every', 'page', 'excel']",print heading field every page excel,0.0,0.0,11,36,3.0,0,0,0,0,0,0,0,0
302,which significance test to use for categorical data,Techniques,which significance test to use for categorical data,"['which', 'significance', 'test', 'to', 'use', 'for', 'categorical', 'data']",0,"['which', 'significance', 'test', 'to', 'use', 'for', 'categorical', 'data']","['significance', 'test', 'use', 'categorical', 'data']",significance test use categorical data,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
303,open source dashboard tool for visualizations,Tools,open source dashboard tool for visualizations,"['open', 'source', 'dashboard', 'tool', 'for', 'visualizations']",0,"['open', 'source', 'dashboard', 'tool', 'for', 'visualization']","['open', 'source', 'dashboard', 'tool', 'visualization']",open source dashboard tool visualization,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
304,using scrapy to extract actual time from relative time,Techniques,using scrapy to extract actual time from relative time,"['using', 'scrapy', 'to', 'extract', 'actual', 'time', 'from', 'relative', 'time']",0,"['using', 'scrapy', 'to', 'extract', 'actual', 'time', 'from', 'relative', 'time']","['using', 'scrapy', 'extract', 'actual', 'time', 'relative', 'time']",using scrapy extract actual time relative time,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
305,distribution fitting for large scale data in python,Techniques,distribution fitting for large scale data in python,"['distribution', 'fitting', 'for', 'large', 'scale', 'data', 'in', 'python']",0,"['distribution', 'fitting', 'for', 'large', 'scale', 'data', 'in', 'python']","['distribution', 'fitting', 'large', 'scale', 'data', 'python']",distribution fitting large scale data python,0.3571428571428571,0.3571428571428571,8,44,4.888888888888889,0,0,0,0,0,0,0,0
306,ms ds grad school advice,Career,ms ds grad school advice,"['ms', 'ds', 'grad', 'school', 'advice']",0,"['m', 'd', 'grad', 'school', 'advice']","['grad', 'school', 'advice']",grad school advice,0.0,0.0,5,18,3.0,0,0,0,0,0,0,0,0
307,problem in tensorflow cannot feed value of shape    for tensor u’placeholder′ which has shape ‘ ’,Tools,problem in tensorflow cannot feed value of shape    for tensor u’placeholder′ which has shape ‘ ’,"['problem', 'in', 'tensorflow', 'can', 'not', 'feed', 'value', 'of', 'shape', 'for', 'tensor', 'u', '’', 'placeholder′', 'which', 'has', 'shape', '‘', '’']",4,"['problem', 'in', 'tensorflow', 'can', 'not', 'feed', 'value', 'of', 'shape', 'for', 'tensor', 'u', '’', 'placeholder′', 'which', 'ha', 'shape', '‘', '’']","['problem', 'tensorflow', 'feed', 'value', 'shape', 'tensor', 'u', '’', 'placeholder′', 'ha', 'shape', '‘', '’']",problem tensorflow feed value shape tensor u ’ placeholder′ ha shape ‘ ’,0.0,0.0,19,72,3.6,0,0,0,0,0,0,0,0
308,discussions for article a comprehensive beginners guide to create a time series forecast with codes in python,Other,discussions for article a comprehensive beginners guide to create a time series forecast with codes in python,"['discussions', 'for', 'article', 'a', 'comprehensive', 'beginners', 'guide', 'to', 'create', 'a', 'time', 'series', 'forecast', 'with', 'codes', 'in', 'python']",0,"['discussion', 'for', 'article', 'a', 'comprehensive', 'beginner', 'guide', 'to', 'create', 'a', 'time', 'series', 'forecast', 'with', 'code', 'in', 'python']","['discussion', 'article', 'comprehensive', 'beginner', 'guide', 'create', 'time', 'series', 'forecast', 'code', 'python']",discussion article comprehensive beginner guide create time series forecast code python,0.0,0.0,17,87,4.833333333333333,0,0,0,0,0,0,0,0
309,scaling a random forest classifier from  classes to ,Techniques,scaling a random forest classifier from  classes to ,"['scaling', 'a', 'random', 'forest', 'classifier', 'from', 'classes', 'to']",2,"['scaling', 'a', 'random', 'forest', 'classifier', 'from', 'class', 'to']","['scaling', 'random', 'forest', 'classifier', 'class']",scaling random forest classifier class,-0.5,-0.5,8,38,4.222222222222222,0,0,0,0,0,0,0,0
310,how to tabulate unstructured data,Techniques,how to tabulate unstructured data,"['how', 'to', 'tabulate', 'unstructured', 'data']",0,"['how', 'to', 'tabulate', 'unstructured', 'data']","['tabulate', 'unstructured', 'data']",tabulate unstructured data,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
311,r  accuracy and “error in xx  ffn  nonnumeric argument to binary operator”,Tools,r  accuracy and “error in xx  ffn  nonnumeric argument to binary operator”,"['r', 'accuracy', 'and', '“', 'error', 'in', 'xx', 'ffn', 'nonnumeric', 'argument', 'to', 'binary', 'operator', '”']",0,"['r', 'accuracy', 'and', '“', 'error', 'in', 'xx', 'ffn', 'nonnumeric', 'argument', 'to', 'binary', 'operator', '”']","['r', 'accuracy', '“', 'error', 'xx', 'ffn', 'nonnumeric', 'argument', 'binary', 'operator', '”']",r accuracy “ error xx ffn nonnumeric argument binary operator ”,0.0,0.0,14,63,4.2,0,0,0,0,0,0,0,0
312,css corp is hiring machine learning developers,Career,css corp is hiring machine learning developers,"['css', 'corp', 'is', 'hiring', 'machine', 'learning', 'developers']",0,"['cs', 'corp', 'is', 'hiring', 'machine', 'learning', 'developer']","['cs', 'corp', 'hiring', 'machine', 'learning', 'developer']",cs corp hiring machine learning developer,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
313,importance of probability in data science,Techniques,importance of probability in data science,"['importance', 'of', 'probability', 'in', 'data', 'science']",0,"['importance', 'of', 'probability', 'in', 'data', 'science']","['importance', 'probability', 'data', 'science']",importance probability data science,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
314,how can i plot the margins of svm in r,Tools,how can i plot the margins of svm in r,"['how', 'can', 'i', 'plot', 'the', 'margins', 'of', 'svm', 'in', 'r']",0,"['how', 'can', 'i', 'plot', 'the', 'margin', 'of', 'svm', 'in', 'r']","['plot', 'margin', 'svm', 'r']",plot margin svm r,0.0,0.0,10,17,1.5454545454545454,0,0,0,0,0,0,0,0
315,how do i plot the specificity vs sensitivity graph in r,Tools,how do i plot the specificity vs sensitivity graph in r,"['how', 'do', 'i', 'plot', 'the', 'specificity', 'vs', 'sensitivity', 'graph', 'in', 'r']",0,"['how', 'do', 'i', 'plot', 'the', 'specificity', 'v', 'sensitivity', 'graph', 'in', 'r']","['plot', 'specificity', 'v', 'sensitivity', 'graph', 'r']",plot specificity v sensitivity graph r,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
316,understanding the math behind xgboost,Techniques,understanding the math behind xgboost,"['understanding', 'the', 'math', 'behind', 'xgboost']",0,"['understanding', 'the', 'math', 'behind', 'xgboost']","['understanding', 'math', 'behind', 'xgboost']",understanding math behind xgboost,-0.4,-0.4,5,33,5.5,0,0,0,0,0,0,0,0
317,what is the difference between svmradial and lssvmradial in r,Tools,what is the difference between svmradial and lssvmradial in r,"['what', 'is', 'the', 'difference', 'between', 'svmradial', 'and', 'lssvmradial', 'in', 'r']",0,"['what', 'is', 'the', 'difference', 'between', 'svmradial', 'and', 'lssvmradial', 'in', 'r']","['difference', 'svmradial', 'lssvmradial', 'r']",difference svmradial lssvmradial r,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
318,use of different distance measures in knn algorithm,Techniques,use of different distance measures in knn algorithm,"['use', 'of', 'different', 'distance', 'measures', 'in', 'knn', 'algorithm']",0,"['use', 'of', 'different', 'distance', 'measure', 'in', 'knn', 'algorithm']","['use', 'different', 'distance', 'measure', 'knn', 'algorithm']",use different distance measure knn algorithm,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
319,tableau vs qlikview vs msbipowerbi – which tool should i learn,Career,tableau vs qlikview vs msbipowerbi – which tool should i learn,"['tableau', 'vs', 'qlikview', 'vs', 'msbipowerbi', '–', 'which', 'tool', 'should', 'i', 'learn']",0,"['tableau', 'v', 'qlikview', 'v', 'msbipowerbi', '–', 'which', 'tool', 'should', 'i', 'learn']","['tableau', 'v', 'qlikview', 'v', 'msbipowerbi', '–', 'tool', 'learn']",tableau v qlikview v msbipowerbi – tool learn,0.0,0.0,11,45,3.75,0,0,0,0,0,0,0,0
320,misctools rsquared,Techniques,misctools rsquared,"['misctools', 'rsquared']",0,"['misctools', 'rsquared']","['misctools', 'rsquared']",misctools rsquared,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
321,creating a new variable depending on another variable value in r,Tools,creating a new variable depending on another variable value in r,"['creating', 'a', 'new', 'variable', 'depending', 'on', 'another', 'variable', 'value', 'in', 'r']",0,"['creating', 'a', 'new', 'variable', 'depending', 'on', 'another', 'variable', 'value', 'in', 'r']","['creating', 'new', 'variable', 'depending', 'another', 'variable', 'value', 'r']",creating new variable depending another variable value r,0.1363636363636363,0.1363636363636363,11,56,4.666666666666667,0,0,0,0,0,0,0,0
322,how to plot heat map in python,Tools,how to plot heat map in python,"['how', 'to', 'plot', 'heat', 'map', 'in', 'python']",0,"['how', 'to', 'plot', 'heat', 'map', 'in', 'python']","['plot', 'heat', 'map', 'python']",plot heat map python,0.0,0.0,7,20,2.5,0,0,0,0,0,0,0,0
323,postgraduate diploma in statistical methods and analytics,Career,postgraduate diploma in statistical methods and analytics,"['postgraduate', 'diploma', 'in', 'statistical', 'methods', 'and', 'analytics']",0,"['postgraduate', 'diploma', 'in', 'statistical', 'method', 'and', 'analytics']","['postgraduate', 'diploma', 'statistical', 'method', 'analytics']",postgraduate diploma statistical method analytics,0.0,0.0,7,49,6.125,0,0,0,0,0,0,0,0
324,how can i import csv file to tableau public,Tools,how can i import csv file to tableau public,"['how', 'can', 'i', 'import', 'csv', 'file', 'to', 'tableau', 'public']",0,"['how', 'can', 'i', 'import', 'csv', 'file', 'to', 'tableau', 'public']","['import', 'csv', 'file', 'tableau', 'public']",import csv file tableau public,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
325,loading sklearn preprocessing throws error,Tools,loading sklearn preprocessing throws error,"['loading', 'sklearn', 'preprocessing', 'throws', 'error']",0,"['loading', 'sklearn', 'preprocessing', 'throw', 'error']","['loading', 'sklearn', 'preprocessing', 'throw', 'error']",loading sklearn preprocessing throw error,0.0,0.0,5,41,6.833333333333333,0,0,0,0,0,0,0,0
326,yolo algorithm for object detection with bounding boxes,Techniques,yolo algorithm for object detection with bounding boxes,"['yolo', 'algorithm', 'for', 'object', 'detection', 'with', 'bounding', 'boxes']",0,"['yolo', 'algorithm', 'for', 'object', 'detection', 'with', 'bounding', 'box']","['yolo', 'algorithm', 'object', 'detection', 'bounding', 'box']",yolo algorithm object detection bounding box,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
327,sentiment analysis,Techniques,sentiment analysis,"['sentiment', 'analysis']",0,"['sentiment', 'analysis']","['sentiment', 'analysis']",sentiment analysis,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
328,logistic ordinal regression,Techniques,logistic ordinal regression,"['logistic', 'ordinal', 'regression']",0,"['logistic', 'ordinal', 'regression']","['logistic', 'ordinal', 'regression']",logistic ordinal regression,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
329,you tube data extraction,Techniques,you tube data extraction,"['you', 'tube', 'data', 'extraction']",0,"['you', 'tube', 'data', 'extraction']","['tube', 'data', 'extraction']",tube data extraction,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
330,error prediction from a rankdeficient fit may be misleading in glm in r,Tools,error prediction from a rankdeficient fit may be misleading in glm in r,"['error', 'prediction', 'from', 'a', 'rankdeficient', 'fit', 'may', 'be', 'misleading', 'in', 'glm', 'in', 'r']",0,"['error', 'prediction', 'from', 'a', 'rankdeficient', 'fit', 'may', 'be', 'misleading', 'in', 'glm', 'in', 'r']","['error', 'prediction', 'rankdeficient', 'fit', 'may', 'misleading', 'glm', 'r']",error prediction rankdeficient fit may misleading glm r,0.4,0.4,13,55,3.9285714285714284,0,0,0,0,0,0,0,0
331,how to calculate exponential in r,Tools,how to calculate exponential in r,"['how', 'to', 'calculate', 'exponential', 'in', 'r']",0,"['how', 'to', 'calculate', 'exponential', 'in', 'r']","['calculate', 'exponential', 'r']",calculate exponential r,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
332,difference between logical operators  and  in r,Tools,difference between logical operators  and  in r,"['difference', 'between', 'logical', 'operators', 'and', 'in', 'r']",0,"['difference', 'between', 'logical', 'operator', 'and', 'in', 'r']","['difference', 'logical', 'operator', 'r']",difference logical operator r,0.25,0.25,7,29,3.625,0,0,0,0,0,0,0,0
333,resourcestraining for learning data science and r,Resources,resourcestraining for learning data science and r,"['resourcestraining', 'for', 'learning', 'data', 'science', 'and', 'r']",0,"['resourcestraining', 'for', 'learning', 'data', 'science', 'and', 'r']","['resourcestraining', 'learning', 'data', 'science', 'r']",resourcestraining learning data science r,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
334,books for analytics interview preparation,Career,books for analytics interview preparation,"['books', 'for', 'analytics', 'interview', 'preparation']",0,"['book', 'for', 'analytics', 'interview', 'preparation']","['book', 'analytics', 'interview', 'preparation']",book analytics interview preparation,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
335,switching in to big data  hadoop  data analytics,Career,switching in to big data  hadoop  data analytics,"['switching', 'in', 'to', 'big', 'data', 'hadoop', 'data', 'analytics']",0,"['switching', 'in', 'to', 'big', 'data', 'hadoop', 'data', 'analytics']","['switching', 'big', 'data', 'hadoop', 'data', 'analytics']",switching big data hadoop data analytics,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
336,overlaid histograms using ggplot in r,Tools,overlaid histograms using ggplot in r,"['overlaid', 'histograms', 'using', 'ggplot', 'in', 'r']",0,"['overlaid', 'histogram', 'using', 'ggplot', 'in', 'r']","['overlaid', 'histogram', 'using', 'ggplot', 'r']",overlaid histogram using ggplot r,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
337,what does the warning message prediction from a rankdeficient fit mean in logistic regression,Techniques,what does the warning message prediction from a rankdeficient fit mean in logistic regression,"['what', 'does', 'the', 'warning', 'message', 'prediction', 'from', 'a', 'rankdeficient', 'fit', 'mean', 'in', 'logistic', 'regression']",0,"['what', 'doe', 'the', 'warning', 'message', 'prediction', 'from', 'a', 'rankdeficient', 'fit', 'mean', 'in', 'logistic', 'regression']","['doe', 'warning', 'message', 'prediction', 'rankdeficient', 'fit', 'mean', 'logistic', 'regression']",doe warning message prediction rankdeficient fit mean logistic regression,0.04375,0.04375,14,73,4.866666666666666,0,0,0,0,0,0,0,0
338,need suggestions for machine learning training institutes,Career,need suggestions for machine learning training institutes,"['need', 'suggestions', 'for', 'machine', 'learning', 'training', 'institutes']",0,"['need', 'suggestion', 'for', 'machine', 'learning', 'training', 'institute']","['need', 'suggestion', 'machine', 'learning', 'training', 'institute']",need suggestion machine learning training institute,0.0,0.0,7,51,6.375,0,0,0,0,0,0,0,0
339,churn prediction bank of gardenia hackathon,Hackathons,churn prediction bank of gardenia hackathon,"['churn', 'prediction', 'bank', 'of', 'gardenia', 'hackathon']",0,"['churn', 'prediction', 'bank', 'of', 'gardenia', 'hackathon']","['churn', 'prediction', 'bank', 'gardenia', 'hackathon']",churn prediction bank gardenia hackathon,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
340,is it possible for you to predict the stock markets,Techniques,is it possible for you to predict the stock markets,"['is', 'it', 'possible', 'for', 'you', 'to', 'predict', 'the', 'stock', 'markets']",0,"['is', 'it', 'possible', 'for', 'you', 'to', 'predict', 'the', 'stock', 'market']","['possible', 'predict', 'stock', 'market']",possible predict stock market,0.0,0.0,10,29,2.6363636363636362,0,0,0,0,0,0,0,0
341,how to sort values based on given order of categories in excel,Tools,how to sort values based on given order of categories in excel,"['how', 'to', 'sort', 'values', 'based', 'on', 'given', 'order', 'of', 'categories', 'in', 'excel']",0,"['how', 'to', 'sort', 'value', 'based', 'on', 'given', 'order', 'of', 'category', 'in', 'excel']","['sort', 'value', 'based', 'given', 'order', 'category', 'excel']",sort value based given order category excel,0.0,0.0,12,43,3.3076923076923075,0,0,0,0,0,0,0,0
342,what is adjusted r squared in anova,Techniques,what is adjusted r squared in anova,"['what', 'is', 'adjusted', 'r', 'squared', 'in', 'anova']",0,"['what', 'is', 'adjusted', 'r', 'squared', 'in', 'anova']","['adjusted', 'r', 'squared', 'anova']",adjusted r squared anova,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
343,how to find mape metric in python,Techniques,how to find mape metric in python,"['how', 'to', 'find', 'mape', 'metric', 'in', 'python']",0,"['how', 'to', 'find', 'mape', 'metric', 'in', 'python']","['find', 'mape', 'metric', 'python']",find mape metric python,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
344,error  cannot rescale a constantzero column to unit variance,Techniques,error  cannot rescale a constantzero column to unit variance,"['error', 'can', 'not', 'rescale', 'a', 'constantzero', 'column', 'to', 'unit', 'variance']",0,"['error', 'can', 'not', 'rescale', 'a', 'constantzero', 'column', 'to', 'unit', 'variance']","['error', 'rescale', 'constantzero', 'column', 'unit', 'variance']",error rescale constantzero column unit variance,0.0,0.0,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
345,how can i display the sorting symbol in table generated using dtablefilter package,Tools,how can i display the sorting symbol in table generated using dtablefilter package,"['how', 'can', 'i', 'display', 'the', 'sorting', 'symbol', 'in', 'table', 'generated', 'using', 'dtablefilter', 'package']",0,"['how', 'can', 'i', 'display', 'the', 'sorting', 'symbol', 'in', 'table', 'generated', 'using', 'dtablefilter', 'package']","['display', 'sorting', 'symbol', 'table', 'generated', 'using', 'dtablefilter', 'package']",display sorting symbol table generated using dtablefilter package,0.0,0.0,13,65,4.642857142857143,0,0,0,0,0,0,0,0
346,data warehouse  bi tool,Tools,data warehouse  bi tool,"['data', 'warehouse', 'bi', 'tool']",0,"['data', 'warehouse', 'bi', 'tool']","['data', 'warehouse', 'bi', 'tool']",data warehouse bi tool,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
347,labels on xaxis are overlapping in bar plot how to fix it,Tools,labels on xaxis are overlapping in bar plot how to fix it,"['labels', 'on', 'xaxis', 'are', 'overlapping', 'in', 'bar', 'plot', 'how', 'to', 'fix', 'it']",0,"['label', 'on', 'xaxis', 'are', 'overlapping', 'in', 'bar', 'plot', 'how', 'to', 'fix', 'it']","['label', 'xaxis', 'overlapping', 'bar', 'plot', 'fix']",label xaxis overlapping bar plot fix,0.0,0.0,12,36,2.769230769230769,0,0,0,0,0,0,0,0
348,how to merge two csv file into a one data frame in r,Tools,how to merge two csv file into a one data frame in r,"['how', 'to', 'merge', 'two', 'csv', 'file', 'into', 'a', 'one', 'data', 'frame', 'in', 'r']",0,"['how', 'to', 'merge', 'two', 'csv', 'file', 'into', 'a', 'one', 'data', 'frame', 'in', 'r']","['merge', 'two', 'csv', 'file', 'one', 'data', 'frame', 'r']",merge two csv file one data frame r,0.0,0.0,13,35,2.5,0,0,0,0,0,0,0,0
349,how do i access sas files directly from qlikview,Tools,how do i access sas files directly from qlikview,"['how', 'do', 'i', 'access', 'sas', 'files', 'directly', 'from', 'qlikview']",0,"['how', 'do', 'i', 'access', 'sa', 'file', 'directly', 'from', 'qlikview']","['access', 'sa', 'file', 'directly', 'qlikview']",access sa file directly qlikview,0.1,0.1,9,32,3.2,0,0,0,0,0,0,0,0
350,statistics in machine learning,Techniques,statistics in machine learning,"['statistics', 'in', 'machine', 'learning']",0,"['statistic', 'in', 'machine', 'learning']","['statistic', 'machine', 'learning']",statistic machine learning,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
351,how to transpose the higher dimension matrix in ipython,Tools,how to transpose the higher dimension matrix in ipython,"['how', 'to', 'transpose', 'the', 'higher', 'dimension', 'matrix', 'in', 'ipython']",0,"['how', 'to', 'transpose', 'the', 'higher', 'dimension', 'matrix', 'in', 'ipython']","['transpose', 'higher', 'dimension', 'matrix', 'ipython']",transpose higher dimension matrix ipython,0.25,0.25,9,41,4.1,0,0,0,0,0,0,0,0
352,calculating aicbic values of model in python sklearn,Techniques,calculating aicbic values of model in python sklearn,"['calculating', 'aicbic', 'values', 'of', 'model', 'in', 'python', 'sklearn']",0,"['calculating', 'aicbic', 'value', 'of', 'model', 'in', 'python', 'sklearn']","['calculating', 'aicbic', 'value', 'model', 'python', 'sklearn']",calculating aicbic value model python sklearn,0.0,0.0,8,45,5.0,0,0,0,0,0,0,0,0
353,take users input in predict function,Techniques,take users input in predict function,"['take', 'users', 'input', 'in', 'predict', 'function']",0,"['take', 'user', 'input', 'in', 'predict', 'function']","['take', 'user', 'input', 'predict', 'function']",take user input predict function,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
354,knocktober  sharing solutions,Hackathons,knocktober  sharing solutions,"['knocktober', 'sharing', 'solutions']",0,"['knocktober', 'sharing', 'solution']","['knocktober', 'sharing', 'solution']",knocktober sharing solution,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
355,take this test  are you meant to become a data scientist,Career,take this test  are you meant to become a data scientist,"['take', 'this', 'test', 'are', 'you', 'meant', 'to', 'become', 'a', 'data', 'scientist']",0,"['take', 'this', 'test', 'are', 'you', 'meant', 'to', 'become', 'a', 'data', 'scientist']","['take', 'test', 'meant', 'become', 'data', 'scientist']",take test meant become data scientist,0.0,0.0,11,37,3.0833333333333335,0,0,0,0,0,0,0,0
356,what is the difference between ar and ma time series models,Techniques,what is the difference between ar and ma time series models,"['what', 'is', 'the', 'difference', 'between', 'ar', 'and', 'ma', 'time', 'series', 'models']",0,"['what', 'is', 'the', 'difference', 'between', 'ar', 'and', 'ma', 'time', 'series', 'model']","['difference', 'ar', 'time', 'series', 'model']",difference ar time series model,0.0,0.0,11,31,2.5833333333333335,0,0,0,0,0,0,0,0
357,hdf vs mdf a suitable file format for big data analytics,Tools,hdf vs mdf a suitable file format for big data analytics,"['hdf', 'vs', 'mdf', 'a', 'suitable', 'file', 'format', 'for', 'big', 'data', 'analytics']",0,"['hdf', 'v', 'mdf', 'a', 'suitable', 'file', 'format', 'for', 'big', 'data', 'analytics']","['hdf', 'v', 'mdf', 'suitable', 'file', 'format', 'big', 'data', 'analytics']",hdf v mdf suitable file format big data analytics,0.275,0.275,11,49,4.083333333333333,0,0,0,0,0,0,0,0
358,unable to export ipython notebook as pdf,Tools,unable to export ipython notebook as pdf,"['unable', 'to', 'export', 'ipython', 'notebook', 'as', 'pdf']",0,"['unable', 'to', 'export', 'ipython', 'notebook', 'a', 'pdf']","['unable', 'export', 'ipython', 'notebook', 'pdf']",unable export ipython notebook pdf,-0.5,-0.5,7,34,4.25,0,0,0,0,0,0,0,0
359,what does modexmode mean,Hackathons,what does modexmode mean,"['what', 'does', 'modexmode', 'mean']",0,"['what', 'doe', 'modexmode', 'mean']","['doe', 'modexmode', 'mean']",doe modexmode mean,-0.3125,-0.3125,4,18,3.6,0,0,0,0,0,0,0,0
360,difference between hdfs and hbase,Techniques,difference between hdfs and hbase,"['difference', 'between', 'hdfs', 'and', 'hbase']",0,"['difference', 'between', 'hdfs', 'and', 'hbase']","['difference', 'hdfs', 'hbase']",difference hdfs hbase,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
361,alternative to checking predictions on datahack,Hackathons,alternative to checking predictions on datahack,"['alternative', 'to', 'checking', 'predictions', 'on', 'datahack']",0,"['alternative', 'to', 'checking', 'prediction', 'on', 'datahack']","['alternative', 'checking', 'prediction', 'datahack']",alternative checking prediction datahack,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
362,why clinical sas training is important,Career,why clinical sas training is important,"['why', 'clinical', 'sas', 'training', 'is', 'important']",0,"['why', 'clinical', 'sa', 'training', 'is', 'important']","['clinical', 'sa', 'training', 'important']",clinical sa training important,0.4,0.4,6,30,4.285714285714286,0,0,0,0,0,0,0,0
363,do you think msc data science fresher can participate in hackathon,Career,do you think msc data science fresher can participate in hackathon,"['do', 'you', 'think', 'msc', 'data', 'science', 'fresher', 'can', 'participate', 'in', 'hackathon']",0,"['do', 'you', 'think', 'msc', 'data', 'science', 'fresher', 'can', 'participate', 'in', 'hackathon']","['think', 'msc', 'data', 'science', 'fresher', 'participate', 'hackathon']",think msc data science fresher participate hackathon,0.0,0.0,11,52,4.333333333333333,0,0,0,0,0,0,0,0
364,how to apply conditions for preparing conjoint cards in conjoint analysis in r,Techniques,how to apply conditions for preparing conjoint cards in conjoint analysis in r,"['how', 'to', 'apply', 'conditions', 'for', 'preparing', 'conjoint', 'cards', 'in', 'conjoint', 'analysis', 'in', 'r']",0,"['how', 'to', 'apply', 'condition', 'for', 'preparing', 'conjoint', 'card', 'in', 'conjoint', 'analysis', 'in', 'r']","['apply', 'condition', 'preparing', 'conjoint', 'card', 'conjoint', 'analysis', 'r']",apply condition preparing conjoint card conjoint analysis r,0.0,0.0,13,59,4.214285714285714,0,0,0,0,0,0,0,0
365,analysis of variance anova,Techniques,analysis of variance anova,"['analysis', 'of', 'variance', 'anova']",0,"['analysis', 'of', 'variance', 'anova']","['analysis', 'variance', 'anova']",analysis variance anova,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
366,using a modified kernel in svm using python,Techniques,using a modified kernel in svm using python,"['using', 'a', 'modified', 'kernel', 'in', 'svm', 'using', 'python']",0,"['using', 'a', 'modified', 'kernel', 'in', 'svm', 'using', 'python']","['using', 'modified', 'kernel', 'svm', 'using', 'python']",using modified kernel svm using python,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
367,cumulative gain charts and qini curve limitations,Techniques,cumulative gain charts and qini curve limitations,"['cumulative', 'gain', 'charts', 'and', 'qini', 'curve', 'limitations']",0,"['cumulative', 'gain', 'chart', 'and', 'qini', 'curve', 'limitation']","['cumulative', 'gain', 'chart', 'qini', 'curve', 'limitation']",cumulative gain chart qini curve limitation,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
368,kaggle titanic logistic regression  higher cross validation scores results in lower accuracy on submission,Techniques,kaggle titanic logistic regression  higher cross validation scores results in lower accuracy on submission,"['kaggle', 'titanic', 'logistic', 'regression', 'higher', 'cross', 'validation', 'scores', 'results', 'in', 'lower', 'accuracy', 'on', 'submission']",0,"['kaggle', 'titanic', 'logistic', 'regression', 'higher', 'cross', 'validation', 'score', 'result', 'in', 'lower', 'accuracy', 'on', 'submission']","['kaggle', 'titanic', 'logistic', 'regression', 'higher', 'cross', 'validation', 'score', 'result', 'lower', 'accuracy', 'submission']",kaggle titanic logistic regression higher cross validation score result lower accuracy submission,0.125,0.125,14,97,6.466666666666667,0,0,0,0,0,0,0,0
369,multiple dependant variable issue,Techniques,multiple dependant variable issue,"['multiple', 'dependant', 'variable', 'issue']",0,"['multiple', 'dependant', 'variable', 'issue']","['multiple', 'dependant', 'variable', 'issue']",multiple dependant variable issue,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
370,how to resolve error while using truncatedsvd in python,Tools,how to resolve error while using truncatedsvd in python,"['how', 'to', 'resolve', 'error', 'while', 'using', 'truncatedsvd', 'in', 'python']",0,"['how', 'to', 'resolve', 'error', 'while', 'using', 'truncatedsvd', 'in', 'python']","['resolve', 'error', 'using', 'truncatedsvd', 'python']",resolve error using truncatedsvd python,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
371,tests to determine the goodness of fit of a model,Techniques,tests to determine the goodness of fit of a model,"['tests', 'to', 'determine', 'the', 'goodness', 'of', 'fit', 'of', 'a', 'model']",0,"['test', 'to', 'determine', 'the', 'goodness', 'of', 'fit', 'of', 'a', 'model']","['test', 'determine', 'goodness', 'fit', 'model']",test determine goodness fit model,0.4,0.4,10,33,3.0,0,0,0,0,0,0,0,0
372,unable to impute missing values through mice for categorical variables,Techniques,unable to impute missing values through mice for categorical variables,"['unable', 'to', 'impute', 'missing', 'values', 'through', 'mice', 'for', 'categorical', 'variables']",0,"['unable', 'to', 'impute', 'missing', 'value', 'through', 'mouse', 'for', 'categorical', 'variable']","['unable', 'impute', 'missing', 'value', 'mouse', 'categorical', 'variable']",unable impute missing value mouse categorical variable,-0.35,-0.35,10,54,4.909090909090909,0,0,0,0,0,0,0,0
373,does random forest algorithm face overfitting issues why,Techniques,does random forest algorithm face overfitting issues why,"['does', 'random', 'forest', 'algorithm', 'face', 'overfitting', 'issues', 'why']",0,"['doe', 'random', 'forest', 'algorithm', 'face', 'overfitting', 'issue', 'why']","['doe', 'random', 'forest', 'algorithm', 'face', 'overfitting', 'issue']",doe random forest algorithm face overfitting issue,-0.5,-0.5,8,50,5.555555555555555,0,0,0,0,0,0,0,0
374,automate time series forecastingusing r,Tools,automate time series forecastingusing r,"['automate', 'time', 'series', 'forecastingusing', 'r']",0,"['automate', 'time', 'series', 'forecastingusing', 'r']","['automate', 'time', 'series', 'forecastingusing', 'r']",automate time series forecastingusing r,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
375,valueerror cannot add integral value to timestamp without freq,Other,valueerror cannot add integral value to timestamp without freq,"['valueerror', 'can', 'not', 'add', 'integral', 'value', 'to', 'timestamp', 'without', 'freq']",0,"['valueerror', 'can', 'not', 'add', 'integral', 'value', 'to', 'timestamp', 'without', 'freq']","['valueerror', 'add', 'integral', 'value', 'timestamp', 'without', 'freq']",valueerror add integral value timestamp without freq,0.0,0.0,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
376,knn how to caculate false negative for a multiple class problem,Techniques,knn how to caculate false negative for a multiple class problem,"['knn', 'how', 'to', 'caculate', 'false', 'negative', 'for', 'a', 'multiple', 'class', 'problem']",0,"['knn', 'how', 'to', 'caculate', 'false', 'negative', 'for', 'a', 'multiple', 'class', 'problem']","['knn', 'caculate', 'false', 'negative', 'multiple', 'class', 'problem']",knn caculate false negative multiple class problem,-0.2333333333333333,-0.2333333333333333,11,50,4.166666666666667,0,0,0,0,0,0,0,0
377,hoglm for regression problem,Techniques,hoglm for regression problem,"['hoglm', 'for', 'regression', 'problem']",0,"['hoglm', 'for', 'regression', 'problem']","['hoglm', 'regression', 'problem']",hoglm regression problem,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
378,solution or path to build best model,Techniques,solution or path to build best model,"['solution', 'or', 'path', 'to', 'build', 'best', 'model']",0,"['solution', 'or', 'path', 'to', 'build', 'best', 'model']","['solution', 'path', 'build', 'best', 'model']",solution path build best model,1.0,1.0,7,30,3.75,0,0,0,0,0,0,0,0
379,p value and the corresponding type  error,Misc,p value and the corresponding type  error,"['p', 'value', 'and', 'the', 'corresponding', 'type', 'error']",1,"['p', 'value', 'and', 'the', 'corresponding', 'type', 'error']","['p', 'value', 'corresponding', 'type', 'error']",p value corresponding type error,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
380,categorial data feature engineering,Techniques,categorial data feature engineering,"['categorial', 'data', 'feature', 'engineering']",0,"['categorial', 'data', 'feature', 'engineering']","['categorial', 'data', 'feature', 'engineering']",categorial data feature engineering,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
381,how to fill the missing value of a series in python,Tools,how to fill the missing value of a series in python,"['how', 'to', 'fill', 'the', 'missing', 'value', 'of', 'a', 'series', 'in', 'python']",0,"['how', 'to', 'fill', 'the', 'missing', 'value', 'of', 'a', 'series', 'in', 'python']","['fill', 'missing', 'value', 'series', 'python']",fill missing value series python,-0.2,-0.2,11,32,2.6666666666666665,0,0,0,0,0,0,0,0
382,how do i take only a fraction of the data while reading in the csv file in r,Tools,how do i take only a fraction of the data while reading in the csv file in r,"['how', 'do', 'i', 'take', 'only', 'a', 'fraction', 'of', 'the', 'data', 'while', 'reading', 'in', 'the', 'csv', 'file', 'in', 'r']",0,"['how', 'do', 'i', 'take', 'only', 'a', 'fraction', 'of', 'the', 'data', 'while', 'reading', 'in', 'the', 'csv', 'file', 'in', 'r']","['take', 'fraction', 'data', 'reading', 'csv', 'file', 'r']",take fraction data reading csv file r,0.0,0.0,18,37,1.9473684210526316,0,0,0,0,0,0,0,0
383,how to get the linear line in svm using r,Techniques,how to get the linear line in svm using r,"['how', 'to', 'get', 'the', 'linear', 'line', 'in', 'svm', 'using', 'r']",0,"['how', 'to', 'get', 'the', 'linear', 'line', 'in', 'svm', 'using', 'r']","['get', 'linear', 'line', 'svm', 'using', 'r']",get linear line svm using r,0.0,0.0,10,27,2.4545454545454546,0,0,0,0,0,0,0,0
384,modelling technique for categorical predictor and continuous target,Techniques,modelling technique for categorical predictor and continuous target,"['modelling', 'technique', 'for', 'categorical', 'predictor', 'and', 'continuous', 'target']",0,"['modelling', 'technique', 'for', 'categorical', 'predictor', 'and', 'continuous', 'target']","['modelling', 'technique', 'categorical', 'predictor', 'continuous', 'target']",modelling technique categorical predictor continuous target,0.0,0.0,8,59,6.555555555555555,0,0,0,0,0,0,0,0
385,how to resolve python error the first argument of bincount must be nonnegative,Tools,how to resolve python error the first argument of bincount must be nonnegative,"['how', 'to', 'resolve', 'python', 'error', 'the', 'first', 'argument', 'of', 'bincount', 'must', 'be', 'nonnegative']",0,"['how', 'to', 'resolve', 'python', 'error', 'the', 'first', 'argument', 'of', 'bincount', 'must', 'be', 'nonnegative']","['resolve', 'python', 'error', 'first', 'argument', 'bincount', 'must', 'nonnegative']",resolve python error first argument bincount must nonnegative,0.25,0.25,13,61,4.357142857142857,0,0,0,0,0,0,0,0
386,how to install boruta package for python on windows,Techniques,how to install boruta package for python on windows,"['how', 'to', 'install', 'boruta', 'package', 'for', 'python', 'on', 'windows']",0,"['how', 'to', 'install', 'boruta', 'package', 'for', 'python', 'on', 'window']","['install', 'boruta', 'package', 'python', 'window']",install boruta package python window,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
387,how svm performs nonlinear classification,Techniques,how svm performs nonlinear classification,"['how', 'svm', 'performs', 'nonlinear', 'classification']",0,"['how', 'svm', 'performs', 'nonlinear', 'classification']","['svm', 'performs', 'nonlinear', 'classification']",svm performs nonlinear classification,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
388,good books for statistics and data science for beginners,Resources,good books for statistics and data science for beginners,"['good', 'books', 'for', 'statistics', 'and', 'data', 'science', 'for', 'beginners']",0,"['good', 'book', 'for', 'statistic', 'and', 'data', 'science', 'for', 'beginner']","['good', 'book', 'statistic', 'data', 'science', 'beginner']",good book statistic data science beginner,0.7,0.7,9,41,4.1,0,0,0,0,0,0,0,0
389,faster way to search in a datatable in r,Techniques,faster way to search in a datatable in r,"['faster', 'way', 'to', 'search', 'in', 'a', 'datatable', 'in', 'r']",0,"['faster', 'way', 'to', 'search', 'in', 'a', 'datatable', 'in', 'r']","['faster', 'way', 'search', 'datatable', 'r']",faster way search datatable r,0.0,0.0,9,29,2.9,0,0,0,0,0,0,0,0
390,using resnet  caffe model for face detection with python,Techniques,using resnet  caffe model for face detection with python,"['using', 'resnet', 'caffe', 'model', 'for', 'face', 'detection', 'with', 'python']",1,"['using', 'resnet', 'caffe', 'model', 'for', 'face', 'detection', 'with', 'python']","['using', 'resnet', 'caffe', 'model', 'face', 'detection', 'python']",using resnet caffe model face detection python,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
391,if loop in r for finding the position of column,Techniques,if loop in r for finding the position of column,"['if', 'loop', 'in', 'r', 'for', 'finding', 'the', 'position', 'of', 'column']",0,"['if', 'loop', 'in', 'r', 'for', 'finding', 'the', 'position', 'of', 'column']","['loop', 'r', 'finding', 'position', 'column']",loop r finding position column,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
392,comparing two vectors and arrange one elements of vector with respect other vector if not in same order,Tools,comparing two vectors and arrange one elements of vector with respect other vector if not in same order,"['comparing', 'two', 'vectors', 'and', 'arrange', 'one', 'elements', 'of', 'vector', 'with', 'respect', 'other', 'vector', 'if', 'not', 'in', 'same', 'order']",0,"['comparing', 'two', 'vector', 'and', 'arrange', 'one', 'element', 'of', 'vector', 'with', 'respect', 'other', 'vector', 'if', 'not', 'in', 'same', 'order']","['comparing', 'two', 'vector', 'arrange', 'one', 'element', 'vector', 'respect', 'vector', 'order']",comparing two vector arrange one element vector respect vector order,-0.0625,0.0,18,68,3.5789473684210527,0,0,0,0,0,0,0,0
393,how to import random rows from a large csv in python,Tools,how to import random rows from a large csv in python,"['how', 'to', 'import', 'random', 'rows', 'from', 'a', 'large', 'csv', 'in', 'python']",0,"['how', 'to', 'import', 'random', 'row', 'from', 'a', 'large', 'csv', 'in', 'python']","['import', 'random', 'row', 'large', 'csv', 'python']",import random row large csv python,-0.1428571428571428,-0.1428571428571428,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
394,mini hack  strategic thinking problem set,Hackathons,mini hack  strategic thinking problem set,"['mini', 'hack', 'strategic', 'thinking', 'problem', 'set']",0,"['mini', 'hack', 'strategic', 'thinking', 'problem', 'set']","['mini', 'hack', 'strategic', 'thinking', 'problem', 'set']",mini hack strategic thinking problem set,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
395,how to apply gradient boosting technique on loan prediction hack,Hackathons,how to apply gradient boosting technique on loan prediction hack,"['how', 'to', 'apply', 'gradient', 'boosting', 'technique', 'on', 'loan', 'prediction', 'hack']",0,"['how', 'to', 'apply', 'gradient', 'boosting', 'technique', 'on', 'loan', 'prediction', 'hack']","['apply', 'gradient', 'boosting', 'technique', 'loan', 'prediction', 'hack']",apply gradient boosting technique loan prediction hack,0.0,0.0,10,54,4.909090909090909,0,0,0,0,0,0,0,0
396,coding open ended questions in r  text classification,Techniques,coding open ended questions in r  text classification,"['coding', 'open', 'ended', 'questions', 'in', 'r', 'text', 'classification']",0,"['coding', 'open', 'ended', 'question', 'in', 'r', 'text', 'classification']","['coding', 'open', 'ended', 'question', 'r', 'text', 'classification']",coding open ended question r text classification,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
397,how is value assigned to a variable in r,Tools,how is value assigned to a variable in r,"['how', 'is', 'value', 'assigned', 'to', 'a', 'variable', 'in', 'r']",0,"['how', 'is', 'value', 'assigned', 'to', 'a', 'variable', 'in', 'r']","['value', 'assigned', 'variable', 'r']",value assigned variable r,0.0,0.0,9,25,2.5,0,0,0,0,0,0,0,0
398,r studio cheat sheet,Tools,r studio cheat sheet,"['r', 'studio', 'cheat', 'sheet']",0,"['r', 'studio', 'cheat', 'sheet']","['r', 'studio', 'cheat', 'sheet']",r studio cheat sheet,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
399,movielens algo query,Techniques,movielens algo query,"['movielens', 'algo', 'query']",0,"['movielens', 'algo', 'query']","['movielens', 'algo', 'query']",movielens algo query,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
400,how to retrieve documents after latent dirichlet allocation,Techniques,how to retrieve documents after latent dirichlet allocation,"['how', 'to', 'retrieve', 'documents', 'after', 'latent', 'dirichlet', 'allocation']",0,"['how', 'to', 'retrieve', 'document', 'after', 'latent', 'dirichlet', 'allocation']","['retrieve', 'document', 'latent', 'dirichlet', 'allocation']",retrieve document latent dirichlet allocation,0.0,0.0,8,45,5.0,0,0,0,0,0,0,0,0
401,how to take data from one csv to another csv file based on some common entity,Techniques,how to take data from one csv to another csv file based on some common entity,"['how', 'to', 'take', 'data', 'from', 'one', 'csv', 'to', 'another', 'csv', 'file', 'based', 'on', 'some', 'common', 'entity']",0,"['how', 'to', 'take', 'data', 'from', 'one', 'csv', 'to', 'another', 'csv', 'file', 'based', 'on', 'some', 'common', 'entity']","['take', 'data', 'one', 'csv', 'another', 'csv', 'file', 'based', 'common', 'entity']",take data one csv another csv file based common entity,-0.3,-0.3,16,54,3.176470588235294,0,0,0,0,0,0,0,0
402,not able to submit solution file in big mart sales,Misc,not able to submit solution file in big mart sales,"['not', 'able', 'to', 'submit', 'solution', 'file', 'in', 'big', 'mart', 'sales']",0,"['not', 'able', 'to', 'submit', 'solution', 'file', 'in', 'big', 'mart', 'sale']","['able', 'submit', 'solution', 'file', 'big', 'mart', 'sale']",able submit solution file big mart sale,-0.125,0.25,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
403,need help with simple r implementation to generate interactions and do normalization,Tools,need help with simple r implementation to generate interactions and do normalization,"['need', 'help', 'with', 'simple', 'r', 'implementation', 'to', 'generate', 'interactions', 'and', 'do', 'normalization']",0,"['need', 'help', 'with', 'simple', 'r', 'implementation', 'to', 'generate', 'interaction', 'and', 'do', 'normalization']","['need', 'help', 'simple', 'r', 'implementation', 'generate', 'interaction', 'normalization']",need help simple r implementation generate interaction normalization,0.0,0.0,12,68,5.230769230769231,0,0,0,0,0,0,0,0
404,shiny locally working but on shinyappio grey out,Tools,shiny locally working but on shinyappio grey out,"['shiny', 'locally', 'working', 'but', 'on', 'shinyappio', 'grey', 'out']",0,"['shiny', 'locally', 'working', 'but', 'on', 'shinyappio', 'grey', 'out']","['shiny', 'locally', 'working', 'shinyappio', 'grey']",shiny locally working shinyappio grey,-0.025,-0.025,8,37,4.111111111111111,0,0,0,0,0,0,0,0
405,how to protect sas code,Tools,how to protect sas code,"['how', 'to', 'protect', 'sas', 'code']",0,"['how', 'to', 'protect', 'sa', 'code']","['protect', 'sa', 'code']",protect sa code,0.0,0.0,5,15,2.5,0,0,0,0,0,0,0,0
406,how to do data imputations  multiple imputations and maximum likelihood in python,Hackathons,how to do data imputations  multiple imputations and maximum likelihood in python,"['how', 'to', 'do', 'data', 'imputations', 'multiple', 'imputations', 'and', 'maximum', 'likelihood', 'in', 'python']",0,"['how', 'to', 'do', 'data', 'imputation', 'multiple', 'imputation', 'and', 'maximum', 'likelihood', 'in', 'python']","['data', 'imputation', 'multiple', 'imputation', 'maximum', 'likelihood', 'python']",data imputation multiple imputation maximum likelihood python,0.0,0.0,12,61,4.6923076923076925,0,0,0,0,0,0,0,0
407,which tools to learn for pharma analytics,Career,which tools to learn for pharma analytics,"['which', 'tools', 'to', 'learn', 'for', 'pharma', 'analytics']",0,"['which', 'tool', 'to', 'learn', 'for', 'pharma', 'analytics']","['tool', 'learn', 'pharma', 'analytics']",tool learn pharma analytics,0.0,0.0,7,27,3.375,0,0,0,0,0,0,0,0
408,calculate pdq for seasonal arima,Techniques,calculate pdq for seasonal arima,"['calculate', 'pdq', 'for', 'seasonal', 'arima']",0,"['calculate', 'pdq', 'for', 'seasonal', 'arima']","['calculate', 'pdq', 'seasonal', 'arima']",calculate pdq seasonal arima,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
409,how to build frequency table in r,Tools,how to build frequency table in r,"['how', 'to', 'build', 'frequency', 'table', 'in', 'r']",0,"['how', 'to', 'build', 'frequency', 'table', 'in', 'r']","['build', 'frequency', 'table', 'r']",build frequency table r,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
410,simple beer recommendation system using cosine similarity,Techniques,simple beer recommendation system using cosine similarity,"['simple', 'beer', 'recommendation', 'system', 'using', 'cosine', 'similarity']",0,"['simple', 'beer', 'recommendation', 'system', 'using', 'cosine', 'similarity']","['simple', 'beer', 'recommendation', 'system', 'using', 'cosine', 'similarity']",simple beer recommendation system using cosine similarity,0.0,0.0,7,57,7.125,0,0,0,0,0,0,0,0
411,explanation of auc roc metric,Techniques,explanation of auc roc metric,"['explanation', 'of', 'auc', 'roc', 'metric']",0,"['explanation', 'of', 'auc', 'roc', 'metric']","['explanation', 'auc', 'roc', 'metric']",explanation auc roc metric,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
412,how to enter into analytics domain from some other technical domain,Career,how to enter into analytics domain from some other technical domain,"['how', 'to', 'enter', 'into', 'analytics', 'domain', 'from', 'some', 'other', 'technical', 'domain']",0,"['how', 'to', 'enter', 'into', 'analytics', 'domain', 'from', 'some', 'other', 'technical', 'domain']","['enter', 'analytics', 'domain', 'technical', 'domain']",enter analytics domain technical domain,-0.0625,0.0,11,39,3.25,0,0,0,0,0,0,0,0
413,error in proc sql while using group by,Tools,error in proc sql while using group by,"['error', 'in', 'proc', 'sql', 'while', 'using', 'group', 'by']",0,"['error', 'in', 'proc', 'sql', 'while', 'using', 'group', 'by']","['error', 'proc', 'sql', 'using', 'group']",error proc sql using group,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
414,can i prevent someone from copying the cell from worksheet in excel,Tools,can i prevent someone from copying the cell from worksheet in excel,"['can', 'i', 'prevent', 'someone', 'from', 'copying', 'the', 'cell', 'from', 'worksheet', 'in', 'excel']",0,"['can', 'i', 'prevent', 'someone', 'from', 'copying', 'the', 'cell', 'from', 'worksheet', 'in', 'excel']","['prevent', 'someone', 'copying', 'cell', 'worksheet', 'excel']",prevent someone copying cell worksheet excel,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
415,how to start coding in r,Tools,how to start coding in r,"['how', 'to', 'start', 'coding', 'in', 'r']",0,"['how', 'to', 'start', 'coding', 'in', 'r']","['start', 'coding', 'r']",start coding r,0.0,0.0,6,14,2.0,0,0,0,0,0,0,0,0
416,discussions for article  types of regression techniques you should know,Other,discussions for article  types of regression techniques you should know,"['discussions', 'for', 'article', 'types', 'of', 'regression', 'techniques', 'you', 'should', 'know']",1,"['discussion', 'for', 'article', 'type', 'of', 'regression', 'technique', 'you', 'should', 'know']","['discussion', 'article', 'type', 'regression', 'technique', 'know']",discussion article type regression technique know,0.0,0.0,10,49,4.454545454545454,0,0,0,0,0,0,0,0
417,gini criterion in decision tree classifier,Tools,gini criterion in decision tree classifier,"['gini', 'criterion', 'in', 'decision', 'tree', 'classifier']",0,"['gini', 'criterion', 'in', 'decision', 'tree', 'classifier']","['gini', 'criterion', 'decision', 'tree', 'classifier']",gini criterion decision tree classifier,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
418,google adwords and r implementation how is it possible,Techniques,google adwords and r implementation how is it possible,"['google', 'adwords', 'and', 'r', 'implementation', 'how', 'is', 'it', 'possible']",0,"['google', 'adwords', 'and', 'r', 'implementation', 'how', 'is', 'it', 'possible']","['google', 'adwords', 'r', 'implementation', 'possible']",google adwords r implementation possible,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
419,making ai imagine stuff research on generating image from text,Resources,making ai imagine stuff research on generating image from text,"['making', 'ai', 'imagine', 'stuff', 'research', 'on', 'generating', 'image', 'from', 'text']",0,"['making', 'ai', 'imagine', 'stuff', 'research', 'on', 'generating', 'image', 'from', 'text']","['making', 'ai', 'imagine', 'stuff', 'research', 'generating', 'image', 'text']",making ai imagine stuff research generating image text,0.0,0.0,10,54,4.909090909090909,0,0,0,0,0,0,0,0
420,auto schedule sas program,Tools,auto schedule sas program,"['auto', 'schedule', 'sas', 'program']",0,"['auto', 'schedule', 'sa', 'program']","['auto', 'schedule', 'sa', 'program']",auto schedule sa program,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
421,typeerror only integer scalar arrays can be converted to a scalar index,Techniques,typeerror only integer scalar arrays can be converted to a scalar index,"['typeerror', 'only', 'integer', 'scalar', 'arrays', 'can', 'be', 'converted', 'to', 'a', 'scalar', 'index']",0,"['typeerror', 'only', 'integer', 'scalar', 'array', 'can', 'be', 'converted', 'to', 'a', 'scalar', 'index']","['typeerror', 'integer', 'scalar', 'array', 'converted', 'scalar', 'index']",typeerror integer scalar array converted scalar index,0.0,0.0,12,53,4.076923076923077,0,0,0,0,0,0,0,0
422,error while reading csv file using pandas,Tools,error while reading csv file using pandas,"['error', 'while', 'reading', 'csv', 'file', 'using', 'pandas']",0,"['error', 'while', 'reading', 'csv', 'file', 'using', 'panda']","['error', 'reading', 'csv', 'file', 'using', 'panda']",error reading csv file using panda,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
423,how to make a text bold within print statement in ipython notebook,Tools,how to make a text bold within print statement in ipython notebook,"['how', 'to', 'make', 'a', 'text', 'bold', 'within', 'print', 'statement', 'in', 'ipython', 'notebook']",0,"['how', 'to', 'make', 'a', 'text', 'bold', 'within', 'print', 'statement', 'in', 'ipython', 'notebook']","['make', 'text', 'bold', 'within', 'print', 'statement', 'ipython', 'notebook']",make text bold within print statement ipython notebook,0.3333333333333333,0.3333333333333333,12,54,4.153846153846154,0,0,0,0,0,0,0,0
424,switching to analytics,Career,switching to analytics,"['switching', 'to', 'analytics']",0,"['switching', 'to', 'analytics']","['switching', 'analytics']",switching analytics,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
425,arr  selfvocabstoix for x in arr keyerror  were there any transgender clones,Hackathons,arr  selfvocabstoix for x in arr keyerror  were there any transgender clones,"['arr', 'selfvocabstoix', 'for', 'x', 'in', 'arr', 'keyerror', 'were', 'there', 'any', 'transgender', 'clones']",0,"['arr', 'selfvocabstoix', 'for', 'x', 'in', 'arr', 'keyerror', 'were', 'there', 'any', 'transgender', 'clone']","['arr', 'selfvocabstoix', 'x', 'arr', 'keyerror', 'transgender', 'clone']",arr selfvocabstoix x arr keyerror transgender clone,0.0,0.0,12,51,3.923076923076923,0,0,0,0,0,0,0,0
426,how to interpret the eigen vectors while doing pca,Techniques,how to interpret the eigen vectors while doing pca,"['how', 'to', 'interpret', 'the', 'eigen', 'vectors', 'while', 'doing', 'pca']",0,"['how', 'to', 'interpret', 'the', 'eigen', 'vector', 'while', 'doing', 'pca']","['interpret', 'eigen', 'vector', 'pca']",interpret eigen vector pca,0.0,0.0,9,26,2.6,0,0,0,0,0,0,0,0
427,option to join slack live chat for mckinsey hackathon,Hackathons,option to join slack live chat for mckinsey hackathon,"['option', 'to', 'join', 'slack', 'live', 'chat', 'for', 'mckinsey', 'hackathon']",0,"['option', 'to', 'join', 'slack', 'live', 'chat', 'for', 'mckinsey', 'hackathon']","['option', 'join', 'slack', 'live', 'chat', 'mckinsey', 'hackathon']",option join slack live chat mckinsey hackathon,0.1363636363636363,0.1363636363636363,9,46,4.6,0,0,0,0,0,0,0,0
428,what does the equation in lasso sparse learning method mean,Techniques,what does the equation in lasso sparse learning method mean,"['what', 'does', 'the', 'equation', 'in', 'lasso', 'sparse', 'learning', 'method', 'mean']",0,"['what', 'doe', 'the', 'equation', 'in', 'lasso', 'sparse', 'learning', 'method', 'mean']","['doe', 'equation', 'lasso', 'sparse', 'learning', 'method', 'mean']",doe equation lasso sparse learning method mean,-0.3125,-0.3125,10,46,4.181818181818182,0,0,0,0,0,0,0,0
429,saving a model state with optimal accuracy in pytorch,Techniques,saving a model state with optimal accuracy in pytorch,"['saving', 'a', 'model', 'state', 'with', 'optimal', 'accuracy', 'in', 'pytorch']",0,"['saving', 'a', 'model', 'state', 'with', 'optimal', 'accuracy', 'in', 'pytorch']","['saving', 'model', 'state', 'optimal', 'accuracy', 'pytorch']",saving model state optimal accuracy pytorch,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
430,apply hmm on iris dataset,Other,apply hmm on iris dataset,"['apply', 'hmm', 'on', 'iris', 'dataset']",0,"['apply', 'hmm', 'on', 'iris', 'dataset']","['apply', 'hmm', 'iris', 'dataset']",apply hmm iris dataset,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
431,which language and library python contour processing image and detect a colored lines values,Techniques,which language and library python contour processing image and detect a colored lines values,"['which', 'language', 'and', 'library', 'python', 'contour', 'processing', 'image', 'and', 'detect', 'a', 'colored', 'lines', 'values']",0,"['which', 'language', 'and', 'library', 'python', 'contour', 'processing', 'image', 'and', 'detect', 'a', 'colored', 'line', 'value']","['language', 'library', 'python', 'contour', 'processing', 'image', 'detect', 'colored', 'line', 'value']",language library python contour processing image detect colored line value,0.0,0.0,14,74,4.933333333333334,0,0,0,0,0,0,0,0
432,warning  longer object length is not a multiple of shorter object length,Tools,warning  longer object length is not a multiple of shorter object length,"['warning', 'longer', 'object', 'length', 'is', 'not', 'a', 'multiple', 'of', 'shorter', 'object', 'length']",0,"['warning', 'longer', 'object', 'length', 'is', 'not', 'a', 'multiple', 'of', 'shorter', 'object', 'length']","['warning', 'longer', 'object', 'length', 'multiple', 'shorter', 'object', 'length']",warning longer object length multiple shorter object length,0.0,0.0,12,59,4.538461538461538,0,0,0,0,0,0,0,0
433,item tagging using r or python,Techniques,item tagging using r or python,"['item', 'tagging', 'using', 'r', 'or', 'python']",0,"['item', 'tagging', 'using', 'r', 'or', 'python']","['item', 'tagging', 'using', 'r', 'python']",item tagging using r python,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
434,how to convert the comma separated data in csv file to column separated file in r,Tools,how to convert the comma separated data in csv file to column separated file in r,"['how', 'to', 'convert', 'the', 'comma', 'separated', 'data', 'in', 'csv', 'file', 'to', 'column', 'separated', 'file', 'in', 'r']",0,"['how', 'to', 'convert', 'the', 'comma', 'separated', 'data', 'in', 'csv', 'file', 'to', 'column', 'separated', 'file', 'in', 'r']","['convert', 'comma', 'separated', 'data', 'csv', 'file', 'column', 'separated', 'file', 'r']",convert comma separated data csv file column separated file r,0.0,0.0,16,61,3.588235294117647,0,0,0,0,0,0,0,0
435,streaming data in r,Hackathons,streaming data in r,"['streaming', 'data', 'in', 'r']",0,"['streaming', 'data', 'in', 'r']","['streaming', 'data', 'r']",streaming data r,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
436,why there is more than one mode in a given distribution,Techniques,why there is more than one mode in a given distribution,"['why', 'there', 'is', 'more', 'than', 'one', 'mode', 'in', 'a', 'given', 'distribution']",0,"['why', 'there', 'is', 'more', 'than', 'one', 'mode', 'in', 'a', 'given', 'distribution']","['one', 'mode', 'given', 'distribution']",one mode given distribution,0.5,0.0,11,27,2.25,0,0,0,0,0,0,0,0
437,missing value imputation in bimodal distribution,Techniques,missing value imputation in bimodal distribution,"['missing', 'value', 'imputation', 'in', 'bimodal', 'distribution']",0,"['missing', 'value', 'imputation', 'in', 'bimodal', 'distribution']","['missing', 'value', 'imputation', 'bimodal', 'distribution']",missing value imputation bimodal distribution,-0.2,-0.2,6,45,6.428571428571429,0,0,0,0,0,0,0,0
438,how to make a career transition into analytics after having more than  years of experience in software testing  manual testing ,Career,how to make a career transition into analytics after having more than  years of experience in software testing  manual testing ,"['how', 'to', 'make', 'a', 'career', 'transition', 'into', 'analytics', 'after', 'having', 'more', 'than', 'years', 'of', 'experience', 'in', 'software', 'testing', 'manual', 'testing']",1,"['how', 'to', 'make', 'a', 'career', 'transition', 'into', 'analytics', 'after', 'having', 'more', 'than', 'year', 'of', 'experience', 'in', 'software', 'testing', 'manual', 'testing']","['make', 'career', 'transition', 'analytics', 'year', 'experience', 'software', 'testing', 'manual', 'testing']",make career transition analytics year experience software testing manual testing,0.5,0.0,20,80,3.8095238095238093,0,0,0,0,0,0,0,0
440,difference betweet the working of a data scientist and data engineer,Resources,difference betweet the working of a data scientist and data engineer,"['difference', 'betweet', 'the', 'working', 'of', 'a', 'data', 'scientist', 'and', 'data', 'engineer']",0,"['difference', 'betweet', 'the', 'working', 'of', 'a', 'data', 'scientist', 'and', 'data', 'engineer']","['difference', 'betweet', 'working', 'data', 'scientist', 'data', 'engineer']",difference betweet working data scientist data engineer,0.0,0.0,11,55,4.583333333333333,0,0,0,0,0,0,0,0
441,how to interpret this dancing code in python  infinite loop,Tools,how to interpret this dancing code in python  infinite loop,"['how', 'to', 'interpret', 'this', 'dancing', 'code', 'in', 'python', 'infinite', 'loop']",0,"['how', 'to', 'interpret', 'this', 'dancing', 'code', 'in', 'python', 'infinite', 'loop']","['interpret', 'dancing', 'code', 'python', 'infinite', 'loop']",interpret dancing code python infinite loop,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
442,why in null hypothesis we take only single value,Techniques,why in null hypothesis we take only single value,"['why', 'in', 'null', 'hypothesis', 'we', 'take', 'only', 'single', 'value']",0,"['why', 'in', 'null', 'hypothesis', 'we', 'take', 'only', 'single', 'value']","['null', 'hypothesis', 'take', 'single', 'value']",null hypothesis take single value,-0.0357142857142857,-0.0714285714285714,9,33,3.3,0,0,0,0,0,0,0,0
443,is it possible to plot two survival curve on same survival graph,Other,is it possible to plot two survival curve on same survival graph,"['is', 'it', 'possible', 'to', 'plot', 'two', 'survival', 'curve', 'on', 'same', 'survival', 'graph']",0,"['is', 'it', 'possible', 'to', 'plot', 'two', 'survival', 'curve', 'on', 'same', 'survival', 'graph']","['possible', 'plot', 'two', 'survival', 'curve', 'survival', 'graph']",possible plot two survival curve survival graph,0.0,0.0,12,47,3.6153846153846154,0,0,0,0,0,0,0,0
444,gartner says  of big data projects fail,Misc,gartner says  of big data projects fail,"['gartner', 'says', 'of', 'big', 'data', 'projects', 'fail']",1,"['gartner', 'say', 'of', 'big', 'data', 'project', 'fail']","['gartner', 'say', 'big', 'data', 'project', 'fail']",gartner say big data project fail,-0.25,-0.25,7,33,4.125,0,0,0,0,0,0,0,0
445,difference between exploratory and confirmatory factor analysis,Techniques,difference between exploratory and confirmatory factor analysis,"['difference', 'between', 'exploratory', 'and', 'confirmatory', 'factor', 'analysis']",0,"['difference', 'between', 'exploratory', 'and', 'confirmatory', 'factor', 'analysis']","['difference', 'exploratory', 'confirmatory', 'factor', 'analysis']",difference exploratory confirmatory factor analysis,0.0,0.0,7,51,6.375,0,0,0,0,0,0,0,0
446,how ml models will be developed and deployed,Techniques,how ml models will be developed and deployed,"['how', 'ml', 'models', 'will', 'be', 'developed', 'and', 'deployed']",0,"['how', 'ml', 'model', 'will', 'be', 'developed', 'and', 'deployed']","['ml', 'model', 'developed', 'deployed']",ml model developed deployed,0.1,0.1,8,27,3.0,0,0,0,0,0,0,0,0
447,should we convert every categorical variable in our model to factor before running the randomforest algorithm,Techniques,should we convert every categorical variable in our model to factor before running the randomforest algorithm,"['should', 'we', 'convert', 'every', 'categorical', 'variable', 'in', 'our', 'model', 'to', 'factor', 'before', 'running', 'the', 'randomforest', 'algorithm']",0,"['should', 'we', 'convert', 'every', 'categorical', 'variable', 'in', 'our', 'model', 'to', 'factor', 'before', 'running', 'the', 'randomforest', 'algorithm']","['convert', 'every', 'categorical', 'variable', 'model', 'factor', 'running', 'randomforest', 'algorithm']",convert every categorical variable model factor running randomforest algorithm,0.0,0.0,16,78,4.588235294117647,0,0,0,0,0,0,0,0
448,how to insert a column at a specific index in pandas dataframe,Tools,how to insert a column at a specific index in pandas dataframe,"['how', 'to', 'insert', 'a', 'column', 'at', 'a', 'specific', 'index', 'in', 'pandas', 'dataframe']",0,"['how', 'to', 'insert', 'a', 'column', 'at', 'a', 'specific', 'index', 'in', 'panda', 'dataframe']","['insert', 'column', 'specific', 'index', 'panda', 'dataframe']",insert column specific index panda dataframe,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
449,calculate sse and sst,Techniques,calculate sse and sst,"['calculate', 'sse', 'and', 'sst']",0,"['calculate', 'sse', 'and', 'sst']","['calculate', 'sse', 'sst']",calculate sse sst,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
450,online post graduate diploma in business analytics,Career,online post graduate diploma in business analytics,"['online', 'post', 'graduate', 'diploma', 'in', 'business', 'analytics']",0,"['online', 'post', 'graduate', 'diploma', 'in', 'business', 'analytics']","['online', 'post', 'graduate', 'diploma', 'business', 'analytics']",online post graduate diploma business analytics,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
451,what are the best online data science programs in the us,Resources,what are the best online data science programs in the us,"['what', 'are', 'the', 'best', 'online', 'data', 'science', 'programs', 'in', 'the', 'us']",0,"['what', 'are', 'the', 'best', 'online', 'data', 'science', 'program', 'in', 'the', 'u']","['best', 'online', 'data', 'science', 'program', 'u']",best online data science program u,1.0,1.0,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
452,nlp unsupervised method,Techniques,nlp unsupervised method,"['nlp', 'unsupervised', 'method']",0,"['nlp', 'unsupervised', 'method']","['nlp', 'unsupervised', 'method']",nlp unsupervised method,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
453,what are some good tutorials on stacking,Techniques,what are some good tutorials on stacking,"['what', 'are', 'some', 'good', 'tutorials', 'on', 'stacking']",0,"['what', 'are', 'some', 'good', 'tutorial', 'on', 'stacking']","['good', 'tutorial', 'stacking']",good tutorial stacking,0.7,0.7,7,22,2.75,0,0,0,0,0,0,0,0
454,data mart practie problem code causing error when imputing data,Other,data mart practie problem code causing error when imputing data,"['data', 'mart', 'practie', 'problem', 'code', 'causing', 'error', 'when', 'imputing', 'data']",0,"['data', 'mart', 'practie', 'problem', 'code', 'causing', 'error', 'when', 'imputing', 'data']","['data', 'mart', 'practie', 'problem', 'code', 'causing', 'error', 'imputing', 'data']",data mart practie problem code causing error imputing data,0.0,0.0,10,58,5.2727272727272725,0,0,0,0,0,0,0,0
455,how are error rates in voting method of ensemble learning calculated,Techniques,how are error rates in voting method of ensemble learning calculated,"['how', 'are', 'error', 'rates', 'in', 'voting', 'method', 'of', 'ensemble', 'learning', 'calculated']",0,"['how', 'are', 'error', 'rate', 'in', 'voting', 'method', 'of', 'ensemble', 'learning', 'calculated']","['error', 'rate', 'voting', 'method', 'ensemble', 'learning', 'calculated']",error rate voting method ensemble learning calculated,0.0,0.0,11,53,4.416666666666667,0,0,0,0,0,0,0,0
456,what should be number of tree in random forest for correct predication,Techniques,what should be number of tree in random forest for correct predication,"['what', 'should', 'be', 'number', 'of', 'tree', 'in', 'random', 'forest', 'for', 'correct', 'predication']",0,"['what', 'should', 'be', 'number', 'of', 'tree', 'in', 'random', 'forest', 'for', 'correct', 'predication']","['number', 'tree', 'random', 'forest', 'correct', 'predication']",number tree random forest correct predication,-0.5,-0.5,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
457,how to get a job in data science,Career,how to get a job in data science,"['how', 'to', 'get', 'a', 'job', 'in', 'data', 'science']",0,"['how', 'to', 'get', 'a', 'job', 'in', 'data', 'science']","['get', 'job', 'data', 'science']",get job data science,0.0,0.0,8,20,2.2222222222222223,0,0,0,0,0,0,0,0
458,changing datetime format,Techniques,changing datetime format,"['changing', 'datetime', 'format']",0,"['changing', 'datetime', 'format']","['changing', 'datetime', 'format']",changing datetime format,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
459,submission for bigmart,Hackathons,submission for bigmart,"['submission', 'for', 'bigmart']",0,"['submission', 'for', 'bigmart']","['submission', 'bigmart']",submission bigmart,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
460,point biserial correlation coefficient or lda,Techniques,point biserial correlation coefficient or lda,"['point', 'biserial', 'correlation', 'coefficient', 'or', 'lda']",0,"['point', 'biserial', 'correlation', 'coefficient', 'or', 'lda']","['point', 'biserial', 'correlation', 'coefficient', 'lda']",point biserial correlation coefficient lda,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
461,how to undo effect of a command in rstudio,Tools,how to undo effect of a command in rstudio,"['how', 'to', 'undo', 'effect', 'of', 'a', 'command', 'in', 'rstudio']",0,"['how', 'to', 'undo', 'effect', 'of', 'a', 'command', 'in', 'rstudio']","['undo', 'effect', 'command', 'rstudio']",undo effect command rstudio,0.0,0.0,9,27,2.7,0,0,0,0,0,0,0,0
462,mechanical guy wants to pursue career in analytics pros and cons,Career,mechanical guy wants to pursue career in analytics pros and cons,"['mechanical', 'guy', 'wants', 'to', 'pursue', 'career', 'in', 'analytics', 'pros', 'and', 'cons']",0,"['mechanical', 'guy', 'want', 'to', 'pursue', 'career', 'in', 'analytics', 'pro', 'and', 'con']","['mechanical', 'guy', 'want', 'pursue', 'career', 'analytics', 'pro', 'con']",mechanical guy want pursue career analytics pro con,0.2,0.0,11,51,4.25,0,0,0,0,0,0,0,0
463,python interview questions for analytics,Resources,python interview questions for analytics,"['python', 'interview', 'questions', 'for', 'analytics']",0,"['python', 'interview', 'question', 'for', 'analytics']","['python', 'interview', 'question', 'analytics']",python interview question analytics,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
464,need help with approach to gift card optimization,Techniques,need help with approach to gift card optimization,"['need', 'help', 'with', 'approach', 'to', 'gift', 'card', 'optimization']",0,"['need', 'help', 'with', 'approach', 'to', 'gift', 'card', 'optimization']","['need', 'help', 'approach', 'gift', 'card', 'optimization']",need help approach gift card optimization,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
465,shift to analytics from java,Career,shift to analytics from java,"['shift', 'to', 'analytics', 'from', 'java']",0,"['shift', 'to', 'analytics', 'from', 'java']","['shift', 'analytics', 'java']",shift analytics java,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
466,how to compute a histogram on multiple related columns in a data frame,Tools,how to compute a histogram on multiple related columns in a data frame,"['how', 'to', 'compute', 'a', 'histogram', 'on', 'multiple', 'related', 'columns', 'in', 'a', 'data', 'frame']",0,"['how', 'to', 'compute', 'a', 'histogram', 'on', 'multiple', 'related', 'column', 'in', 'a', 'data', 'frame']","['compute', 'histogram', 'multiple', 'related', 'column', 'data', 'frame']",compute histogram multiple related column data frame,0.0,0.0,13,52,3.7142857142857144,0,0,0,0,0,0,0,0
467,how to delete any column from series in ipython,Tools,how to delete any column from series in ipython,"['how', 'to', 'delete', 'any', 'column', 'from', 'series', 'in', 'ipython']",0,"['how', 'to', 'delete', 'any', 'column', 'from', 'series', 'in', 'ipython']","['delete', 'column', 'series', 'ipython']",delete column series ipython,0.0,0.0,9,28,2.8,0,0,0,0,0,0,0,0
468,how can we hide or unhide sheet tabs in qlikview,Tools,how can we hide or unhide sheet tabs in qlikview,"['how', 'can', 'we', 'hide', 'or', 'unhide', 'sheet', 'tabs', 'in', 'qlikview']",0,"['how', 'can', 'we', 'hide', 'or', 'unhide', 'sheet', 'tab', 'in', 'qlikview']","['hide', 'unhide', 'sheet', 'tab', 'qlikview']",hide unhide sheet tab qlikview,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
469,data visualization packages in r,Tools,data visualization packages in r,"['data', 'visualization', 'packages', 'in', 'r']",0,"['data', 'visualization', 'package', 'in', 'r']","['data', 'visualization', 'package', 'r']",data visualization package r,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
470,my random nonsense,Resources,my random nonsense,"['my', 'random', 'nonsense']",0,"['my', 'random', 'nonsense']","['random', 'nonsense']",random nonsense,-0.5,-0.5,3,15,3.75,0,0,0,0,0,0,0,0
471,how to handle data with unique interaction id but with multiple events,Techniques,how to handle data with unique interaction id but with multiple events,"['how', 'to', 'handle', 'data', 'with', 'unique', 'interaction', 'id', 'but', 'with', 'multiple', 'events']",0,"['how', 'to', 'handle', 'data', 'with', 'unique', 'interaction', 'id', 'but', 'with', 'multiple', 'event']","['handle', 'data', 'unique', 'interaction', 'id', 'multiple', 'event']",handle data unique interaction id multiple event,0.1875,0.1875,12,48,3.6923076923076925,0,0,0,0,0,0,0,0
472,sas functions query,Tools,sas functions query,"['sas', 'functions', 'query']",0,"['sa', 'function', 'query']","['sa', 'function', 'query']",sa function query,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
473,different performance of kmeans in r  and r ,Tools,different performance of kmeans in r  and r ,"['different', 'performance', 'of', 'kmeans', 'in', 'r', 'and', 'r']",2,"['different', 'performance', 'of', 'kmeans', 'in', 'r', 'and', 'r']","['different', 'performance', 'kmeans', 'r', 'r']",different performance kmeans r r,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
474,how type attribute affect the logistic model in r,Tools,how type attribute affect the logistic model in r,"['how', 'type', 'attribute', 'affect', 'the', 'logistic', 'model', 'in', 'r']",0,"['how', 'type', 'attribute', 'affect', 'the', 'logistic', 'model', 'in', 'r']","['type', 'attribute', 'affect', 'logistic', 'model', 'r']",type attribute affect logistic model r,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
475,how to plot images stores in array,Techniques,how to plot images stores in array,"['how', 'to', 'plot', 'images', 'stores', 'in', 'array']",0,"['how', 'to', 'plot', 'image', 'store', 'in', 'array']","['plot', 'image', 'store', 'array']",plot image store array,0.0,0.0,7,22,2.75,0,0,0,0,0,0,0,0
476,classification of  categories,Techniques,classification of  categories,"['classification', 'of', 'categories']",1,"['classification', 'of', 'category']","['classification', 'category']",classification category,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
477,getting error using keras for nn,Tools,getting error using keras for nn,"['getting', 'error', 'using', 'keras', 'for', 'nn']",0,"['getting', 'error', 'using', 'kera', 'for', 'nn']","['getting', 'error', 'using', 'kera', 'nn']",getting error using kera nn,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
478,about of original raw data and intermediate data has been transformed,Career,about of original raw data and intermediate data has been transformed,"['about', 'of', 'original', 'raw', 'data', 'and', 'intermediate', 'data', 'has', 'been', 'transformed']",0,"['about', 'of', 'original', 'raw', 'data', 'and', 'intermediate', 'data', 'ha', 'been', 'transformed']","['original', 'raw', 'data', 'intermediate', 'data', 'ha', 'transformed']",original raw data intermediate data ha transformed,0.0721153846153846,0.0721153846153846,11,50,4.166666666666667,0,0,0,0,0,0,0,0
479,how to set font parameters of a plot in python,Tools,how to set font parameters of a plot in python,"['how', 'to', 'set', 'font', 'parameters', 'of', 'a', 'plot', 'in', 'python']",0,"['how', 'to', 'set', 'font', 'parameter', 'of', 'a', 'plot', 'in', 'python']","['set', 'font', 'parameter', 'plot', 'python']",set font parameter plot python,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
480,categorical variables with lot many levels,Techniques,categorical variables with lot many levels,"['categorical', 'variables', 'with', 'lot', 'many', 'levels']",0,"['categorical', 'variable', 'with', 'lot', 'many', 'level']","['categorical', 'variable', 'lot', 'many', 'level']",categorical variable lot many level,0.5,0.5,6,35,5.0,0,0,0,0,0,0,0,0
481,wns analytics wizard ,Hackathons,wns analytics wizard ,"['wns', 'analytics', 'wizard']",1,"['wns', 'analytics', 'wizard']","['wns', 'analytics', 'wizard']",wns analytics wizard,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
482,rmse practiceproblemtimeseries,Techniques,rmse practiceproblemtimeseries,"['rmse', 'practiceproblemtimeseries']",0,"['rmse', 'practiceproblemtimeseries']","['rmse', 'practiceproblemtimeseries']",rmse practiceproblemtimeseries,0.0,0.0,2,30,10.0,0,0,0,0,0,0,0,0
483,please suggest some methods to improve problem solving skills,Resources,please suggest some methods to improve problem solving skills,"['please', 'suggest', 'some', 'methods', 'to', 'improve', 'problem', 'solving', 'skills']",0,"['please', 'suggest', 'some', 'method', 'to', 'improve', 'problem', 'solving', 'skill']","['please', 'suggest', 'method', 'improve', 'problem', 'solving', 'skill']",please suggest method improve problem solving skill,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
484,help required on web scraping with python,Techniques,help required on web scraping with python,"['help', 'required', 'on', 'web', 'scraping', 'with', 'python']",0,"['help', 'required', 'on', 'web', 'scraping', 'with', 'python']","['help', 'required', 'web', 'scraping', 'python']",help required web scraping python,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
485,issue in machine setup,Tools,issue in machine setup,"['issue', 'in', 'machine', 'setup']",0,"['issue', 'in', 'machine', 'setup']","['issue', 'machine', 'setup']",issue machine setup,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
486,how can i arrange columns as per condition,Tools,how can i arrange columns as per condition,"['how', 'can', 'i', 'arrange', 'columns', 'as', 'per', 'condition']",0,"['how', 'can', 'i', 'arrange', 'column', 'a', 'per', 'condition']","['arrange', 'column', 'per', 'condition']",arrange column per condition,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
487,how to decide on feature engineering while making my prediction model,Techniques,how to decide on feature engineering while making my prediction model,"['how', 'to', 'decide', 'on', 'feature', 'engineering', 'while', 'making', 'my', 'prediction', 'model']",0,"['how', 'to', 'decide', 'on', 'feature', 'engineering', 'while', 'making', 'my', 'prediction', 'model']","['decide', 'feature', 'engineering', 'making', 'prediction', 'model']",decide feature engineering making prediction model,0.0,0.0,11,50,4.166666666666667,0,0,0,0,0,0,0,0
488,plotting heatmap over the san francisco map for crime classification problem,Techniques,plotting heatmap over the san francisco map for crime classification problem,"['plotting', 'heatmap', 'over', 'the', 'san', 'francisco', 'map', 'for', 'crime', 'classification', 'problem']",0,"['plotting', 'heatmap', 'over', 'the', 'san', 'francisco', 'map', 'for', 'crime', 'classification', 'problem']","['plotting', 'heatmap', 'san', 'francisco', 'map', 'crime', 'classification', 'problem']",plotting heatmap san francisco map crime classification problem,0.0,0.0,11,63,5.25,0,0,0,0,0,0,0,0
489,career suggestion for sas certification,Career,career suggestion for sas certification,"['career', 'suggestion', 'for', 'sas', 'certification']",0,"['career', 'suggestion', 'for', 'sa', 'certification']","['career', 'suggestion', 'sa', 'certification']",career suggestion sa certification,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
490,unable to download the big mart data sales,Hackathons,unable to download the big mart data sales,"['unable', 'to', 'download', 'the', 'big', 'mart', 'data', 'sales']",0,"['unable', 'to', 'download', 'the', 'big', 'mart', 'data', 'sale']","['unable', 'download', 'big', 'mart', 'data', 'sale']",unable download big mart data sale,-0.25,-0.25,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
491,classifying it incident,Techniques,classifying it incident,"['classifying', 'it', 'incident']",0,"['classifying', 'it', 'incident']","['classifying', 'incident']",classifying incident,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
492,convert string to number in sas,Tools,convert string to number in sas,"['convert', 'string', 'to', 'number', 'in', 'sas']",0,"['convert', 'string', 'to', 'number', 'in', 'sa']","['convert', 'string', 'number', 'sa']",convert string number sa,0.0,0.0,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
493,face emotions analysis,Tools,face emotions analysis,"['face', 'emotions', 'analysis']",0,"['face', 'emotion', 'analysis']","['face', 'emotion', 'analysis']",face emotion analysis,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
494,how to do ordinal data analysis,Techniques,how to do ordinal data analysis,"['how', 'to', 'do', 'ordinal', 'data', 'analysis']",0,"['how', 'to', 'do', 'ordinal', 'data', 'analysis']","['ordinal', 'data', 'analysis']",ordinal data analysis,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
495,recommender systems  is it a data science or programming,Techniques,recommender systems  is it a data science or programming,"['recommender', 'systems', 'is', 'it', 'a', 'data', 'science', 'or', 'programming']",0,"['recommender', 'system', 'is', 'it', 'a', 'data', 'science', 'or', 'programming']","['recommender', 'system', 'data', 'science', 'programming']",recommender system data science programming,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
496,python pivot table,Tools,python pivot table,"['python', 'pivot', 'table']",0,"['python', 'pivot', 'table']","['python', 'pivot', 'table']",python pivot table,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
497,filter algorithms for dimensionality reduction,Techniques,filter algorithms for dimensionality reduction,"['filter', 'algorithms', 'for', 'dimensionality', 'reduction']",0,"['filter', 'algorithm', 'for', 'dimensionality', 'reduction']","['filter', 'algorithm', 'dimensionality', 'reduction']",filter algorithm dimensionality reduction,0.0,0.0,5,41,6.833333333333333,0,0,0,0,0,0,0,0
498,recommendation engines application for association rule mining,Techniques,recommendation engines application for association rule mining,"['recommendation', 'engines', 'application', 'for', 'association', 'rule', 'mining']",0,"['recommendation', 'engine', 'application', 'for', 'association', 'rule', 'mining']","['recommendation', 'engine', 'application', 'association', 'rule', 'mining']",recommendation engine application association rule mining,0.0,0.0,7,57,7.125,0,0,0,0,0,0,0,0
499,developing outlier visualization for multivariate data,Techniques,developing outlier visualization for multivariate data,"['developing', 'outlier', 'visualization', 'for', 'multivariate', 'data']",0,"['developing', 'outlier', 'visualization', 'for', 'multivariate', 'data']","['developing', 'outlier', 'visualization', 'multivariate', 'data']",developing outlier visualization multivariate data,0.0,0.0,6,50,7.142857142857143,0,0,0,0,0,0,0,0
500,what is a publicprivate split,Hackathons,what is a publicprivate split,"['what', 'is', 'a', 'publicprivate', 'split']",0,"['what', 'is', 'a', 'publicprivate', 'split']","['publicprivate', 'split']",publicprivate split,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
501,picklesharedb help required,Tools,picklesharedb help required,"['picklesharedb', 'help', 'required']",0,"['picklesharedb', 'help', 'required']","['picklesharedb', 'help', 'required']",picklesharedb help required,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
502,blind classification,Techniques,blind classification,"['blind', 'classification']",0,"['blind', 'classification']","['blind', 'classification']",blind classification,-0.5,-0.5,2,20,6.666666666666667,0,0,0,0,0,0,0,0
503,download the complete list of powerful r libraries for data analysis,Resources,download the complete list of powerful r libraries for data analysis,"['download', 'the', 'complete', 'list', 'of', 'powerful', 'r', 'libraries', 'for', 'data', 'analysis']",0,"['download', 'the', 'complete', 'list', 'of', 'powerful', 'r', 'library', 'for', 'data', 'analysis']","['download', 'complete', 'list', 'powerful', 'r', 'library', 'data', 'analysis']",download complete list powerful r library data analysis,0.2,0.2,11,55,4.583333333333333,0,0,0,0,0,0,0,0
504,sas bi certification,Career,sas bi certification,"['sas', 'bi', 'certification']",0,"['sa', 'bi', 'certification']","['sa', 'bi', 'certification']",sa bi certification,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
505,tensorflow or caffe which is better for running deep learning models in production,Tools,tensorflow or caffe which is better for running deep learning models in production,"['tensorflow', 'or', 'caffe', 'which', 'is', 'better', 'for', 'running', 'deep', 'learning', 'models', 'in', 'production']",0,"['tensorflow', 'or', 'caffe', 'which', 'is', 'better', 'for', 'running', 'deep', 'learning', 'model', 'in', 'production']","['tensorflow', 'caffe', 'better', 'running', 'deep', 'learning', 'model', 'production']",tensorflow caffe better running deep learning model production,0.25,0.25,13,62,4.428571428571429,0,0,0,0,0,0,0,0
506,handle missing values first and then do variable analysis or vice versa,Techniques,handle missing values first and then do variable analysis or vice versa,"['handle', 'missing', 'values', 'first', 'and', 'then', 'do', 'variable', 'analysis', 'or', 'vice', 'versa']",0,"['handle', 'missing', 'value', 'first', 'and', 'then', 'do', 'variable', 'analysis', 'or', 'vice', 'versa']","['handle', 'missing', 'value', 'first', 'variable', 'analysis', 'vice', 'versa']",handle missing value first variable analysis vice versa,0.0249999999999999,0.0249999999999999,12,55,4.230769230769231,0,0,0,0,0,0,0,0
507,where can i get sample datacase studies for customer analyticscross sellup sell,Techniques,where can i get sample datacase studies for customer analyticscross sellup sell,"['where', 'can', 'i', 'get', 'sample', 'datacase', 'studies', 'for', 'customer', 'analyticscross', 'sellup', 'sell']",0,"['where', 'can', 'i', 'get', 'sample', 'datacase', 'study', 'for', 'customer', 'analyticscross', 'sellup', 'sell']","['get', 'sample', 'datacase', 'study', 'customer', 'analyticscross', 'sellup', 'sell']",get sample datacase study customer analyticscross sellup sell,0.0,0.0,12,61,4.6923076923076925,0,0,0,0,0,0,0,0
508,practice problem loan prediction,Hackathons,practice problem loan prediction,"['practice', 'problem', 'loan', 'prediction']",0,"['practice', 'problem', 'loan', 'prediction']","['practice', 'problem', 'loan', 'prediction']",practice problem loan prediction,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
509,how to learn cognos independently,Tools,how to learn cognos independently,"['how', 'to', 'learn', 'cognos', 'independently']",0,"['how', 'to', 'learn', 'cognos', 'independently']","['learn', 'cognos', 'independently']",learn cognos independently,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
510,data types are not recognized when importing the csv file,Tools,data types are not recognized when importing the csv file,"['data', 'types', 'are', 'not', 'recognized', 'when', 'importing', 'the', 'csv', 'file']",0,"['data', 'type', 'are', 'not', 'recognized', 'when', 'importing', 'the', 'csv', 'file']","['data', 'type', 'recognized', 'importing', 'csv', 'file']",data type recognized importing csv file,0.0,0.0,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
511,reddit ama with andrew ng and adam coates,Resources,reddit ama with andrew ng and adam coates,"['reddit', 'ama', 'with', 'andrew', 'ng', 'and', 'adam', 'coates']",0,"['reddit', 'ama', 'with', 'andrew', 'ng', 'and', 'adam', 'coates']","['reddit', 'ama', 'andrew', 'ng', 'adam', 'coates']",reddit ama andrew ng adam coates,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
512,multicollinearity in random forest,Techniques,multicollinearity in random forest,"['multicollinearity', 'in', 'random', 'forest']",0,"['multicollinearity', 'in', 'random', 'forest']","['multicollinearity', 'random', 'forest']",multicollinearity random forest,-0.5,-0.5,4,31,6.2,0,0,0,0,0,0,0,0
513,author prediction,Techniques,author prediction,"['author', 'prediction']",0,"['author', 'prediction']","['author', 'prediction']",author prediction,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
514,awesome data science ideas a curated list for data science usecasesapplications,Resources,awesome data science ideas a curated list for data science usecasesapplications,"['awesome', 'data', 'science', 'ideas', 'a', 'curated', 'list', 'for', 'data', 'science', 'usecasesapplications']",0,"['awesome', 'data', 'science', 'idea', 'a', 'curated', 'list', 'for', 'data', 'science', 'usecasesapplications']","['awesome', 'data', 'science', 'idea', 'curated', 'list', 'data', 'science', 'usecasesapplications']",awesome data science idea curated list data science usecasesapplications,1.0,1.0,11,72,6.0,0,0,0,0,0,0,0,0
515,limitations on categorical variable,Techniques,limitations on categorical variable,"['limitations', 'on', 'categorical', 'variable']",0,"['limitation', 'on', 'categorical', 'variable']","['limitation', 'categorical', 'variable']",limitation categorical variable,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
516,career change to analytics,Career,career change to analytics,"['career', 'change', 'to', 'analytics']",0,"['career', 'change', 'to', 'analytics']","['career', 'change', 'analytics']",career change analytics,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
517,how clustering can be used to impute the missing in the categorical variable,Techniques,how clustering can be used to impute the missing in the categorical variable,"['how', 'clustering', 'can', 'be', 'used', 'to', 'impute', 'the', 'missing', 'in', 'the', 'categorical', 'variable']",0,"['how', 'clustering', 'can', 'be', 'used', 'to', 'impute', 'the', 'missing', 'in', 'the', 'categorical', 'variable']","['clustering', 'used', 'impute', 'missing', 'categorical', 'variable']",clustering used impute missing categorical variable,-0.2,-0.2,13,51,3.642857142857143,0,0,0,0,0,0,0,0
518,how is length normalization done for images done in r,Techniques,how is length normalization done for images done in r,"['how', 'is', 'length', 'normalization', 'done', 'for', 'images', 'done', 'in', 'r']",0,"['how', 'is', 'length', 'normalization', 'done', 'for', 'image', 'done', 'in', 'r']","['length', 'normalization', 'done', 'image', 'done', 'r']",length normalization done image done r,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
519,is it possible to classify text with regex,Techniques,is it possible to classify text with regex,"['is', 'it', 'possible', 'to', 'classify', 'text', 'with', 'regex']",0,"['is', 'it', 'possible', 'to', 'classify', 'text', 'with', 'regex']","['possible', 'classify', 'text', 'regex']",possible classify text regex,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
520,where can i learn more about bigdata,Tools,where can i learn more about bigdata,"['where', 'can', 'i', 'learn', 'more', 'about', 'bigdata']",0,"['where', 'can', 'i', 'learn', 'more', 'about', 'bigdata']","['learn', 'bigdata']",learn bigdata,0.5,0.0,7,13,1.625,0,0,0,0,0,0,0,0
521,predicting customer activity absence,Techniques,predicting customer activity absence,"['predicting', 'customer', 'activity', 'absence']",0,"['predicting', 'customer', 'activity', 'absence']","['predicting', 'customer', 'activity', 'absence']",predicting customer activity absence,-0.0125,-0.0125,4,36,7.2,0,0,0,0,0,0,0,0
522,efficiency of decision tree c,Techniques,efficiency of decision tree c,"['efficiency', 'of', 'decision', 'tree', 'c']",0,"['efficiency', 'of', 'decision', 'tree', 'c']","['efficiency', 'decision', 'tree', 'c']",efficiency decision tree c,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
523,how gini index is different from entropy value for splitting the node,Techniques,how gini index is different from entropy value for splitting the node,"['how', 'gini', 'index', 'is', 'different', 'from', 'entropy', 'value', 'for', 'splitting', 'the', 'node']",0,"['how', 'gini', 'index', 'is', 'different', 'from', 'entropy', 'value', 'for', 'splitting', 'the', 'node']","['gini', 'index', 'different', 'entropy', 'value', 'splitting', 'node']",gini index different entropy value splitting node,0.0,0.0,12,49,3.769230769230769,0,0,0,0,0,0,0,0
524,what is difference between rmd file and normal file in r,Tools,what is difference between rmd file and normal file in r,"['what', 'is', 'difference', 'between', 'rmd', 'file', 'and', 'normal', 'file', 'in', 'r']",0,"['what', 'is', 'difference', 'between', 'rmd', 'file', 'and', 'normal', 'file', 'in', 'r']","['difference', 'rmd', 'file', 'normal', 'file', 'r']",difference rmd file normal file r,0.15,0.15,11,33,2.75,0,0,0,0,0,0,0,0
525,source of loan prediction data,Hackathons,source of loan prediction data,"['source', 'of', 'loan', 'prediction', 'data']",0,"['source', 'of', 'loan', 'prediction', 'data']","['source', 'loan', 'prediction', 'data']",source loan prediction data,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
526,career switch from mechanical engineer role to analytics,Career,career switch from mechanical engineer role to analytics,"['career', 'switch', 'from', 'mechanical', 'engineer', 'role', 'to', 'analytics']",0,"['career', 'switch', 'from', 'mechanical', 'engineer', 'role', 'to', 'analytics']","['career', 'switch', 'mechanical', 'engineer', 'role', 'analytics']",career switch mechanical engineer role analytics,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
527,how does a machine learning algorithm really learn,Techniques,how does a machine learning algorithm really learn,"['how', 'does', 'a', 'machine', 'learning', 'algorithm', 'really', 'learn']",0,"['how', 'doe', 'a', 'machine', 'learning', 'algorithm', 'really', 'learn']","['doe', 'machine', 'learning', 'algorithm', 'really', 'learn']",doe machine learning algorithm really learn,0.2,0.2,8,43,4.777777777777778,0,0,0,0,0,0,0,0
528,what are categorical variables,Techniques,what are categorical variables,"['what', 'are', 'categorical', 'variables']",0,"['what', 'are', 'categorical', 'variable']","['categorical', 'variable']",categorical variable,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
529,executive certification programmes,Career,executive certification programmes,"['executive', 'certification', 'programmes']",0,"['executive', 'certification', 'programme']","['executive', 'certification', 'programme']",executive certification programme,0.0,0.0,3,33,8.25,0,0,0,0,0,0,0,0
530,any free courses on ds ml ai which give certificate also,Resources,any free courses on ds ml ai which give certificate also,"['any', 'free', 'courses', 'on', 'ds', 'ml', 'ai', 'which', 'give', 'certificate', 'also']",0,"['any', 'free', 'course', 'on', 'd', 'ml', 'ai', 'which', 'give', 'certificate', 'also']","['free', 'course', 'ml', 'ai', 'give', 'certificate', 'also']",free course ml ai give certificate also,0.4,0.4,11,39,3.25,0,0,0,0,0,0,0,0
531,pos tagging along with lemmatization,Techniques,pos tagging along with lemmatization,"['pos', 'tagging', 'along', 'with', 'lemmatization']",0,"['po', 'tagging', 'along', 'with', 'lemmatization']","['po', 'tagging', 'along', 'lemmatization']",po tagging along lemmatization,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
532,is mathematics required for ml,Techniques,is mathematics required for ml,"['is', 'mathematics', 'required', 'for', 'ml']",0,"['is', 'mathematics', 'required', 'for', 'ml']","['mathematics', 'required', 'ml']",mathematics required ml,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
533,suitable location for data science job,Career,suitable location for data science job,"['suitable', 'location', 'for', 'data', 'science', 'job']",0,"['suitable', 'location', 'for', 'data', 'science', 'job']","['suitable', 'location', 'data', 'science', 'job']",suitable location data science job,0.55,0.55,6,34,4.857142857142857,0,0,0,0,0,0,0,0
534,what is semisupervised learning,Techniques,what is semisupervised learning,"['what', 'is', 'semisupervised', 'learning']",0,"['what', 'is', 'semisupervised', 'learning']","['semisupervised', 'learning']",semisupervised learning,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
535,finding thresold in logistic regression,Techniques,finding thresold in logistic regression,"['finding', 'thresold', 'in', 'logistic', 'regression']",0,"['finding', 'thresold', 'in', 'logistic', 'regression']","['finding', 'thresold', 'logistic', 'regression']",finding thresold logistic regression,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
536,guidance to start a career in analytics,Career,guidance to start a career in analytics,"['guidance', 'to', 'start', 'a', 'career', 'in', 'analytics']",0,"['guidance', 'to', 'start', 'a', 'career', 'in', 'analytics']","['guidance', 'start', 'career', 'analytics']",guidance start career analytics,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
537,when i must make scaling on data,Techniques,when i must make scaling on data,"['when', 'i', 'must', 'make', 'scaling', 'on', 'data']",0,"['when', 'i', 'must', 'make', 'scaling', 'on', 'data']","['must', 'make', 'scaling', 'data']",must make scaling data,0.0,0.0,7,22,2.75,0,0,0,0,0,0,0,0
538,sas etllearning material,Tools,sas etllearning material,"['sas', 'etllearning', 'material']",0,"['sa', 'etllearning', 'material']","['sa', 'etllearning', 'material']",sa etllearning material,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
539,call center optimization,Other,call center optimization,"['call', 'center', 'optimization']",0,"['call', 'center', 'optimization']","['call', 'center', 'optimization']",call center optimization,-0.1,-0.1,3,24,6.0,0,0,0,0,0,0,0,0
540,guidance required please help,Resources,guidance required please help,"['guidance', 'required', 'please', 'help']",0,"['guidance', 'required', 'please', 'help']","['guidance', 'required', 'please', 'help']",guidance required please help,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
541,data science questions to ask for an ag dataset,Other,data science questions to ask for an ag dataset,"['data', 'science', 'questions', 'to', 'ask', 'for', 'an', 'ag', 'dataset']",0,"['data', 'science', 'question', 'to', 'ask', 'for', 'an', 'ag', 'dataset']","['data', 'science', 'question', 'ask', 'ag', 'dataset']",data science question ask ag dataset,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
542,multiple integer optimization with weighted  priority approaches,Techniques,multiple integer optimization with weighted  priority approaches,"['multiple', 'integer', 'optimization', 'with', 'weighted', 'priority', 'approaches']",0,"['multiple', 'integer', 'optimization', 'with', 'weighted', 'priority', 'approach']","['multiple', 'integer', 'optimization', 'weighted', 'priority', 'approach']",multiple integer optimization weighted priority approach,0.0,0.0,7,56,7.0,0,0,0,0,0,0,0,0
543,how to consider seasonality while doing market basket analysis,Techniques,how to consider seasonality while doing market basket analysis,"['how', 'to', 'consider', 'seasonality', 'while', 'doing', 'market', 'basket', 'analysis']",0,"['how', 'to', 'consider', 'seasonality', 'while', 'doing', 'market', 'basket', 'analysis']","['consider', 'seasonality', 'market', 'basket', 'analysis']",consider seasonality market basket analysis,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
544,which problem would you like to crack on the upcoming hackathon lord of the machines,Hackathons,which problem would you like to crack on the upcoming hackathon lord of the machines,"['which', 'problem', 'would', 'you', 'like', 'to', 'crack', 'on', 'the', 'upcoming', 'hackathon', 'lord', 'of', 'the', 'machines']",0,"['which', 'problem', 'would', 'you', 'like', 'to', 'crack', 'on', 'the', 'upcoming', 'hackathon', 'lord', 'of', 'the', 'machine']","['problem', 'would', 'like', 'crack', 'upcoming', 'hackathon', 'lord', 'machine']",problem would like crack upcoming hackathon lord machine,0.0,0.0,15,56,3.5,0,0,0,0,0,0,0,0
545,free data science courses starting very soon  learning statistics  sap hana text analysis,Resources,free data science courses starting very soon  learning statistics  sap hana text analysis,"['free', 'data', 'science', 'courses', 'starting', 'very', 'soon', 'learning', 'statistics', 'sap', 'hana', 'text', 'analysis']",0,"['free', 'data', 'science', 'course', 'starting', 'very', 'soon', 'learning', 'statistic', 'sap', 'hana', 'text', 'analysis']","['free', 'data', 'science', 'course', 'starting', 'soon', 'learning', 'statistic', 'sap', 'hana', 'text', 'analysis']",free data science course starting soon learning statistic sap hana text analysis,0.2,0.2,13,80,5.714285714285714,0,0,0,0,0,0,0,0
546,managing potential skew randomly generated test v control cell population splits,Techniques,managing potential skew randomly generated test v control cell population splits,"['managing', 'potential', 'skew', 'randomly', 'generated', 'test', 'v', 'control', 'cell', 'population', 'splits']",0,"['managing', 'potential', 'skew', 'randomly', 'generated', 'test', 'v', 'control', 'cell', 'population', 'split']","['managing', 'potential', 'skew', 'randomly', 'generated', 'test', 'v', 'control', 'cell', 'population', 'split']",managing potential skew randomly generated test v control cell population split,-0.25,-0.25,11,79,6.583333333333333,0,0,0,0,0,0,0,0
547,predicting driver behaviour speed and angle,Techniques,predicting driver behaviour speed and angle,"['predicting', 'driver', 'behaviour', 'speed', 'and', 'angle']",0,"['predicting', 'driver', 'behaviour', 'speed', 'and', 'angle']","['predicting', 'driver', 'behaviour', 'speed', 'angle']",predicting driver behaviour speed angle,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
548,how datamining and machine learning are different,Misc,how datamining and machine learning are different,"['how', 'datamining', 'and', 'machine', 'learning', 'are', 'different']",0,"['how', 'datamining', 'and', 'machine', 'learning', 'are', 'different']","['datamining', 'machine', 'learning', 'different']",datamining machine learning different,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
549,pollution index forecasting,Techniques,pollution index forecasting,"['pollution', 'index', 'forecasting']",0,"['pollution', 'index', 'forecasting']","['pollution', 'index', 'forecasting']",pollution index forecasting,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
550,keras to pytorch cnn is not working  dogs vs cats classification,Techniques,keras to pytorch cnn is not working  dogs vs cats classification,"['keras', 'to', 'pytorch', 'cnn', 'is', 'not', 'working', 'dogs', 'vs', 'cats', 'classification']",0,"['kera', 'to', 'pytorch', 'cnn', 'is', 'not', 'working', 'dog', 'v', 'cat', 'classification']","['kera', 'pytorch', 'cnn', 'working', 'dog', 'v', 'cat', 'classification']",kera pytorch cnn working dog v cat classification,0.0,0.0,11,49,4.083333333333333,0,0,0,0,0,0,0,0
551,perform multiple linear regression for time series data,Techniques,perform multiple linear regression for time series data,"['perform', 'multiple', 'linear', 'regression', 'for', 'time', 'series', 'data']",0,"['perform', 'multiple', 'linear', 'regression', 'for', 'time', 'series', 'data']","['perform', 'multiple', 'linear', 'regression', 'time', 'series', 'data']",perform multiple linear regression time series data,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
552,what is the variance of multiple regression model,Techniques,what is the variance of multiple regression model,"['what', 'is', 'the', 'variance', 'of', 'multiple', 'regression', 'model']",0,"['what', 'is', 'the', 'variance', 'of', 'multiple', 'regression', 'model']","['variance', 'multiple', 'regression', 'model']",variance multiple regression model,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
553,how to resolve multi  class prediction error in xgboost in r,Tools,how to resolve multi  class prediction error in xgboost in r,"['how', 'to', 'resolve', 'multi', 'class', 'prediction', 'error', 'in', 'xgboost', 'in', 'r']",0,"['how', 'to', 'resolve', 'multi', 'class', 'prediction', 'error', 'in', 'xgboost', 'in', 'r']","['resolve', 'multi', 'class', 'prediction', 'error', 'xgboost', 'r']",resolve multi class prediction error xgboost r,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
554,what is role different of predictive analyst and statistician,Other,what is role different of predictive analyst and statistician,"['what', 'is', 'role', 'different', 'of', 'predictive', 'analyst', 'and', 'statistician']",0,"['what', 'is', 'role', 'different', 'of', 'predictive', 'analyst', 'and', 'statistician']","['role', 'different', 'predictive', 'analyst', 'statistician']",role different predictive analyst statistician,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
555,error when using kerasdml in apache spark,Techniques,error when using kerasdml in apache spark,"['error', 'when', 'using', 'kerasdml', 'in', 'apache', 'spark']",0,"['error', 'when', 'using', 'kerasdml', 'in', 'apache', 'spark']","['error', 'using', 'kerasdml', 'apache', 'spark']",error using kerasdml apache spark,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
556,yolo how manage video streaming,Other,yolo how manage video streaming,"['yolo', 'how', 'manage', 'video', 'streaming']",0,"['yolo', 'how', 'manage', 'video', 'streaming']","['yolo', 'manage', 'video', 'streaming']",yolo manage video streaming,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
557,winterholtz model and learning material in r,Techniques,winterholtz model and learning material in r,"['winterholtz', 'model', 'and', 'learning', 'material', 'in', 'r']",0,"['winterholtz', 'model', 'and', 'learning', 'material', 'in', 'r']","['winterholtz', 'model', 'learning', 'material', 'r']",winterholtz model learning material r,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
558,confusion matrix in random forest r with na in output varaible,Tools,confusion matrix in random forest r with na in output varaible,"['confusion', 'matrix', 'in', 'random', 'forest', 'r', 'with', 'na', 'in', 'output', 'varaible']",0,"['confusion', 'matrix', 'in', 'random', 'forest', 'r', 'with', 'na', 'in', 'output', 'varaible']","['confusion', 'matrix', 'random', 'forest', 'r', 'na', 'output', 'varaible']",confusion matrix random forest r na output varaible,-0.5,-0.5,11,51,4.25,0,0,0,0,0,0,0,0
559,randomforestclassifier fit fails with memory error on ec but runs without error locally,Techniques,randomforestclassifier fit fails with memory error on ec but runs without error locally,"['randomforestclassifier', 'fit', 'fails', 'with', 'memory', 'error', 'on', 'ec', 'but', 'runs', 'without', 'error', 'locally']",0,"['randomforestclassifier', 'fit', 'fails', 'with', 'memory', 'error', 'on', 'ec', 'but', 'run', 'without', 'error', 'locally']","['randomforestclassifier', 'fit', 'fails', 'memory', 'error', 'ec', 'run', 'without', 'error', 'locally']",randomforestclassifier fit fails memory error ec run without error locally,-0.0333333333333333,-0.0333333333333333,13,74,5.285714285714286,0,0,0,0,0,0,0,0
560,analytics  effort estimates,Techniques,analytics  effort estimates,"['analytics', 'effort', 'estimates']",0,"['analytics', 'effort', 'estimate']","['analytics', 'effort', 'estimate']",analytics effort estimate,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
561,how to deal with missing values in test dataset,Hackathons,how to deal with missing values in test dataset,"['how', 'to', 'deal', 'with', 'missing', 'values', 'in', 'test', 'dataset']",0,"['how', 'to', 'deal', 'with', 'missing', 'value', 'in', 'test', 'dataset']","['deal', 'missing', 'value', 'test', 'dataset']",deal missing value test dataset,-0.2,-0.2,9,31,3.1,0,0,0,0,0,0,0,0
562,loan prediction problem dataset,Hackathons,loan prediction problem dataset,"['loan', 'prediction', 'problem', 'dataset']",0,"['loan', 'prediction', 'problem', 'dataset']","['loan', 'prediction', 'problem', 'dataset']",loan prediction problem dataset,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
563,how can we read a random sample of records from a csv file in r,Tools,how can we read a random sample of records from a csv file in r,"['how', 'can', 'we', 'read', 'a', 'random', 'sample', 'of', 'records', 'from', 'a', 'csv', 'file', 'in', 'r']",0,"['how', 'can', 'we', 'read', 'a', 'random', 'sample', 'of', 'record', 'from', 'a', 'csv', 'file', 'in', 'r']","['read', 'random', 'sample', 'record', 'csv', 'file', 'r']",read random sample record csv file r,-0.5,-0.5,15,36,2.25,0,0,0,0,0,0,0,0
564,not getting private leader board rank,Hackathons,not getting private leader board rank,"['not', 'getting', 'private', 'leader', 'board', 'rank']",0,"['not', 'getting', 'private', 'leader', 'board', 'rank']","['getting', 'private', 'leader', 'board', 'rank']",getting private leader board rank,-0.4,-0.4,6,33,4.714285714285714,0,0,0,0,0,0,0,0
565,fetching list of idshandlesuser names from twitter,Tools,fetching list of idshandlesuser names from twitter,"['fetching', 'list', 'of', 'idshandlesuser', 'names', 'from', 'twitter']",0,"['fetching', 'list', 'of', 'idshandlesuser', 'name', 'from', 'twitter']","['fetching', 'list', 'idshandlesuser', 'name', 'twitter']",fetching list idshandlesuser name twitter,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
566,do you want to join a growing analytics team in a leading schooltech company,Career,do you want to join a growing analytics team in a leading schooltech company,"['do', 'you', 'want', 'to', 'join', 'a', 'growing', 'analytics', 'team', 'in', 'a', 'leading', 'schooltech', 'company']",0,"['do', 'you', 'want', 'to', 'join', 'a', 'growing', 'analytics', 'team', 'in', 'a', 'leading', 'schooltech', 'company']","['want', 'join', 'growing', 'analytics', 'team', 'leading', 'schooltech', 'company']",want join growing analytics team leading schooltech company,0.0,0.0,14,59,3.933333333333333,0,0,0,0,0,0,0,0
567,how to reduce the support vector in svm,Techniques,how to reduce the support vector in svm,"['how', 'to', 'reduce', 'the', 'support', 'vector', 'in', 'svm']",0,"['how', 'to', 'reduce', 'the', 'support', 'vector', 'in', 'svm']","['reduce', 'support', 'vector', 'svm']",reduce support vector svm,0.0,0.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
568,research the effects of big data analytics and distinct dynamic capabilities on firm performance,Techniques,research the effects of big data analytics and distinct dynamic capabilities on firm performance,"['research', 'the', 'effects', 'of', 'big', 'data', 'analytics', 'and', 'distinct', 'dynamic', 'capabilities', 'on', 'firm', 'performance']",0,"['research', 'the', 'effect', 'of', 'big', 'data', 'analytics', 'and', 'distinct', 'dynamic', 'capability', 'on', 'firm', 'performance']","['research', 'effect', 'big', 'data', 'analytics', 'distinct', 'dynamic', 'capability', 'firm', 'performance']",research effect big data analytics distinct dynamic capability firm performance,0.0249999999999999,0.0249999999999999,14,79,5.266666666666667,0,0,0,0,0,0,0,0
569,help needed in time series problem,Techniques,help needed in time series problem,"['help', 'needed', 'in', 'time', 'series', 'problem']",0,"['help', 'needed', 'in', 'time', 'series', 'problem']","['help', 'needed', 'time', 'series', 'problem']",help needed time series problem,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
570,deep learning activation function selection,Techniques,deep learning activation function selection,"['deep', 'learning', 'activation', 'function', 'selection']",0,"['deep', 'learning', 'activation', 'function', 'selection']","['deep', 'learning', 'activation', 'function', 'selection']",deep learning activation function selection,0.0,0.0,5,43,7.166666666666667,0,0,0,0,0,0,0,0
571,error reading in data in sas using datalines,Tools,error reading in data in sas using datalines,"['error', 'reading', 'in', 'data', 'in', 'sas', 'using', 'datalines']",0,"['error', 'reading', 'in', 'data', 'in', 'sa', 'using', 'datalines']","['error', 'reading', 'data', 'sa', 'using', 'datalines']",error reading data sa using datalines,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
572,how does personalized machine learning work,Techniques,how does personalized machine learning work,"['how', 'does', 'personalized', 'machine', 'learning', 'work']",0,"['how', 'doe', 'personalized', 'machine', 'learning', 'work']","['doe', 'personalized', 'machine', 'learning', 'work']",doe personalized machine learning work,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
573,how to handle numeric values in yn variable in r,Techniques,how to handle numeric values in yn variable in r,"['how', 'to', 'handle', 'numeric', 'values', 'in', 'yn', 'variable', 'in', 'r']",0,"['how', 'to', 'handle', 'numeric', 'value', 'in', 'yn', 'variable', 'in', 'r']","['handle', 'numeric', 'value', 'yn', 'variable', 'r']",handle numeric value yn variable r,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
574,text classification misclassification,Techniques,text classification misclassification,"['text', 'classification', 'misclassification']",0,"['text', 'classification', 'misclassification']","['text', 'classification', 'misclassification']",text classification misclassification,0.0,0.0,3,37,9.25,0,0,0,0,0,0,0,0
575,natural language processing  tweet data,Techniques,natural language processing  tweet data,"['natural', 'language', 'processing', 'tweet', 'data']",0,"['natural', 'language', 'processing', 'tweet', 'data']","['natural', 'language', 'processing', 'tweet', 'data']",natural language processing tweet data,0.1,0.1,5,38,6.333333333333333,0,0,0,0,0,0,0,0
576,what all tools do we use to create a fully functional shiny web app in r,Tools,what all tools do we use to create a fully functional shiny web app in r,"['what', 'all', 'tools', 'do', 'we', 'use', 'to', 'create', 'a', 'fully', 'functional', 'shiny', 'web', 'app', 'in', 'r']",0,"['what', 'all', 'tool', 'do', 'we', 'use', 'to', 'create', 'a', 'fully', 'functional', 'shiny', 'web', 'app', 'in', 'r']","['tool', 'use', 'create', 'fully', 'functional', 'shiny', 'web', 'app', 'r']",tool use create fully functional shiny web app r,0.0,0.0,16,48,2.823529411764706,0,0,0,0,0,0,0,0
577,positive skewed distribution,Techniques,positive skewed distribution,"['positive', 'skewed', 'distribution']",0,"['positive', 'skewed', 'distribution']","['positive', 'skewed', 'distribution']",positive skewed distribution,0.2272727272727272,0.2272727272727272,3,28,7.0,0,0,0,0,0,0,0,0
578,how to choose best data analytics course,Career,how to choose best data analytics course,"['how', 'to', 'choose', 'best', 'data', 'analytics', 'course']",0,"['how', 'to', 'choose', 'best', 'data', 'analytics', 'course']","['choose', 'best', 'data', 'analytics', 'course']",choose best data analytics course,1.0,1.0,7,33,4.125,0,0,0,0,0,0,0,0
579,analytics in fashion retail,Other,analytics in fashion retail,"['analytics', 'in', 'fashion', 'retail']",0,"['analytics', 'in', 'fashion', 'retail']","['analytics', 'fashion', 'retail']",analytics fashion retail,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
580,about tutorial on  powerful r packages used for imputing missing values,Tools,about tutorial on  powerful r packages used for imputing missing values,"['about', 'tutorial', 'on', 'powerful', 'r', 'packages', 'used', 'for', 'imputing', 'missing', 'values']",1,"['about', 'tutorial', 'on', 'powerful', 'r', 'package', 'used', 'for', 'imputing', 'missing', 'value']","['tutorial', 'powerful', 'r', 'package', 'used', 'imputing', 'missing', 'value']",tutorial powerful r package used imputing missing value,0.0499999999999999,0.0499999999999999,11,55,4.583333333333333,0,0,0,0,0,0,0,0
581,how to do one hot encoding in r,Tools,how to do one hot encoding in r,"['how', 'to', 'do', 'one', 'hot', 'encoding', 'in', 'r']",0,"['how', 'to', 'do', 'one', 'hot', 'encoding', 'in', 'r']","['one', 'hot', 'encoding', 'r']",one hot encoding r,0.25,0.25,8,18,2.0,0,0,0,0,0,0,0,0
582,more than one dependent variable in predicitive modelling,Techniques,more than one dependent variable in predicitive modelling,"['more', 'than', 'one', 'dependent', 'variable', 'in', 'predicitive', 'modelling']",0,"['more', 'than', 'one', 'dependent', 'variable', 'in', 'predicitive', 'modelling']","['one', 'dependent', 'variable', 'predicitive', 'modelling']",one dependent variable predicitive modelling,0.5,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
583,why is the sum of the squared components of each pca is equal to ,Techniques,why is the sum of the squared components of each pca is equal to ,"['why', 'is', 'the', 'sum', 'of', 'the', 'squared', 'components', 'of', 'each', 'pca', 'is', 'equal', 'to']",1,"['why', 'is', 'the', 'sum', 'of', 'the', 'squared', 'component', 'of', 'each', 'pca', 'is', 'equal', 'to']","['sum', 'squared', 'component', 'pca', 'equal']",sum squared component pca equal,0.0,0.0,14,31,2.066666666666667,0,0,0,0,0,0,0,0
584,data clustering with kmeans with data in columns,Techniques,data clustering with kmeans with data in columns,"['data', 'clustering', 'with', 'kmeans', 'with', 'data', 'in', 'columns']",0,"['data', 'clustering', 'with', 'kmeans', 'with', 'data', 'in', 'column']","['data', 'clustering', 'kmeans', 'data', 'column']",data clustering kmeans data column,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
585,dead photo links on a page in your site,Misc,dead photo links on a page in your site,"['dead', 'photo', 'links', 'on', 'a', 'page', 'in', 'your', 'site']",0,"['dead', 'photo', 'link', 'on', 'a', 'page', 'in', 'your', 'site']","['dead', 'photo', 'link', 'page', 'site']",dead photo link page site,-0.2,-0.2,9,25,2.5,0,0,0,0,0,0,0,0
586,can we use hierarchical clustering to determine optimal number of clusters,Techniques,can we use hierarchical clustering to determine optimal number of clusters,"['can', 'we', 'use', 'hierarchical', 'clustering', 'to', 'determine', 'optimal', 'number', 'of', 'clusters']",0,"['can', 'we', 'use', 'hierarchical', 'clustering', 'to', 'determine', 'optimal', 'number', 'of', 'cluster']","['use', 'hierarchical', 'clustering', 'determine', 'optimal', 'number', 'cluster']",use hierarchical clustering determine optimal number cluster,0.0,0.0,11,60,5.0,0,0,0,0,0,0,0,0
587,how to create level in the split function in r,Tools,how to create level in the split function in r,"['how', 'to', 'create', 'level', 'in', 'the', 'split', 'function', 'in', 'r']",0,"['how', 'to', 'create', 'level', 'in', 'the', 'split', 'function', 'in', 'r']","['create', 'level', 'split', 'function', 'r']",create level split function r,0.0,0.0,10,29,2.6363636363636362,0,0,0,0,0,0,0,0
588,tips for aspiring data scientists,Career,tips for aspiring data scientists,"['tips', 'for', 'aspiring', 'data', 'scientists']",0,"['tip', 'for', 'aspiring', 'data', 'scientist']","['tip', 'aspiring', 'data', 'scientist']",tip aspiring data scientist,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
589,how to get numeric value of output variable in linear regression,Techniques,how to get numeric value of output variable in linear regression,"['how', 'to', 'get', 'numeric', 'value', 'of', 'output', 'variable', 'in', 'linear', 'regression']",0,"['how', 'to', 'get', 'numeric', 'value', 'of', 'output', 'variable', 'in', 'linear', 'regression']","['get', 'numeric', 'value', 'output', 'variable', 'linear', 'regression']",get numeric value output variable linear regression,0.0,0.0,11,51,4.25,0,0,0,0,0,0,0,0
590,regression and kfold values python,Techniques,regression and kfold values python,"['regression', 'and', 'kfold', 'values', 'python']",0,"['regression', 'and', 'kfold', 'value', 'python']","['regression', 'kfold', 'value', 'python']",regression kfold value python,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
591,what does a point on roc curve represents,Techniques,what does a point on roc curve represents,"['what', 'does', 'a', 'point', 'on', 'roc', 'curve', 'represents']",0,"['what', 'doe', 'a', 'point', 'on', 'roc', 'curve', 'represents']","['doe', 'point', 'roc', 'curve', 'represents']",doe point roc curve represents,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
592,robust way to find significant variables to build a model in r,Tools,robust way to find significant variables to build a model in r,"['robust', 'way', 'to', 'find', 'significant', 'variables', 'to', 'build', 'a', 'model', 'in', 'r']",0,"['robust', 'way', 'to', 'find', 'significant', 'variable', 'to', 'build', 'a', 'model', 'in', 'r']","['robust', 'way', 'find', 'significant', 'variable', 'build', 'model', 'r']",robust way find significant variable build model r,0.375,0.375,12,50,3.8461538461538463,0,0,0,0,0,0,0,0
593,how to find roc plot in r,Tools,how to find roc plot in r,"['how', 'to', 'find', 'roc', 'plot', 'in', 'r']",0,"['how', 'to', 'find', 'roc', 'plot', 'in', 'r']","['find', 'roc', 'plot', 'r']",find roc plot r,0.0,0.0,7,15,1.875,0,0,0,0,0,0,0,0
594,problem to understand data exploring using r,Hackathons,problem to understand data exploring using r,"['problem', 'to', 'understand', 'data', 'exploring', 'using', 'r']",0,"['problem', 'to', 'understand', 'data', 'exploring', 'using', 'r']","['problem', 'understand', 'data', 'exploring', 'using', 'r']",problem understand data exploring using r,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
595,benchmark for datahack premier league ,Hackathons,benchmark for datahack premier league ,"['benchmark', 'for', 'datahack', 'premier', 'league']",1,"['benchmark', 'for', 'datahack', 'premier', 'league']","['benchmark', 'datahack', 'premier', 'league']",benchmark datahack premier league,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
596,difficulty in exploratory data analysis and modeling for a newbie,Career,difficulty in exploratory data analysis and modeling for a newbie,"['difficulty', 'in', 'exploratory', 'data', 'analysis', 'and', 'modeling', 'for', 'a', 'newbie']",0,"['difficulty', 'in', 'exploratory', 'data', 'analysis', 'and', 'modeling', 'for', 'a', 'newbie']","['difficulty', 'exploratory', 'data', 'analysis', 'modeling', 'newbie']",difficulty exploratory data analysis modeling newbie,0.0,0.0,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
597,help with brainstorming for data analytics portfolio,Career,help with brainstorming for data analytics portfolio,"['help', 'with', 'brainstorming', 'for', 'data', 'analytics', 'portfolio']",0,"['help', 'with', 'brainstorming', 'for', 'data', 'analytics', 'portfolio']","['help', 'brainstorming', 'data', 'analytics', 'portfolio']",help brainstorming data analytics portfolio,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
598,how to avoid overfitting with classification techniques,Techniques,how to avoid overfitting with classification techniques,"['how', 'to', 'avoid', 'overfitting', 'with', 'classification', 'techniques']",0,"['how', 'to', 'avoid', 'overfitting', 'with', 'classification', 'technique']","['avoid', 'overfitting', 'classification', 'technique']",avoid overfitting classification technique,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
599,how to deal with dates which are less than  in r,Tools,how to deal with dates which are less than  in r,"['how', 'to', 'deal', 'with', 'dates', 'which', 'are', 'less', 'than', 'in', 'r']",1,"['how', 'to', 'deal', 'with', 'date', 'which', 'are', 'le', 'than', 'in', 'r']","['deal', 'date', 'le', 'r']",deal date le r,-0.1666666666666666,0.0,11,14,1.1666666666666667,0,0,0,0,0,0,0,0
600,error in numclass  result would be too long a vector in r,Tools,error in numclass  result would be too long a vector in r,"['error', 'in', 'numclass', 'result', 'would', 'be', 'too', 'long', 'a', 'vector', 'in', 'r']",0,"['error', 'in', 'numclass', 'result', 'would', 'be', 'too', 'long', 'a', 'vector', 'in', 'r']","['error', 'numclass', 'result', 'would', 'long', 'vector', 'r']",error numclass result would long vector r,-0.05,-0.05,12,41,3.1538461538461537,0,0,0,0,0,0,0,0
601,custom for loop very slow in dataframe,Tools,custom for loop very slow in dataframe,"['custom', 'for', 'loop', 'very', 'slow', 'in', 'dataframe']",0,"['custom', 'for', 'loop', 'very', 'slow', 'in', 'dataframe']","['custom', 'loop', 'slow', 'dataframe']",custom loop slow dataframe,-0.39,-0.3,7,26,3.25,0,0,0,0,0,0,0,0
602,how to implement random forests in sas,Tools,how to implement random forests in sas,"['how', 'to', 'implement', 'random', 'forests', 'in', 'sas']",0,"['how', 'to', 'implement', 'random', 'forest', 'in', 'sa']","['implement', 'random', 'forest', 'sa']",implement random forest sa,-0.5,-0.5,7,26,3.25,0,0,0,0,0,0,0,0
603,career in analytics in agriculture field,Career,career in analytics in agriculture field,"['career', 'in', 'analytics', 'in', 'agriculture', 'field']",0,"['career', 'in', 'analytics', 'in', 'agriculture', 'field']","['career', 'analytics', 'agriculture', 'field']",career analytics agriculture field,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
604,xgboost only predicts nan after removing all nans from the training data in python,Tools,xgboost only predicts nan after removing all nans from the training data in python,"['xgboost', 'only', 'predicts', 'nan', 'after', 'removing', 'all', 'nans', 'from', 'the', 'training', 'data', 'in', 'python']",0,"['xgboost', 'only', 'predicts', 'nan', 'after', 'removing', 'all', 'nan', 'from', 'the', 'training', 'data', 'in', 'python']","['xgboost', 'predicts', 'nan', 'removing', 'nan', 'training', 'data', 'python']",xgboost predicts nan removing nan training data python,0.0,0.0,14,54,3.6,0,0,0,0,0,0,0,0
605,how to create vertical sliders using shiny,Tools,how to create vertical sliders using shiny,"['how', 'to', 'create', 'vertical', 'sliders', 'using', 'shiny']",0,"['how', 'to', 'create', 'vertical', 'slider', 'using', 'shiny']","['create', 'vertical', 'slider', 'using', 'shiny']",create vertical slider using shiny,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
606,mini hack  strategic thinking,Hackathons,mini hack  strategic thinking,"['mini', 'hack', 'strategic', 'thinking']",0,"['mini', 'hack', 'strategic', 'thinking']","['mini', 'hack', 'strategic', 'thinking']",mini hack strategic thinking,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
607,hyperparameter tuning xgboost on gpu,Tools,hyperparameter tuning xgboost on gpu,"['hyperparameter', 'tuning', 'xgboost', 'on', 'gpu']",0,"['hyperparameter', 'tuning', 'xgboost', 'on', 'gpu']","['hyperparameter', 'tuning', 'xgboost', 'gpu']",hyperparameter tuning xgboost gpu,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
608,career after masters in data science for a non cse student,Career,career after masters in data science for a non cse student,"['career', 'after', 'masters', 'in', 'data', 'science', 'for', 'a', 'non', 'cse', 'student']",0,"['career', 'after', 'master', 'in', 'data', 'science', 'for', 'a', 'non', 'cse', 'student']","['career', 'master', 'data', 'science', 'non', 'cse', 'student']",career master data science non cse student,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
609,what all machine learning techniques can be used for predicting continuous variables,Techniques,what all machine learning techniques can be used for predicting continuous variables,"['what', 'all', 'machine', 'learning', 'techniques', 'can', 'be', 'used', 'for', 'predicting', 'continuous', 'variables']",0,"['what', 'all', 'machine', 'learning', 'technique', 'can', 'be', 'used', 'for', 'predicting', 'continuous', 'variable']","['machine', 'learning', 'technique', 'used', 'predicting', 'continuous', 'variable']",machine learning technique used predicting continuous variable,0.0,0.0,12,62,4.769230769230769,0,0,0,0,0,0,0,0
610,how to calculate confidence interval in the acf and the pacf graph,Techniques,how to calculate confidence interval in the acf and the pacf graph,"['how', 'to', 'calculate', 'confidence', 'interval', 'in', 'the', 'acf', 'and', 'the', 'pacf', 'graph']",0,"['how', 'to', 'calculate', 'confidence', 'interval', 'in', 'the', 'acf', 'and', 'the', 'pacf', 'graph']","['calculate', 'confidence', 'interval', 'acf', 'pacf', 'graph']",calculate confidence interval acf pacf graph,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
611,careers in web analytics,Career,careers in web analytics,"['careers', 'in', 'web', 'analytics']",0,"['career', 'in', 'web', 'analytics']","['career', 'web', 'analytics']",career web analytics,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
612,pgdba iimcisiiitkgp,Career,pgdba iimcisiiitkgp,"['pgdba', 'iimcisiiitkgp']",0,"['pgdba', 'iimcisiiitkgp']","['pgdba', 'iimcisiiitkgp']",pgdba iimcisiiitkgp,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
613,access control in plumber package in r,Techniques,access control in plumber package in r,"['access', 'control', 'in', 'plumber', 'package', 'in', 'r']",0,"['access', 'control', 'in', 'plumber', 'package', 'in', 'r']","['access', 'control', 'plumber', 'package', 'r']",access control plumber package r,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
614,can a non java guy become a data scientist,Career,can a non java guy become a data scientist,"['can', 'a', 'non', 'java', 'guy', 'become', 'a', 'data', 'scientist']",0,"['can', 'a', 'non', 'java', 'guy', 'become', 'a', 'data', 'scientist']","['non', 'java', 'guy', 'become', 'data', 'scientist']",non java guy become data scientist,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
615,on performing division in jupyter notebook it is printing only the integer part of quotient how to fix it,Tools,on performing division in jupyter notebook it is printing only the integer part of quotient how to fix it,"['on', 'performing', 'division', 'in', 'jupyter', 'notebook', 'it', 'is', 'printing', 'only', 'the', 'integer', 'part', 'of', 'quotient', 'how', 'to', 'fix', 'it']",0,"['on', 'performing', 'division', 'in', 'jupyter', 'notebook', 'it', 'is', 'printing', 'only', 'the', 'integer', 'part', 'of', 'quotient', 'how', 'to', 'fix', 'it']","['performing', 'division', 'jupyter', 'notebook', 'printing', 'integer', 'part', 'quotient', 'fix']",performing division jupyter notebook printing integer part quotient fix,0.0,0.0,19,71,3.55,0,0,0,0,0,0,0,0
616,what are limitations validation set of approach over kfold cross validation,Techniques,what are limitations validation set of approach over kfold cross validation,"['what', 'are', 'limitations', 'validation', 'set', 'of', 'approach', 'over', 'kfold', 'cross', 'validation']",0,"['what', 'are', 'limitation', 'validation', 'set', 'of', 'approach', 'over', 'kfold', 'cross', 'validation']","['limitation', 'validation', 'set', 'approach', 'kfold', 'cross', 'validation']",limitation validation set approach kfold cross validation,0.0,0.0,11,57,4.75,0,0,0,0,0,0,0,0
617,online hackathon  information about var,Hackathons,online hackathon  information about var,"['online', 'hackathon', 'information', 'about', 'var']",0,"['online', 'hackathon', 'information', 'about', 'var']","['online', 'hackathon', 'information', 'var']",online hackathon information var,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
618,onehotencoding in python,Tools,onehotencoding in python,"['onehotencoding', 'in', 'python']",0,"['onehotencoding', 'in', 'python']","['onehotencoding', 'python']",onehotencoding python,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
619,central limit theorem,Techniques,central limit theorem,"['central', 'limit', 'theorem']",0,"['central', 'limit', 'theorem']","['central', 'limit', 'theorem']",central limit theorem,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
620,date your data how to upload the code file,Hackathons,date your data how to upload the code file,"['date', 'your', 'data', 'how', 'to', 'upload', 'the', 'code', 'file']",0,"['date', 'your', 'data', 'how', 'to', 'upload', 'the', 'code', 'file']","['date', 'data', 'upload', 'code', 'file']",date data upload code file,0.0,0.0,9,26,2.6,0,0,0,0,0,0,0,0
621,stock prediction using lstm algo,Techniques,stock prediction using lstm algo,"['stock', 'prediction', 'using', 'lstm', 'algo']",0,"['stock', 'prediction', 'using', 'lstm', 'algo']","['stock', 'prediction', 'using', 'lstm', 'algo']",stock prediction using lstm algo,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
622,why is the zscore taken to be  for  of the data,Techniques,why is the zscore taken to be  for  of the data,"['why', 'is', 'the', 'zscore', 'taken', 'to', 'be', 'for', 'of', 'the', 'data']",2,"['why', 'is', 'the', 'zscore', 'taken', 'to', 'be', 'for', 'of', 'the', 'data']","['zscore', 'taken', 'data']",zscore taken data,0.0,0.0,11,17,1.4166666666666667,0,0,0,0,0,0,0,0
623,sorting a data frame according to multiple columns in r,Tools,sorting a data frame according to multiple columns in r,"['sorting', 'a', 'data', 'frame', 'according', 'to', 'multiple', 'columns', 'in', 'r']",0,"['sorting', 'a', 'data', 'frame', 'according', 'to', 'multiple', 'column', 'in', 'r']","['sorting', 'data', 'frame', 'according', 'multiple', 'column', 'r']",sorting data frame according multiple column r,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
624,how to interpret log loss metric,Techniques,how to interpret log loss metric,"['how', 'to', 'interpret', 'log', 'loss', 'metric']",0,"['how', 'to', 'interpret', 'log', 'loss', 'metric']","['interpret', 'log', 'loss', 'metric']",interpret log loss metric,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
625,how to read a bunch of docx files in python,Tools,how to read a bunch of docx files in python,"['how', 'to', 'read', 'a', 'bunch', 'of', 'docx', 'files', 'in', 'python']",0,"['how', 'to', 'read', 'a', 'bunch', 'of', 'docx', 'file', 'in', 'python']","['read', 'bunch', 'docx', 'file', 'python']",read bunch docx file python,0.0,0.0,10,27,2.4545454545454546,0,0,0,0,0,0,0,0
626,data visualization for san francisco crime classification problem,Techniques,data visualization for san francisco crime classification problem,"['data', 'visualization', 'for', 'san', 'francisco', 'crime', 'classification', 'problem']",0,"['data', 'visualization', 'for', 'san', 'francisco', 'crime', 'classification', 'problem']","['data', 'visualization', 'san', 'francisco', 'crime', 'classification', 'problem']",data visualization san francisco crime classification problem,0.0,0.0,8,61,6.777777777777778,0,0,0,0,0,0,0,0
627,zerofrequency problem,Techniques,zerofrequency problem,"['zerofrequency', 'problem']",0,"['zerofrequency', 'problem']","['zerofrequency', 'problem']",zerofrequency problem,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
628,open source data lake  external python integration,Tools,open source data lake  external python integration,"['open', 'source', 'data', 'lake', 'external', 'python', 'integration']",0,"['open', 'source', 'data', 'lake', 'external', 'python', 'integration']","['open', 'source', 'data', 'lake', 'external', 'python', 'integration']",open source data lake external python integration,0.0,0.0,7,49,6.125,0,0,0,0,0,0,0,0
629,literacy prediction,Misc,literacy prediction,"['literacy', 'prediction']",0,"['literacy', 'prediction']","['literacy', 'prediction']",literacy prediction,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
630,logic clarification behind decision tree,Techniques,logic clarification behind decision tree,"['logic', 'clarification', 'behind', 'decision', 'tree']",0,"['logic', 'clarification', 'behind', 'decision', 'tree']","['logic', 'clarification', 'behind', 'decision', 'tree']",logic clarification behind decision tree,-0.4,-0.4,5,40,6.666666666666667,0,0,0,0,0,0,0,0
631,error metrics classification model,Techniques,error metrics classification model,"['error', 'metrics', 'classification', 'model']",0,"['error', 'metric', 'classification', 'model']","['error', 'metric', 'classification', 'model']",error metric classification model,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
632,which set of statistic videos can i use for concept building in statistics,Resources,which set of statistic videos can i use for concept building in statistics,"['which', 'set', 'of', 'statistic', 'videos', 'can', 'i', 'use', 'for', 'concept', 'building', 'in', 'statistics']",0,"['which', 'set', 'of', 'statistic', 'video', 'can', 'i', 'use', 'for', 'concept', 'building', 'in', 'statistic']","['set', 'statistic', 'video', 'use', 'concept', 'building', 'statistic']",set statistic video use concept building statistic,0.0,0.0,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
633,solution checker d dalai lama,Hackathons,solution checker d dalai lama,"['solution', 'checker', 'd', 'dalai', 'lama']",0,"['solution', 'checker', 'd', 'dalai', 'lama']","['solution', 'checker', 'dalai', 'lama']",solution checker dalai lama,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
634,which sas course is the best,Career,which sas course is the best,"['which', 'sas', 'course', 'is', 'the', 'best']",0,"['which', 'sa', 'course', 'is', 'the', 'best']","['sa', 'course', 'best']",sa course best,1.0,1.0,6,14,2.0,0,0,0,0,0,0,0,0
635,how to resolve variable lengths differ error in aggregate function in r,Tools,how to resolve variable lengths differ error in aggregate function in r,"['how', 'to', 'resolve', 'variable', 'lengths', 'differ', 'error', 'in', 'aggregate', 'function', 'in', 'r']",0,"['how', 'to', 'resolve', 'variable', 'length', 'differ', 'error', 'in', 'aggregate', 'function', 'in', 'r']","['resolve', 'variable', 'length', 'differ', 'error', 'aggregate', 'function', 'r']",resolve variable length differ error aggregate function r,0.0,0.0,12,57,4.384615384615385,0,0,0,0,0,0,0,0
636,problem in submitting the solution,Hackathons,problem in submitting the solution,"['problem', 'in', 'submitting', 'the', 'solution']",0,"['problem', 'in', 'submitting', 'the', 'solution']","['problem', 'submitting', 'solution']",problem submitting solution,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
637,pg diploma  data science,Career,pg diploma  data science,"['pg', 'diploma', 'data', 'science']",0,"['pg', 'diploma', 'data', 'science']","['pg', 'diploma', 'data', 'science']",pg diploma data science,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
638,how to handle new and missing records when calculating  change in year over year,Techniques,how to handle new and missing records when calculating  change in year over year,"['how', 'to', 'handle', 'new', 'and', 'missing', 'records', 'when', 'calculating', 'change', 'in', 'year', 'over', 'year']",0,"['how', 'to', 'handle', 'new', 'and', 'missing', 'record', 'when', 'calculating', 'change', 'in', 'year', 'over', 'year']","['handle', 'new', 'missing', 'record', 'calculating', 'change', 'year', 'year']",handle new missing record calculating change year year,-0.0318181818181818,-0.0318181818181818,14,54,3.6,0,0,0,0,0,0,0,0
639,required help in digital analytics techinques  analysis ,Techniques,required help in digital analytics techinques  analysis ,"['required', 'help', 'in', 'digital', 'analytics', 'techinques', 'analysis']",0,"['required', 'help', 'in', 'digital', 'analytics', 'techinques', 'analysis']","['required', 'help', 'digital', 'analytics', 'techinques', 'analysis']",required help digital analytics techinques analysis,0.0,0.0,7,51,6.375,0,0,0,0,0,0,0,0
640,how to pass the variable y to ggplot in r,Tools,how to pass the variable y to ggplot in r,"['how', 'to', 'pass', 'the', 'variable', 'y', 'to', 'ggplot', 'in', 'r']",0,"['how', 'to', 'pas', 'the', 'variable', 'y', 'to', 'ggplot', 'in', 'r']","['pas', 'variable', 'ggplot', 'r']",pas variable ggplot r,0.0,0.0,10,21,1.9090909090909092,0,0,0,0,0,0,0,0
641,why it is necessary to normalize in knn,Techniques,why it is necessary to normalize in knn,"['why', 'it', 'is', 'necessary', 'to', 'normalize', 'in', 'knn']",0,"['why', 'it', 'is', 'necessary', 'to', 'normalize', 'in', 'knn']","['necessary', 'normalize', 'knn']",necessary normalize knn,0.0,0.0,8,23,2.5555555555555554,0,0,0,0,0,0,0,0
642,distributed tensorflow,Techniques,distributed tensorflow,"['distributed', 'tensorflow']",0,"['distributed', 'tensorflow']","['distributed', 'tensorflow']",distributed tensorflow,0.0,0.0,2,22,7.333333333333333,0,0,0,0,0,0,0,0
643,where can i get some data to implement adaboost in r,Tools,where can i get some data to implement adaboost in r,"['where', 'can', 'i', 'get', 'some', 'data', 'to', 'implement', 'adaboost', 'in', 'r']",0,"['where', 'can', 'i', 'get', 'some', 'data', 'to', 'implement', 'adaboost', 'in', 'r']","['get', 'data', 'implement', 'adaboost', 'r']",get data implement adaboost r,0.0,0.0,11,29,2.4166666666666665,0,0,0,0,0,0,0,0
644,resources to get solution for general syntax errors in python,Resources,resources to get solution for general syntax errors in python,"['resources', 'to', 'get', 'solution', 'for', 'general', 'syntax', 'errors', 'in', 'python']",0,"['resource', 'to', 'get', 'solution', 'for', 'general', 'syntax', 'error', 'in', 'python']","['resource', 'get', 'solution', 'general', 'syntax', 'error', 'python']",resource get solution general syntax error python,0.05,0.05,10,49,4.454545454545454,0,0,0,0,0,0,0,0
645,calculating predicted values from the negative linear regression using pglm,Techniques,calculating predicted values from the negative linear regression using pglm,"['calculating', 'predicted', 'values', 'from', 'the', 'negative', 'linear', 'regression', 'using', 'pglm']",0,"['calculating', 'predicted', 'value', 'from', 'the', 'negative', 'linear', 'regression', 'using', 'pglm']","['calculating', 'predicted', 'value', 'negative', 'linear', 'regression', 'using', 'pglm']",calculating predicted value negative linear regression using pglm,-0.3,-0.3,10,65,5.909090909090909,0,0,0,0,0,0,0,0
646,how to combine different dimension both frame has one column with different sort and dimension,Tools,how to combine different dimension both frame has one column with different sort and dimension,"['how', 'to', 'combine', 'different', 'dimension', 'both', 'frame', 'has', 'one', 'column', 'with', 'different', 'sort', 'and', 'dimension']",0,"['how', 'to', 'combine', 'different', 'dimension', 'both', 'frame', 'ha', 'one', 'column', 'with', 'different', 'sort', 'and', 'dimension']","['combine', 'different', 'dimension', 'frame', 'ha', 'one', 'column', 'different', 'sort', 'dimension']",combine different dimension frame ha one column different sort dimension,0.0,0.0,15,72,4.5,0,0,0,0,0,0,0,0
647,need help working on data science projects,Techniques,need help working on data science projects,"['need', 'help', 'working', 'on', 'data', 'science', 'projects']",0,"['need', 'help', 'working', 'on', 'data', 'science', 'project']","['need', 'help', 'working', 'data', 'science', 'project']",need help working data science project,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
648,analytics for data science from institute of statistics education  yesno,Career,analytics for data science from institute of statistics education  yesno,"['analytics', 'for', 'data', 'science', 'from', 'institute', 'of', 'statistics', 'education', 'yesno']",0,"['analytics', 'for', 'data', 'science', 'from', 'institute', 'of', 'statistic', 'education', 'yesno']","['analytics', 'data', 'science', 'institute', 'statistic', 'education', 'yesno']",analytics data science institute statistic education yesno,0.0,0.0,10,58,5.2727272727272725,0,0,0,0,0,0,0,0
649,resources for optimization,Resources,resources for optimization,"['resources', 'for', 'optimization']",0,"['resource', 'for', 'optimization']","['resource', 'optimization']",resource optimization,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
650,trying to understand cost matrix in roc  auc,Techniques,trying to understand cost matrix in roc  auc,"['trying', 'to', 'understand', 'cost', 'matrix', 'in', 'roc', 'auc']",0,"['trying', 'to', 'understand', 'cost', 'matrix', 'in', 'roc', 'auc']","['trying', 'understand', 'cost', 'matrix', 'roc', 'auc']",trying understand cost matrix roc auc,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
651,combine categorical variables into factors to form clusters,Techniques,combine categorical variables into factors to form clusters,"['combine', 'categorical', 'variables', 'into', 'factors', 'to', 'form', 'clusters']",0,"['combine', 'categorical', 'variable', 'into', 'factor', 'to', 'form', 'cluster']","['combine', 'categorical', 'variable', 'factor', 'form', 'cluster']",combine categorical variable factor form cluster,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
652,how does point system work,Other,how does point system work,"['how', 'does', 'point', 'system', 'work']",0,"['how', 'doe', 'point', 'system', 'work']","['doe', 'point', 'system', 'work']",doe point system work,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
653,how can i use coapplicaantincome as a feature,Hackathons,how can i use coapplicaantincome as a feature,"['how', 'can', 'i', 'use', 'coapplicaantincome', 'as', 'a', 'feature']",0,"['how', 'can', 'i', 'use', 'coapplicaantincome', 'a', 'a', 'feature']","['use', 'coapplicaantincome', 'feature']",use coapplicaantincome feature,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
654,how to handle missing values of categorical variables for unsupervised data,Techniques,how to handle missing values of categorical variables for unsupervised data,"['how', 'to', 'handle', 'missing', 'values', 'of', 'categorical', 'variables', 'for', 'unsupervised', 'data']",0,"['how', 'to', 'handle', 'missing', 'value', 'of', 'categorical', 'variable', 'for', 'unsupervised', 'data']","['handle', 'missing', 'value', 'categorical', 'variable', 'unsupervised', 'data']",handle missing value categorical variable unsupervised data,-0.2,-0.2,11,59,4.916666666666667,0,0,0,0,0,0,0,0
655,how to make boxplots in r using two specific variables,Tools,how to make boxplots in r using two specific variables,"['how', 'to', 'make', 'boxplots', 'in', 'r', 'using', 'two', 'specific', 'variables']",0,"['how', 'to', 'make', 'boxplots', 'in', 'r', 'using', 'two', 'specific', 'variable']","['make', 'boxplots', 'r', 'using', 'two', 'specific', 'variable']",make boxplots r using two specific variable,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
656,how to use binary variables in k meanshierarchical clustering in sasr,Techniques,how to use binary variables in k meanshierarchical clustering in sasr,"['how', 'to', 'use', 'binary', 'variables', 'in', 'k', 'meanshierarchical', 'clustering', 'in', 'sasr']",0,"['how', 'to', 'use', 'binary', 'variable', 'in', 'k', 'meanshierarchical', 'clustering', 'in', 'sasr']","['use', 'binary', 'variable', 'k', 'meanshierarchical', 'clustering', 'sasr']",use binary variable k meanshierarchical clustering sasr,0.0,0.0,11,55,4.583333333333333,0,0,0,0,0,0,0,0
657,reading a subset from a sas file using libname data and set statement,Tools,reading a subset from a sas file using libname data and set statement,"['reading', 'a', 'subset', 'from', 'a', 'sas', 'file', 'using', 'libname', 'data', 'and', 'set', 'statement']",0,"['reading', 'a', 'subset', 'from', 'a', 'sa', 'file', 'using', 'libname', 'data', 'and', 'set', 'statement']","['reading', 'subset', 'sa', 'file', 'using', 'libname', 'data', 'set', 'statement']",reading subset sa file using libname data set statement,0.0,0.0,13,55,3.9285714285714284,0,0,0,0,0,0,0,0
658,how varimax rotation helps in principal component analysis,Techniques,how varimax rotation helps in principal component analysis,"['how', 'varimax', 'rotation', 'helps', 'in', 'principal', 'component', 'analysis']",0,"['how', 'varimax', 'rotation', 'help', 'in', 'principal', 'component', 'analysis']","['varimax', 'rotation', 'help', 'principal', 'component', 'analysis']",varimax rotation help principal component analysis,0.0,0.0,8,50,5.555555555555555,0,0,0,0,0,0,0,0
659,using xgboost in r for regression with only numeric variables,Tools,using xgboost in r for regression with only numeric variables,"['using', 'xgboost', 'in', 'r', 'for', 'regression', 'with', 'only', 'numeric', 'variables']",0,"['using', 'xgboost', 'in', 'r', 'for', 'regression', 'with', 'only', 'numeric', 'variable']","['using', 'xgboost', 'r', 'regression', 'numeric', 'variable']",using xgboost r regression numeric variable,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
660,india ml hiring hackathon ,Hackathons,india ml hiring hackathon ,"['india', 'ml', 'hiring', 'hackathon']",1,"['india', 'ml', 'hiring', 'hackathon']","['india', 'ml', 'hiring', 'hackathon']",india ml hiring hackathon,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
661,questions regarding blogathon ,Hackathons,questions regarding blogathon ,"['questions', 'regarding', 'blogathon']",1,"['question', 'regarding', 'blogathon']","['question', 'regarding', 'blogathon']",question regarding blogathon,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
662,encoding categorical attributes,Techniques,encoding categorical attributes,"['encoding', 'categorical', 'attributes']",0,"['encoding', 'categorical', 'attribute']","['encoding', 'categorical', 'attribute']",encoding categorical attribute,0.0,0.0,3,30,7.5,0,0,0,0,0,0,0,0
663,how to group or classify the patterns in the trend,Techniques,how to group or classify the patterns in the trend,"['how', 'to', 'group', 'or', 'classify', 'the', 'patterns', 'in', 'the', 'trend']",0,"['how', 'to', 'group', 'or', 'classify', 'the', 'pattern', 'in', 'the', 'trend']","['group', 'classify', 'pattern', 'trend']",group classify pattern trend,0.0,0.0,10,28,2.5454545454545454,0,0,0,0,0,0,0,0
664,converting factor to date format getting stream of nas,Techniques,converting factor to date format getting stream of nas,"['converting', 'factor', 'to', 'date', 'format', 'getting', 'stream', 'of', 'nas']",0,"['converting', 'factor', 'to', 'date', 'format', 'getting', 'stream', 'of', 'na']","['converting', 'factor', 'date', 'format', 'getting', 'stream', 'na']",converting factor date format getting stream na,0.0,0.0,9,47,4.7,0,0,0,0,0,0,0,0
665,isb certificate programme in business analytics,Career,isb certificate programme in business analytics,"['isb', 'certificate', 'programme', 'in', 'business', 'analytics']",0,"['isb', 'certificate', 'programme', 'in', 'business', 'analytics']","['isb', 'certificate', 'programme', 'business', 'analytics']",isb certificate programme business analytics,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
666,mixed effect modelling in r,Techniques,mixed effect modelling in r,"['mixed', 'effect', 'modelling', 'in', 'r']",0,"['mixed', 'effect', 'modelling', 'in', 'r']","['mixed', 'effect', 'modelling', 'r']",mixed effect modelling r,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
667,do ensemble techniques take care of high correlation,Techniques,do ensemble techniques take care of high correlation,"['do', 'ensemble', 'techniques', 'take', 'care', 'of', 'high', 'correlation']",0,"['do', 'ensemble', 'technique', 'take', 'care', 'of', 'high', 'correlation']","['ensemble', 'technique', 'take', 'care', 'high', 'correlation']",ensemble technique take care high correlation,0.16,0.16,8,45,5.0,0,0,0,0,0,0,0,0
668,text generator tools online,Tools,text generator tools online,"['text', 'generator', 'tools', 'online']",0,"['text', 'generator', 'tool', 'online']","['text', 'generator', 'tool', 'online']",text generator tool online,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
669,need help  pg diploma upgrad  iiit b,Career,need help  pg diploma upgrad  iiit b,"['need', 'help', 'pg', 'diploma', 'upgrad', 'iiit', 'b']",0,"['need', 'help', 'pg', 'diploma', 'upgrad', 'iiit', 'b']","['need', 'help', 'pg', 'diploma', 'upgrad', 'iiit', 'b']",need help pg diploma upgrad iiit b,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
670,logistic regression model validation in layman terms,Techniques,logistic regression model validation in layman terms,"['logistic', 'regression', 'model', 'validation', 'in', 'layman', 'terms']",0,"['logistic', 'regression', 'model', 'validation', 'in', 'layman', 'term']","['logistic', 'regression', 'model', 'validation', 'layman', 'term']",logistic regression model validation layman term,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
671,online hackathon   find the next brain wong,Hackathons,online hackathon   find the next brain wong,"['online', 'hackathon', 'find', 'the', 'next', 'brain', 'wong']",1,"['online', 'hackathon', 'find', 'the', 'next', 'brain', 'wong']","['online', 'hackathon', 'find', 'next', 'brain', 'wong']",online hackathon find next brain wong,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
672, rank improvement,Career, rank improvement,"['rank', 'improvement']",0,"['rank', 'improvement']","['rank', 'improvement']",rank improvement,-0.8,-0.8,2,16,5.333333333333333,0,0,0,0,0,0,0,0
673,what percentage of training data should be used for testing of a model,Techniques,what percentage of training data should be used for testing of a model,"['what', 'percentage', 'of', 'training', 'data', 'should', 'be', 'used', 'for', 'testing', 'of', 'a', 'model']",0,"['what', 'percentage', 'of', 'training', 'data', 'should', 'be', 'used', 'for', 'testing', 'of', 'a', 'model']","['percentage', 'training', 'data', 'used', 'testing', 'model']",percentage training data used testing model,0.0,0.0,13,43,3.0714285714285716,0,0,0,0,0,0,0,0
674,how to find the square root of a number in r without using any function,Tools,how to find the square root of a number in r without using any function,"['how', 'to', 'find', 'the', 'square', 'root', 'of', 'a', 'number', 'in', 'r', 'without', 'using', 'any', 'function']",0,"['how', 'to', 'find', 'the', 'square', 'root', 'of', 'a', 'number', 'in', 'r', 'without', 'using', 'any', 'function']","['find', 'square', 'root', 'number', 'r', 'without', 'using', 'function']",find square root number r without using function,0.0,0.0,15,48,3.0,0,0,0,0,0,0,0,0
675,how to select the value of mfinal in boosting,Techniques,how to select the value of mfinal in boosting,"['how', 'to', 'select', 'the', 'value', 'of', 'mfinal', 'in', 'boosting']",0,"['how', 'to', 'select', 'the', 'value', 'of', 'mfinal', 'in', 'boosting']","['select', 'value', 'mfinal', 'boosting']",select value mfinal boosting,0.0,0.0,9,28,2.8,0,0,0,0,0,0,0,0
676,can we use qlikview objects and metrics in powerpoint,Tools,can we use qlikview objects and metrics in powerpoint,"['can', 'we', 'use', 'qlikview', 'objects', 'and', 'metrics', 'in', 'powerpoint']",0,"['can', 'we', 'use', 'qlikview', 'object', 'and', 'metric', 'in', 'powerpoint']","['use', 'qlikview', 'object', 'metric', 'powerpoint']",use qlikview object metric powerpoint,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
677,how to calculate accuracy of a decision tree using rpart in r,Tools,how to calculate accuracy of a decision tree using rpart in r,"['how', 'to', 'calculate', 'accuracy', 'of', 'a', 'decision', 'tree', 'using', 'rpart', 'in', 'r']",0,"['how', 'to', 'calculate', 'accuracy', 'of', 'a', 'decision', 'tree', 'using', 'rpart', 'in', 'r']","['calculate', 'accuracy', 'decision', 'tree', 'using', 'rpart', 'r']",calculate accuracy decision tree using rpart r,0.0,0.0,12,46,3.5384615384615383,0,0,0,0,0,0,0,0
678,how to check the accuracy of a model without submitting on kaggle,Techniques,how to check the accuracy of a model without submitting on kaggle,"['how', 'to', 'check', 'the', 'accuracy', 'of', 'a', 'model', 'without', 'submitting', 'on', 'kaggle']",0,"['how', 'to', 'check', 'the', 'accuracy', 'of', 'a', 'model', 'without', 'submitting', 'on', 'kaggle']","['check', 'accuracy', 'model', 'without', 'submitting', 'kaggle']",check accuracy model without submitting kaggle,0.0,0.0,12,46,3.5384615384615383,0,0,0,0,0,0,0,0
679,how to plot a graph using knn algorithm,Techniques,how to plot a graph using knn algorithm,"['how', 'to', 'plot', 'a', 'graph', 'using', 'knn', 'algorithm']",0,"['how', 'to', 'plot', 'a', 'graph', 'using', 'knn', 'algorithm']","['plot', 'graph', 'using', 'knn', 'algorithm']",plot graph using knn algorithm,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
680,feedback  suggestions  experience on online hackathon ,Hackathons,feedback  suggestions  experience on online hackathon ,"['feedback', 'suggestions', 'experience', 'on', 'online', 'hackathon']",1,"['feedback', 'suggestion', 'experience', 'on', 'online', 'hackathon']","['feedback', 'suggestion', 'experience', 'online', 'hackathon']",feedback suggestion experience online hackathon,0.0,0.0,6,47,6.714285714285714,0,0,0,0,0,0,0,0
681,sas programmer to data scientist,Career,sas programmer to data scientist,"['sas', 'programmer', 'to', 'data', 'scientist']",0,"['sa', 'programmer', 'to', 'data', 'scientist']","['sa', 'programmer', 'data', 'scientist']",sa programmer data scientist,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
682,pca on correlated environmental variables for a sdm  presence and absence points,Techniques,pca on correlated environmental variables for a sdm  presence and absence points,"['pca', 'on', 'correlated', 'environmental', 'variables', 'for', 'a', 'sdm', 'presence', 'and', 'absence', 'points']",0,"['pca', 'on', 'correlated', 'environmental', 'variable', 'for', 'a', 'sdm', 'presence', 'and', 'absence', 'point']","['pca', 'correlated', 'environmental', 'variable', 'sdm', 'presence', 'absence', 'point']",pca correlated environmental variable sdm presence absence point,-0.0125,-0.0125,12,64,4.923076923076923,0,0,0,0,0,0,0,0
683,in depth tutorial for pytorchtransformers,Techniques,in depth tutorial for pytorchtransformers,"['in', 'depth', 'tutorial', 'for', 'pytorchtransformers']",0,"['in', 'depth', 'tutorial', 'for', 'pytorchtransformers']","['depth', 'tutorial', 'pytorchtransformers']",depth tutorial pytorchtransformers,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
684,business analyst role in investment banks,Career,business analyst role in investment banks,"['business', 'analyst', 'role', 'in', 'investment', 'banks']",0,"['business', 'analyst', 'role', 'in', 'investment', 'bank']","['business', 'analyst', 'role', 'investment', 'bank']",business analyst role investment bank,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
685,optimize the products price for an online vendor,Techniques,optimize the products price for an online vendor,"['optimize', 'the', 'products', 'price', 'for', 'an', 'online', 'vendor']",0,"['optimize', 'the', 'product', 'price', 'for', 'an', 'online', 'vendor']","['optimize', 'product', 'price', 'online', 'vendor']",optimize product price online vendor,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
686,new york taxi trip duration,Techniques,new york taxi trip duration,"['new', 'york', 'taxi', 'trip', 'duration']",0,"['new', 'york', 'taxi', 'trip', 'duration']","['new', 'york', 'taxi', 'trip', 'duration']",new york taxi trip duration,0.1363636363636363,0.1363636363636363,5,27,4.5,0,0,0,0,0,0,0,0
687,time series  can i use any other factor like any numeric factor except date and time for a time series,Techniques,time series  can i use any other factor like any numeric factor except date and time for a time series,"['time', 'series', 'can', 'i', 'use', 'any', 'other', 'factor', 'like', 'any', 'numeric', 'factor', 'except', 'date', 'and', 'time', 'for', 'a', 'time', 'series']",0,"['time', 'series', 'can', 'i', 'use', 'any', 'other', 'factor', 'like', 'any', 'numeric', 'factor', 'except', 'date', 'and', 'time', 'for', 'a', 'time', 'series']","['time', 'series', 'use', 'factor', 'like', 'numeric', 'factor', 'except', 'date', 'time', 'time', 'series']",time series use factor like numeric factor except date time time series,-0.125,0.0,20,71,3.380952380952381,0,0,0,0,0,0,0,0
688,how to make grid of plot in r,Tools,how to make grid of plot in r,"['how', 'to', 'make', 'grid', 'of', 'plot', 'in', 'r']",0,"['how', 'to', 'make', 'grid', 'of', 'plot', 'in', 'r']","['make', 'grid', 'plot', 'r']",make grid plot r,0.0,0.0,8,16,1.7777777777777777,0,0,0,0,0,0,0,0
689,how to predict contract winning changes,Techniques,how to predict contract winning changes,"['how', 'to', 'predict', 'contract', 'winning', 'changes']",0,"['how', 'to', 'predict', 'contract', 'winning', 'change']","['predict', 'contract', 'winning', 'change']",predict contract winning change,0.5,0.5,6,31,4.428571428571429,0,0,0,0,0,0,0,0
690,r text navie byes same values for class posterior probability,Techniques,r text navie byes same values for class posterior probability,"['r', 'text', 'navie', 'byes', 'same', 'values', 'for', 'class', 'posterior', 'probability']",0,"['r', 'text', 'navie', 'bye', 'same', 'value', 'for', 'class', 'posterior', 'probability']","['r', 'text', 'navie', 'bye', 'value', 'class', 'posterior', 'probability']",r text navie bye value class posterior probability,0.0,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
691,how many possible solution kmeans have of n points and k cluster,Techniques,how many possible solution kmeans have of n points and k cluster,"['how', 'many', 'possible', 'solution', 'kmeans', 'have', 'of', 'n', 'points', 'and', 'k', 'cluster']",0,"['how', 'many', 'possible', 'solution', 'kmeans', 'have', 'of', 'n', 'point', 'and', 'k', 'cluster']","['many', 'possible', 'solution', 'kmeans', 'n', 'point', 'k', 'cluster']",many possible solution kmeans n point k cluster,0.25,0.25,12,47,3.6153846153846154,0,0,0,0,0,0,0,0
692,what is the difference between machine learning data analysis data mining data science and ai,Other,what is the difference between machine learning data analysis data mining data science and ai,"['what', 'is', 'the', 'difference', 'between', 'machine', 'learning', 'data', 'analysis', 'data', 'mining', 'data', 'science', 'and', 'ai']",0,"['what', 'is', 'the', 'difference', 'between', 'machine', 'learning', 'data', 'analysis', 'data', 'mining', 'data', 'science', 'and', 'ai']","['difference', 'machine', 'learning', 'data', 'analysis', 'data', 'mining', 'data', 'science', 'ai']",difference machine learning data analysis data mining data science ai,0.0,0.0,15,69,4.3125,0,0,0,0,0,0,0,0
693,how do i select important variables for my model using python sklearn,Techniques,how do i select important variables for my model using python sklearn,"['how', 'do', 'i', 'select', 'important', 'variables', 'for', 'my', 'model', 'using', 'python', 'sklearn']",0,"['how', 'do', 'i', 'select', 'important', 'variable', 'for', 'my', 'model', 'using', 'python', 'sklearn']","['select', 'important', 'variable', 'model', 'using', 'python', 'sklearn']",select important variable model using python sklearn,0.4,0.4,12,52,4.0,0,0,0,0,0,0,0,0
694,age detection of bollywood actors,Hackathons,age detection of bollywood actors,"['age', 'detection', 'of', 'bollywood', 'actors']",0,"['age', 'detection', 'of', 'bollywood', 'actor']","['age', 'detection', 'bollywood', 'actor']",age detection bollywood actor,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
695,how to place the legend outside the barplot in r,Tools,how to place the legend outside the barplot in r,"['how', 'to', 'place', 'the', 'legend', 'outside', 'the', 'barplot', 'in', 'r']",0,"['how', 'to', 'place', 'the', 'legend', 'outside', 'the', 'barplot', 'in', 'r']","['place', 'legend', 'outside', 'barplot', 'r']",place legend outside barplot r,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
696,how to work with multiclass dependent text classification,Techniques,how to work with multiclass dependent text classification,"['how', 'to', 'work', 'with', 'multiclass', 'dependent', 'text', 'classification']",0,"['how', 'to', 'work', 'with', 'multiclass', 'dependent', 'text', 'classification']","['work', 'multiclass', 'dependent', 'text', 'classification']",work multiclass dependent text classification,0.0,0.0,8,45,5.0,0,0,0,0,0,0,0,0
697,how to download data from internet directly into r,Tools,how to download data from internet directly into r,"['how', 'to', 'download', 'data', 'from', 'internet', 'directly', 'into', 'r']",0,"['how', 'to', 'download', 'data', 'from', 'internet', 'directly', 'into', 'r']","['download', 'data', 'internet', 'directly', 'r']",download data internet directly r,0.1,0.1,9,33,3.3,0,0,0,0,0,0,0,0
698,matrixlearningdifferent dimensions,Techniques,matrixlearningdifferent dimensions,"['matrixlearningdifferent', 'dimensions']",0,"['matrixlearningdifferent', 'dimension']","['matrixlearningdifferent', 'dimension']",matrixlearningdifferent dimension,0.0,0.0,2,33,11.0,0,0,0,0,0,0,0,0
699,extract single numeric id and name attached to another numeric id and name,Techniques,extract single numeric id and name attached to another numeric id and name,"['extract', 'single', 'numeric', 'id', 'and', 'name', 'attached', 'to', 'another', 'numeric', 'id', 'and', 'name']",0,"['extract', 'single', 'numeric', 'id', 'and', 'name', 'attached', 'to', 'another', 'numeric', 'id', 'and', 'name']","['extract', 'single', 'numeric', 'id', 'name', 'attached', 'another', 'numeric', 'id', 'name']",extract single numeric id name attached another numeric id name,-0.0714285714285714,-0.0714285714285714,13,63,4.5,0,0,0,0,0,0,0,0
700,modeling rare events in logistic regression,Techniques,modeling rare events in logistic regression,"['modeling', 'rare', 'events', 'in', 'logistic', 'regression']",0,"['modeling', 'rare', 'event', 'in', 'logistic', 'regression']","['modeling', 'rare', 'event', 'logistic', 'regression']",modeling rare event logistic regression,0.3,0.3,6,39,5.571428571428571,0,0,0,0,0,0,0,0
701,qlikviewdropdown menu,Techniques,qlikviewdropdown menu,"['qlikviewdropdown', 'menu']",0,"['qlikviewdropdown', 'menu']","['qlikviewdropdown', 'menu']",qlikviewdropdown menu,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
702,why zscore is used instead of a tscore for confidence interval of proportion parameter,Techniques,why zscore is used instead of a tscore for confidence interval of proportion parameter,"['why', 'zscore', 'is', 'used', 'instead', 'of', 'a', 'tscore', 'for', 'confidence', 'interval', 'of', 'proportion', 'parameter']",0,"['why', 'zscore', 'is', 'used', 'instead', 'of', 'a', 'tscore', 'for', 'confidence', 'interval', 'of', 'proportion', 'parameter']","['zscore', 'used', 'instead', 'tscore', 'confidence', 'interval', 'proportion', 'parameter']",zscore used instead tscore confidence interval proportion parameter,0.0,0.0,14,67,4.466666666666667,0,0,0,0,0,0,0,0
703,how to rearrange the data of series in python,Tools,how to rearrange the data of series in python,"['how', 'to', 'rearrange', 'the', 'data', 'of', 'series', 'in', 'python']",0,"['how', 'to', 'rearrange', 'the', 'data', 'of', 'series', 'in', 'python']","['rearrange', 'data', 'series', 'python']",rearrange data series python,0.0,0.0,9,28,2.8,0,0,0,0,0,0,0,0
704,collinearity among categorical variables,Techniques,collinearity among categorical variables,"['collinearity', 'among', 'categorical', 'variables']",0,"['collinearity', 'among', 'categorical', 'variable']","['collinearity', 'among', 'categorical', 'variable']",collinearity among categorical variable,0.0,0.0,4,39,7.8,0,0,0,0,0,0,0,0
705,what is difference between random forest and decision tree,Techniques,what is difference between random forest and decision tree,"['what', 'is', 'difference', 'between', 'random', 'forest', 'and', 'decision', 'tree']",0,"['what', 'is', 'difference', 'between', 'random', 'forest', 'and', 'decision', 'tree']","['difference', 'random', 'forest', 'decision', 'tree']",difference random forest decision tree,-0.5,-0.5,9,38,3.8,0,0,0,0,0,0,0,0
706,matchbox recommender algorithm in r,Techniques,matchbox recommender algorithm in r,"['matchbox', 'recommender', 'algorithm', 'in', 'r']",0,"['matchbox', 'recommender', 'algorithm', 'in', 'r']","['matchbox', 'recommender', 'algorithm', 'r']",matchbox recommender algorithm r,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
707,what is the career path in biostatistics in india,Career,what is the career path in biostatistics in india,"['what', 'is', 'the', 'career', 'path', 'in', 'biostatistics', 'in', 'india']",0,"['what', 'is', 'the', 'career', 'path', 'in', 'biostatistics', 'in', 'india']","['career', 'path', 'biostatistics', 'india']",career path biostatistics india,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
708,how to find missing values,Techniques,how to find missing values,"['how', 'to', 'find', 'missing', 'values']",0,"['how', 'to', 'find', 'missing', 'value']","['find', 'missing', 'value']",find missing value,-0.2,-0.2,5,18,3.0,0,0,0,0,0,0,0,0
709,download link the ai comic zain  issue  facial recognition using computer vision,Techniques,download link the ai comic zain  issue  facial recognition using computer vision,"['download', 'link', 'the', 'ai', 'comic', 'zain', 'issue', 'facial', 'recognition', 'using', 'computer', 'vision']",1,"['download', 'link', 'the', 'ai', 'comic', 'zain', 'issue', 'facial', 'recognition', 'using', 'computer', 'vision']","['download', 'link', 'ai', 'comic', 'zain', 'issue', 'facial', 'recognition', 'using', 'computer', 'vision']",download link ai comic zain issue facial recognition using computer vision,0.125,0.125,12,74,5.6923076923076925,0,0,0,0,0,0,0,0
710,how to print two if statement in python,Tools,how to print two if statement in python,"['how', 'to', 'print', 'two', 'if', 'statement', 'in', 'python']",0,"['how', 'to', 'print', 'two', 'if', 'statement', 'in', 'python']","['print', 'two', 'statement', 'python']",print two statement python,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
711,reveal approach for mckinsey hiring hack,Hackathons,reveal approach for mckinsey hiring hack,"['reveal', 'approach', 'for', 'mckinsey', 'hiring', 'hack']",0,"['reveal', 'approach', 'for', 'mckinsey', 'hiring', 'hack']","['reveal', 'approach', 'mckinsey', 'hiring', 'hack']",reveal approach mckinsey hiring hack,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
712,data science vs data mining vs data analysis,Techniques,data science vs data mining vs data analysis,"['data', 'science', 'vs', 'data', 'mining', 'vs', 'data', 'analysis']",0,"['data', 'science', 'v', 'data', 'mining', 'v', 'data', 'analysis']","['data', 'science', 'v', 'data', 'mining', 'v', 'data', 'analysis']",data science v data mining v data analysis,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
713,how to get a government job in india using data science skills as a data analystdata scientist,Career,how to get a government job in india using data science skills as a data analystdata scientist,"['how', 'to', 'get', 'a', 'government', 'job', 'in', 'india', 'using', 'data', 'science', 'skills', 'as', 'a', 'data', 'analystdata', 'scientist']",0,"['how', 'to', 'get', 'a', 'government', 'job', 'in', 'india', 'using', 'data', 'science', 'skill', 'a', 'a', 'data', 'analystdata', 'scientist']","['get', 'government', 'job', 'india', 'using', 'data', 'science', 'skill', 'data', 'analystdata', 'scientist']",get government job india using data science skill data analystdata scientist,0.0,0.0,17,76,4.222222222222222,0,0,0,0,0,0,0,0
714,how to generate inferences from over plotted scatter plot,Techniques,how to generate inferences from over plotted scatter plot,"['how', 'to', 'generate', 'inferences', 'from', 'over', 'plotted', 'scatter', 'plot']",0,"['how', 'to', 'generate', 'inference', 'from', 'over', 'plotted', 'scatter', 'plot']","['generate', 'inference', 'plotted', 'scatter', 'plot']",generate inference plotted scatter plot,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
715,how to join slack live chat,Hackathons,how to join slack live chat,"['how', 'to', 'join', 'slack', 'live', 'chat']",0,"['how', 'to', 'join', 'slack', 'live', 'chat']","['join', 'slack', 'live', 'chat']",join slack live chat,0.1363636363636363,0.1363636363636363,6,20,2.857142857142857,0,0,0,0,0,0,0,0
716,big mart sales using catboost,Techniques,big mart sales using catboost,"['big', 'mart', 'sales', 'using', 'catboost']",0,"['big', 'mart', 'sale', 'using', 'catboost']","['big', 'mart', 'sale', 'using', 'catboost']",big mart sale using catboost,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
717,spliting data for random forest,Techniques,spliting data for random forest,"['spliting', 'data', 'for', 'random', 'forest']",0,"['spliting', 'data', 'for', 'random', 'forest']","['spliting', 'data', 'random', 'forest']",spliting data random forest,-0.5,-0.5,5,27,4.5,0,0,0,0,0,0,0,0
718,what should be the value of control argument in bagging model,Techniques,what should be the value of control argument in bagging model,"['what', 'should', 'be', 'the', 'value', 'of', 'control', 'argument', 'in', 'bagging', 'model']",0,"['what', 'should', 'be', 'the', 'value', 'of', 'control', 'argument', 'in', 'bagging', 'model']","['value', 'control', 'argument', 'bagging', 'model']",value control argument bagging model,0.0,0.0,11,36,3.0,0,0,0,0,0,0,0,0
719,how to be a consultant data scientist,Misc,how to be a consultant data scientist,"['how', 'to', 'be', 'a', 'consultant', 'data', 'scientist']",0,"['how', 'to', 'be', 'a', 'consultant', 'data', 'scientist']","['consultant', 'data', 'scientist']",consultant data scientist,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
720,multivariate lstm rmse value is getting very high,Techniques,multivariate lstm rmse value is getting very high,"['multivariate', 'lstm', 'rmse', 'value', 'is', 'getting', 'very', 'high']",0,"['multivariate', 'lstm', 'rmse', 'value', 'is', 'getting', 'very', 'high']","['multivariate', 'lstm', 'rmse', 'value', 'getting', 'high']",multivariate lstm rmse value getting high,0.208,0.16,8,41,4.555555555555555,0,0,0,0,0,0,0,0
721,what is the difference between pandas series and python lists,Tools,what is the difference between pandas series and python lists,"['what', 'is', 'the', 'difference', 'between', 'pandas', 'series', 'and', 'python', 'lists']",0,"['what', 'is', 'the', 'difference', 'between', 'panda', 'series', 'and', 'python', 'list']","['difference', 'panda', 'series', 'python', 'list']",difference panda series python list,0.0,0.0,10,35,3.1818181818181817,0,0,0,0,0,0,0,0
722,python value error x has  features per sample expecting ,Tools,python value error x has  features per sample expecting ,"['python', 'value', 'error', 'x', 'has', 'features', 'per', 'sample', 'expecting']",2,"['python', 'value', 'error', 'x', 'ha', 'feature', 'per', 'sample', 'expecting']","['python', 'value', 'error', 'x', 'ha', 'feature', 'per', 'sample', 'expecting']",python value error x ha feature per sample expecting,0.0,0.0,9,52,5.2,0,0,0,0,0,0,0,0
723,outlier analysis a pre processing technique,Techniques,outlier analysis a pre processing technique,"['outlier', 'analysis', 'a', 'pre', 'processing', 'technique']",0,"['outlier', 'analysis', 'a', 'pre', 'processing', 'technique']","['outlier', 'analysis', 'pre', 'processing', 'technique']",outlier analysis pre processing technique,0.0,0.0,6,41,5.857142857142857,0,0,0,0,0,0,0,0
724,how do i create box plot in excel,Techniques,how do i create box plot in excel,"['how', 'do', 'i', 'create', 'box', 'plot', 'in', 'excel']",0,"['how', 'do', 'i', 'create', 'box', 'plot', 'in', 'excel']","['create', 'box', 'plot', 'excel']",create box plot excel,0.0,0.0,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
725,how to get an option to join slack live chat,Hackathons,how to get an option to join slack live chat,"['how', 'to', 'get', 'an', 'option', 'to', 'join', 'slack', 'live', 'chat']",0,"['how', 'to', 'get', 'an', 'option', 'to', 'join', 'slack', 'live', 'chat']","['get', 'option', 'join', 'slack', 'live', 'chat']",get option join slack live chat,0.1363636363636363,0.1363636363636363,10,31,2.8181818181818183,0,0,0,0,0,0,0,0
726,can hadoop clusters be used simultaneously for other uses,Tools,can hadoop clusters be used simultaneously for other uses,"['can', 'hadoop', 'clusters', 'be', 'used', 'simultaneously', 'for', 'other', 'uses']",0,"['can', 'hadoop', 'cluster', 'be', 'used', 'simultaneously', 'for', 'other', 'us']","['hadoop', 'cluster', 'used', 'simultaneously', 'us']",hadoop cluster used simultaneously us,-0.125,0.0,9,37,3.7,0,0,0,0,0,0,0,0
727,point system ,Techniques,point system ,"['point', 'system']",0,"['point', 'system']","['point', 'system']",point system,0.0,0.0,2,12,4.0,0,0,0,0,0,0,0,0
728,how can i predict tsunami using machine learning where can i get the dataset for prediction,Resources,how can i predict tsunami using machine learning where can i get the dataset for prediction,"['how', 'can', 'i', 'predict', 'tsunami', 'using', 'machine', 'learning', 'where', 'can', 'i', 'get', 'the', 'dataset', 'for', 'prediction']",0,"['how', 'can', 'i', 'predict', 'tsunami', 'using', 'machine', 'learning', 'where', 'can', 'i', 'get', 'the', 'dataset', 'for', 'prediction']","['predict', 'tsunami', 'using', 'machine', 'learning', 'get', 'dataset', 'prediction']",predict tsunami using machine learning get dataset prediction,0.0,0.0,16,61,3.588235294117647,0,0,0,0,0,0,0,0
729,encountered error during imputation by mice package,Techniques,encountered error during imputation by mice package,"['encountered', 'error', 'during', 'imputation', 'by', 'mice', 'package']",0,"['encountered', 'error', 'during', 'imputation', 'by', 'mouse', 'package']","['encountered', 'error', 'imputation', 'mouse', 'package']",encountered error imputation mouse package,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
730,log of target variable before training random forest regressor,Techniques,log of target variable before training random forest regressor,"['log', 'of', 'target', 'variable', 'before', 'training', 'random', 'forest', 'regressor']",0,"['log', 'of', 'target', 'variable', 'before', 'training', 'random', 'forest', 'regressor']","['log', 'target', 'variable', 'training', 'random', 'forest', 'regressor']",log target variable training random forest regressor,-0.5,-0.5,9,52,5.2,0,0,0,0,0,0,0,0
731,strategy hackathons,Techniques,strategy hackathons,"['strategy', 'hackathons']",0,"['strategy', 'hackathons']","['strategy', 'hackathons']",strategy hackathons,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
732,mini hack machine learning  revealing your approach,Techniques,mini hack machine learning  revealing your approach,"['mini', 'hack', 'machine', 'learning', 'revealing', 'your', 'approach']",0,"['mini', 'hack', 'machine', 'learning', 'revealing', 'your', 'approach']","['mini', 'hack', 'machine', 'learning', 'revealing', 'approach']",mini hack machine learning revealing approach,0.0,0.0,7,45,5.625,0,0,0,0,0,0,0,0
733,how to add new column using python,Tools,how to add new column using python,"['how', 'to', 'add', 'new', 'column', 'using', 'python']",0,"['how', 'to', 'add', 'new', 'column', 'using', 'python']","['add', 'new', 'column', 'using', 'python']",add new column using python,0.1363636363636363,0.1363636363636363,7,27,3.375,0,0,0,0,0,0,0,0
734,ms in india in data science ai,Career,ms in india in data science ai,"['ms', 'in', 'india', 'in', 'data', 'science', 'ai']",0,"['m', 'in', 'india', 'in', 'data', 'science', 'ai']","['india', 'data', 'science', 'ai']",india data science ai,0.0,0.0,7,21,2.625,0,0,0,0,0,0,0,0
735,boxplots with groupby using multiple columns,Tools,boxplots with groupby using multiple columns,"['boxplots', 'with', 'groupby', 'using', 'multiple', 'columns']",0,"['boxplots', 'with', 'groupby', 'using', 'multiple', 'column']","['boxplots', 'groupby', 'using', 'multiple', 'column']",boxplots groupby using multiple column,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
736,need helpmajor thesis for college,Other,need helpmajor thesis for college,"['need', 'helpmajor', 'thesis', 'for', 'college']",0,"['need', 'helpmajor', 'thesis', 'for', 'college']","['need', 'helpmajor', 'thesis', 'college']",need helpmajor thesis college,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
737,how to resolve errorlabel and prediction size not matching while implementing xgboost in r,Tools,how to resolve errorlabel and prediction size not matching while implementing xgboost in r,"['how', 'to', 'resolve', 'errorlabel', 'and', 'prediction', 'size', 'not', 'matching', 'while', 'implementing', 'xgboost', 'in', 'r']",0,"['how', 'to', 'resolve', 'errorlabel', 'and', 'prediction', 'size', 'not', 'matching', 'while', 'implementing', 'xgboost', 'in', 'r']","['resolve', 'errorlabel', 'prediction', 'size', 'matching', 'implementing', 'xgboost', 'r']",resolve errorlabel prediction size matching implementing xgboost r,0.0,0.0,14,66,4.4,0,0,0,0,0,0,0,0
738,data hackathon  online date th june ,Hackathons,data hackathon  online date th june ,"['data', 'hackathon', 'online', 'date', 'th', 'june']",1,"['data', 'hackathon', 'online', 'date', 'th', 'june']","['data', 'hackathon', 'online', 'date', 'th', 'june']",data hackathon online date th june,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
739,how to open a website in r,Tools,how to open a website in r,"['how', 'to', 'open', 'a', 'website', 'in', 'r']",0,"['how', 'to', 'open', 'a', 'website', 'in', 'r']","['open', 'website', 'r']",open website r,0.0,0.0,7,14,1.75,0,0,0,0,0,0,0,0
740,help  line of approach for data science problem,Techniques,help  line of approach for data science problem,"['help', 'line', 'of', 'approach', 'for', 'data', 'science', 'problem']",0,"['help', 'line', 'of', 'approach', 'for', 'data', 'science', 'problem']","['help', 'line', 'approach', 'data', 'science', 'problem']",help line approach data science problem,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
741,pretrained  deep learning,Techniques,pretrained  deep learning,"['pretrained', 'deep', 'learning']",0,"['pretrained', 'deep', 'learning']","['pretrained', 'deep', 'learning']",pretrained deep learning,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
742,concepts with example of multivariate forecasting in r,Techniques,concepts with example of multivariate forecasting in r,"['concepts', 'with', 'example', 'of', 'multivariate', 'forecasting', 'in', 'r']",0,"['concept', 'with', 'example', 'of', 'multivariate', 'forecasting', 'in', 'r']","['concept', 'example', 'multivariate', 'forecasting', 'r']",concept example multivariate forecasting r,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
743,image segmentation query,Techniques,image segmentation query,"['image', 'segmentation', 'query']",0,"['image', 'segmentation', 'query']","['image', 'segmentation', 'query']",image segmentation query,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
744,am i right in choosing nb classifier in such a task,Techniques,am i right in choosing nb classifier in such a task,"['am', 'i', 'right', 'in', 'choosing', 'nb', 'classifier', 'in', 'such', 'a', 'task']",0,"['am', 'i', 'right', 'in', 'choosing', 'nb', 'classifier', 'in', 'such', 'a', 'task']","['right', 'choosing', 'nb', 'classifier', 'task']",right choosing nb classifier task,0.1428571428571428,0.2857142857142857,11,33,2.75,0,0,0,0,0,0,0,0
745,scaling r model to production,Tools,scaling r model to production,"['scaling', 'r', 'model', 'to', 'production']",0,"['scaling', 'r', 'model', 'to', 'production']","['scaling', 'r', 'model', 'production']",scaling r model production,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
746,how good is the program analytics essentials by iiit bangalore for a beginner in analytics with  yrs of it experience to switch to analytics domain,Career,how good is the program analytics essentials by iiit bangalore for a beginner in analytics with  yrs of it experience to switch to analytics domain,"['how', 'good', 'is', 'the', 'program', 'analytics', 'essentials', 'by', 'iiit', 'bangalore', 'for', 'a', 'beginner', 'in', 'analytics', 'with', 'yrs', 'of', 'it', 'experience', 'to', 'switch', 'to', 'analytics', 'domain']",1,"['how', 'good', 'is', 'the', 'program', 'analytics', 'essential', 'by', 'iiit', 'bangalore', 'for', 'a', 'beginner', 'in', 'analytics', 'with', 'yr', 'of', 'it', 'experience', 'to', 'switch', 'to', 'analytics', 'domain']","['good', 'program', 'analytics', 'essential', 'iiit', 'bangalore', 'beginner', 'analytics', 'yr', 'experience', 'switch', 'analytics', 'domain']",good program analytics essential iiit bangalore beginner analytics yr experience switch analytics domain,0.7,0.35,25,104,4.0,0,0,0,0,0,0,0,0
747,web scrapping using pandas in python,Tools,web scrapping using pandas in python,"['web', 'scrapping', 'using', 'pandas', 'in', 'python']",0,"['web', 'scrapping', 'using', 'panda', 'in', 'python']","['web', 'scrapping', 'using', 'panda', 'python']",web scrapping using panda python,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
748,how do we decide the number of clusters to use while implementing the kmeans clustering algorithm,Techniques,how do we decide the number of clusters to use while implementing the kmeans clustering algorithm,"['how', 'do', 'we', 'decide', 'the', 'number', 'of', 'clusters', 'to', 'use', 'while', 'implementing', 'the', 'kmeans', 'clustering', 'algorithm']",0,"['how', 'do', 'we', 'decide', 'the', 'number', 'of', 'cluster', 'to', 'use', 'while', 'implementing', 'the', 'kmeans', 'clustering', 'algorithm']","['decide', 'number', 'cluster', 'use', 'implementing', 'kmeans', 'clustering', 'algorithm']",decide number cluster use implementing kmeans clustering algorithm,0.0,0.0,16,66,3.8823529411764706,0,0,0,0,0,0,0,0
749,unable to see my published article,Hackathons,unable to see my published article,"['unable', 'to', 'see', 'my', 'published', 'article']",0,"['unable', 'to', 'see', 'my', 'published', 'article']","['unable', 'see', 'published', 'article']",unable see published article,-0.5,-0.5,6,28,4.0,0,0,0,0,0,0,0,0
750,need help on python,Tools,need help on python,"['need', 'help', 'on', 'python']",0,"['need', 'help', 'on', 'python']","['need', 'help', 'python']",need help python,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
751,dataset for feature engineering,Other,dataset for feature engineering,"['dataset', 'for', 'feature', 'engineering']",0,"['dataset', 'for', 'feature', 'engineering']","['dataset', 'feature', 'engineering']",dataset feature engineering,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
752,data scientist at big or at a fast growing startup,Career,data scientist at big or at a fast growing startup,"['data', 'scientist', 'at', 'big', 'or', 'at', 'a', 'fast', 'growing', 'startup']",0,"['data', 'scientist', 'at', 'big', 'or', 'at', 'a', 'fast', 'growing', 'startup']","['data', 'scientist', 'big', 'fast', 'growing', 'startup']",data scientist big fast growing startup,0.1,0.1,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
753,where do we use sql in data science,Tools,where do we use sql in data science,"['where', 'do', 'we', 'use', 'sql', 'in', 'data', 'science']",0,"['where', 'do', 'we', 'use', 'sql', 'in', 'data', 'science']","['use', 'sql', 'data', 'science']",use sql data science,0.0,0.0,8,20,2.2222222222222223,0,0,0,0,0,0,0,0
754,best analytics training institutes in bangalore,Resources,best analytics training institutes in bangalore,"['best', 'analytics', 'training', 'institutes', 'in', 'bangalore']",0,"['best', 'analytics', 'training', 'institute', 'in', 'bangalore']","['best', 'analytics', 'training', 'institute', 'bangalore']",best analytics training institute bangalore,1.0,1.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
755,creating company groups from customer relationships,Techniques,creating company groups from customer relationships,"['creating', 'company', 'groups', 'from', 'customer', 'relationships']",0,"['creating', 'company', 'group', 'from', 'customer', 'relationship']","['creating', 'company', 'group', 'customer', 'relationship']",creating company group customer relationship,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
756,how do you deal with imbalance data,Tools,how do you deal with imbalance data,"['how', 'do', 'you', 'deal', 'with', 'imbalance', 'data']",0,"['how', 'do', 'you', 'deal', 'with', 'imbalance', 'data']","['deal', 'imbalance', 'data']",deal imbalance data,0.0,0.0,7,19,2.375,0,0,0,0,0,0,0,0
757,hackathon solution,Hackathons,hackathon solution,"['hackathon', 'solution']",0,"['hackathon', 'solution']","['hackathon', 'solution']",hackathon solution,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
758,how to do this operation of sas proc univariate pctlpts     to  by  in python,Misc,how to do this operation of sas proc univariate pctlpts     to  by  in python,"['how', 'to', 'do', 'this', 'operation', 'of', 'sas', 'proc', 'univariate', 'pctlpts', 'to', 'by', 'in', 'python']",6,"['how', 'to', 'do', 'this', 'operation', 'of', 'sa', 'proc', 'univariate', 'pctlpts', 'to', 'by', 'in', 'python']","['operation', 'sa', 'proc', 'univariate', 'pctlpts', 'python']",operation sa proc univariate pctlpts python,0.0,0.0,14,43,2.8666666666666667,0,0,0,0,0,0,0,0
759,data analysis steps involved,Techniques,data analysis steps involved,"['data', 'analysis', 'steps', 'involved']",0,"['data', 'analysis', 'step', 'involved']","['data', 'analysis', 'step', 'involved']",data analysis step involved,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
760,data science how important is statistics,Career,data science how important is statistics,"['data', 'science', 'how', 'important', 'is', 'statistics']",0,"['data', 'science', 'how', 'important', 'is', 'statistic']","['data', 'science', 'important', 'statistic']",data science important statistic,0.4,0.4,6,32,4.571428571428571,0,0,0,0,0,0,0,0
761,how to plot vertical and horizontal bars in different plots,Tools,how to plot vertical and horizontal bars in different plots,"['how', 'to', 'plot', 'vertical', 'and', 'horizontal', 'bars', 'in', 'different', 'plots']",0,"['how', 'to', 'plot', 'vertical', 'and', 'horizontal', 'bar', 'in', 'different', 'plot']","['plot', 'vertical', 'horizontal', 'bar', 'different', 'plot']",plot vertical horizontal bar different plot,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
762,how can i create all possible combination of words from characters of given word in python,Tools,how can i create all possible combination of words from characters of given word in python,"['how', 'can', 'i', 'create', 'all', 'possible', 'combination', 'of', 'words', 'from', 'characters', 'of', 'given', 'word', 'in', 'python']",0,"['how', 'can', 'i', 'create', 'all', 'possible', 'combination', 'of', 'word', 'from', 'character', 'of', 'given', 'word', 'in', 'python']","['create', 'possible', 'combination', 'word', 'character', 'given', 'word', 'python']",create possible combination word character given word python,0.0,0.0,16,60,3.5294117647058822,0,0,0,0,0,0,0,0
763,interactive new user tutorial interactive advanced user tutorial,Misc,interactive new user tutorial interactive advanced user tutorial,"['interactive', 'new', 'user', 'tutorial', 'interactive', 'advanced', 'user', 'tutorial']",0,"['interactive', 'new', 'user', 'tutorial', 'interactive', 'advanced', 'user', 'tutorial']","['interactive', 'new', 'user', 'tutorial', 'interactive', 'advanced', 'user', 'tutorial']",interactive new user tutorial interactive advanced user tutorial,0.2681818181818182,0.2681818181818182,8,64,7.111111111111111,0,0,0,0,0,0,0,0
764,engine response functions,Techniques,engine response functions,"['engine', 'response', 'functions']",0,"['engine', 'response', 'function']","['engine', 'response', 'function']",engine response function,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
765,post hoc analysis for one way anova with unequal sample size and variance,Techniques,post hoc analysis for one way anova with unequal sample size and variance,"['post', 'hoc', 'analysis', 'for', 'one', 'way', 'anova', 'with', 'unequal', 'sample', 'size', 'and', 'variance']",0,"['post', 'hoc', 'analysis', 'for', 'one', 'way', 'anova', 'with', 'unequal', 'sample', 'size', 'and', 'variance']","['post', 'hoc', 'analysis', 'one', 'way', 'anova', 'unequal', 'sample', 'size', 'variance']",post hoc analysis one way anova unequal sample size variance,0.0,0.0,13,60,4.285714285714286,0,0,0,0,0,0,0,0
766,logistic regressionsklearn,Tools,logistic regressionsklearn,"['logistic', 'regressionsklearn']",0,"['logistic', 'regressionsklearn']","['logistic', 'regressionsklearn']",logistic regressionsklearn,0.0,0.0,2,26,8.666666666666666,0,0,0,0,0,0,0,0
767,beginners tutorial for regular expressions in python  python learning,Resources,beginners tutorial for regular expressions in python  python learning,"['beginners', 'tutorial', 'for', 'regular', 'expressions', 'in', 'python', 'python', 'learning']",0,"['beginner', 'tutorial', 'for', 'regular', 'expression', 'in', 'python', 'python', 'learning']","['beginner', 'tutorial', 'regular', 'expression', 'python', 'python', 'learning']",beginner tutorial regular expression python python learning,0.0,0.0,9,59,5.9,0,0,0,0,0,0,0,0
768,error in imputing missing values using fillna,Techniques,error in imputing missing values using fillna,"['error', 'in', 'imputing', 'missing', 'values', 'using', 'fillna']",0,"['error', 'in', 'imputing', 'missing', 'value', 'using', 'fillna']","['error', 'imputing', 'missing', 'value', 'using', 'fillna']",error imputing missing value using fillna,-0.2,-0.2,7,41,5.125,0,0,0,0,0,0,0,0
769,analyse large rdbs data schema,Techniques,analyse large rdbs data schema,"['analyse', 'large', 'rdbs', 'data', 'schema']",0,"['analyse', 'large', 'rdbs', 'data', 'schema']","['analyse', 'large', 'rdbs', 'data', 'schema']",analyse large rdbs data schema,0.2142857142857142,0.2142857142857142,5,30,5.0,0,0,0,0,0,0,0,0
770,how do we check  attribure later purchase behaviour of customers in ecommerce,Techniques,how do we check  attribure later purchase behaviour of customers in ecommerce,"['how', 'do', 'we', 'check', 'attribure', 'later', 'purchase', 'behaviour', 'of', 'customers', 'in', 'ecommerce']",0,"['how', 'do', 'we', 'check', 'attribure', 'later', 'purchase', 'behaviour', 'of', 'customer', 'in', 'ecommerce']","['check', 'attribure', 'later', 'purchase', 'behaviour', 'customer', 'ecommerce']",check attribure later purchase behaviour customer ecommerce,0.0,0.0,12,59,4.538461538461538,0,0,0,0,0,0,0,0
771,what is sas di,Tools,what is sas di,"['what', 'is', 'sas', 'di']",0,"['what', 'is', 'sa', 'di']","['sa', 'di']",sa di,0.0,0.0,4,5,1.0,0,0,0,0,0,0,0,0
773,data science  dimensionality reduction,Techniques,data science  dimensionality reduction,"['data', 'science', 'dimensionality', 'reduction']",0,"['data', 'science', 'dimensionality', 'reduction']","['data', 'science', 'dimensionality', 'reduction']",data science dimensionality reduction,0.0,0.0,4,37,7.4,0,0,0,0,0,0,0,0
774,how to plot a heatmap in r,Tools,how to plot a heatmap in r,"['how', 'to', 'plot', 'a', 'heatmap', 'in', 'r']",0,"['how', 'to', 'plot', 'a', 'heatmap', 'in', 'r']","['plot', 'heatmap', 'r']",plot heatmap r,0.0,0.0,7,14,1.75,0,0,0,0,0,0,0,0
775,python or r for data analytics,Career,python or r for data analytics,"['python', 'or', 'r', 'for', 'data', 'analytics']",0,"['python', 'or', 'r', 'for', 'data', 'analytics']","['python', 'r', 'data', 'analytics']",python r data analytics,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
776,how to compare values in two vectors element wise in r,Tools,how to compare values in two vectors element wise in r,"['how', 'to', 'compare', 'values', 'in', 'two', 'vectors', 'element', 'wise', 'in', 'r']",0,"['how', 'to', 'compare', 'value', 'in', 'two', 'vector', 'element', 'wise', 'in', 'r']","['compare', 'value', 'two', 'vector', 'element', 'wise', 'r']",compare value two vector element wise r,0.7,0.7,11,39,3.25,0,0,0,0,0,0,0,0
777,no missing value find,Hackathons,no missing value find,"['no', 'missing', 'value', 'find']",0,"['no', 'missing', 'value', 'find']","['missing', 'value', 'find']",missing value find,0.1,-0.2,4,18,3.6,0,0,0,0,0,0,0,0
778,big data query optimization,Techniques,big data query optimization,"['big', 'data', 'query', 'optimization']",0,"['big', 'data', 'query', 'optimization']","['big', 'data', 'query', 'optimization']",big data query optimization,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
779,write a r program to get following tasks done,Techniques,write a r program to get following tasks done,"['write', 'a', 'r', 'program', 'to', 'get', 'following', 'tasks', 'done']",0,"['write', 'a', 'r', 'program', 'to', 'get', 'following', 'task', 'done']","['write', 'r', 'program', 'get', 'following', 'task', 'done']",write r program get following task done,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
780,starter code in r for stacked generalization,Techniques,starter code in r for stacked generalization,"['starter', 'code', 'in', 'r', 'for', 'stacked', 'generalization']",0,"['starter', 'code', 'in', 'r', 'for', 'stacked', 'generalization']","['starter', 'code', 'r', 'stacked', 'generalization']",starter code r stacked generalization,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
781,ai application question from a newbie,Other,ai application question from a newbie,"['ai', 'application', 'question', 'from', 'a', 'newbie']",0,"['ai', 'application', 'question', 'from', 'a', 'newbie']","['ai', 'application', 'question', 'newbie']",ai application question newbie,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
782,rnn or lstm numerical example in excel,Techniques,rnn or lstm numerical example in excel,"['rnn', 'or', 'lstm', 'numerical', 'example', 'in', 'excel']",0,"['rnn', 'or', 'lstm', 'numerical', 'example', 'in', 'excel']","['rnn', 'lstm', 'numerical', 'example', 'excel']",rnn lstm numerical example excel,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
783,dimension reduction technique for categorical variable,Techniques,dimension reduction technique for categorical variable,"['dimension', 'reduction', 'technique', 'for', 'categorical', 'variable']",0,"['dimension', 'reduction', 'technique', 'for', 'categorical', 'variable']","['dimension', 'reduction', 'technique', 'categorical', 'variable']",dimension reduction technique categorical variable,0.0,0.0,6,50,7.142857142857143,0,0,0,0,0,0,0,0
784,logistic regression doubts,Techniques,logistic regression doubts,"['logistic', 'regression', 'doubts']",0,"['logistic', 'regression', 'doubt']","['logistic', 'regression', 'doubt']",logistic regression doubt,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
785,multivariate time series,Techniques,multivariate time series,"['multivariate', 'time', 'series']",0,"['multivariate', 'time', 'series']","['multivariate', 'time', 'series']",multivariate time series,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
786,time series in r  converting to ts object,Tools,time series in r  converting to ts object,"['time', 'series', 'in', 'r', 'converting', 'to', 'ts', 'object']",0,"['time', 'series', 'in', 'r', 'converting', 'to', 't', 'object']","['time', 'series', 'r', 'converting', 'object']",time series r converting object,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
787,last man standing  less than  hrs to go,Hackathons,last man standing  less than  hrs to go,"['last', 'man', 'standing', 'less', 'than', 'hrs', 'to', 'go']",1,"['last', 'man', 'standing', 'le', 'than', 'hr', 'to', 'go']","['last', 'man', 'standing', 'le', 'hr', 'go']",last man standing le hr go,-0.0833333333333333,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
788,categorical variable in regression,Techniques,categorical variable in regression,"['categorical', 'variable', 'in', 'regression']",0,"['categorical', 'variable', 'in', 'regression']","['categorical', 'variable', 'regression']",categorical variable regression,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
789,not able to read missing values using readtable,Other,not able to read missing values using readtable,"['not', 'able', 'to', 'read', 'missing', 'values', 'using', 'readtable']",0,"['not', 'able', 'to', 'read', 'missing', 'value', 'using', 'readtable']","['able', 'read', 'missing', 'value', 'using', 'readtable']",able read missing value using readtable,-0.225,0.15,8,39,4.333333333333333,0,0,0,0,0,0,0,0
790,shift to data science from software testing background,Career,shift to data science from software testing background,"['shift', 'to', 'data', 'science', 'from', 'software', 'testing', 'background']",0,"['shift', 'to', 'data', 'science', 'from', 'software', 'testing', 'background']","['shift', 'data', 'science', 'software', 'testing', 'background']",shift data science software testing background,0.0,0.0,8,46,5.111111111111111,0,0,0,0,0,0,0,0
791,logistic regression vs decision trees,Techniques,logistic regression vs decision trees,"['logistic', 'regression', 'vs', 'decision', 'trees']",0,"['logistic', 'regression', 'v', 'decision', 'tree']","['logistic', 'regression', 'v', 'decision', 'tree']",logistic regression v decision tree,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
792,how to assign names to matrix in r,Tools,how to assign names to matrix in r,"['how', 'to', 'assign', 'names', 'to', 'matrix', 'in', 'r']",0,"['how', 'to', 'assign', 'name', 'to', 'matrix', 'in', 'r']","['assign', 'name', 'matrix', 'r']",assign name matrix r,0.0,0.0,8,20,2.2222222222222223,0,0,0,0,0,0,0,0
793,how to decide if we need to use the bartletts test of sphericity before applying pca,Techniques,how to decide if we need to use the bartletts test of sphericity before applying pca,"['how', 'to', 'decide', 'if', 'we', 'need', 'to', 'use', 'the', 'bartletts', 'test', 'of', 'sphericity', 'before', 'applying', 'pca']",0,"['how', 'to', 'decide', 'if', 'we', 'need', 'to', 'use', 'the', 'bartlett', 'test', 'of', 'sphericity', 'before', 'applying', 'pca']","['decide', 'need', 'use', 'bartlett', 'test', 'sphericity', 'applying', 'pca']",decide need use bartlett test sphericity applying pca,0.0,0.0,16,53,3.1176470588235294,0,0,0,0,0,0,0,0
794,best ml algorithm  project prevent school failure,Techniques,best ml algorithm  project prevent school failure,"['best', 'ml', 'algorithm', 'project', 'prevent', 'school', 'failure']",0,"['best', 'ml', 'algorithm', 'project', 'prevent', 'school', 'failure']","['best', 'ml', 'algorithm', 'project', 'prevent', 'school', 'failure']",best ml algorithm project prevent school failure,0.3416666666666667,0.3416666666666667,7,48,6.0,0,0,0,0,0,0,0,0
796,need some help in the approach to text mining and then market basket analysis,Techniques,need some help in the approach to text mining and then market basket analysis,"['need', 'some', 'help', 'in', 'the', 'approach', 'to', 'text', 'mining', 'and', 'then', 'market', 'basket', 'analysis']",0,"['need', 'some', 'help', 'in', 'the', 'approach', 'to', 'text', 'mining', 'and', 'then', 'market', 'basket', 'analysis']","['need', 'help', 'approach', 'text', 'mining', 'market', 'basket', 'analysis']",need help approach text mining market basket analysis,0.0,0.0,14,53,3.533333333333333,0,0,0,0,0,0,0,0
797,model performance,Techniques,model performance,"['model', 'performance']",0,"['model', 'performance']","['model', 'performance']",model performance,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
798,how to explain an output of neural nets to a business user,Techniques,how to explain an output of neural nets to a business user,"['how', 'to', 'explain', 'an', 'output', 'of', 'neural', 'nets', 'to', 'a', 'business', 'user']",0,"['how', 'to', 'explain', 'an', 'output', 'of', 'neural', 'net', 'to', 'a', 'business', 'user']","['explain', 'output', 'neural', 'net', 'business', 'user']",explain output neural net business user,0.0,0.0,12,39,3.0,0,0,0,0,0,0,0,0
799,credit rating prediction model,Techniques,credit rating prediction model,"['credit', 'rating', 'prediction', 'model']",0,"['credit', 'rating', 'prediction', 'model']","['credit', 'rating', 'prediction', 'model']",credit rating prediction model,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
800,how to read values of data file row by row in sas,Tools,how to read values of data file row by row in sas,"['how', 'to', 'read', 'values', 'of', 'data', 'file', 'row', 'by', 'row', 'in', 'sas']",0,"['how', 'to', 'read', 'value', 'of', 'data', 'file', 'row', 'by', 'row', 'in', 'sa']","['read', 'value', 'data', 'file', 'row', 'row', 'sa']",read value data file row row sa,0.0,0.0,12,31,2.3846153846153846,0,0,0,0,0,0,0,0
801,help with choosing the accurate ml algorithm type,Techniques,help with choosing the accurate ml algorithm type,"['help', 'with', 'choosing', 'the', 'accurate', 'ml', 'algorithm', 'type']",0,"['help', 'with', 'choosing', 'the', 'accurate', 'ml', 'algorithm', 'type']","['help', 'choosing', 'accurate', 'ml', 'algorithm', 'type']",help choosing accurate ml algorithm type,0.4000000000000001,0.4000000000000001,8,40,4.444444444444445,0,0,0,0,0,0,0,0
802,how dimension reduction technique helps in classification technique,Techniques,how dimension reduction technique helps in classification technique,"['how', 'dimension', 'reduction', 'technique', 'helps', 'in', 'classification', 'technique']",0,"['how', 'dimension', 'reduction', 'technique', 'help', 'in', 'classification', 'technique']","['dimension', 'reduction', 'technique', 'help', 'classification', 'technique']",dimension reduction technique help classification technique,0.0,0.0,8,59,6.555555555555555,0,0,0,0,0,0,0,0
803,how to identify the best suited algorithm for classificationdiscriminant analysis vs logistic regression,Techniques,how to identify the best suited algorithm for classificationdiscriminant analysis vs logistic regression,"['how', 'to', 'identify', 'the', 'best', 'suited', 'algorithm', 'for', 'classificationdiscriminant', 'analysis', 'vs', 'logistic', 'regression']",0,"['how', 'to', 'identify', 'the', 'best', 'suited', 'algorithm', 'for', 'classificationdiscriminant', 'analysis', 'v', 'logistic', 'regression']","['identify', 'best', 'suited', 'algorithm', 'classificationdiscriminant', 'analysis', 'v', 'logistic', 'regression']",identify best suited algorithm classificationdiscriminant analysis v logistic regression,1.0,1.0,13,88,6.285714285714286,0,0,0,0,0,0,0,0
804,predicting next digit given a sequence of digits ranging from  to ,Techniques,predicting next digit given a sequence of digits ranging from  to ,"['predicting', 'next', 'digit', 'given', 'a', 'sequence', 'of', 'digits', 'ranging', 'from', 'to']",2,"['predicting', 'next', 'digit', 'given', 'a', 'sequence', 'of', 'digit', 'ranging', 'from', 'to']","['predicting', 'next', 'digit', 'given', 'sequence', 'digit', 'ranging']",predicting next digit given sequence digit ranging,0.0,0.0,11,50,4.166666666666667,0,0,0,0,0,0,0,0
805,date formats in csv file imported to r,Techniques,date formats in csv file imported to r,"['date', 'formats', 'in', 'csv', 'file', 'imported', 'to', 'r']",0,"['date', 'format', 'in', 'csv', 'file', 'imported', 'to', 'r']","['date', 'format', 'csv', 'file', 'imported', 'r']",date format csv file imported r,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
806,is learning sas from accredited training centres worth it,Career,is learning sas from accredited training centres worth it,"['is', 'learning', 'sas', 'from', 'accredited', 'training', 'centres', 'worth', 'it']",0,"['is', 'learning', 'sa', 'from', 'accredited', 'training', 'centre', 'worth', 'it']","['learning', 'sa', 'accredited', 'training', 'centre', 'worth']",learning sa accredited training centre worth,0.3,0.3,9,44,4.4,0,0,0,0,0,0,0,0
807,outlier analysis,Techniques,outlier analysis,"['outlier', 'analysis']",0,"['outlier', 'analysis']","['outlier', 'analysis']",outlier analysis,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
808,error in randomforestdefaultm y   nananinf in foreign function call arg  in r,Tools,error in randomforestdefaultm y   nananinf in foreign function call arg  in r,"['error', 'in', 'randomforestdefaultm', 'y', 'nananinf', 'in', 'foreign', 'function', 'call', 'arg', 'in', 'r']",1,"['error', 'in', 'randomforestdefaultm', 'y', 'nananinf', 'in', 'foreign', 'function', 'call', 'arg', 'in', 'r']","['error', 'randomforestdefaultm', 'nananinf', 'foreign', 'function', 'call', 'arg', 'r']",error randomforestdefaultm nananinf foreign function call arg r,-0.125,-0.125,12,63,4.846153846153846,0,0,0,0,0,0,0,0
809,how to create a term vector in python containing all the terms from a document list,Techniques,how to create a term vector in python containing all the terms from a document list,"['how', 'to', 'create', 'a', 'term', 'vector', 'in', 'python', 'containing', 'all', 'the', 'terms', 'from', 'a', 'document', 'list']",0,"['how', 'to', 'create', 'a', 'term', 'vector', 'in', 'python', 'containing', 'all', 'the', 'term', 'from', 'a', 'document', 'list']","['create', 'term', 'vector', 'python', 'containing', 'term', 'document', 'list']",create term vector python containing term document list,0.0,0.0,16,55,3.235294117647059,0,0,0,0,0,0,0,0
810,one hot encoding in pca,Techniques,one hot encoding in pca,"['one', 'hot', 'encoding', 'in', 'pca']",0,"['one', 'hot', 'encoding', 'in', 'pca']","['one', 'hot', 'encoding', 'pca']",one hot encoding pca,0.25,0.25,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
811,error encountered while executing mode calculation in big mart sales prediction problem,Hackathons,error encountered while executing mode calculation in big mart sales prediction problem,"['error', 'encountered', 'while', 'executing', 'mode', 'calculation', 'in', 'big', 'mart', 'sales', 'prediction', 'problem']",0,"['error', 'encountered', 'while', 'executing', 'mode', 'calculation', 'in', 'big', 'mart', 'sale', 'prediction', 'problem']","['error', 'encountered', 'executing', 'mode', 'calculation', 'big', 'mart', 'sale', 'prediction', 'problem']",error encountered executing mode calculation big mart sale prediction problem,0.0,0.0,12,77,5.923076923076923,0,0,0,0,0,0,0,0
812,how fstatic help in finding the importance of the variable,Techniques,how fstatic help in finding the importance of the variable,"['how', 'fstatic', 'help', 'in', 'finding', 'the', 'importance', 'of', 'the', 'variable']",0,"['how', 'fstatic', 'help', 'in', 'finding', 'the', 'importance', 'of', 'the', 'variable']","['fstatic', 'help', 'finding', 'importance', 'variable']",fstatic help finding importance variable,0.0,0.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
813,what is loadings and ss loadings signifies in factor analysis,Techniques,what is loadings and ss loadings signifies in factor analysis,"['what', 'is', 'loadings', 'and', 'ss', 'loadings', 'signifies', 'in', 'factor', 'analysis']",0,"['what', 'is', 'loading', 'and', 's', 'loading', 'signifies', 'in', 'factor', 'analysis']","['loading', 'loading', 'signifies', 'factor', 'analysis']",loading loading signifies factor analysis,0.0,0.0,10,41,3.727272727272727,0,0,0,0,0,0,0,0
814,considerations for including a feature  input in a neural network,Techniques,considerations for including a feature  input in a neural network,"['considerations', 'for', 'including', 'a', 'feature', 'input', 'in', 'a', 'neural', 'network']",0,"['consideration', 'for', 'including', 'a', 'feature', 'input', 'in', 'a', 'neural', 'network']","['consideration', 'including', 'feature', 'input', 'neural', 'network']",consideration including feature input neural network,0.0,0.0,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
815,how can i effectively translate business problem into a data mining task,Techniques,how can i effectively translate business problem into a data mining task,"['how', 'can', 'i', 'effectively', 'translate', 'business', 'problem', 'into', 'a', 'data', 'mining', 'task']",0,"['how', 'can', 'i', 'effectively', 'translate', 'business', 'problem', 'into', 'a', 'data', 'mining', 'task']","['effectively', 'translate', 'business', 'problem', 'data', 'mining', 'task']",effectively translate business problem data mining task,0.6,0.6,12,55,4.230769230769231,0,0,0,0,0,0,0,0
816,question about the poembot,Techniques,question about the poembot,"['question', 'about', 'the', 'poembot']",0,"['question', 'about', 'the', 'poembot']","['question', 'poembot']",question poembot,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
817,seeking reviews on business analytics for managers in india course by babson college,Misc,seeking reviews on business analytics for managers in india course by babson college,"['seeking', 'reviews', 'on', 'business', 'analytics', 'for', 'managers', 'in', 'india', 'course', 'by', 'babson', 'college']",0,"['seeking', 'review', 'on', 'business', 'analytics', 'for', 'manager', 'in', 'india', 'course', 'by', 'babson', 'college']","['seeking', 'review', 'business', 'analytics', 'manager', 'india', 'course', 'babson', 'college']",seeking review business analytics manager india course babson college,0.0,0.0,13,69,4.928571428571429,0,0,0,0,0,0,0,0
818,nltk download error,Techniques,nltk download error,"['nltk', 'download', 'error']",0,"['nltk', 'download', 'error']","['nltk', 'download', 'error']",nltk download error,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
819,what is the difference between gradient boosting and stochastic gradient boosting,Techniques,what is the difference between gradient boosting and stochastic gradient boosting,"['what', 'is', 'the', 'difference', 'between', 'gradient', 'boosting', 'and', 'stochastic', 'gradient', 'boosting']",0,"['what', 'is', 'the', 'difference', 'between', 'gradient', 'boosting', 'and', 'stochastic', 'gradient', 'boosting']","['difference', 'gradient', 'boosting', 'stochastic', 'gradient', 'boosting']",difference gradient boosting stochastic gradient boosting,0.0,0.0,11,57,4.75,0,0,0,0,0,0,0,0
820,value error  features,Techniques,value error  features,"['value', 'error', 'features']",0,"['value', 'error', 'feature']","['value', 'error', 'feature']",value error feature,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
821,how to decide which algorithm to use for a given dataset,Techniques,how to decide which algorithm to use for a given dataset,"['how', 'to', 'decide', 'which', 'algorithm', 'to', 'use', 'for', 'a', 'given', 'dataset']",0,"['how', 'to', 'decide', 'which', 'algorithm', 'to', 'use', 'for', 'a', 'given', 'dataset']","['decide', 'algorithm', 'use', 'given', 'dataset']",decide algorithm use given dataset,0.0,0.0,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
822,join slack chat,Hackathons,join slack chat,"['join', 'slack', 'chat']",0,"['join', 'slack', 'chat']","['join', 'slack', 'chat']",join slack chat,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
823,internship in analytics,Tools,internship in analytics,"['internship', 'in', 'analytics']",0,"['internship', 'in', 'analytics']","['internship', 'analytics']",internship analytics,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
824,bygroup regression in base python,Tools,bygroup regression in base python,"['bygroup', 'regression', 'in', 'base', 'python']",0,"['bygroup', 'regression', 'in', 'base', 'python']","['bygroup', 'regression', 'base', 'python']",bygroup regression base python,-0.8,-0.8,5,30,5.0,0,0,0,0,0,0,0,0
825,group lasso implementation in r,Techniques,group lasso implementation in r,"['group', 'lasso', 'implementation', 'in', 'r']",0,"['group', 'lasso', 'implementation', 'in', 'r']","['group', 'lasso', 'implementation', 'r']",group lasso implementation r,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
826,beginner python,Tools,beginner python,"['beginner', 'python']",0,"['beginner', 'python']","['beginner', 'python']",beginner python,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
827,how to get bar type plots for two points in a plot in r,Tools,how to get bar type plots for two points in a plot in r,"['how', 'to', 'get', 'bar', 'type', 'plots', 'for', 'two', 'points', 'in', 'a', 'plot', 'in', 'r']",0,"['how', 'to', 'get', 'bar', 'type', 'plot', 'for', 'two', 'point', 'in', 'a', 'plot', 'in', 'r']","['get', 'bar', 'type', 'plot', 'two', 'point', 'plot', 'r']",get bar type plot two point plot r,0.0,0.0,14,34,2.2666666666666666,0,0,0,0,0,0,0,0
828,how to compare adaboost and gradient boosting based on different data sets,Techniques,how to compare adaboost and gradient boosting based on different data sets,"['how', 'to', 'compare', 'adaboost', 'and', 'gradient', 'boosting', 'based', 'on', 'different', 'data', 'sets']",0,"['how', 'to', 'compare', 'adaboost', 'and', 'gradient', 'boosting', 'based', 'on', 'different', 'data', 'set']","['compare', 'adaboost', 'gradient', 'boosting', 'based', 'different', 'data', 'set']",compare adaboost gradient boosting based different data set,0.0,0.0,12,59,4.538461538461538,0,0,0,0,0,0,0,0
829,can i use svm and random forest for unsupervised learning,Techniques,can i use svm and random forest for unsupervised learning,"['can', 'i', 'use', 'svm', 'and', 'random', 'forest', 'for', 'unsupervised', 'learning']",0,"['can', 'i', 'use', 'svm', 'and', 'random', 'forest', 'for', 'unsupervised', 'learning']","['use', 'svm', 'random', 'forest', 'unsupervised', 'learning']",use svm random forest unsupervised learning,-0.5,-0.5,10,43,3.909090909090909,0,0,0,0,0,0,0,0
830,random forrest training doubt,Techniques,random forrest training doubt,"['random', 'forrest', 'training', 'doubt']",0,"['random', 'forrest', 'training', 'doubt']","['random', 'forrest', 'training', 'doubt']",random forrest training doubt,-0.5,-0.5,4,29,5.8,0,0,0,0,0,0,0,0
831,methods for daily water consumption prediction,Techniques,methods for daily water consumption prediction,"['methods', 'for', 'daily', 'water', 'consumption', 'prediction']",0,"['method', 'for', 'daily', 'water', 'consumption', 'prediction']","['method', 'daily', 'water', 'consumption', 'prediction']",method daily water consumption prediction,0.0,0.0,6,41,5.857142857142857,0,0,0,0,0,0,0,0
832,what are the broad inferences we could make by plots when exploring any dataset,Techniques,what are the broad inferences we could make by plots when exploring any dataset,"['what', 'are', 'the', 'broad', 'inferences', 'we', 'could', 'make', 'by', 'plots', 'when', 'exploring', 'any', 'dataset']",0,"['what', 'are', 'the', 'broad', 'inference', 'we', 'could', 'make', 'by', 'plot', 'when', 'exploring', 'any', 'dataset']","['broad', 'inference', 'could', 'make', 'plot', 'exploring', 'dataset']",broad inference could make plot exploring dataset,0.0625,0.0625,14,49,3.2666666666666666,0,0,0,0,0,0,0,0
833,a question on solving multilabel classification problems,Techniques,a question on solving multilabel classification problems,"['a', 'question', 'on', 'solving', 'multilabel', 'classification', 'problems']",0,"['a', 'question', 'on', 'solving', 'multilabel', 'classification', 'problem']","['question', 'solving', 'multilabel', 'classification', 'problem']",question solving multilabel classification problem,0.0,0.0,7,50,6.25,0,0,0,0,0,0,0,0
834,solution submission walk through,Hackathons,solution submission walk through,"['solution', 'submission', 'walk', 'through']",0,"['solution', 'submission', 'walk', 'through']","['solution', 'submission', 'walk']",solution submission walk,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
835,advanced data analysis and visualization in python,Tools,advanced data analysis and visualization in python,"['advanced', 'data', 'analysis', 'and', 'visualization', 'in', 'python']",0,"['advanced', 'data', 'analysis', 'and', 'visualization', 'in', 'python']","['advanced', 'data', 'analysis', 'visualization', 'python']",advanced data analysis visualization python,0.4,0.4,7,43,5.375,0,0,0,0,0,0,0,0
836,word embeddings  docvec why it fails  twitter sentiment analysis,Hackathons,word embeddings  docvec why it fails  twitter sentiment analysis,"['word', 'embeddings', 'docvec', 'why', 'it', 'fails', 'twitter', 'sentiment', 'analysis']",0,"['word', 'embeddings', 'docvec', 'why', 'it', 'fails', 'twitter', 'sentiment', 'analysis']","['word', 'embeddings', 'docvec', 'fails', 'twitter', 'sentiment', 'analysis']",word embeddings docvec fails twitter sentiment analysis,-0.5,-0.5,9,55,5.5,0,0,0,0,0,0,0,0
837,how to load rmysql package with windows,Tools,how to load rmysql package with windows,"['how', 'to', 'load', 'rmysql', 'package', 'with', 'windows']",0,"['how', 'to', 'load', 'rmysql', 'package', 'with', 'window']","['load', 'rmysql', 'package', 'window']",load rmysql package window,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
838,creating new features in the bike sharing problem,Techniques,creating new features in the bike sharing problem,"['creating', 'new', 'features', 'in', 'the', 'bike', 'sharing', 'problem']",0,"['creating', 'new', 'feature', 'in', 'the', 'bike', 'sharing', 'problem']","['creating', 'new', 'feature', 'bike', 'sharing', 'problem']",creating new feature bike sharing problem,0.1363636363636363,0.1363636363636363,8,41,4.555555555555555,0,0,0,0,0,0,0,0
839,multiple replacement in r,Tools,multiple replacement in r,"['multiple', 'replacement', 'in', 'r']",0,"['multiple', 'replacement', 'in', 'r']","['multiple', 'replacement', 'r']",multiple replacement r,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
840,what is prescriptive analytics which tools are used for prescriptive analytics,Techniques,what is prescriptive analytics which tools are used for prescriptive analytics,"['what', 'is', 'prescriptive', 'analytics', 'which', 'tools', 'are', 'used', 'for', 'prescriptive', 'analytics']",0,"['what', 'is', 'prescriptive', 'analytics', 'which', 'tool', 'are', 'used', 'for', 'prescriptive', 'analytics']","['prescriptive', 'analytics', 'tool', 'used', 'prescriptive', 'analytics']",prescriptive analytics tool used prescriptive analytics,0.0,0.0,11,55,4.583333333333333,0,0,0,0,0,0,0,0
841,interpreting aic and bic,Techniques,interpreting aic and bic,"['interpreting', 'aic', 'and', 'bic']",0,"['interpreting', 'aic', 'and', 'bic']","['interpreting', 'aic', 'bic']",interpreting aic bic,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
842,use of a score within a model,Techniques,use of a score within a model,"['use', 'of', 'a', 'score', 'within', 'a', 'model']",0,"['use', 'of', 'a', 'score', 'within', 'a', 'model']","['use', 'score', 'within', 'model']",use score within model,0.0,0.0,7,22,2.75,0,0,0,0,0,0,0,0
843,copy paste not working properly,Techniques,copy paste not working properly,"['copy', 'paste', 'not', 'working', 'properly']",0,"['copy', 'paste', 'not', 'working', 'properly']","['copy', 'paste', 'working', 'properly']",copy paste working properly,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
844,learning r or continue with python for data science,Tools,learning r or continue with python for data science,"['learning', 'r', 'or', 'continue', 'with', 'python', 'for', 'data', 'science']",0,"['learning', 'r', 'or', 'continue', 'with', 'python', 'for', 'data', 'science']","['learning', 'r', 'continue', 'python', 'data', 'science']",learning r continue python data science,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
845,feedback  online hackathon  predict the gem of auxesia for magazino,Hackathons,feedback  online hackathon  predict the gem of auxesia for magazino,"['feedback', 'online', 'hackathon', 'predict', 'the', 'gem', 'of', 'auxesia', 'for', 'magazino']",0,"['feedback', 'online', 'hackathon', 'predict', 'the', 'gem', 'of', 'auxesia', 'for', 'magazino']","['feedback', 'online', 'hackathon', 'predict', 'gem', 'auxesia', 'magazino']",feedback online hackathon predict gem auxesia magazino,0.0,0.0,10,54,4.909090909090909,0,0,0,0,0,0,0,0
846,bihar vikas commission  analytics in government   job openings  last date th march,Career,bihar vikas commission  analytics in government   job openings  last date th march,"['bihar', 'vikas', 'commission', 'analytics', 'in', 'government', 'job', 'openings', 'last', 'date', 'th', 'march']",1,"['bihar', 'vikas', 'commission', 'analytics', 'in', 'government', 'job', 'opening', 'last', 'date', 'th', 'march']","['bihar', 'vikas', 'commission', 'analytics', 'government', 'job', 'opening', 'last', 'date', 'th', 'march']",bihar vikas commission analytics government job opening last date th march,0.0,0.0,12,74,5.6923076923076925,0,0,0,0,0,0,0,0
847,discrete fourier transform,Techniques,discrete fourier transform,"['discrete', 'fourier', 'transform']",0,"['discrete', 'fourier', 'transform']","['discrete', 'fourier', 'transform']",discrete fourier transform,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
848,how to open tbl file in r,Tools,how to open tbl file in r,"['how', 'to', 'open', 'tbl', 'file', 'in', 'r']",0,"['how', 'to', 'open', 'tbl', 'file', 'in', 'r']","['open', 'tbl', 'file', 'r']",open tbl file r,0.0,0.0,7,15,1.875,0,0,0,0,0,0,0,0
849,scraping website,Techniques,scraping website,"['scraping', 'website']",0,"['scraping', 'website']","['scraping', 'website']",scraping website,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
850,hadoop clusters and node setup in real office environment,Tools,hadoop clusters and node setup in real office environment,"['hadoop', 'clusters', 'and', 'node', 'setup', 'in', 'real', 'office', 'environment']",0,"['hadoop', 'cluster', 'and', 'node', 'setup', 'in', 'real', 'office', 'environment']","['hadoop', 'cluster', 'node', 'setup', 'real', 'office', 'environment']",hadoop cluster node setup real office environment,0.2,0.2,9,49,4.9,0,0,0,0,0,0,0,0
851,package ‘h’ is not available for r version ,Tools,package ‘h’ is not available for r version ,"['package', '‘', 'h', '’', 'is', 'not', 'available', 'for', 'r', 'version']",1,"['package', '‘', 'h', '’', 'is', 'not', 'available', 'for', 'r', 'version']","['package', '‘', 'h', '’', 'available', 'r', 'version']",package ‘ h ’ available r version,-0.2,0.4,10,33,3.0,0,0,0,0,0,0,0,0
852,correlations  predictive analytics for a car dealership,Tools,correlations  predictive analytics for a car dealership,"['correlations', 'predictive', 'analytics', 'for', 'a', 'car', 'dealership']",0,"['correlation', 'predictive', 'analytics', 'for', 'a', 'car', 'dealership']","['correlation', 'predictive', 'analytics', 'car', 'dealership']",correlation predictive analytics car dealership,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
853,what will be an easy way to inter splice columns in r,Tools,what will be an easy way to inter splice columns in r,"['what', 'will', 'be', 'an', 'easy', 'way', 'to', 'inter', 'splice', 'columns', 'in', 'r']",0,"['what', 'will', 'be', 'an', 'easy', 'way', 'to', 'inter', 'splice', 'column', 'in', 'r']","['easy', 'way', 'inter', 'splice', 'column', 'r']",easy way inter splice column r,0.4333333333333333,0.4333333333333333,12,30,2.3076923076923075,0,0,0,0,0,0,0,0
854,i want to predict that which politics party will win in  in india,Techniques,i want to predict that which politics party will win in  in india,"['i', 'want', 'to', 'predict', 'that', 'which', 'politics', 'party', 'will', 'win', 'in', 'in', 'india']",1,"['i', 'want', 'to', 'predict', 'that', 'which', 'politics', 'party', 'will', 'win', 'in', 'in', 'india']","['want', 'predict', 'politics', 'party', 'win', 'india']",want predict politics party win india,0.8,0.8,13,37,2.642857142857143,0,0,0,0,0,0,0,0
855,the seers accuracy,Hackathons,the seers accuracy,"['the', 'seers', 'accuracy']",0,"['the', 'seer', 'accuracy']","['seer', 'accuracy']",seer accuracy,0.0,0.0,3,13,3.25,0,0,0,0,0,0,0,0
856,split criteria in random forest,Techniques,split criteria in random forest,"['split', 'criteria', 'in', 'random', 'forest']",0,"['split', 'criterion', 'in', 'random', 'forest']","['split', 'criterion', 'random', 'forest']",split criterion random forest,-0.5,-0.5,5,29,4.833333333333333,0,0,0,0,0,0,0,0
857,knowledge based competitions data science,Hackathons,knowledge based competitions data science,"['knowledge', 'based', 'competitions', 'data', 'science']",0,"['knowledge', 'based', 'competition', 'data', 'science']","['knowledge', 'based', 'competition', 'data', 'science']",knowledge based competition data science,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
858,predictive failure analysis,Techniques,predictive failure analysis,"['predictive', 'failure', 'analysis']",0,"['predictive', 'failure', 'analysis']","['predictive', 'failure', 'analysis']",predictive failure analysis,-0.3166666666666667,-0.3166666666666667,3,27,6.75,0,0,0,0,0,0,0,0
859,one hot encoding to carry out kmeans clustering,Techniques,one hot encoding to carry out kmeans clustering,"['one', 'hot', 'encoding', 'to', 'carry', 'out', 'kmeans', 'clustering']",0,"['one', 'hot', 'encoding', 'to', 'carry', 'out', 'kmeans', 'clustering']","['one', 'hot', 'encoding', 'carry', 'kmeans', 'clustering']",one hot encoding carry kmeans clustering,0.25,0.25,8,40,4.444444444444445,0,0,0,0,0,0,0,0
860,unsupervised multi label text classification,Techniques,unsupervised multi label text classification,"['unsupervised', 'multi', 'label', 'text', 'classification']",0,"['unsupervised', 'multi', 'label', 'text', 'classification']","['unsupervised', 'multi', 'label', 'text', 'classification']",unsupervised multi label text classification,0.0,0.0,5,44,7.333333333333333,0,0,0,0,0,0,0,0
861,what is plr plr,Techniques,what is plr plr,"['what', 'is', 'plr', 'plr']",0,"['what', 'is', 'plr', 'plr']","['plr', 'plr']",plr plr,0.0,0.0,4,7,1.4,0,0,0,0,0,0,0,0
862,regular expressions,Techniques,regular expressions,"['regular', 'expressions']",0,"['regular', 'expression']","['regular', 'expression']",regular expression,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
863,data analytics data science career after yrs break,Career,data analytics data science career after yrs break,"['data', 'analytics', 'data', 'science', 'career', 'after', 'yrs', 'break']",0,"['data', 'analytics', 'data', 'science', 'career', 'after', 'yr', 'break']","['data', 'analytics', 'data', 'science', 'career', 'yr', 'break']",data analytics data science career yr break,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
864,can anyone help me in weather prediction project  i have some doubts,Techniques,can anyone help me in weather prediction project  i have some doubts,"['can', 'anyone', 'help', 'me', 'in', 'weather', 'prediction', 'project', 'i', 'have', 'some', 'doubts']",0,"['can', 'anyone', 'help', 'me', 'in', 'weather', 'prediction', 'project', 'i', 'have', 'some', 'doubt']","['anyone', 'help', 'weather', 'prediction', 'project', 'doubt']",anyone help weather prediction project doubt,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
865,why tukeys hsd uses mean squares within the samples not between the samples,Techniques,why tukeys hsd uses mean squares within the samples not between the samples,"['why', 'tukeys', 'hsd', 'uses', 'mean', 'squares', 'within', 'the', 'samples', 'not', 'between', 'the', 'samples']",0,"['why', 'tukeys', 'hsd', 'us', 'mean', 'square', 'within', 'the', 'sample', 'not', 'between', 'the', 'sample']","['tukeys', 'hsd', 'us', 'mean', 'square', 'within', 'sample', 'sample']",tukeys hsd us mean square within sample sample,-0.3125,-0.3125,13,46,3.2857142857142856,0,0,0,0,0,0,0,0
866,predicting delays in a multi node supply chain of a courier company,Other,predicting delays in a multi node supply chain of a courier company,"['predicting', 'delays', 'in', 'a', 'multi', 'node', 'supply', 'chain', 'of', 'a', 'courier', 'company']",0,"['predicting', 'delay', 'in', 'a', 'multi', 'node', 'supply', 'chain', 'of', 'a', 'courier', 'company']","['predicting', 'delay', 'multi', 'node', 'supply', 'chain', 'courier', 'company']",predicting delay multi node supply chain courier company,0.0,0.0,12,56,4.3076923076923075,0,0,0,0,0,0,0,0
867,installing the gbm light package in r,Techniques,installing the gbm light package in r,"['installing', 'the', 'gbm', 'light', 'package', 'in', 'r']",0,"['installing', 'the', 'gbm', 'light', 'package', 'in', 'r']","['installing', 'gbm', 'light', 'package', 'r']",installing gbm light package r,0.4,0.4,7,30,3.75,0,0,0,0,0,0,0,0
868,how to do multi collinearity check while running logistic regression,Techniques,how to do multi collinearity check while running logistic regression,"['how', 'to', 'do', 'multi', 'collinearity', 'check', 'while', 'running', 'logistic', 'regression']",0,"['how', 'to', 'do', 'multi', 'collinearity', 'check', 'while', 'running', 'logistic', 'regression']","['multi', 'collinearity', 'check', 'running', 'logistic', 'regression']",multi collinearity check running logistic regression,0.0,0.0,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
869,help  finding patterns of identical values across fields in large data,Techniques,help  finding patterns of identical values across fields in large data,"['help', 'finding', 'patterns', 'of', 'identical', 'values', 'across', 'fields', 'in', 'large', 'data']",0,"['help', 'finding', 'pattern', 'of', 'identical', 'value', 'across', 'field', 'in', 'large', 'data']","['help', 'finding', 'pattern', 'identical', 'value', 'across', 'field', 'large', 'data']",help finding pattern identical value across field large data,0.2142857142857142,0.2142857142857142,11,60,5.0,0,0,0,0,0,0,0,0
870,poll will artificial intelligence be biggest existential threat to humanity,Misc,poll will artificial intelligence be biggest existential threat to humanity,"['poll', 'will', 'artificial', 'intelligence', 'be', 'biggest', 'existential', 'threat', 'to', 'humanity']",0,"['poll', 'will', 'artificial', 'intelligence', 'be', 'biggest', 'existential', 'threat', 'to', 'humanity']","['poll', 'artificial', 'intelligence', 'biggest', 'existential', 'threat', 'humanity']",poll artificial intelligence biggest existential threat humanity,-0.6,-0.6,10,64,5.818181818181818,0,0,0,0,0,0,0,0
871,finding document similarity,Techniques,finding document similarity,"['finding', 'document', 'similarity']",0,"['finding', 'document', 'similarity']","['finding', 'document', 'similarity']",finding document similarity,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
872,how to scrape data from dd and dl tag using beautifulsoup,Tools,how to scrape data from dd and dl tag using beautifulsoup,"['how', 'to', 'scrape', 'data', 'from', 'dd', 'and', 'dl', 'tag', 'using', 'beautifulsoup']",0,"['how', 'to', 'scrape', 'data', 'from', 'dd', 'and', 'dl', 'tag', 'using', 'beautifulsoup']","['scrape', 'data', 'dd', 'dl', 'tag', 'using', 'beautifulsoup']",scrape data dd dl tag using beautifulsoup,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
873,transition from r to python,Career,transition from r to python,"['transition', 'from', 'r', 'to', 'python']",0,"['transition', 'from', 'r', 'to', 'python']","['transition', 'r', 'python']",transition r python,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
874,career switch to data analytics after  years of it exp,Career,career switch to data analytics after  years of it exp,"['career', 'switch', 'to', 'data', 'analytics', 'after', 'years', 'of', 'it', 'exp']",1,"['career', 'switch', 'to', 'data', 'analytics', 'after', 'year', 'of', 'it', 'exp']","['career', 'switch', 'data', 'analytics', 'year', 'exp']",career switch data analytics year exp,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
875,number of features of the model must match the input,Techniques,number of features of the model must match the input,"['number', 'of', 'features', 'of', 'the', 'model', 'must', 'match', 'the', 'input']",0,"['number', 'of', 'feature', 'of', 'the', 'model', 'must', 'match', 'the', 'input']","['number', 'feature', 'model', 'must', 'match', 'input']",number feature model must match input,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
876,how to find variable importance in r,Tools,how to find variable importance in r,"['how', 'to', 'find', 'variable', 'importance', 'in', 'r']",0,"['how', 'to', 'find', 'variable', 'importance', 'in', 'r']","['find', 'variable', 'importance', 'r']",find variable importance r,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
877,feature selection techniques using python,Techniques,feature selection techniques using python,"['feature', 'selection', 'techniques', 'using', 'python']",0,"['feature', 'selection', 'technique', 'using', 'python']","['feature', 'selection', 'technique', 'using', 'python']",feature selection technique using python,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
878,disaggregation algorithms in electricity consumption data,Techniques,disaggregation algorithms in electricity consumption data,"['disaggregation', 'algorithms', 'in', 'electricity', 'consumption', 'data']",0,"['disaggregation', 'algorithm', 'in', 'electricity', 'consumption', 'data']","['disaggregation', 'algorithm', 'electricity', 'consumption', 'data']",disaggregation algorithm electricity consumption data,0.0,0.0,6,53,7.571428571428571,0,0,0,0,0,0,0,0
879,are the webinars recorded,Other,are the webinars recorded,"['are', 'the', 'webinars', 'recorded']",0,"['are', 'the', 'webinars', 'recorded']","['webinars', 'recorded']",webinars recorded,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
880,how to handle multi level factor variable in linear regression,Techniques,how to handle multi level factor variable in linear regression,"['how', 'to', 'handle', 'multi', 'level', 'factor', 'variable', 'in', 'linear', 'regression']",0,"['how', 'to', 'handle', 'multi', 'level', 'factor', 'variable', 'in', 'linear', 'regression']","['handle', 'multi', 'level', 'factor', 'variable', 'linear', 'regression']",handle multi level factor variable linear regression,0.0,0.0,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
881,need help in finding which claims to audit,Techniques,need help in finding which claims to audit,"['need', 'help', 'in', 'finding', 'which', 'claims', 'to', 'audit']",0,"['need', 'help', 'in', 'finding', 'which', 'claim', 'to', 'audit']","['need', 'help', 'finding', 'claim', 'audit']",need help finding claim audit,0.0,0.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
882,how to extract the rating of a movie from imdb using scrapy in python,Tools,how to extract the rating of a movie from imdb using scrapy in python,"['how', 'to', 'extract', 'the', 'rating', 'of', 'a', 'movie', 'from', 'imdb', 'using', 'scrapy', 'in', 'python']",0,"['how', 'to', 'extract', 'the', 'rating', 'of', 'a', 'movie', 'from', 'imdb', 'using', 'scrapy', 'in', 'python']","['extract', 'rating', 'movie', 'imdb', 'using', 'scrapy', 'python']",extract rating movie imdb using scrapy python,0.0,0.0,14,45,3.0,0,0,0,0,0,0,0,0
883,how to improve fuel efficiency of a vessel ie vessel performance using data,Other,how to improve fuel efficiency of a vessel ie vessel performance using data,"['how', 'to', 'improve', 'fuel', 'efficiency', 'of', 'a', 'vessel', 'ie', 'vessel', 'performance', 'using', 'data']",0,"['how', 'to', 'improve', 'fuel', 'efficiency', 'of', 'a', 'vessel', 'ie', 'vessel', 'performance', 'using', 'data']","['improve', 'fuel', 'efficiency', 'vessel', 'ie', 'vessel', 'performance', 'using', 'data']",improve fuel efficiency vessel ie vessel performance using data,0.0,0.0,13,63,4.5,0,0,0,0,0,0,0,0
884,what does the option rotation  varimax in factanal in r do,Techniques,what does the option rotation  varimax in factanal in r do,"['what', 'does', 'the', 'option', 'rotation', 'varimax', 'in', 'factanal', 'in', 'r', 'do']",0,"['what', 'doe', 'the', 'option', 'rotation', 'varimax', 'in', 'factanal', 'in', 'r', 'do']","['doe', 'option', 'rotation', 'varimax', 'factanal', 'r']",doe option rotation varimax factanal r,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
885,restrict values in specified cells in excel,Tools,restrict values in specified cells in excel,"['restrict', 'values', 'in', 'specified', 'cells', 'in', 'excel']",0,"['restrict', 'value', 'in', 'specified', 'cell', 'in', 'excel']","['restrict', 'value', 'specified', 'cell', 'excel']",restrict value specified cell excel,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
886,career transition from javaexp  years to data science,Career,career transition from javaexp  years to data science,"['career', 'transition', 'from', 'javaexp', 'years', 'to', 'data', 'science']",1,"['career', 'transition', 'from', 'javaexp', 'year', 'to', 'data', 'science']","['career', 'transition', 'javaexp', 'year', 'data', 'science']",career transition javaexp year data science,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
887,path to be a data analyst,Career,path to be a data analyst,"['path', 'to', 'be', 'a', 'data', 'analyst']",0,"['path', 'to', 'be', 'a', 'data', 'analyst']","['path', 'data', 'analyst']",path data analyst,0.0,0.0,6,17,2.4285714285714284,0,0,0,0,0,0,0,0
888,how to create top  leader board for store or merchant performance,Techniques,how to create top  leader board for store or merchant performance,"['how', 'to', 'create', 'top', 'leader', 'board', 'for', 'store', 'or', 'merchant', 'performance']",1,"['how', 'to', 'create', 'top', 'leader', 'board', 'for', 'store', 'or', 'merchant', 'performance']","['create', 'top', 'leader', 'board', 'store', 'merchant', 'performance']",create top leader board store merchant performance,0.5,0.5,11,50,4.166666666666667,0,0,0,0,0,0,0,0
889,except kaggle and github where else can i find open to public health related datasets,Resources,except kaggle and github where else can i find open to public health related datasets,"['except', 'kaggle', 'and', 'github', 'where', 'else', 'can', 'i', 'find', 'open', 'to', 'public', 'health', 'related', 'datasets']",0,"['except', 'kaggle', 'and', 'github', 'where', 'else', 'can', 'i', 'find', 'open', 'to', 'public', 'health', 'related', 'datasets']","['except', 'kaggle', 'github', 'else', 'find', 'open', 'public', 'health', 'related', 'datasets']",except kaggle github else find open public health related datasets,0.0,0.0,15,66,4.125,0,0,0,0,0,0,0,0
890,data merging in python,Techniques,data merging in python,"['data', 'merging', 'in', 'python']",0,"['data', 'merging', 'in', 'python']","['data', 'merging', 'python']",data merging python,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
891,how to merge datasets on nearest values in r,Tools,how to merge datasets on nearest values in r,"['how', 'to', 'merge', 'datasets', 'on', 'nearest', 'values', 'in', 'r']",0,"['how', 'to', 'merge', 'datasets', 'on', 'nearest', 'value', 'in', 'r']","['merge', 'datasets', 'nearest', 'value', 'r']",merge datasets nearest value r,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
892,data hackathon online x  th  th september ,Hackathons,data hackathon online x  th  th september ,"['data', 'hackathon', 'online', 'x', 'th', 'th', 'september']",1,"['data', 'hackathon', 'online', 'x', 'th', 'th', 'september']","['data', 'hackathon', 'online', 'x', 'th', 'th', 'september']",data hackathon online x th th september,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
893,difference between train and test file,Hackathons,difference between train and test file,"['difference', 'between', 'train', 'and', 'test', 'file']",0,"['difference', 'between', 'train', 'and', 'test', 'file']","['difference', 'train', 'test', 'file']",difference train test file,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
894,masters in sciencebig data analytics,Career,masters in sciencebig data analytics,"['masters', 'in', 'sciencebig', 'data', 'analytics']",0,"['master', 'in', 'sciencebig', 'data', 'analytics']","['master', 'sciencebig', 'data', 'analytics']",master sciencebig data analytics,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
895,how to skip nd row while importing the data in r,Tools,how to skip nd row while importing the data in r,"['how', 'to', 'skip', 'nd', 'row', 'while', 'importing', 'the', 'data', 'in', 'r']",0,"['how', 'to', 'skip', 'nd', 'row', 'while', 'importing', 'the', 'data', 'in', 'r']","['skip', 'nd', 'row', 'importing', 'data', 'r']",skip nd row importing data r,0.0,0.0,11,28,2.3333333333333335,0,0,0,0,0,0,0,0
896,problems related to statistical evidence in datascience,Techniques,problems related to statistical evidence in datascience,"['problems', 'related', 'to', 'statistical', 'evidence', 'in', 'datascience']",0,"['problem', 'related', 'to', 'statistical', 'evidence', 'in', 'datascience']","['problem', 'related', 'statistical', 'evidence', 'datascience']",problem related statistical evidence datascience,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
897,r install error,Tools,r install error,"['r', 'install', 'error']",0,"['r', 'install', 'error']","['r', 'install', 'error']",r install error,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
898,project related to share market,Resources,project related to share market,"['project', 'related', 'to', 'share', 'market']",0,"['project', 'related', 'to', 'share', 'market']","['project', 'related', 'share', 'market']",project related share market,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
899,not able to submit the solution,Hackathons,not able to submit the solution,"['not', 'able', 'to', 'submit', 'the', 'solution']",0,"['not', 'able', 'to', 'submit', 'the', 'solution']","['able', 'submit', 'solution']",able submit solution,-0.25,0.5,6,20,2.857142857142857,0,0,0,0,0,0,0,0
900,how to convert unordered factor to ordered factor in r,Tools,how to convert unordered factor to ordered factor in r,"['how', 'to', 'convert', 'unordered', 'factor', 'to', 'ordered', 'factor', 'in', 'r']",0,"['how', 'to', 'convert', 'unordered', 'factor', 'to', 'ordered', 'factor', 'in', 'r']","['convert', 'unordered', 'factor', 'ordered', 'factor', 'r']",convert unordered factor ordered factor r,0.0,0.0,10,41,3.727272727272727,0,0,0,0,0,0,0,0
901,career and role of mis,Career,career and role of mis,"['career', 'and', 'role', 'of', 'mis']",0,"['career', 'and', 'role', 'of', 'mi']","['career', 'role', 'mi']",career role mi,0.0,0.0,5,14,2.3333333333333335,0,0,0,0,0,0,0,0
902,begginners guide on web scrapping in r,Techniques,begginners guide on web scrapping in r,"['begginners', 'guide', 'on', 'web', 'scrapping', 'in', 'r']",0,"['begginners', 'guide', 'on', 'web', 'scrapping', 'in', 'r']","['begginners', 'guide', 'web', 'scrapping', 'r']",begginners guide web scrapping r,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
903,how can i differentiate line curve for different categories in qlikview,Tools,how can i differentiate line curve for different categories in qlikview,"['how', 'can', 'i', 'differentiate', 'line', 'curve', 'for', 'different', 'categories', 'in', 'qlikview']",0,"['how', 'can', 'i', 'differentiate', 'line', 'curve', 'for', 'different', 'category', 'in', 'qlikview']","['differentiate', 'line', 'curve', 'different', 'category', 'qlikview']",differentiate line curve different category qlikview,0.0,0.0,11,52,4.333333333333333,0,0,0,0,0,0,0,0
904,plots used for showing the assumption violation in linear regresion,Tools,plots used for showing the assumption violation in linear regresion,"['plots', 'used', 'for', 'showing', 'the', 'assumption', 'violation', 'in', 'linear', 'regresion']",0,"['plot', 'used', 'for', 'showing', 'the', 'assumption', 'violation', 'in', 'linear', 'regresion']","['plot', 'used', 'showing', 'assumption', 'violation', 'linear', 'regresion']",plot used showing assumption violation linear regresion,0.0,0.0,10,55,5.0,0,0,0,0,0,0,0,0
905,fetching data using rpostgresql package in r,Techniques,fetching data using rpostgresql package in r,"['fetching', 'data', 'using', 'rpostgresql', 'package', 'in', 'r']",0,"['fetching', 'data', 'using', 'rpostgresql', 'package', 'in', 'r']","['fetching', 'data', 'using', 'rpostgresql', 'package', 'r']",fetching data using rpostgresql package r,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
906,deep learning with tensorflow  challenges  need advice,Tools,deep learning with tensorflow  challenges  need advice,"['deep', 'learning', 'with', 'tensorflow', 'challenges', 'need', 'advice']",0,"['deep', 'learning', 'with', 'tensorflow', 'challenge', 'need', 'advice']","['deep', 'learning', 'tensorflow', 'challenge', 'need', 'advice']",deep learning tensorflow challenge need advice,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
907,regarding text analytics and association rules,Techniques,regarding text analytics and association rules,"['regarding', 'text', 'analytics', 'and', 'association', 'rules']",0,"['regarding', 'text', 'analytics', 'and', 'association', 'rule']","['regarding', 'text', 'analytics', 'association', 'rule']",regarding text analytics association rule,0.0,0.0,6,41,5.857142857142857,0,0,0,0,0,0,0,0
908,clustering analysis,Techniques,clustering analysis,"['clustering', 'analysis']",0,"['clustering', 'analysis']","['clustering', 'analysis']",clustering analysis,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
909,similarity measure,Techniques,similarity measure,"['similarity', 'measure']",0,"['similarity', 'measure']","['similarity', 'measure']",similarity measure,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
910,read excel  except the first sheet,Techniques,read excel  except the first sheet,"['read', 'excel', 'except', 'the', 'first', 'sheet']",0,"['read', 'excel', 'except', 'the', 'first', 'sheet']","['read', 'excel', 'except', 'first', 'sheet']",read excel except first sheet,0.25,0.25,6,29,4.142857142857143,0,0,0,0,0,0,0,0
911,how many columns should be used in dummy coding  one hot encoding in python,Techniques,how many columns should be used in dummy coding  one hot encoding in python,"['how', 'many', 'columns', 'should', 'be', 'used', 'in', 'dummy', 'coding', 'one', 'hot', 'encoding', 'in', 'python']",0,"['how', 'many', 'column', 'should', 'be', 'used', 'in', 'dummy', 'coding', 'one', 'hot', 'encoding', 'in', 'python']","['many', 'column', 'used', 'dummy', 'coding', 'one', 'hot', 'encoding', 'python']",many column used dummy coding one hot encoding python,0.375,0.375,14,53,3.533333333333333,0,0,0,0,0,0,0,0
912,if we have different frequencies for target and features how to do machine learning,Techniques,if we have different frequencies for target and features how to do machine learning,"['if', 'we', 'have', 'different', 'frequencies', 'for', 'target', 'and', 'features', 'how', 'to', 'do', 'machine', 'learning']",0,"['if', 'we', 'have', 'different', 'frequency', 'for', 'target', 'and', 'feature', 'how', 'to', 'do', 'machine', 'learning']","['different', 'frequency', 'target', 'feature', 'machine', 'learning']",different frequency target feature machine learning,0.0,0.0,14,51,3.4,0,0,0,0,0,0,0,0
913,ensemble learning  ensure its better performance,Techniques,ensemble learning  ensure its better performance,"['ensemble', 'learning', 'ensure', 'its', 'better', 'performance']",0,"['ensemble', 'learning', 'ensure', 'it', 'better', 'performance']","['ensemble', 'learning', 'ensure', 'better', 'performance']",ensemble learning ensure better performance,0.5,0.5,6,43,6.142857142857143,0,0,0,0,0,0,0,0
914,how to read a column subset of a csv file into a data frame in r,Tools,how to read a column subset of a csv file into a data frame in r,"['how', 'to', 'read', 'a', 'column', 'subset', 'of', 'a', 'csv', 'file', 'into', 'a', 'data', 'frame', 'in', 'r']",0,"['how', 'to', 'read', 'a', 'column', 'subset', 'of', 'a', 'csv', 'file', 'into', 'a', 'data', 'frame', 'in', 'r']","['read', 'column', 'subset', 'csv', 'file', 'data', 'frame', 'r']",read column subset csv file data frame r,0.0,0.0,16,40,2.3529411764705883,0,0,0,0,0,0,0,0
915,new iim vs praxis business school,Career,new iim vs praxis business school,"['new', 'iim', 'vs', 'praxis', 'business', 'school']",0,"['new', 'iim', 'v', 'praxis', 'business', 'school']","['new', 'iim', 'v', 'praxis', 'business', 'school']",new iim v praxis business school,0.1363636363636363,0.1363636363636363,6,32,4.571428571428571,0,0,0,0,0,0,0,0
916,what is hackathon score,Hackathons,what is hackathon score,"['what', 'is', 'hackathon', 'score']",0,"['what', 'is', 'hackathon', 'score']","['hackathon', 'score']",hackathon score,0.0,0.0,4,15,3.0,0,0,0,0,0,0,0,0
917,how to use diagnostic statistics in r for outliers and influential observations,Tools,how to use diagnostic statistics in r for outliers and influential observations,"['how', 'to', 'use', 'diagnostic', 'statistics', 'in', 'r', 'for', 'outliers', 'and', 'influential', 'observations']",0,"['how', 'to', 'use', 'diagnostic', 'statistic', 'in', 'r', 'for', 'outlier', 'and', 'influential', 'observation']","['use', 'diagnostic', 'statistic', 'r', 'outlier', 'influential', 'observation']",use diagnostic statistic r outlier influential observation,0.0,0.0,12,58,4.461538461538462,0,0,0,0,0,0,0,0
918,mean and variance,Techniques,mean and variance,"['mean', 'and', 'variance']",0,"['mean', 'and', 'variance']","['mean', 'variance']",mean variance,-0.3125,-0.3125,3,13,3.25,0,0,0,0,0,0,0,0
919,guidance for switching career into big data bi or data analytics,Career,guidance for switching career into big data bi or data analytics,"['guidance', 'for', 'switching', 'career', 'into', 'big', 'data', 'bi', 'or', 'data', 'analytics']",0,"['guidance', 'for', 'switching', 'career', 'into', 'big', 'data', 'bi', 'or', 'data', 'analytics']","['guidance', 'switching', 'career', 'big', 'data', 'bi', 'data', 'analytics']",guidance switching career big data bi data analytics,0.0,0.0,11,52,4.333333333333333,0,0,0,0,0,0,0,0
920,what does rotation in pca do,Techniques,what does rotation in pca do,"['what', 'does', 'rotation', 'in', 'pca', 'do']",0,"['what', 'doe', 'rotation', 'in', 'pca', 'do']","['doe', 'rotation', 'pca']",doe rotation pca,0.0,0.0,6,16,2.2857142857142856,0,0,0,0,0,0,0,0
921,fractal analytics hiring,Hackathons,fractal analytics hiring,"['fractal', 'analytics', 'hiring']",0,"['fractal', 'analytics', 'hiring']","['fractal', 'analytics', 'hiring']",fractal analytics hiring,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
922,how is singular value decomposition used in dimensionality reduction,Techniques,how is singular value decomposition used in dimensionality reduction,"['how', 'is', 'singular', 'value', 'decomposition', 'used', 'in', 'dimensionality', 'reduction']",0,"['how', 'is', 'singular', 'value', 'decomposition', 'used', 'in', 'dimensionality', 'reduction']","['singular', 'value', 'decomposition', 'used', 'dimensionality', 'reduction']",singular value decomposition used dimensionality reduction,0.0,0.0,9,58,5.8,0,0,0,0,0,0,0,0
923,init got multiple values for argument nsplits,Hackathons,init got multiple values for argument nsplits,"['init', 'got', 'multiple', 'values', 'for', 'argument', 'nsplits']",0,"['init', 'got', 'multiple', 'value', 'for', 'argument', 'nsplits']","['init', 'got', 'multiple', 'value', 'argument', 'nsplits']",init got multiple value argument nsplits,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
924,found error message while tokenise a tweet text in python,Tools,found error message while tokenise a tweet text in python,"['found', 'error', 'message', 'while', 'tokenise', 'a', 'tweet', 'text', 'in', 'python']",0,"['found', 'error', 'message', 'while', 'tokenise', 'a', 'tweet', 'text', 'in', 'python']","['found', 'error', 'message', 'tokenise', 'tweet', 'text', 'python']",found error message tokenise tweet text python,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
925,variable selection and eda,Techniques,variable selection and eda,"['variable', 'selection', 'and', 'eda']",0,"['variable', 'selection', 'and', 'eda']","['variable', 'selection', 'eda']",variable selection eda,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
926,interaction terms in ordinal logistic regression,Techniques,interaction terms in ordinal logistic regression,"['interaction', 'terms', 'in', 'ordinal', 'logistic', 'regression']",0,"['interaction', 'term', 'in', 'ordinal', 'logistic', 'regression']","['interaction', 'term', 'ordinal', 'logistic', 'regression']",interaction term ordinal logistic regression,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
927,how to build a triple exponential smoothing model for forecasting,Techniques,how to build a triple exponential smoothing model for forecasting,"['how', 'to', 'build', 'a', 'triple', 'exponential', 'smoothing', 'model', 'for', 'forecasting']",0,"['how', 'to', 'build', 'a', 'triple', 'exponential', 'smoothing', 'model', 'for', 'forecasting']","['build', 'triple', 'exponential', 'smoothing', 'model', 'forecasting']",build triple exponential smoothing model forecasting,0.0,0.0,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
929,dependent variable  ordinal data   to  scale,Techniques,dependent variable  ordinal data   to  scale,"['dependent', 'variable', 'ordinal', 'data', 'to', 'scale']",2,"['dependent', 'variable', 'ordinal', 'data', 'to', 'scale']","['dependent', 'variable', 'ordinal', 'data', 'scale']",dependent variable ordinal data scale,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
930,career transition question,Career,career transition question,"['career', 'transition', 'question']",0,"['career', 'transition', 'question']","['career', 'transition', 'question']",career transition question,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
931,observed vs unobserved variables,Techniques,observed vs unobserved variables,"['observed', 'vs', 'unobserved', 'variables']",0,"['observed', 'v', 'unobserved', 'variable']","['observed', 'v', 'unobserved', 'variable']",observed v unobserved variable,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
932,take home exercise,Career,take home exercise,"['take', 'home', 'exercise']",0,"['take', 'home', 'exercise']","['take', 'home', 'exercise']",take home exercise,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
933,label script for text classification,Techniques,label script for text classification,"['label', 'script', 'for', 'text', 'classification']",0,"['label', 'script', 'for', 'text', 'classification']","['label', 'script', 'text', 'classification']",label script text classification,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
934,internship opportunities for msc economics candidate in delhi,Career,internship opportunities for msc economics candidate in delhi,"['internship', 'opportunities', 'for', 'msc', 'economics', 'candidate', 'in', 'delhi']",0,"['internship', 'opportunity', 'for', 'msc', 'economics', 'candidate', 'in', 'delhi']","['internship', 'opportunity', 'msc', 'economics', 'candidate', 'delhi']",internship opportunity msc economics candidate delhi,0.0,0.0,8,52,5.777777777777778,0,0,0,0,0,0,0,0
935,cluster validation,Techniques,cluster validation,"['cluster', 'validation']",0,"['cluster', 'validation']","['cluster', 'validation']",cluster validation,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
936,why is decision tree give only two nodes,Techniques,why is decision tree give only two nodes,"['why', 'is', 'decision', 'tree', 'give', 'only', 'two', 'nodes']",0,"['why', 'is', 'decision', 'tree', 'give', 'only', 'two', 'node']","['decision', 'tree', 'give', 'two', 'node']",decision tree give two node,0.0,0.0,8,27,3.0,0,0,0,0,0,0,0,0
937,generate  of missing value in r,Tools,generate  of missing value in r,"['generate', 'of', 'missing', 'value', 'in', 'r']",1,"['generate', 'of', 'missing', 'value', 'in', 'r']","['generate', 'missing', 'value', 'r']",generate missing value r,-0.2,-0.2,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
938,titanic kaggle solution using sas,Tools,titanic kaggle solution using sas,"['titanic', 'kaggle', 'solution', 'using', 'sas']",0,"['titanic', 'kaggle', 'solution', 'using', 'sa']","['titanic', 'kaggle', 'solution', 'using', 'sa']",titanic kaggle solution using sa,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
939,rapidminer or python,Tools,rapidminer or python,"['rapidminer', 'or', 'python']",0,"['rapidminer', 'or', 'python']","['rapidminer', 'python']",rapidminer python,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
940,final year project suggestions,Resources,final year project suggestions,"['final', 'year', 'project', 'suggestions']",0,"['final', 'year', 'project', 'suggestion']","['final', 'year', 'project', 'suggestion']",final year project suggestion,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
941,using decision trees for feature reduction,Techniques,using decision trees for feature reduction,"['using', 'decision', 'trees', 'for', 'feature', 'reduction']",0,"['using', 'decision', 'tree', 'for', 'feature', 'reduction']","['using', 'decision', 'tree', 'feature', 'reduction']",using decision tree feature reduction,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
942,gdpr compliance,Other,gdpr compliance,"['gdpr', 'compliance']",0,"['gdpr', 'compliance']","['gdpr', 'compliance']",gdpr compliance,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
943,movie recommendation engine  movielens,Techniques,movie recommendation engine  movielens,"['movie', 'recommendation', 'engine', 'movielens']",0,"['movie', 'recommendation', 'engine', 'movielens']","['movie', 'recommendation', 'engine', 'movielens']",movie recommendation engine movielens,0.0,0.0,4,37,7.4,0,0,0,0,0,0,0,0
944,data preprocessing normalization  standardization,Techniques,data preprocessing normalization  standardization,"['data', 'preprocessing', 'normalization', 'standardization']",0,"['data', 'preprocessing', 'normalization', 'standardization']","['data', 'preprocessing', 'normalization', 'standardization']",data preprocessing normalization standardization,0.0,0.0,4,48,9.6,0,0,0,0,0,0,0,0
945,quick overview data set for bank,Hackathons,quick overview data set for bank,"['quick', 'overview', 'data', 'set', 'for', 'bank']",0,"['quick', 'overview', 'data', 'set', 'for', 'bank']","['quick', 'overview', 'data', 'set', 'bank']",quick overview data set bank,0.3333333333333333,0.3333333333333333,6,28,4.0,0,0,0,0,0,0,0,0
946,frequently bought together algorithm and code,Techniques,frequently bought together algorithm and code,"['frequently', 'bought', 'together', 'algorithm', 'and', 'code']",0,"['frequently', 'bought', 'together', 'algorithm', 'and', 'code']","['frequently', 'bought', 'together', 'algorithm', 'code']",frequently bought together algorithm code,0.1,0.1,6,41,5.857142857142857,0,0,0,0,0,0,0,0
947,python  qliksense for advanced data analytics,Tools,python  qliksense for advanced data analytics,"['python', 'qliksense', 'for', 'advanced', 'data', 'analytics']",0,"['python', 'qliksense', 'for', 'advanced', 'data', 'analytics']","['python', 'qliksense', 'advanced', 'data', 'analytics']",python qliksense advanced data analytics,0.4,0.4,6,40,5.714285714285714,0,0,0,0,0,0,0,0
948,data visualization toolsqlikview vs r,Career,data visualization toolsqlikview vs r,"['data', 'visualization', 'toolsqlikview', 'vs', 'r']",0,"['data', 'visualization', 'toolsqlikview', 'v', 'r']","['data', 'visualization', 'toolsqlikview', 'v', 'r']",data visualization toolsqlikview v r,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
949,how to convert from category to numeric,Techniques,how to convert from category to numeric,"['how', 'to', 'convert', 'from', 'category', 'to', 'numeric']",0,"['how', 'to', 'convert', 'from', 'category', 'to', 'numeric']","['convert', 'category', 'numeric']",convert category numeric,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
950,is it okay not to split the dataset into training and testing for text classification python code for stacking ensemble learning,Techniques,is it okay not to split the dataset into training and testing for text classification python code for stacking ensemble learning,"['is', 'it', 'okay', 'not', 'to', 'split', 'the', 'dataset', 'into', 'training', 'and', 'testing', 'for', 'text', 'classification', 'python', 'code', 'for', 'stacking', 'ensemble', 'learning']",0,"['is', 'it', 'okay', 'not', 'to', 'split', 'the', 'dataset', 'into', 'training', 'and', 'testing', 'for', 'text', 'classification', 'python', 'code', 'for', 'stacking', 'ensemble', 'learning']","['okay', 'split', 'dataset', 'training', 'testing', 'text', 'classification', 'python', 'code', 'stacking', 'ensemble', 'learning']",okay split dataset training testing text classification python code stacking ensemble learning,0.5,0.5,21,94,4.2727272727272725,0,0,0,0,0,0,0,0
951,how to plot the data set in two different color using plot function in r,Techniques,how to plot the data set in two different color using plot function in r,"['how', 'to', 'plot', 'the', 'data', 'set', 'in', 'two', 'different', 'color', 'using', 'plot', 'function', 'in', 'r']",0,"['how', 'to', 'plot', 'the', 'data', 'set', 'in', 'two', 'different', 'color', 'using', 'plot', 'function', 'in', 'r']","['plot', 'data', 'set', 'two', 'different', 'color', 'using', 'plot', 'function', 'r']",plot data set two different color using plot function r,0.0,0.0,15,55,3.4375,0,0,0,0,0,0,0,0
952,how to shift the axis from continuous to discrete one,Techniques,how to shift the axis from continuous to discrete one,"['how', 'to', 'shift', 'the', 'axis', 'from', 'continuous', 'to', 'discrete', 'one']",0,"['how', 'to', 'shift', 'the', 'axis', 'from', 'continuous', 'to', 'discrete', 'one']","['shift', 'axis', 'continuous', 'discrete', 'one']",shift axis continuous discrete one,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
953,downloading a file from a list of weblinks in python ,Tools,downloading a file from a list of weblinks in python ,"['downloading', 'a', 'file', 'from', 'a', 'list', 'of', 'weblinks', 'in', 'python']",1,"['downloading', 'a', 'file', 'from', 'a', 'list', 'of', 'weblinks', 'in', 'python']","['downloading', 'file', 'list', 'weblinks', 'python']",downloading file list weblinks python,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
954,how to choose null or alternate hypothesis for z test,Techniques,how to choose null or alternate hypothesis for z test,"['how', 'to', 'choose', 'null', 'or', 'alternate', 'hypothesis', 'for', 'z', 'test']",0,"['how', 'to', 'choose', 'null', 'or', 'alternate', 'hypothesis', 'for', 'z', 'test']","['choose', 'null', 'alternate', 'hypothesis', 'z', 'test']",choose null alternate hypothesis z test,0.0,0.0,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
955,algorithm to use for below problem,Techniques,algorithm to use for below problem,"['algorithm', 'to', 'use', 'for', 'below', 'problem']",0,"['algorithm', 'to', 'use', 'for', 'below', 'problem']","['algorithm', 'use', 'problem']",algorithm use problem,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
956,•explain how you validate that the data received from sources is suitable for modelling,Techniques,•explain how you validate that the data received from sources is suitable for modelling,"['•explain', 'how', 'you', 'validate', 'that', 'the', 'data', 'received', 'from', 'sources', 'is', 'suitable', 'for', 'modelling']",0,"['•explain', 'how', 'you', 'validate', 'that', 'the', 'data', 'received', 'from', 'source', 'is', 'suitable', 'for', 'modelling']","['•explain', 'validate', 'data', 'received', 'source', 'suitable', 'modelling']",•explain validate data received source suitable modelling,0.55,0.55,14,57,3.8,0,0,0,0,0,0,0,0
957,text summarization  encoder decoder using attention model,Techniques,text summarization  encoder decoder using attention model,"['text', 'summarization', 'encoder', 'decoder', 'using', 'attention', 'model']",0,"['text', 'summarization', 'encoder', 'decoder', 'using', 'attention', 'model']","['text', 'summarization', 'encoder', 'decoder', 'using', 'attention', 'model']",text summarization encoder decoder using attention model,0.0,0.0,7,56,7.0,0,0,0,0,0,0,0,0
958,how to determine the most important factor for a particular scenario,Techniques,how to determine the most important factor for a particular scenario,"['how', 'to', 'determine', 'the', 'most', 'important', 'factor', 'for', 'a', 'particular', 'scenario']",0,"['how', 'to', 'determine', 'the', 'most', 'important', 'factor', 'for', 'a', 'particular', 'scenario']","['determine', 'important', 'factor', 'particular', 'scenario']",determine important factor particular scenario,0.3555555555555555,0.2833333333333333,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
959,official tensorflow support for windows,Resources,official tensorflow support for windows,"['official', 'tensorflow', 'support', 'for', 'windows']",0,"['official', 'tensorflow', 'support', 'for', 'window']","['official', 'tensorflow', 'support', 'window']",official tensorflow support window,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
960,chaidcart pre requisites usage and guidelines to be followed,Techniques,chaidcart pre requisites usage and guidelines to be followed,"['chaidcart', 'pre', 'requisites', 'usage', 'and', 'guidelines', 'to', 'be', 'followed']",0,"['chaidcart', 'pre', 'requisite', 'usage', 'and', 'guideline', 'to', 'be', 'followed']","['chaidcart', 'pre', 'requisite', 'usage', 'guideline', 'followed']",chaidcart pre requisite usage guideline followed,0.0,0.0,9,48,4.8,0,0,0,0,0,0,0,0
961,machine learning can help government to deploy better policy,Techniques,machine learning can help government to deploy better policy,"['machine', 'learning', 'can', 'help', 'government', 'to', 'deploy', 'better', 'policy']",0,"['machine', 'learning', 'can', 'help', 'government', 'to', 'deploy', 'better', 'policy']","['machine', 'learning', 'help', 'government', 'deploy', 'better', 'policy']",machine learning help government deploy better policy,0.5,0.5,9,53,5.3,0,0,0,0,0,0,0,0
962,need to mapcreate dataframe my test prediction testpred with actual data set which have customer column,Techniques,need to mapcreate dataframe my test prediction testpred with actual data set which have customer column,"['need', 'to', 'mapcreate', 'dataframe', 'my', 'test', 'prediction', 'testpred', 'with', 'actual', 'data', 'set', 'which', 'have', 'customer', 'column']",0,"['need', 'to', 'mapcreate', 'dataframe', 'my', 'test', 'prediction', 'testpred', 'with', 'actual', 'data', 'set', 'which', 'have', 'customer', 'column']","['need', 'mapcreate', 'dataframe', 'test', 'prediction', 'testpred', 'actual', 'data', 'set', 'customer', 'column']",need mapcreate dataframe test prediction testpred actual data set customer column,0.0,0.0,16,81,4.764705882352941,0,0,0,0,0,0,0,0
963,random forest to choose multiple variable in consumer lending portfolio,Techniques,random forest to choose multiple variable in consumer lending portfolio,"['random', 'forest', 'to', 'choose', 'multiple', 'variable', 'in', 'consumer', 'lending', 'portfolio']",0,"['random', 'forest', 'to', 'choose', 'multiple', 'variable', 'in', 'consumer', 'lending', 'portfolio']","['random', 'forest', 'choose', 'multiple', 'variable', 'consumer', 'lending', 'portfolio']",random forest choose multiple variable consumer lending portfolio,-0.25,-0.25,10,65,5.909090909090909,0,0,0,0,0,0,0,0
964,installing caffe on ubuntu ,Tools,installing caffe on ubuntu ,"['installing', 'caffe', 'on', 'ubuntu']",1,"['installing', 'caffe', 'on', 'ubuntu']","['installing', 'caffe', 'ubuntu']",installing caffe ubuntu,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
965,decision tree gini index,Techniques,decision tree gini index,"['decision', 'tree', 'gini', 'index']",0,"['decision', 'tree', 'gini', 'index']","['decision', 'tree', 'gini', 'index']",decision tree gini index,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
966,what does the error condition has length   in r mean,Tools,what does the error condition has length   in r mean,"['what', 'does', 'the', 'error', 'condition', 'has', 'length', 'in', 'r', 'mean']",1,"['what', 'doe', 'the', 'error', 'condition', 'ha', 'length', 'in', 'r', 'mean']","['doe', 'error', 'condition', 'ha', 'length', 'r', 'mean']",doe error condition ha length r mean,-0.3125,-0.3125,10,36,3.272727272727273,0,0,0,0,0,0,0,0
967,transformation for continuous predictors,Techniques,transformation for continuous predictors,"['transformation', 'for', 'continuous', 'predictors']",0,"['transformation', 'for', 'continuous', 'predictor']","['transformation', 'continuous', 'predictor']",transformation continuous predictor,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
968,using several tools at once for a project,Tools,using several tools at once for a project,"['using', 'several', 'tools', 'at', 'once', 'for', 'a', 'project']",0,"['using', 'several', 'tool', 'at', 'once', 'for', 'a', 'project']","['using', 'several', 'tool', 'project']",using several tool project,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
969,how to install rpivot table package in r studio,Tools,how to install rpivot table package in r studio,"['how', 'to', 'install', 'rpivot', 'table', 'package', 'in', 'r', 'studio']",0,"['how', 'to', 'install', 'rpivot', 'table', 'package', 'in', 'r', 'studio']","['install', 'rpivot', 'table', 'package', 'r', 'studio']",install rpivot table package r studio,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
970,which one to use  randomforest vs svm vs knn,Techniques,which one to use  randomforest vs svm vs knn,"['which', 'one', 'to', 'use', 'randomforest', 'vs', 'svm', 'vs', 'knn']",0,"['which', 'one', 'to', 'use', 'randomforest', 'v', 'svm', 'v', 'knn']","['one', 'use', 'randomforest', 'v', 'svm', 'v', 'knn']",one use randomforest v svm v knn,0.0,0.0,9,32,3.2,0,0,0,0,0,0,0,0
971,how to properly extract time series hourly data,Techniques,how to properly extract time series hourly data,"['how', 'to', 'properly', 'extract', 'time', 'series', 'hourly', 'data']",0,"['how', 'to', 'properly', 'extract', 'time', 'series', 'hourly', 'data']","['properly', 'extract', 'time', 'series', 'hourly', 'data']",properly extract time series hourly data,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
972,datasets for practice,Resources,datasets for practice,"['datasets', 'for', 'practice']",0,"['datasets', 'for', 'practice']","['datasets', 'practice']",datasets practice,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
973,weightage based clustering,Techniques,weightage based clustering,"['weightage', 'based', 'clustering']",0,"['weightage', 'based', 'clustering']","['weightage', 'based', 'clustering']",weightage based clustering,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
974,what should i learn r or python,Tools,what should i learn r or python,"['what', 'should', 'i', 'learn', 'r', 'or', 'python']",0,"['what', 'should', 'i', 'learn', 'r', 'or', 'python']","['learn', 'r', 'python']",learn r python,0.0,0.0,7,14,1.75,0,0,0,0,0,0,0,0
975,clustering users based on apps he uses,Techniques,clustering users based on apps he uses,"['clustering', 'users', 'based', 'on', 'apps', 'he', 'uses']",0,"['clustering', 'user', 'based', 'on', 'apps', 'he', 'us']","['clustering', 'user', 'based', 'apps', 'us']",clustering user based apps us,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
976,project ideas on machine learning,Techniques,project ideas on machine learning,"['project', 'ideas', 'on', 'machine', 'learning']",0,"['project', 'idea', 'on', 'machine', 'learning']","['project', 'idea', 'machine', 'learning']",project idea machine learning,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
977,which machine learning algorithm i should use to mapping data between two data sets,Techniques,which machine learning algorithm i should use to mapping data between two data sets,"['which', 'machine', 'learning', 'algorithm', 'i', 'should', 'use', 'to', 'mapping', 'data', 'between', 'two', 'data', 'sets']",0,"['which', 'machine', 'learning', 'algorithm', 'i', 'should', 'use', 'to', 'mapping', 'data', 'between', 'two', 'data', 'set']","['machine', 'learning', 'algorithm', 'use', 'mapping', 'data', 'two', 'data', 'set']",machine learning algorithm use mapping data two data set,0.0,0.0,14,56,3.7333333333333334,0,0,0,0,0,0,0,0
978,nlp technique for avoid number of features modification,Techniques,nlp technique for avoid number of features modification,"['nlp', 'technique', 'for', 'avoid', 'number', 'of', 'features', 'modification']",0,"['nlp', 'technique', 'for', 'avoid', 'number', 'of', 'feature', 'modification']","['nlp', 'technique', 'avoid', 'number', 'feature', 'modification']",nlp technique avoid number feature modification,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
979,need help in this puzzle,Techniques,need help in this puzzle,"['need', 'help', 'in', 'this', 'puzzle']",0,"['need', 'help', 'in', 'this', 'puzzle']","['need', 'help', 'puzzle']",need help puzzle,0.0,0.0,5,16,2.6666666666666665,0,0,0,0,0,0,0,0
980,learning analytics from private institute,Career,learning analytics from private institute,"['learning', 'analytics', 'from', 'private', 'institute']",0,"['learning', 'analytics', 'from', 'private', 'institute']","['learning', 'analytics', 'private', 'institute']",learning analytics private institute,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
981,loan prediction iii  wanted to know about final solution option,Hackathons,loan prediction iii  wanted to know about final solution option,"['loan', 'prediction', 'iii', 'wanted', 'to', 'know', 'about', 'final', 'solution', 'option']",0,"['loan', 'prediction', 'iii', 'wanted', 'to', 'know', 'about', 'final', 'solution', 'option']","['loan', 'prediction', 'iii', 'wanted', 'know', 'final', 'solution', 'option']",loan prediction iii wanted know final solution option,0.0,0.0,10,53,4.818181818181818,0,0,0,0,0,0,0,0
982,how to enhance a logistic regression model,Techniques,how to enhance a logistic regression model,"['how', 'to', 'enhance', 'a', 'logistic', 'regression', 'model']",0,"['how', 'to', 'enhance', 'a', 'logistic', 'regression', 'model']","['enhance', 'logistic', 'regression', 'model']",enhance logistic regression model,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
983,using contours to expand image in python,Techniques,using contours to expand image in python,"['using', 'contours', 'to', 'expand', 'image', 'in', 'python']",0,"['using', 'contour', 'to', 'expand', 'image', 'in', 'python']","['using', 'contour', 'expand', 'image', 'python']",using contour expand image python,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
984,how to decide when to use naive bayes for classification,Techniques,how to decide when to use naive bayes for classification,"['how', 'to', 'decide', 'when', 'to', 'use', 'naive', 'bayes', 'for', 'classification']",0,"['how', 'to', 'decide', 'when', 'to', 'use', 'naive', 'bayes', 'for', 'classification']","['decide', 'use', 'naive', 'bayes', 'classification']",decide use naive bayes classification,-0.3,-0.3,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
985,how to create the nested directory in r,Tools,how to create the nested directory in r,"['how', 'to', 'create', 'the', 'nested', 'directory', 'in', 'r']",0,"['how', 'to', 'create', 'the', 'nested', 'directory', 'in', 'r']","['create', 'nested', 'directory', 'r']",create nested directory r,0.0,0.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
986,need help in starting a forecasting project,Other,need help in starting a forecasting project,"['need', 'help', 'in', 'starting', 'a', 'forecasting', 'project']",0,"['need', 'help', 'in', 'starting', 'a', 'forecasting', 'project']","['need', 'help', 'starting', 'forecasting', 'project']",need help starting forecasting project,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
987,how to implement stacking and blending of various models in r,Tools,how to implement stacking and blending of various models in r,"['how', 'to', 'implement', 'stacking', 'and', 'blending', 'of', 'various', 'models', 'in', 'r']",0,"['how', 'to', 'implement', 'stacking', 'and', 'blending', 'of', 'various', 'model', 'in', 'r']","['implement', 'stacking', 'blending', 'various', 'model', 'r']",implement stacking blending various model r,0.0,0.0,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
988,how to reshape data as transactions in r,Tools,how to reshape data as transactions in r,"['how', 'to', 'reshape', 'data', 'as', 'transactions', 'in', 'r']",0,"['how', 'to', 'reshape', 'data', 'a', 'transaction', 'in', 'r']","['reshape', 'data', 'transaction', 'r']",reshape data transaction r,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
989,maximum likelihood estimate,Techniques,maximum likelihood estimate,"['maximum', 'likelihood', 'estimate']",0,"['maximum', 'likelihood', 'estimate']","['maximum', 'likelihood', 'estimate']",maximum likelihood estimate,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
990,svm and neural networks,Techniques,svm and neural networks,"['svm', 'and', 'neural', 'networks']",0,"['svm', 'and', 'neural', 'network']","['svm', 'neural', 'network']",svm neural network,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
991,how to change the level of factor variable in r,Tools,how to change the level of factor variable in r,"['how', 'to', 'change', 'the', 'level', 'of', 'factor', 'variable', 'in', 'r']",0,"['how', 'to', 'change', 'the', 'level', 'of', 'factor', 'variable', 'in', 'r']","['change', 'level', 'factor', 'variable', 'r']",change level factor variable r,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
992,keyerror in big mart sales problem,Hackathons,keyerror in big mart sales problem,"['keyerror', 'in', 'big', 'mart', 'sales', 'problem']",0,"['keyerror', 'in', 'big', 'mart', 'sale', 'problem']","['keyerror', 'big', 'mart', 'sale', 'problem']",keyerror big mart sale problem,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
993,analytics contests to participate and win prize money,Career,analytics contests to participate and win prize money,"['analytics', 'contests', 'to', 'participate', 'and', 'win', 'prize', 'money']",0,"['analytics', 'contest', 'to', 'participate', 'and', 'win', 'prize', 'money']","['analytics', 'contest', 'participate', 'win', 'prize', 'money']",analytics contest participate win prize money,0.8,0.8,8,45,5.0,0,0,0,0,0,0,0,0
994,decision tree  output interpretaion,Tools,decision tree  output interpretaion,"['decision', 'tree', 'output', 'interpretaion']",0,"['decision', 'tree', 'output', 'interpretaion']","['decision', 'tree', 'output', 'interpretaion']",decision tree output interpretaion,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
995,working with ahp in r studio,Techniques,working with ahp in r studio,"['working', 'with', 'ahp', 'in', 'r', 'studio']",0,"['working', 'with', 'ahp', 'in', 'r', 'studio']","['working', 'ahp', 'r', 'studio']",working ahp r studio,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
996,stacked generalization,Techniques,stacked generalization,"['stacked', 'generalization']",0,"['stacked', 'generalization']","['stacked', 'generalization']",stacked generalization,0.0,0.0,2,22,7.333333333333333,0,0,0,0,0,0,0,0
997,importance of statistics in predictive modelling,Career,importance of statistics in predictive modelling,"['importance', 'of', 'statistics', 'in', 'predictive', 'modelling']",0,"['importance', 'of', 'statistic', 'in', 'predictive', 'modelling']","['importance', 'statistic', 'predictive', 'modelling']",importance statistic predictive modelling,0.0,0.0,6,41,5.857142857142857,0,0,0,0,0,0,0,0
998,•explain white noise series,Techniques,•explain white noise series,"['•explain', 'white', 'noise', 'series']",0,"['•explain', 'white', 'noise', 'series']","['•explain', 'white', 'noise', 'series']",•explain white noise series,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
999,error in plotting trends of same variable over different sets of rows simultaneously,Tools,error in plotting trends of same variable over different sets of rows simultaneously,"['error', 'in', 'plotting', 'trends', 'of', 'same', 'variable', 'over', 'different', 'sets', 'of', 'rows', 'simultaneously']",0,"['error', 'in', 'plotting', 'trend', 'of', 'same', 'variable', 'over', 'different', 'set', 'of', 'row', 'simultaneously']","['error', 'plotting', 'trend', 'variable', 'different', 'set', 'row', 'simultaneously']",error plotting trend variable different set row simultaneously,0.0,0.0,13,62,4.428571428571429,0,0,0,0,0,0,0,0
1000,data science vs data mining,Other,data science vs data mining,"['data', 'science', 'vs', 'data', 'mining']",0,"['data', 'science', 'v', 'data', 'mining']","['data', 'science', 'v', 'data', 'mining']",data science v data mining,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
1001,coin toss pattern recognition problem,Techniques,coin toss pattern recognition problem,"['coin', 'toss', 'pattern', 'recognition', 'problem']",0,"['coin', 'toss', 'pattern', 'recognition', 'problem']","['coin', 'toss', 'pattern', 'recognition', 'problem']",coin toss pattern recognition problem,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
1002,how to show all days of the month in line chart of qlikview,Tools,how to show all days of the month in line chart of qlikview,"['how', 'to', 'show', 'all', 'days', 'of', 'the', 'month', 'in', 'line', 'chart', 'of', 'qlikview']",0,"['how', 'to', 'show', 'all', 'day', 'of', 'the', 'month', 'in', 'line', 'chart', 'of', 'qlikview']","['show', 'day', 'month', 'line', 'chart', 'qlikview']",show day month line chart qlikview,0.0,0.0,13,34,2.4285714285714284,0,0,0,0,0,0,0,0
1003,relative importance of predictors for an ordinal response variable,Techniques,relative importance of predictors for an ordinal response variable,"['relative', 'importance', 'of', 'predictors', 'for', 'an', 'ordinal', 'response', 'variable']",0,"['relative', 'importance', 'of', 'predictor', 'for', 'an', 'ordinal', 'response', 'variable']","['relative', 'importance', 'predictor', 'ordinal', 'response', 'variable']",relative importance predictor ordinal response variable,0.0,0.0,9,55,5.5,0,0,0,0,0,0,0,0
1004,graduate programmes analytics vs science,Career,graduate programmes analytics vs science,"['graduate', 'programmes', 'analytics', 'vs', 'science']",0,"['graduate', 'programme', 'analytics', 'v', 'science']","['graduate', 'programme', 'analytics', 'v', 'science']",graduate programme analytics v science,0.0,0.0,5,38,6.333333333333333,0,0,0,0,0,0,0,0
1005,recommended analytics certifications for database professional,Career,recommended analytics certifications for database professional,"['recommended', 'analytics', 'certifications', 'for', 'database', 'professional']",0,"['recommended', 'analytics', 'certification', 'for', 'database', 'professional']","['recommended', 'analytics', 'certification', 'database', 'professional']",recommended analytics certification database professional,0.1,0.1,6,57,8.142857142857142,0,0,0,0,0,0,0,0
1006,knearest neighbors knn classification problem,Techniques,knearest neighbors knn classification problem,"['knearest', 'neighbors', 'knn', 'classification', 'problem']",0,"['knearest', 'neighbor', 'knn', 'classification', 'problem']","['knearest', 'neighbor', 'knn', 'classification', 'problem']",knearest neighbor knn classification problem,0.0,0.0,5,44,7.333333333333333,0,0,0,0,0,0,0,0
1007,date comparison,Techniques,date comparison,"['date', 'comparison']",0,"['date', 'comparison']","['date', 'comparison']",date comparison,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
1008,automating removal of high vif values in r,Tools,automating removal of high vif values in r,"['automating', 'removal', 'of', 'high', 'vif', 'values', 'in', 'r']",0,"['automating', 'removal', 'of', 'high', 'vif', 'value', 'in', 'r']","['automating', 'removal', 'high', 'vif', 'value', 'r']",automating removal high vif value r,0.16,0.16,8,35,3.888888888888889,0,0,0,0,0,0,0,0
1009,xgboost  python installation on windows,Techniques,xgboost  python installation on windows,"['xgboost', 'python', 'installation', 'on', 'windows']",0,"['xgboost', 'python', 'installation', 'on', 'window']","['xgboost', 'python', 'installation', 'window']",xgboost python installation window,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
1010,how to put the variable names center alligned using dtablefilter package,Tools,how to put the variable names center alligned using dtablefilter package,"['how', 'to', 'put', 'the', 'variable', 'names', 'center', 'alligned', 'using', 'dtablefilter', 'package']",0,"['how', 'to', 'put', 'the', 'variable', 'name', 'center', 'alligned', 'using', 'dtablefilter', 'package']","['put', 'variable', 'name', 'center', 'alligned', 'using', 'dtablefilter', 'package']",put variable name center alligned using dtablefilter package,-0.1,-0.1,11,60,5.0,0,0,0,0,0,0,0,0
1011,suggestions required for phd in analytics,Career,suggestions required for phd in analytics,"['suggestions', 'required', 'for', 'phd', 'in', 'analytics']",0,"['suggestion', 'required', 'for', 'phd', 'in', 'analytics']","['suggestion', 'required', 'phd', 'analytics']",suggestion required phd analytics,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
1012,what does the option boos in boosting function mean,Tools,what does the option boos in boosting function mean,"['what', 'does', 'the', 'option', 'boos', 'in', 'boosting', 'function', 'mean']",0,"['what', 'doe', 'the', 'option', 'boo', 'in', 'boosting', 'function', 'mean']","['doe', 'option', 'boo', 'boosting', 'function', 'mean']",doe option boo boosting function mean,-0.3125,-0.3125,9,37,3.7,0,0,0,0,0,0,0,0
1013,extracting the best fitted decisiontreeclassifier after grid search,Techniques,extracting the best fitted decisiontreeclassifier after grid search,"['extracting', 'the', 'best', 'fitted', 'decisiontreeclassifier', 'after', 'grid', 'search']",0,"['extracting', 'the', 'best', 'fitted', 'decisiontreeclassifier', 'after', 'grid', 'search']","['extracting', 'best', 'fitted', 'decisiontreeclassifier', 'grid', 'search']",extracting best fitted decisiontreeclassifier grid search,1.0,1.0,8,57,6.333333333333333,0,0,0,0,0,0,0,0
1014,sp jain global vs aegis school of business,Career,sp jain global vs aegis school of business,"['sp', 'jain', 'global', 'vs', 'aegis', 'school', 'of', 'business']",0,"['sp', 'jain', 'global', 'v', 'aegis', 'school', 'of', 'business']","['sp', 'jain', 'global', 'v', 'aegis', 'school', 'business']",sp jain global v aegis school business,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
1015,when to use variable transformation,Techniques,when to use variable transformation,"['when', 'to', 'use', 'variable', 'transformation']",0,"['when', 'to', 'use', 'variable', 'transformation']","['use', 'variable', 'transformation']",use variable transformation,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
1016,welcome to practice problem  twitter sentiment analysis,Hackathons,welcome to practice problem  twitter sentiment analysis,"['welcome', 'to', 'practice', 'problem', 'twitter', 'sentiment', 'analysis']",0,"['welcome', 'to', 'practice', 'problem', 'twitter', 'sentiment', 'analysis']","['welcome', 'practice', 'problem', 'twitter', 'sentiment', 'analysis']",welcome practice problem twitter sentiment analysis,0.8,0.8,7,51,6.375,0,0,0,0,0,0,0,0
1017,median is more than mean  interpretation,Techniques,median is more than mean  interpretation,"['median', 'is', 'more', 'than', 'mean', 'interpretation']",0,"['median', 'is', 'more', 'than', 'mean', 'interpretation']","['median', 'mean', 'interpretation']",median mean interpretation,0.09375,-0.3125,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
1018,career switch from it to analytics,Career,career switch from it to analytics,"['career', 'switch', 'from', 'it', 'to', 'analytics']",0,"['career', 'switch', 'from', 'it', 'to', 'analytics']","['career', 'switch', 'analytics']",career switch analytics,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
1019,machine vision and video analytics development,Career,machine vision and video analytics development,"['machine', 'vision', 'and', 'video', 'analytics', 'development']",0,"['machine', 'vision', 'and', 'video', 'analytics', 'development']","['machine', 'vision', 'video', 'analytics', 'development']",machine vision video analytics development,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
1020,overcoming energy equipements,Techniques,overcoming energy equipements,"['overcoming', 'energy', 'equipements']",0,"['overcoming', 'energy', 'equipements']","['overcoming', 'energy', 'equipements']",overcoming energy equipements,0.0,0.0,3,29,7.25,0,0,0,0,0,0,0,0
1021,difference between supervised and unsupervised learning,Techniques,difference between supervised and unsupervised learning,"['difference', 'between', 'supervised', 'and', 'unsupervised', 'learning']",0,"['difference', 'between', 'supervised', 'and', 'unsupervised', 'learning']","['difference', 'supervised', 'unsupervised', 'learning']",difference supervised unsupervised learning,0.0,0.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
1022,how to interpret the decision boundary output in r,Tools,how to interpret the decision boundary output in r,"['how', 'to', 'interpret', 'the', 'decision', 'boundary', 'output', 'in', 'r']",0,"['how', 'to', 'interpret', 'the', 'decision', 'boundary', 'output', 'in', 'r']","['interpret', 'decision', 'boundary', 'output', 'r']",interpret decision boundary output r,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
1023,how to decide which type of kernel to use in svm,Techniques,how to decide which type of kernel to use in svm,"['how', 'to', 'decide', 'which', 'type', 'of', 'kernel', 'to', 'use', 'in', 'svm']",0,"['how', 'to', 'decide', 'which', 'type', 'of', 'kernel', 'to', 'use', 'in', 'svm']","['decide', 'type', 'kernel', 'use', 'svm']",decide type kernel use svm,0.0,0.0,11,26,2.1666666666666665,0,0,0,0,0,0,0,0
1024,dimensionality reduction is good or bad,Techniques,dimensionality reduction is good or bad,"['dimensionality', 'reduction', 'is', 'good', 'or', 'bad']",0,"['dimensionality', 'reduction', 'is', 'good', 'or', 'bad']","['dimensionality', 'reduction', 'good', 'bad']",dimensionality reduction good bad,5.551115123125783e-17,5.551115123125783e-17,6,33,4.714285714285714,0,0,0,0,0,0,0,0
1025,aic values in arima in r,Techniques,aic values in arima in r,"['aic', 'values', 'in', 'arima', 'in', 'r']",0,"['aic', 'value', 'in', 'arima', 'in', 'r']","['aic', 'value', 'arima', 'r']",aic value arima r,0.0,0.0,6,17,2.4285714285714284,0,0,0,0,0,0,0,0
1026,which tool do you generally use to build deep learning models specific to python,Tools,which tool do you generally use to build deep learning models specific to python,"['which', 'tool', 'do', 'you', 'generally', 'use', 'to', 'build', 'deep', 'learning', 'models', 'specific', 'to', 'python']",0,"['which', 'tool', 'do', 'you', 'generally', 'use', 'to', 'build', 'deep', 'learning', 'model', 'specific', 'to', 'python']","['tool', 'generally', 'use', 'build', 'deep', 'learning', 'model', 'specific', 'python']",tool generally use build deep learning model specific python,0.0166666666666666,0.0166666666666666,14,60,4.0,0,0,0,0,0,0,0,0
1027,what does loop function signifies in r,Tools,what does loop function signifies in r,"['what', 'does', 'loop', 'function', 'signifies', 'in', 'r']",0,"['what', 'doe', 'loop', 'function', 'signifies', 'in', 'r']","['doe', 'loop', 'function', 'signifies', 'r']",doe loop function signifies r,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
1028,extracting a paragraph using text mining,Techniques,extracting a paragraph using text mining,"['extracting', 'a', 'paragraph', 'using', 'text', 'mining']",0,"['extracting', 'a', 'paragraph', 'using', 'text', 'mining']","['extracting', 'paragraph', 'using', 'text', 'mining']",extracting paragraph using text mining,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
1029,dataset to create dashboard using tableau,Tools,dataset to create dashboard using tableau,"['dataset', 'to', 'create', 'dashboard', 'using', 'tableau']",0,"['dataset', 'to', 'create', 'dashboard', 'using', 'tableau']","['dataset', 'create', 'dashboard', 'using', 'tableau']",dataset create dashboard using tableau,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
1030,hackathon problem do you know whos a megastar,Hackathons,hackathon problem do you know whos a megastar,"['hackathon', 'problem', 'do', 'you', 'know', 'whos', 'a', 'megastar']",0,"['hackathon', 'problem', 'do', 'you', 'know', 'who', 'a', 'megastar']","['hackathon', 'problem', 'know', 'megastar']",hackathon problem know megastar,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
1031,handson practice of prediction modelling,Resources,handson practice of prediction modelling,"['handson', 'practice', 'of', 'prediction', 'modelling']",0,"['handson', 'practice', 'of', 'prediction', 'modelling']","['handson', 'practice', 'prediction', 'modelling']",handson practice prediction modelling,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
1032,how to encrypt data transfer from r to sql server,Techniques,how to encrypt data transfer from r to sql server,"['how', 'to', 'encrypt', 'data', 'transfer', 'from', 'r', 'to', 'sql', 'server']",0,"['how', 'to', 'encrypt', 'data', 'transfer', 'from', 'r', 'to', 'sql', 'server']","['encrypt', 'data', 'transfer', 'r', 'sql', 'server']",encrypt data transfer r sql server,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
1033,starting data mining with poor statistic knowledge,Career,starting data mining with poor statistic knowledge,"['starting', 'data', 'mining', 'with', 'poor', 'statistic', 'knowledge']",0,"['starting', 'data', 'mining', 'with', 'poor', 'statistic', 'knowledge']","['starting', 'data', 'mining', 'poor', 'statistic', 'knowledge']",starting data mining poor statistic knowledge,-0.2,-0.2,7,45,5.625,0,0,0,0,0,0,0,0
1034,getting error while using elmo on google colab,Techniques,getting error while using elmo on google colab,"['getting', 'error', 'while', 'using', 'elmo', 'on', 'google', 'colab']",0,"['getting', 'error', 'while', 'using', 'elmo', 'on', 'google', 'colab']","['getting', 'error', 'using', 'elmo', 'google', 'colab']",getting error using elmo google colab,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
1035,learning from data  relaunched,Resources,learning from data  relaunched,"['learning', 'from', 'data', 'relaunched']",0,"['learning', 'from', 'data', 'relaunched']","['learning', 'data', 'relaunched']",learning data relaunched,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
1036,best platform for big data analytics for beginners  aws vs azure vs google cloud,Tools,best platform for big data analytics for beginners  aws vs azure vs google cloud,"['best', 'platform', 'for', 'big', 'data', 'analytics', 'for', 'beginners', 'aws', 'vs', 'azure', 'vs', 'google', 'cloud']",0,"['best', 'platform', 'for', 'big', 'data', 'analytics', 'for', 'beginner', 'aws', 'v', 'azure', 'v', 'google', 'cloud']","['best', 'platform', 'big', 'data', 'analytics', 'beginner', 'aws', 'v', 'azure', 'v', 'google', 'cloud']",best platform big data analytics beginner aws v azure v google cloud,0.5,0.5,14,68,4.533333333333333,0,0,0,0,0,0,0,0
1037,what are the best online courses in business intelligence,Career,what are the best online courses in business intelligence,"['what', 'are', 'the', 'best', 'online', 'courses', 'in', 'business', 'intelligence']",0,"['what', 'are', 'the', 'best', 'online', 'course', 'in', 'business', 'intelligence']","['best', 'online', 'course', 'business', 'intelligence']",best online course business intelligence,1.0,1.0,9,40,4.0,0,0,0,0,0,0,0,0
1038,data exploration using elastic search and kibana,Hackathons,data exploration using elastic search and kibana,"['data', 'exploration', 'using', 'elastic', 'search', 'and', 'kibana']",0,"['data', 'exploration', 'using', 'elastic', 'search', 'and', 'kibana']","['data', 'exploration', 'using', 'elastic', 'search', 'kibana']",data exploration using elastic search kibana,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
1039,features importance xgboostregressor,Techniques,features importance xgboostregressor,"['features', 'importance', 'xgboostregressor']",0,"['feature', 'importance', 'xgboostregressor']","['feature', 'importance', 'xgboostregressor']",feature importance xgboostregressor,0.0,0.0,3,35,8.75,0,0,0,0,0,0,0,0
1040,how much does the accuracy of the model depend upon the number of trees in random forest,Techniques,how much does the accuracy of the model depend upon the number of trees in random forest,"['how', 'much', 'does', 'the', 'accuracy', 'of', 'the', 'model', 'depend', 'upon', 'the', 'number', 'of', 'trees', 'in', 'random', 'forest']",0,"['how', 'much', 'doe', 'the', 'accuracy', 'of', 'the', 'model', 'depend', 'upon', 'the', 'number', 'of', 'tree', 'in', 'random', 'forest']","['much', 'doe', 'accuracy', 'model', 'depend', 'upon', 'number', 'tree', 'random', 'forest']",much doe accuracy model depend upon number tree random forest,-0.15,-0.15,17,61,3.388888888888889,0,0,0,0,0,0,0,0
1041,is there any way to calculate cross validation logloss for ho ensemble model just like cross validation auc,Techniques,is there any way to calculate cross validation logloss for ho ensemble model just like cross validation auc,"['is', 'there', 'any', 'way', 'to', 'calculate', 'cross', 'validation', 'logloss', 'for', 'ho', 'ensemble', 'model', 'just', 'like', 'cross', 'validation', 'auc']",0,"['is', 'there', 'any', 'way', 'to', 'calculate', 'cross', 'validation', 'logloss', 'for', 'ho', 'ensemble', 'model', 'just', 'like', 'cross', 'validation', 'auc']","['way', 'calculate', 'cross', 'validation', 'logloss', 'ho', 'ensemble', 'model', 'like', 'cross', 'validation', 'auc']",way calculate cross validation logloss ho ensemble model like cross validation auc,0.0,0.0,18,82,4.315789473684211,0,0,0,0,0,0,0,0
1042,just data but no business problem,Career,just data but no business problem,"['just', 'data', 'but', 'no', 'business', 'problem']",0,"['just', 'data', 'but', 'no', 'business', 'problem']","['data', 'business', 'problem']",data business problem,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
1043,intro into hackathon,Hackathons,intro into hackathon,"['intro', 'into', 'hackathon']",0,"['intro', 'into', 'hackathon']","['intro', 'hackathon']",intro hackathon,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
1044,overfitting problem in random forest,Techniques,overfitting problem in random forest,"['overfitting', 'problem', 'in', 'random', 'forest']",0,"['overfitting', 'problem', 'in', 'random', 'forest']","['overfitting', 'problem', 'random', 'forest']",overfitting problem random forest,-0.5,-0.5,5,33,5.5,0,0,0,0,0,0,0,0
1045,valueerror x has  features per sample expecting ,Techniques,valueerror x has  features per sample expecting ,"['valueerror', 'x', 'has', 'features', 'per', 'sample', 'expecting']",2,"['valueerror', 'x', 'ha', 'feature', 'per', 'sample', 'expecting']","['valueerror', 'x', 'ha', 'feature', 'per', 'sample', 'expecting']",valueerror x ha feature per sample expecting,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
1046,black friday practice problem,Resources,black friday practice problem,"['black', 'friday', 'practice', 'problem']",0,"['black', 'friday', 'practice', 'problem']","['black', 'friday', 'practice', 'problem']",black friday practice problem,-0.1666666666666666,-0.1666666666666666,4,29,5.8,0,0,0,0,0,0,0,0
1047,imputing missing data,Techniques,imputing missing data,"['imputing', 'missing', 'data']",0,"['imputing', 'missing', 'data']","['imputing', 'missing', 'data']",imputing missing data,-0.2,-0.2,3,21,5.25,0,0,0,0,0,0,0,0
1048,how to decide no of ntrees in randomforest,Techniques,how to decide no of ntrees in randomforest,"['how', 'to', 'decide', 'no', 'of', 'ntrees', 'in', 'randomforest']",0,"['how', 'to', 'decide', 'no', 'of', 'ntrees', 'in', 'randomforest']","['decide', 'ntrees', 'randomforest']",decide ntrees randomforest,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
1049,difference between nlp and text mining,Techniques,difference between nlp and text mining,"['difference', 'between', 'nlp', 'and', 'text', 'mining']",0,"['difference', 'between', 'nlp', 'and', 'text', 'mining']","['difference', 'nlp', 'text', 'mining']",difference nlp text mining,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
1050,pandas qcut  technique,Techniques,pandas qcut  technique,"['pandas', 'qcut', 'technique']",0,"['panda', 'qcut', 'technique']","['panda', 'qcut', 'technique']",panda qcut technique,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
1051,will this feature extraction technique work for gender classification using audio,Techniques,will this feature extraction technique work for gender classification using audio,"['will', 'this', 'feature', 'extraction', 'technique', 'work', 'for', 'gender', 'classification', 'using', 'audio']",0,"['will', 'this', 'feature', 'extraction', 'technique', 'work', 'for', 'gender', 'classification', 'using', 'audio']","['feature', 'extraction', 'technique', 'work', 'gender', 'classification', 'using', 'audio']",feature extraction technique work gender classification using audio,0.0,0.0,11,67,5.583333333333333,0,0,0,0,0,0,0,0
1052,how to secure my machine learning model,Techniques,how to secure my machine learning model,"['how', 'to', 'secure', 'my', 'machine', 'learning', 'model']",0,"['how', 'to', 'secure', 'my', 'machine', 'learning', 'model']","['secure', 'machine', 'learning', 'model']",secure machine learning model,0.4,0.4,7,29,3.625,0,0,0,0,0,0,0,0
1053,how can i create sparkline chart in excel ,Tools,how can i create sparkline chart in excel ,"['how', 'can', 'i', 'create', 'sparkline', 'chart', 'in', 'excel']",1,"['how', 'can', 'i', 'create', 'sparkline', 'chart', 'in', 'excel']","['create', 'sparkline', 'chart', 'excel']",create sparkline chart excel,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
1054,how to create multiple tabs in tableau,Tools,how to create multiple tabs in tableau,"['how', 'to', 'create', 'multiple', 'tabs', 'in', 'tableau']",0,"['how', 'to', 'create', 'multiple', 'tab', 'in', 'tableau']","['create', 'multiple', 'tab', 'tableau']",create multiple tab tableau,0.0,0.0,7,27,3.375,0,0,0,0,0,0,0,0
1055,basic questions,Techniques,basic questions,"['basic', 'questions']",0,"['basic', 'question']","['basic', 'question']",basic question,0.0,0.0,2,14,4.666666666666667,0,0,0,0,0,0,0,0
1056,pgpba at scmhrd vs pgpba at praxis business school,Career,pgpba at scmhrd vs pgpba at praxis business school,"['pgpba', 'at', 'scmhrd', 'vs', 'pgpba', 'at', 'praxis', 'business', 'school']",0,"['pgpba', 'at', 'scmhrd', 'v', 'pgpba', 'at', 'praxis', 'business', 'school']","['pgpba', 'scmhrd', 'v', 'pgpba', 'praxis', 'business', 'school']",pgpba scmhrd v pgpba praxis business school,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
1057,error while implementing machine learning with caret package in r,Techniques,error while implementing machine learning with caret package in r,"['error', 'while', 'implementing', 'machine', 'learning', 'with', 'caret', 'package', 'in', 'r']",0,"['error', 'while', 'implementing', 'machine', 'learning', 'with', 'caret', 'package', 'in', 'r']","['error', 'implementing', 'machine', 'learning', 'caret', 'package', 'r']",error implementing machine learning caret package r,0.0,0.0,10,51,4.636363636363637,0,0,0,0,0,0,0,0
1058,python error cannot reindex from a duplicate axis,Tools,python error cannot reindex from a duplicate axis,"['python', 'error', 'can', 'not', 'reindex', 'from', 'a', 'duplicate', 'axis']",0,"['python', 'error', 'can', 'not', 'reindex', 'from', 'a', 'duplicate', 'axis']","['python', 'error', 'reindex', 'duplicate', 'axis']",python error reindex duplicate axis,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
1059,what is difference between double bracket and  in r,Tools,what is difference between double bracket and  in r,"['what', 'is', 'difference', 'between', 'double', 'bracket', 'and', 'in', 'r']",0,"['what', 'is', 'difference', 'between', 'double', 'bracket', 'and', 'in', 'r']","['difference', 'double', 'bracket', 'r']",difference double bracket r,0.0,0.0,9,27,2.7,0,0,0,0,0,0,0,0
1060,r basic exercise,Techniques,r basic exercise,"['r', 'basic', 'exercise']",0,"['r', 'basic', 'exercise']","['r', 'basic', 'exercise']",r basic exercise,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
1061,how to plot data related to some country or region on the map of that region in r,Tools,how to plot data related to some country or region on the map of that region in r,"['how', 'to', 'plot', 'data', 'related', 'to', 'some', 'country', 'or', 'region', 'on', 'the', 'map', 'of', 'that', 'region', 'in', 'r']",0,"['how', 'to', 'plot', 'data', 'related', 'to', 'some', 'country', 'or', 'region', 'on', 'the', 'map', 'of', 'that', 'region', 'in', 'r']","['plot', 'data', 'related', 'country', 'region', 'map', 'region', 'r']",plot data related country region map region r,0.0,0.0,18,45,2.3684210526315788,0,0,0,0,0,0,0,0
1062,how to find number of cluster in cluster dendrogram,Techniques,how to find number of cluster in cluster dendrogram,"['how', 'to', 'find', 'number', 'of', 'cluster', 'in', 'cluster', 'dendrogram']",0,"['how', 'to', 'find', 'number', 'of', 'cluster', 'in', 'cluster', 'dendrogram']","['find', 'number', 'cluster', 'cluster', 'dendrogram']",find number cluster cluster dendrogram,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
1063,what is attribute drop signify in r,Tools,what is attribute drop signify in r,"['what', 'is', 'attribute', 'drop', 'signify', 'in', 'r']",0,"['what', 'is', 'attribute', 'drop', 'signify', 'in', 'r']","['attribute', 'drop', 'signify', 'r']",attribute drop signify r,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
1064,basic questions from newbie,Techniques,basic questions from newbie,"['basic', 'questions', 'from', 'newbie']",0,"['basic', 'question', 'from', 'newbie']","['basic', 'question', 'newbie']",basic question newbie,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
1065,creating a modelling engine,Techniques,creating a modelling engine,"['creating', 'a', 'modelling', 'engine']",0,"['creating', 'a', 'modelling', 'engine']","['creating', 'modelling', 'engine']",creating modelling engine,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
1066,what should be the value of boos and coeflearn argument in ada boosting,Techniques,what should be the value of boos and coeflearn argument in ada boosting,"['what', 'should', 'be', 'the', 'value', 'of', 'boos', 'and', 'coeflearn', 'argument', 'in', 'ada', 'boosting']",0,"['what', 'should', 'be', 'the', 'value', 'of', 'boo', 'and', 'coeflearn', 'argument', 'in', 'ada', 'boosting']","['value', 'boo', 'coeflearn', 'argument', 'ada', 'boosting']",value boo coeflearn argument ada boosting,0.0,0.0,13,41,2.9285714285714284,0,0,0,0,0,0,0,0
1067,python code unable to understand the output,Techniques,python code unable to understand the output,"['python', 'code', 'unable', 'to', 'understand', 'the', 'output']",0,"['python', 'code', 'unable', 'to', 'understand', 'the', 'output']","['python', 'code', 'unable', 'understand', 'output']",python code unable understand output,-0.5,-0.5,7,36,4.5,0,0,0,0,0,0,0,0
1068,career advice to move into big databusiness analytics to b tech graduate with  months exp in digital analytics,Career,career advice to move into big databusiness analytics to b tech graduate with  months exp in digital analytics,"['career', 'advice', 'to', 'move', 'into', 'big', 'databusiness', 'analytics', 'to', 'b', 'tech', 'graduate', 'with', 'months', 'exp', 'in', 'digital', 'analytics']",1,"['career', 'advice', 'to', 'move', 'into', 'big', 'databusiness', 'analytics', 'to', 'b', 'tech', 'graduate', 'with', 'month', 'exp', 'in', 'digital', 'analytics']","['career', 'advice', 'move', 'big', 'databusiness', 'analytics', 'b', 'tech', 'graduate', 'month', 'exp', 'digital', 'analytics']",career advice move big databusiness analytics b tech graduate month exp digital analytics,0.0,0.0,18,89,4.684210526315789,0,0,0,0,0,0,0,0
1069,rd place solution club mahindra dataolympics,Hackathons,rd place solution club mahindra dataolympics,"['rd', 'place', 'solution', 'club', 'mahindra', 'dataolympics']",0,"['rd', 'place', 'solution', 'club', 'mahindra', 'dataolympics']","['rd', 'place', 'solution', 'club', 'mahindra', 'dataolympics']",rd place solution club mahindra dataolympics,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
1070,am i underpaid as a data analyst,Career,am i underpaid as a data analyst,"['am', 'i', 'underpaid', 'as', 'a', 'data', 'analyst']",0,"['am', 'i', 'underpaid', 'a', 'a', 'data', 'analyst']","['underpaid', 'data', 'analyst']",underpaid data analyst,0.0,0.0,7,22,2.75,0,0,0,0,0,0,0,0
1071,error when extracting data through gtrendsr,Tools,error when extracting data through gtrendsr,"['error', 'when', 'extracting', 'data', 'through', 'gtrendsr']",0,"['error', 'when', 'extracting', 'data', 'through', 'gtrendsr']","['error', 'extracting', 'data', 'gtrendsr']",error extracting data gtrendsr,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
1072,download infographic steps for text data cleaning using python,Techniques,download infographic steps for text data cleaning using python,"['download', 'infographic', 'steps', 'for', 'text', 'data', 'cleaning', 'using', 'python']",0,"['download', 'infographic', 'step', 'for', 'text', 'data', 'cleaning', 'using', 'python']","['download', 'infographic', 'step', 'text', 'data', 'cleaning', 'using', 'python']",download infographic step text data cleaning using python,0.0,0.0,9,57,5.7,0,0,0,0,0,0,0,0
1073,complete machine learning guide to parameter tuning in gradient boosting in python,Techniques,complete machine learning guide to parameter tuning in gradient boosting in python,"['complete', 'machine', 'learning', 'guide', 'to', 'parameter', 'tuning', 'in', 'gradient', 'boosting', 'in', 'python']",0,"['complete', 'machine', 'learning', 'guide', 'to', 'parameter', 'tuning', 'in', 'gradient', 'boosting', 'in', 'python']","['complete', 'machine', 'learning', 'guide', 'parameter', 'tuning', 'gradient', 'boosting', 'python']",complete machine learning guide parameter tuning gradient boosting python,0.1,0.1,12,73,5.615384615384615,0,0,0,0,0,0,0,0
1074,career in big data for jobs in australia,Career,career in big data for jobs in australia,"['career', 'in', 'big', 'data', 'for', 'jobs', 'in', 'australia']",0,"['career', 'in', 'big', 'data', 'for', 'job', 'in', 'australia']","['career', 'big', 'data', 'job', 'australia']",career big data job australia,0.0,0.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
1075,handwritten digit recognition using r,Techniques,handwritten digit recognition using r,"['handwritten', 'digit', 'recognition', 'using', 'r']",0,"['handwritten', 'digit', 'recognition', 'using', 'r']","['handwritten', 'digit', 'recognition', 'using', 'r']",handwritten digit recognition using r,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
1076,how much the analytixlab courses are valued and the course on data science with sas and r for analytics job,Career,how much the analytixlab courses are valued and the course on data science with sas and r for analytics job,"['how', 'much', 'the', 'analytixlab', 'courses', 'are', 'valued', 'and', 'the', 'course', 'on', 'data', 'science', 'with', 'sas', 'and', 'r', 'for', 'analytics', 'job']",0,"['how', 'much', 'the', 'analytixlab', 'course', 'are', 'valued', 'and', 'the', 'course', 'on', 'data', 'science', 'with', 'sa', 'and', 'r', 'for', 'analytics', 'job']","['much', 'analytixlab', 'course', 'valued', 'course', 'data', 'science', 'sa', 'r', 'analytics', 'job']",much analytixlab course valued course data science sa r analytics job,0.2,0.2,20,69,3.2857142857142856,0,0,0,0,0,0,0,0
1077,you know you are meant to be a data science professional when,Misc,you know you are meant to be a data science professional when,"['you', 'know', 'you', 'are', 'meant', 'to', 'be', 'a', 'data', 'science', 'professional', 'when']",0,"['you', 'know', 'you', 'are', 'meant', 'to', 'be', 'a', 'data', 'science', 'professional', 'when']","['know', 'meant', 'data', 'science', 'professional']",know meant data science professional,0.1,0.1,12,36,2.769230769230769,0,0,0,0,0,0,0,0
1078,can someone explain the variable ‘attemptsrange’,Hackathons,can someone explain the variable ‘attemptsrange’,"['can', 'someone', 'explain', 'the', 'variable', '‘', 'attemptsrange', '’']",0,"['can', 'someone', 'explain', 'the', 'variable', '‘', 'attemptsrange', '’']","['someone', 'explain', 'variable', '‘', 'attemptsrange', '’']",someone explain variable ‘ attemptsrange ’,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
1079,error in installing an r library in ubuntu,Tools,error in installing an r library in ubuntu,"['error', 'in', 'installing', 'an', 'r', 'library', 'in', 'ubuntu']",0,"['error', 'in', 'installing', 'an', 'r', 'library', 'in', 'ubuntu']","['error', 'installing', 'r', 'library', 'ubuntu']",error installing r library ubuntu,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
1080,techniques to evaluate performance of individual,Techniques,techniques to evaluate performance of individual,"['techniques', 'to', 'evaluate', 'performance', 'of', 'individual']",0,"['technique', 'to', 'evaluate', 'performance', 'of', 'individual']","['technique', 'evaluate', 'performance', 'individual']",technique evaluate performance individual,0.0,0.0,6,41,5.857142857142857,0,0,0,0,0,0,0,0
1081,factorization machines  their application on huge datasets with codes in python,Techniques,factorization machines  their application on huge datasets with codes in python,"['factorization', 'machines', 'their', 'application', 'on', 'huge', 'datasets', 'with', 'codes', 'in', 'python']",0,"['factorization', 'machine', 'their', 'application', 'on', 'huge', 'datasets', 'with', 'code', 'in', 'python']","['factorization', 'machine', 'application', 'huge', 'datasets', 'code', 'python']",factorization machine application huge datasets code python,0.4000000000000001,0.4000000000000001,11,59,4.916666666666667,0,0,0,0,0,0,0,0
1082,checking if every present record between next records in python,Techniques,checking if every present record between next records in python,"['checking', 'if', 'every', 'present', 'record', 'between', 'next', 'records', 'in', 'python']",0,"['checking', 'if', 'every', 'present', 'record', 'between', 'next', 'record', 'in', 'python']","['checking', 'every', 'present', 'record', 'next', 'record', 'python']",checking every present record next record python,0.0,0.0,10,48,4.363636363636363,0,0,0,0,0,0,0,0
1083,text categorization,Techniques,text categorization,"['text', 'categorization']",0,"['text', 'categorization']","['text', 'categorization']",text categorization,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
1084,how to write code in r software,Tools,how to write code in r software,"['how', 'to', 'write', 'code', 'in', 'r', 'software']",0,"['how', 'to', 'write', 'code', 'in', 'r', 'software']","['write', 'code', 'r', 'software']",write code r software,0.0,0.0,7,21,2.625,0,0,0,0,0,0,0,0
1085,how to improve sensitivity,Techniques,how to improve sensitivity,"['how', 'to', 'improve', 'sensitivity']",0,"['how', 'to', 'improve', 'sensitivity']","['improve', 'sensitivity']",improve sensitivity,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
1086,standard deviation of the data,Techniques,standard deviation of the data,"['standard', 'deviation', 'of', 'the', 'data']",0,"['standard', 'deviation', 'of', 'the', 'data']","['standard', 'deviation', 'data']",standard deviation data,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
1087,hypothesis test problem,Techniques,hypothesis test problem,"['hypothesis', 'test', 'problem']",0,"['hypothesis', 'test', 'problem']","['hypothesis', 'test', 'problem']",hypothesis test problem,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
1088,using rbf kernel in svm with high gamma value what does this signify,Techniques,using rbf kernel in svm with high gamma value what does this signify,"['using', 'rbf', 'kernel', 'in', 'svm', 'with', 'high', 'gamma', 'value', 'what', 'does', 'this', 'signify']",0,"['using', 'rbf', 'kernel', 'in', 'svm', 'with', 'high', 'gamma', 'value', 'what', 'doe', 'this', 'signify']","['using', 'rbf', 'kernel', 'svm', 'high', 'gamma', 'value', 'doe', 'signify']",using rbf kernel svm high gamma value doe signify,0.16,0.16,13,49,3.5,0,0,0,0,0,0,0,0
1089,how to remove empty level form a vector in r,Tools,how to remove empty level form a vector in r,"['how', 'to', 'remove', 'empty', 'level', 'form', 'a', 'vector', 'in', 'r']",0,"['how', 'to', 'remove', 'empty', 'level', 'form', 'a', 'vector', 'in', 'r']","['remove', 'empty', 'level', 'form', 'vector', 'r']",remove empty level form vector r,-0.1,-0.1,10,32,2.909090909090909,0,0,0,0,0,0,0,0
1090,when should one apply pca and how to tune the number of components in pca,Techniques,when should one apply pca and how to tune the number of components in pca,"['when', 'should', 'one', 'apply', 'pca', 'and', 'how', 'to', 'tune', 'the', 'number', 'of', 'components', 'in', 'pca']",0,"['when', 'should', 'one', 'apply', 'pca', 'and', 'how', 'to', 'tune', 'the', 'number', 'of', 'component', 'in', 'pca']","['one', 'apply', 'pca', 'tune', 'number', 'component', 'pca']",one apply pca tune number component pca,0.0,0.0,15,39,2.4375,0,0,0,0,0,0,0,0
1091,what does a typical day  future options look as a data scientist or business analyst,Career,what does a typical day  future options look as a data scientist or business analyst,"['what', 'does', 'a', 'typical', 'day', 'future', 'options', 'look', 'as', 'a', 'data', 'scientist', 'or', 'business', 'analyst']",0,"['what', 'doe', 'a', 'typical', 'day', 'future', 'option', 'look', 'a', 'a', 'data', 'scientist', 'or', 'business', 'analyst']","['doe', 'typical', 'day', 'future', 'option', 'look', 'data', 'scientist', 'business', 'analyst']",doe typical day future option look data scientist business analyst,-0.0833333333333333,-0.0833333333333333,15,66,4.125,0,0,0,0,0,0,0,0
1092,invalid headers header should be useridproductid and purchase,Hackathons,invalid headers header should be useridproductid and purchase,"['invalid', 'headers', 'header', 'should', 'be', 'useridproductid', 'and', 'purchase']",0,"['invalid', 'header', 'header', 'should', 'be', 'useridproductid', 'and', 'purchase']","['invalid', 'header', 'header', 'useridproductid', 'purchase']",invalid header header useridproductid purchase,0.0,0.0,8,46,5.111111111111111,0,0,0,0,0,0,0,0
1093,facing error in creating submission file,Techniques,facing error in creating submission file,"['facing', 'error', 'in', 'creating', 'submission', 'file']",0,"['facing', 'error', 'in', 'creating', 'submission', 'file']","['facing', 'error', 'creating', 'submission', 'file']",facing error creating submission file,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
1094,is there any limits for independent variables count wrto observations count,Techniques,is there any limits for independent variables count wrto observations count,"['is', 'there', 'any', 'limits', 'for', 'independent', 'variables', 'count', 'wrto', 'observations', 'count']",0,"['is', 'there', 'any', 'limit', 'for', 'independent', 'variable', 'count', 'wrto', 'observation', 'count']","['limit', 'independent', 'variable', 'count', 'wrto', 'observation', 'count']",limit independent variable count wrto observation count,0.0,0.0,11,55,4.583333333333333,0,0,0,0,0,0,0,0
1095,obtaining the optimal tuning parameter value for ridge regression,Techniques,obtaining the optimal tuning parameter value for ridge regression,"['obtaining', 'the', 'optimal', 'tuning', 'parameter', 'value', 'for', 'ridge', 'regression']",0,"['obtaining', 'the', 'optimal', 'tuning', 'parameter', 'value', 'for', 'ridge', 'regression']","['obtaining', 'optimal', 'tuning', 'parameter', 'value', 'ridge', 'regression']",obtaining optimal tuning parameter value ridge regression,0.0,0.0,9,57,5.7,0,0,0,0,0,0,0,0
1096,python basic practice questions,Resources,python basic practice questions,"['python', 'basic', 'practice', 'questions']",0,"['python', 'basic', 'practice', 'question']","['python', 'basic', 'practice', 'question']",python basic practice question,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
1097,xgboost prediction scores,Techniques,xgboost prediction scores,"['xgboost', 'prediction', 'scores']",0,"['xgboost', 'prediction', 'score']","['xgboost', 'prediction', 'score']",xgboost prediction score,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
1098,how to rotate digit images in r,Tools,how to rotate digit images in r,"['how', 'to', 'rotate', 'digit', 'images', 'in', 'r']",0,"['how', 'to', 'rotate', 'digit', 'image', 'in', 'r']","['rotate', 'digit', 'image', 'r']",rotate digit image r,0.0,0.0,7,20,2.5,0,0,0,0,0,0,0,0
1099,a complete tutorial which teaches data exploration in detail,Techniques,a complete tutorial which teaches data exploration in detail,"['a', 'complete', 'tutorial', 'which', 'teaches', 'data', 'exploration', 'in', 'detail']",0,"['a', 'complete', 'tutorial', 'which', 'teach', 'data', 'exploration', 'in', 'detail']","['complete', 'tutorial', 'teach', 'data', 'exploration', 'detail']",complete tutorial teach data exploration detail,0.1,0.1,9,47,4.7,0,0,0,0,0,0,0,0
1100,stanford nlp  stanford nlp python  stanford nlp tutorial,Tools,stanford nlp  stanford nlp python  stanford nlp tutorial,"['stanford', 'nlp', 'stanford', 'nlp', 'python', 'stanford', 'nlp', 'tutorial']",0,"['stanford', 'nlp', 'stanford', 'nlp', 'python', 'stanford', 'nlp', 'tutorial']","['stanford', 'nlp', 'stanford', 'nlp', 'python', 'stanford', 'nlp', 'tutorial']",stanford nlp stanford nlp python stanford nlp tutorial,0.0,0.0,8,54,6.0,0,0,0,0,0,0,0,0
1101,scope of big data and hadoop,Techniques,scope of big data and hadoop,"['scope', 'of', 'big', 'data', 'and', 'hadoop']",0,"['scope', 'of', 'big', 'data', 'and', 'hadoop']","['scope', 'big', 'data', 'hadoop']",scope big data hadoop,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
1102,markov chain attribution model,Techniques,markov chain attribution model,"['markov', 'chain', 'attribution', 'model']",0,"['markov', 'chain', 'attribution', 'model']","['markov', 'chain', 'attribution', 'model']",markov chain attribution model,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
1103,looking for a team to learn data science together,Career,looking for a team to learn data science together,"['looking', 'for', 'a', 'team', 'to', 'learn', 'data', 'science', 'together']",0,"['looking', 'for', 'a', 'team', 'to', 'learn', 'data', 'science', 'together']","['looking', 'team', 'learn', 'data', 'science', 'together']",looking team learn data science together,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
1104,submitting work return keys loanstatus loanid error,Hackathons,submitting work return keys loanstatus loanid error,"['submitting', 'work', 'return', 'keys', 'loanstatus', 'loanid', 'error']",0,"['submitting', 'work', 'return', 'key', 'loanstatus', 'loanid', 'error']","['submitting', 'work', 'return', 'key', 'loanstatus', 'loanid', 'error']",submitting work return key loanstatus loanid error,0.0,0.0,7,50,6.25,0,0,0,0,0,0,0,0
1105,chatbots building different faqs for different users,Techniques,chatbots building different faqs for different users,"['chatbots', 'building', 'different', 'faqs', 'for', 'different', 'users']",0,"['chatbots', 'building', 'different', 'faq', 'for', 'different', 'user']","['chatbots', 'building', 'different', 'faq', 'different', 'user']",chatbots building different faq different user,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
1106,deprecationwarning,Techniques,deprecationwarning,['deprecationwarning'],0,['deprecationwarning'],['deprecationwarning'],deprecationwarning,0.0,0.0,1,18,9.0,0,0,0,0,0,0,0,0
1107,data projection to national level,Techniques,data projection to national level,"['data', 'projection', 'to', 'national', 'level']",0,"['data', 'projection', 'to', 'national', 'level']","['data', 'projection', 'national', 'level']",data projection national level,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
1108,facing problem in access the workshop,Hackathons,facing problem in access the workshop,"['facing', 'problem', 'in', 'access', 'the', 'workshop']",0,"['facing', 'problem', 'in', 'access', 'the', 'workshop']","['facing', 'problem', 'access', 'workshop']",facing problem access workshop,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
1109,rfm with random forest,Techniques,rfm with random forest,"['rfm', 'with', 'random', 'forest']",0,"['rfm', 'with', 'random', 'forest']","['rfm', 'random', 'forest']",rfm random forest,-0.5,-0.5,4,17,3.4,0,0,0,0,0,0,0,0
1110,what is pdv in sas,Tools,what is pdv in sas,"['what', 'is', 'pdv', 'in', 'sas']",0,"['what', 'is', 'pdv', 'in', 'sa']","['pdv', 'sa']",pdv sa,0.0,0.0,5,6,1.0,0,0,0,0,0,0,0,0
1111,top  management reporting best practices ,Resources,top  management reporting best practices ,"['top', 'management', 'reporting', 'best', 'practices']",2,"['top', 'management', 'reporting', 'best', 'practice']","['top', 'management', 'reporting', 'best', 'practice']",top management reporting best practice,0.75,0.75,5,38,6.333333333333333,0,0,0,0,0,0,0,0
1112,how to use modelpredict in keras for nlp multilabel text classification,Techniques,how to use modelpredict in keras for nlp multilabel text classification,"['how', 'to', 'use', 'modelpredict', 'in', 'keras', 'for', 'nlp', 'multilabel', 'text', 'classification']",0,"['how', 'to', 'use', 'modelpredict', 'in', 'kera', 'for', 'nlp', 'multilabel', 'text', 'classification']","['use', 'modelpredict', 'kera', 'nlp', 'multilabel', 'text', 'classification']",use modelpredict kera nlp multilabel text classification,0.0,0.0,11,56,4.666666666666667,0,0,0,0,0,0,0,0
1113,pursue data science course full time in india,Career,pursue data science course full time in india,"['pursue', 'data', 'science', 'course', 'full', 'time', 'in', 'india']",0,"['pursue', 'data', 'science', 'course', 'full', 'time', 'in', 'india']","['pursue', 'data', 'science', 'course', 'full', 'time', 'india']",pursue data science course full time india,0.35,0.35,8,42,4.666666666666667,0,0,0,0,0,0,0,0
1114, realworld cases of business intelligence,Resources, realworld cases of business intelligence,"['realworld', 'cases', 'of', 'business', 'intelligence']",1,"['realworld', 'case', 'of', 'business', 'intelligence']","['realworld', 'case', 'business', 'intelligence']",realworld case business intelligence,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
1115,plot in r for showing two columns in a data set on x axis using single line graph,Tools,plot in r for showing two columns in a data set on x axis using single line graph,"['plot', 'in', 'r', 'for', 'showing', 'two', 'columns', 'in', 'a', 'data', 'set', 'on', 'x', 'axis', 'using', 'single', 'line', 'graph']",0,"['plot', 'in', 'r', 'for', 'showing', 'two', 'column', 'in', 'a', 'data', 'set', 'on', 'x', 'axis', 'using', 'single', 'line', 'graph']","['plot', 'r', 'showing', 'two', 'column', 'data', 'set', 'x', 'axis', 'using', 'single', 'line', 'graph']",plot r showing two column data set x axis using single line graph,-0.0714285714285714,-0.0714285714285714,18,65,3.4210526315789473,0,0,0,0,0,0,0,0
1116,error in accessing twitter api in r,Tools,error in accessing twitter api in r,"['error', 'in', 'accessing', 'twitter', 'api', 'in', 'r']",0,"['error', 'in', 'accessing', 'twitter', 'api', 'in', 'r']","['error', 'accessing', 'twitter', 'api', 'r']",error accessing twitter api r,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
1117,fetching user data from linkedin,Tools,fetching user data from linkedin,"['fetching', 'user', 'data', 'from', 'linkedin']",0,"['fetching', 'user', 'data', 'from', 'linkedin']","['fetching', 'user', 'data', 'linkedin']",fetching user data linkedin,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
1118,help required  need people with experience in text mining for an interview,Misc,help required  need people with experience in text mining for an interview,"['help', 'required', 'need', 'people', 'with', 'experience', 'in', 'text', 'mining', 'for', 'an', 'interview']",0,"['help', 'required', 'need', 'people', 'with', 'experience', 'in', 'text', 'mining', 'for', 'an', 'interview']","['help', 'required', 'need', 'people', 'experience', 'text', 'mining', 'interview']",help required need people experience text mining interview,0.0,0.0,12,58,4.461538461538462,0,0,0,0,0,0,0,0
1119,re methodology on fuzzy logic in sas,Techniques,re methodology on fuzzy logic in sas,"['re', 'methodology', 'on', 'fuzzy', 'logic', 'in', 'sas']",0,"['re', 'methodology', 'on', 'fuzzy', 'logic', 'in', 'sa']","['methodology', 'fuzzy', 'logic', 'sa']",methodology fuzzy logic sa,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
1120,how to start career in analytics,Career,how to start career in analytics,"['how', 'to', 'start', 'career', 'in', 'analytics']",0,"['how', 'to', 'start', 'career', 'in', 'analytics']","['start', 'career', 'analytics']",start career analytics,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
1121,logistic regression results counterintuitive,Techniques,logistic regression results counterintuitive,"['logistic', 'regression', 'results', 'counterintuitive']",0,"['logistic', 'regression', 'result', 'counterintuitive']","['logistic', 'regression', 'result', 'counterintuitive']",logistic regression result counterintuitive,0.0,0.0,4,43,8.6,0,0,0,0,0,0,0,0
1122,extracting number of comments,Techniques,extracting number of comments,"['extracting', 'number', 'of', 'comments']",0,"['extracting', 'number', 'of', 'comment']","['extracting', 'number', 'comment']",extracting number comment,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
1123,how to display variable and change datatype from uploaded file in shiny,Tools,how to display variable and change datatype from uploaded file in shiny,"['how', 'to', 'display', 'variable', 'and', 'change', 'datatype', 'from', 'uploaded', 'file', 'in', 'shiny']",0,"['how', 'to', 'display', 'variable', 'and', 'change', 'datatype', 'from', 'uploaded', 'file', 'in', 'shiny']","['display', 'variable', 'change', 'datatype', 'uploaded', 'file', 'shiny']",display variable change datatype uploaded file shiny,0.0,0.0,12,52,4.0,0,0,0,0,0,0,0,0
1124,what should be value of gamma in svm,Techniques,what should be value of gamma in svm,"['what', 'should', 'be', 'value', 'of', 'gamma', 'in', 'svm']",0,"['what', 'should', 'be', 'value', 'of', 'gamma', 'in', 'svm']","['value', 'gamma', 'svm']",value gamma svm,0.0,0.0,8,15,1.6666666666666667,0,0,0,0,0,0,0,0
1125,interview questions,Career,interview questions,"['interview', 'questions']",0,"['interview', 'question']","['interview', 'question']",interview question,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
1126,movie genre prediction using multi label classification,Other,movie genre prediction using multi label classification,"['movie', 'genre', 'prediction', 'using', 'multi', 'label', 'classification']",0,"['movie', 'genre', 'prediction', 'using', 'multi', 'label', 'classification']","['movie', 'genre', 'prediction', 'using', 'multi', 'label', 'classification']",movie genre prediction using multi label classification,0.0,0.0,7,55,6.875,0,0,0,0,0,0,0,0
1127,labelencoder error,Hackathons,labelencoder error,"['labelencoder', 'error']",0,"['labelencoder', 'error']","['labelencoder', 'error']",labelencoder error,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
1128,unable to read data using readcsvsql in r,Tools,unable to read data using readcsvsql in r,"['unable', 'to', 'read', 'data', 'using', 'readcsvsql', 'in', 'r']",0,"['unable', 'to', 'read', 'data', 'using', 'readcsvsql', 'in', 'r']","['unable', 'read', 'data', 'using', 'readcsvsql', 'r']",unable read data using readcsvsql r,-0.5,-0.5,8,35,3.888888888888889,0,0,0,0,0,0,0,0
1129,gaining experience in analytics,Career,gaining experience in analytics,"['gaining', 'experience', 'in', 'analytics']",0,"['gaining', 'experience', 'in', 'analytics']","['gaining', 'experience', 'analytics']",gaining experience analytics,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
1130,influential factors in persistency model for life insurance,Other,influential factors in persistency model for life insurance,"['influential', 'factors', 'in', 'persistency', 'model', 'for', 'life', 'insurance']",0,"['influential', 'factor', 'in', 'persistency', 'model', 'for', 'life', 'insurance']","['influential', 'factor', 'persistency', 'model', 'life', 'insurance']",influential factor persistency model life insurance,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
1131,can i start my data science journey with python,Tools,can i start my data science journey with python,"['can', 'i', 'start', 'my', 'data', 'science', 'journey', 'with', 'python']",0,"['can', 'i', 'start', 'my', 'data', 'science', 'journey', 'with', 'python']","['start', 'data', 'science', 'journey', 'python']",start data science journey python,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
1132,what is the function of k in knn,Techniques,what is the function of k in knn,"['what', 'is', 'the', 'function', 'of', 'k', 'in', 'knn']",0,"['what', 'is', 'the', 'function', 'of', 'k', 'in', 'knn']","['function', 'k', 'knn']",function k knn,0.0,0.0,8,14,1.5555555555555556,0,0,0,0,0,0,0,0
1133,class imbalance,Techniques,class imbalance,"['class', 'imbalance']",0,"['class', 'imbalance']","['class', 'imbalance']",class imbalance,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
1134,big data image processing,Techniques,big data image processing,"['big', 'data', 'image', 'processing']",0,"['big', 'data', 'image', 'processing']","['big', 'data', 'image', 'processing']",big data image processing,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
1135,no of trees in random forest and time taken to execute the algorithm,Techniques,no of trees in random forest and time taken to execute the algorithm,"['no', 'of', 'trees', 'in', 'random', 'forest', 'and', 'time', 'taken', 'to', 'execute', 'the', 'algorithm']",0,"['no', 'of', 'tree', 'in', 'random', 'forest', 'and', 'time', 'taken', 'to', 'execute', 'the', 'algorithm']","['tree', 'random', 'forest', 'time', 'taken', 'execute', 'algorithm']",tree random forest time taken execute algorithm,-0.5,-0.5,13,47,3.357142857142857,0,0,0,0,0,0,0,0
1136,what is the difference between pearson and polychoric correlation,Techniques,what is the difference between pearson and polychoric correlation,"['what', 'is', 'the', 'difference', 'between', 'pearson', 'and', 'polychoric', 'correlation']",0,"['what', 'is', 'the', 'difference', 'between', 'pearson', 'and', 'polychoric', 'correlation']","['difference', 'pearson', 'polychoric', 'correlation']",difference pearson polychoric correlation,0.0,0.0,9,41,4.1,0,0,0,0,0,0,0,0
1137,how to do the panel data regression in r or python,Techniques,how to do the panel data regression in r or python,"['how', 'to', 'do', 'the', 'panel', 'data', 'regression', 'in', 'r', 'or', 'python']",0,"['how', 'to', 'do', 'the', 'panel', 'data', 'regression', 'in', 'r', 'or', 'python']","['panel', 'data', 'regression', 'r', 'python']",panel data regression r python,0.0,0.0,11,30,2.5,0,0,0,0,0,0,0,0
1138,laptophardware suggestions for deep learning,Misc,laptophardware suggestions for deep learning,"['laptophardware', 'suggestions', 'for', 'deep', 'learning']",0,"['laptophardware', 'suggestion', 'for', 'deep', 'learning']","['laptophardware', 'suggestion', 'deep', 'learning']",laptophardware suggestion deep learning,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
1139,data science in finance,Resources,data science in finance,"['data', 'science', 'in', 'finance']",0,"['data', 'science', 'in', 'finance']","['data', 'science', 'finance']",data science finance,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
1140,time series whitenoise,Techniques,time series whitenoise,"['time', 'series', 'whitenoise']",0,"['time', 'series', 'whitenoise']","['time', 'series', 'whitenoise']",time series whitenoise,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
1141, useful pandas techniques in python for data manipulation error in filling missing values,Techniques, useful pandas techniques in python for data manipulation error in filling missing values,"['useful', 'pandas', 'techniques', 'in', 'python', 'for', 'data', 'manipulation', 'error', 'in', 'filling', 'missing', 'values']",1,"['useful', 'panda', 'technique', 'in', 'python', 'for', 'data', 'manipulation', 'error', 'in', 'filling', 'missing', 'value']","['useful', 'panda', 'technique', 'python', 'data', 'manipulation', 'error', 'filling', 'missing', 'value']",useful panda technique python data manipulation error filling missing value,0.0499999999999999,0.0499999999999999,13,75,5.357142857142857,0,0,0,0,0,0,0,0
1142,how to resolvepython error cannot compare a dtyped float array with a scalar of type bool,Tools,how to resolvepython error cannot compare a dtyped float array with a scalar of type bool,"['how', 'to', 'resolvepython', 'error', 'can', 'not', 'compare', 'a', 'dtyped', 'float', 'array', 'with', 'a', 'scalar', 'of', 'type', 'bool']",0,"['how', 'to', 'resolvepython', 'error', 'can', 'not', 'compare', 'a', 'dtyped', 'float', 'array', 'with', 'a', 'scalar', 'of', 'type', 'bool']","['resolvepython', 'error', 'compare', 'dtyped', 'float', 'array', 'scalar', 'type', 'bool']",resolvepython error compare dtyped float array scalar type bool,0.0,0.0,17,63,3.5,0,0,0,0,0,0,0,0
1143,is this a classification problem given the sample data below,Techniques,is this a classification problem given the sample data below,"['is', 'this', 'a', 'classification', 'problem', 'given', 'the', 'sample', 'data', 'below']",0,"['is', 'this', 'a', 'classification', 'problem', 'given', 'the', 'sample', 'data', 'below']","['classification', 'problem', 'given', 'sample', 'data']",classification problem given sample data,0.0,0.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
1144,what is a kernel in a support vector machine algorithm,Techniques,what is a kernel in a support vector machine algorithm,"['what', 'is', 'a', 'kernel', 'in', 'a', 'support', 'vector', 'machine', 'algorithm']",0,"['what', 'is', 'a', 'kernel', 'in', 'a', 'support', 'vector', 'machine', 'algorithm']","['kernel', 'support', 'vector', 'machine', 'algorithm']",kernel support vector machine algorithm,0.0,0.0,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
1145,not able to install python scikit learn library in ubuntu ,Tools,not able to install python scikit learn library in ubuntu ,"['not', 'able', 'to', 'install', 'python', 'scikit', 'learn', 'library', 'in', 'ubuntu']",1,"['not', 'able', 'to', 'install', 'python', 'scikit', 'learn', 'library', 'in', 'ubuntu']","['able', 'install', 'python', 'scikit', 'learn', 'library', 'ubuntu']",able install python scikit learn library ubuntu,-0.25,0.5,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
1146,python  download a  gb of datasetdatadump from oracle server to my local disk drive using python,Tools,python  download a  gb of datasetdatadump from oracle server to my local disk drive using python,"['python', 'download', 'a', 'gb', 'of', 'datasetdatadump', 'from', 'oracle', 'server', 'to', 'my', 'local', 'disk', 'drive', 'using', 'python']",1,"['python', 'download', 'a', 'gb', 'of', 'datasetdatadump', 'from', 'oracle', 'server', 'to', 'my', 'local', 'disk', 'drive', 'using', 'python']","['python', 'download', 'gb', 'datasetdatadump', 'oracle', 'server', 'local', 'disk', 'drive', 'using', 'python']",python download gb datasetdatadump oracle server local disk drive using python,0.0,0.0,16,78,4.588235294117647,0,0,0,0,0,0,0,0
1147,anaconda error importing exponentialsmoothing,Tools,anaconda error importing exponentialsmoothing,"['anaconda', 'error', 'importing', 'exponentialsmoothing']",0,"['anaconda', 'error', 'importing', 'exponentialsmoothing']","['anaconda', 'error', 'importing', 'exponentialsmoothing']",anaconda error importing exponentialsmoothing,0.0,0.0,4,45,9.0,0,0,0,0,0,0,0,0
1148,what are ensemble methods,Techniques,what are ensemble methods,"['what', 'are', 'ensemble', 'methods']",0,"['what', 'are', 'ensemble', 'method']","['ensemble', 'method']",ensemble method,0.0,0.0,4,15,3.0,0,0,0,0,0,0,0,0
1149,practice problem  time series,Techniques,practice problem  time series,"['practice', 'problem', 'time', 'series']",0,"['practice', 'problem', 'time', 'series']","['practice', 'problem', 'time', 'series']",practice problem time series,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
1150,why does feature created in a temp dataframe get created in original dataframe as well,Techniques,why does feature created in a temp dataframe get created in original dataframe as well,"['why', 'does', 'feature', 'created', 'in', 'a', 'temp', 'dataframe', 'get', 'created', 'in', 'original', 'dataframe', 'as', 'well']",0,"['why', 'doe', 'feature', 'created', 'in', 'a', 'temp', 'dataframe', 'get', 'created', 'in', 'original', 'dataframe', 'a', 'well']","['doe', 'feature', 'created', 'temp', 'dataframe', 'get', 'created', 'original', 'dataframe', 'well']",doe feature created temp dataframe get created original dataframe well,0.375,0.375,15,70,4.375,0,0,0,0,0,0,0,0
1151,error  length of dimnames  not equal to array extent,Techniques,error  length of dimnames  not equal to array extent,"['error', 'length', 'of', 'dimnames', 'not', 'equal', 'to', 'array', 'extent']",1,"['error', 'length', 'of', 'dimnames', 'not', 'equal', 'to', 'array', 'extent']","['error', 'length', 'dimnames', 'equal', 'array', 'extent']",error length dimnames equal array extent,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
1152,error could not find function “samplesplit”,Techniques,error could not find function “samplesplit”,"['error', 'could', 'not', 'find', 'function', '“', 'samplesplit', '”']",0,"['error', 'could', 'not', 'find', 'function', '“', 'samplesplit', '”']","['error', 'could', 'find', 'function', '“', 'samplesplit', '”']",error could find function “ samplesplit ”,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
1153,distinction between the approach of self learning and college work,Career,distinction between the approach of self learning and college work,"['distinction', 'between', 'the', 'approach', 'of', 'self', 'learning', 'and', 'college', 'work']",0,"['distinction', 'between', 'the', 'approach', 'of', 'self', 'learning', 'and', 'college', 'work']","['distinction', 'approach', 'self', 'learning', 'college', 'work']",distinction approach self learning college work,0.0,0.0,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
1154,where to start withto be a data scientist,Career,where to start withto be a data scientist,"['where', 'to', 'start', 'withto', 'be', 'a', 'data', 'scientist']",0,"['where', 'to', 'start', 'withto', 'be', 'a', 'data', 'scientist']","['start', 'withto', 'data', 'scientist']",start withto data scientist,0.0,0.0,8,27,3.0,0,0,0,0,0,0,0,0
1155,how to start data analysis in python,Tools,how to start data analysis in python,"['how', 'to', 'start', 'data', 'analysis', 'in', 'python']",0,"['how', 'to', 'start', 'data', 'analysis', 'in', 'python']","['start', 'data', 'analysis', 'python']",start data analysis python,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
1156,road map for learning image analytics,Resources,road map for learning image analytics,"['road', 'map', 'for', 'learning', 'image', 'analytics']",0,"['road', 'map', 'for', 'learning', 'image', 'analytics']","['road', 'map', 'learning', 'image', 'analytics']",road map learning image analytics,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
1157,how to predict average wait time in a queue at petrol stations,Techniques,how to predict average wait time in a queue at petrol stations,"['how', 'to', 'predict', 'average', 'wait', 'time', 'in', 'a', 'queue', 'at', 'petrol', 'stations']",0,"['how', 'to', 'predict', 'average', 'wait', 'time', 'in', 'a', 'queue', 'at', 'petrol', 'station']","['predict', 'average', 'wait', 'time', 'queue', 'petrol', 'station']",predict average wait time queue petrol station,-0.15,-0.15,12,46,3.5384615384615383,0,0,0,0,0,0,0,0
1158,how do i create a survival object with the surv in r,Techniques,how do i create a survival object with the surv in r,"['how', 'do', 'i', 'create', 'a', 'survival', 'object', 'with', 'the', 'surv', 'in', 'r']",0,"['how', 'do', 'i', 'create', 'a', 'survival', 'object', 'with', 'the', 'surv', 'in', 'r']","['create', 'survival', 'object', 'surv', 'r']",create survival object surv r,0.0,0.0,12,29,2.230769230769231,0,0,0,0,0,0,0,0
1159,how to interpret the result of concatenation using numpy library in python,Techniques,how to interpret the result of concatenation using numpy library in python,"['how', 'to', 'interpret', 'the', 'result', 'of', 'concatenation', 'using', 'numpy', 'library', 'in', 'python']",0,"['how', 'to', 'interpret', 'the', 'result', 'of', 'concatenation', 'using', 'numpy', 'library', 'in', 'python']","['interpret', 'result', 'concatenation', 'using', 'numpy', 'library', 'python']",interpret result concatenation using numpy library python,0.0,0.0,12,57,4.384615384615385,0,0,0,0,0,0,0,0
1160,datascience career,Career,datascience career,"['datascience', 'career']",0,"['datascience', 'career']","['datascience', 'career']",datascience career,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
1161,examples of r visualizations powered by ga data,Techniques,examples of r visualizations powered by ga data,"['examples', 'of', 'r', 'visualizations', 'powered', 'by', 'ga', 'data']",0,"['example', 'of', 'r', 'visualization', 'powered', 'by', 'ga', 'data']","['example', 'r', 'visualization', 'powered', 'ga', 'data']",example r visualization powered ga data,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
1162,meaning about idioms in data science,Misc,meaning about idioms in data science,"['meaning', 'about', 'idioms', 'in', 'data', 'science']",0,"['meaning', 'about', 'idiom', 'in', 'data', 'science']","['meaning', 'idiom', 'data', 'science']",meaning idiom data science,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
1163,machine learning predictions,Techniques,machine learning predictions,"['machine', 'learning', 'predictions']",0,"['machine', 'learning', 'prediction']","['machine', 'learning', 'prediction']",machine learning prediction,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
1164,why is logistic regression required why not linear regression,Techniques,why is logistic regression required why not linear regression,"['why', 'is', 'logistic', 'regression', 'required', 'why', 'not', 'linear', 'regression']",0,"['why', 'is', 'logistic', 'regression', 'required', 'why', 'not', 'linear', 'regression']","['logistic', 'regression', 'required', 'linear', 'regression']",logistic regression required linear regression,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
1165,increase accuracy of predicting true negatives minority class,Techniques,increase accuracy of predicting true negatives minority class,"['increase', 'accuracy', 'of', 'predicting', 'true', 'negatives', 'minority', 'class']",0,"['increase', 'accuracy', 'of', 'predicting', 'true', 'negative', 'minority', 'class']","['increase', 'accuracy', 'predicting', 'true', 'negative', 'minority', 'class']",increase accuracy predicting true negative minority class,0.35,0.0249999999999999,8,57,6.333333333333333,0,0,0,0,0,0,0,0
1166,tfidf on sklearn library is giving me a huge file and memory error,Techniques,tfidf on sklearn library is giving me a huge file and memory error,"['tfidf', 'on', 'sklearn', 'library', 'is', 'giving', 'me', 'a', 'huge', 'file', 'and', 'memory', 'error']",0,"['tfidf', 'on', 'sklearn', 'library', 'is', 'giving', 'me', 'a', 'huge', 'file', 'and', 'memory', 'error']","['tfidf', 'sklearn', 'library', 'giving', 'huge', 'file', 'memory', 'error']",tfidf sklearn library giving huge file memory error,0.4000000000000001,0.4000000000000001,13,51,3.642857142857143,0,0,0,0,0,0,0,0
1167,a large meaningful tree of knowledge  mind mapping,Techniques,a large meaningful tree of knowledge  mind mapping,"['a', 'large', 'meaningful', 'tree', 'of', 'knowledge', 'mind', 'mapping']",0,"['a', 'large', 'meaningful', 'tree', 'of', 'knowledge', 'mind', 'mapping']","['large', 'meaningful', 'tree', 'knowledge', 'mind', 'mapping']",large meaningful tree knowledge mind mapping,0.3571428571428571,0.3571428571428571,8,44,4.888888888888889,0,0,0,0,0,0,0,0
1168,hardware configuration for running deep learning,Tools,hardware configuration for running deep learning,"['hardware', 'configuration', 'for', 'running', 'deep', 'learning']",0,"['hardware', 'configuration', 'for', 'running', 'deep', 'learning']","['hardware', 'configuration', 'running', 'deep', 'learning']",hardware configuration running deep learning,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
1169,what does the option naonaomit mean in factor analysis in r,Tools,what does the option naonaomit mean in factor analysis in r,"['what', 'does', 'the', 'option', 'naonaomit', 'mean', 'in', 'factor', 'analysis', 'in', 'r']",0,"['what', 'doe', 'the', 'option', 'naonaomit', 'mean', 'in', 'factor', 'analysis', 'in', 'r']","['doe', 'option', 'naonaomit', 'mean', 'factor', 'analysis', 'r']",doe option naonaomit mean factor analysis r,-0.3125,-0.3125,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
1170,how to resolve different levels in confusion matrix in r,Techniques,how to resolve different levels in confusion matrix in r,"['how', 'to', 'resolve', 'different', 'levels', 'in', 'confusion', 'matrix', 'in', 'r']",0,"['how', 'to', 'resolve', 'different', 'level', 'in', 'confusion', 'matrix', 'in', 'r']","['resolve', 'different', 'level', 'confusion', 'matrix', 'r']",resolve different level confusion matrix r,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
1171,how to parse nested json using pyspark,Techniques,how to parse nested json using pyspark,"['how', 'to', 'parse', 'nested', 'json', 'using', 'pyspark']",0,"['how', 'to', 'parse', 'nested', 'json', 'using', 'pyspark']","['parse', 'nested', 'json', 'using', 'pyspark']",parse nested json using pyspark,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
1172,explore ml ops with ml works  trail launch  feedback required,Tools,explore ml ops with ml works  trail launch  feedback required,"['explore', 'ml', 'ops', 'with', 'ml', 'works', 'trail', 'launch', 'feedback', 'required']",0,"['explore', 'ml', 'ops', 'with', 'ml', 'work', 'trail', 'launch', 'feedback', 'required']","['explore', 'ml', 'ops', 'ml', 'work', 'trail', 'launch', 'feedback', 'required']",explore ml ops ml work trail launch feedback required,0.0,0.0,10,53,4.818181818181818,0,0,0,0,0,0,0,0
1173,detect a word a commondictionary word in r,Techniques,detect a word a commondictionary word in r,"['detect', 'a', 'word', 'a', 'commondictionary', 'word', 'in', 'r']",0,"['detect', 'a', 'word', 'a', 'commondictionary', 'word', 'in', 'r']","['detect', 'word', 'commondictionary', 'word', 'r']",detect word commondictionary word r,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
1174,how to resolve error on installing package car,Tools,how to resolve error on installing package car,"['how', 'to', 'resolve', 'error', 'on', 'installing', 'package', 'car']",0,"['how', 'to', 'resolve', 'error', 'on', 'installing', 'package', 'car']","['resolve', 'error', 'installing', 'package', 'car']",resolve error installing package car,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
1175,why and when is hypothesis generation important,Techniques,why and when is hypothesis generation important,"['why', 'and', 'when', 'is', 'hypothesis', 'generation', 'important']",0,"['why', 'and', 'when', 'is', 'hypothesis', 'generation', 'important']","['hypothesis', 'generation', 'important']",hypothesis generation important,0.4,0.4,7,31,3.875,0,0,0,0,0,0,0,0
1176,apply log to linear regression,Techniques,apply log to linear regression,"['apply', 'log', 'to', 'linear', 'regression']",0,"['apply', 'log', 'to', 'linear', 'regression']","['apply', 'log', 'linear', 'regression']",apply log linear regression,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
1177,model deployment to web service,Techniques,model deployment to web service,"['model', 'deployment', 'to', 'web', 'service']",0,"['model', 'deployment', 'to', 'web', 'service']","['model', 'deployment', 'web', 'service']",model deployment web service,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
1178,techniques to collapse the categorical variables in r,Techniques,techniques to collapse the categorical variables in r,"['techniques', 'to', 'collapse', 'the', 'categorical', 'variables', 'in', 'r']",0,"['technique', 'to', 'collapse', 'the', 'categorical', 'variable', 'in', 'r']","['technique', 'collapse', 'categorical', 'variable', 'r']",technique collapse categorical variable r,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
1179,where can i find some free telecom data,Resources,where can i find some free telecom data,"['where', 'can', 'i', 'find', 'some', 'free', 'telecom', 'data']",0,"['where', 'can', 'i', 'find', 'some', 'free', 'telecom', 'data']","['find', 'free', 'telecom', 'data']",find free telecom data,0.4,0.4,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
1180,dataset used in article building trust in ml models through lime,Techniques,dataset used in article building trust in ml models through lime,"['dataset', 'used', 'in', 'article', 'building', 'trust', 'in', 'ml', 'models', 'through', 'lime']",0,"['dataset', 'used', 'in', 'article', 'building', 'trust', 'in', 'ml', 'model', 'through', 'lime']","['dataset', 'used', 'article', 'building', 'trust', 'ml', 'model', 'lime']",dataset used article building trust ml model lime,0.0,0.0,11,49,4.083333333333333,0,0,0,0,0,0,0,0
1181,how to test your prediction for insurance company dataset,Techniques,how to test your prediction for insurance company dataset,"['how', 'to', 'test', 'your', 'prediction', 'for', 'insurance', 'company', 'dataset']",0,"['how', 'to', 'test', 'your', 'prediction', 'for', 'insurance', 'company', 'dataset']","['test', 'prediction', 'insurance', 'company', 'dataset']",test prediction insurance company dataset,0.0,0.0,9,41,4.1,0,0,0,0,0,0,0,0
1182,what is weakly supervised learningcan anyone help me with example,Techniques,what is weakly supervised learningcan anyone help me with example,"['what', 'is', 'weakly', 'supervised', 'learningcan', 'anyone', 'help', 'me', 'with', 'example']",0,"['what', 'is', 'weakly', 'supervised', 'learningcan', 'anyone', 'help', 'me', 'with', 'example']","['weakly', 'supervised', 'learningcan', 'anyone', 'help', 'example']",weakly supervised learningcan anyone help example,-0.375,-0.375,10,49,4.454545454545454,0,0,0,0,0,0,0,0
1183,i am willing to start my career in data scientist as a fresher,Career,i am willing to start my career in data scientist as a fresher,"['i', 'am', 'willing', 'to', 'start', 'my', 'career', 'in', 'data', 'scientist', 'as', 'a', 'fresher']",0,"['i', 'am', 'willing', 'to', 'start', 'my', 'career', 'in', 'data', 'scientist', 'a', 'a', 'fresher']","['willing', 'start', 'career', 'data', 'scientist', 'fresher']",willing start career data scientist fresher,0.25,0.25,13,43,3.0714285714285716,0,0,0,0,0,0,0,0
1184,when does correlation imply causation,Techniques,when does correlation imply causation,"['when', 'does', 'correlation', 'imply', 'causation']",0,"['when', 'doe', 'correlation', 'imply', 'causation']","['doe', 'correlation', 'imply', 'causation']",doe correlation imply causation,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1185,fine tuned code,Hackathons,fine tuned code,"['fine', 'tuned', 'code']",0,"['fine', 'tuned', 'code']","['fine', 'tuned', 'code']",fine tuned code,0.4166666666666667,0.4166666666666667,3,15,3.75,0,0,0,0,0,0,0,0
1186,quick question about this line of code  median of a column in r,Tools,quick question about this line of code  median of a column in r,"['quick', 'question', 'about', 'this', 'line', 'of', 'code', 'median', 'of', 'a', 'column', 'in', 'r']",0,"['quick', 'question', 'about', 'this', 'line', 'of', 'code', 'median', 'of', 'a', 'column', 'in', 'r']","['quick', 'question', 'line', 'code', 'median', 'column', 'r']",quick question line code median column r,0.3333333333333333,0.3333333333333333,13,40,2.857142857142857,0,0,0,0,0,0,0,0
1187,which regression algorithm to use when there is weak correlation between target and numerical variables,Techniques,which regression algorithm to use when there is weak correlation between target and numerical variables,"['which', 'regression', 'algorithm', 'to', 'use', 'when', 'there', 'is', 'weak', 'correlation', 'between', 'target', 'and', 'numerical', 'variables']",0,"['which', 'regression', 'algorithm', 'to', 'use', 'when', 'there', 'is', 'weak', 'correlation', 'between', 'target', 'and', 'numerical', 'variable']","['regression', 'algorithm', 'use', 'weak', 'correlation', 'target', 'numerical', 'variable']",regression algorithm use weak correlation target numerical variable,-0.375,-0.375,15,67,4.1875,0,0,0,0,0,0,0,0
1188,how to resolve errornon numeric argument to binary operator while applying lda using caret,Tools,how to resolve errornon numeric argument to binary operator while applying lda using caret,"['how', 'to', 'resolve', 'errornon', 'numeric', 'argument', 'to', 'binary', 'operator', 'while', 'applying', 'lda', 'using', 'caret']",0,"['how', 'to', 'resolve', 'errornon', 'numeric', 'argument', 'to', 'binary', 'operator', 'while', 'applying', 'lda', 'using', 'caret']","['resolve', 'errornon', 'numeric', 'argument', 'binary', 'operator', 'applying', 'lda', 'using', 'caret']",resolve errornon numeric argument binary operator applying lda using caret,0.0,0.0,14,74,4.933333333333334,0,0,0,0,0,0,0,0
1189,difference between nominal and ordinal categorical variable,Techniques,difference between nominal and ordinal categorical variable,"['difference', 'between', 'nominal', 'and', 'ordinal', 'categorical', 'variable']",0,"['difference', 'between', 'nominal', 'and', 'ordinal', 'categorical', 'variable']","['difference', 'nominal', 'ordinal', 'categorical', 'variable']",difference nominal ordinal categorical variable,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
1190,valueerror  while executing a shallow neural network having tfidf as featured,Tools,valueerror  while executing a shallow neural network having tfidf as featured,"['valueerror', 'while', 'executing', 'a', 'shallow', 'neural', 'network', 'having', 'tfidf', 'as', 'featured']",0,"['valueerror', 'while', 'executing', 'a', 'shallow', 'neural', 'network', 'having', 'tfidf', 'a', 'featured']","['valueerror', 'executing', 'shallow', 'neural', 'network', 'tfidf', 'featured']",valueerror executing shallow neural network tfidf featured,-0.3333333333333333,-0.3333333333333333,11,58,4.833333333333333,0,0,0,0,0,0,0,0
1191,which is best technique for giving rating or scoring for resume analysis,Techniques,which is best technique for giving rating or scoring for resume analysis,"['which', 'is', 'best', 'technique', 'for', 'giving', 'rating', 'or', 'scoring', 'for', 'resume', 'analysis']",0,"['which', 'is', 'best', 'technique', 'for', 'giving', 'rating', 'or', 'scoring', 'for', 'resume', 'analysis']","['best', 'technique', 'giving', 'rating', 'scoring', 'resume', 'analysis']",best technique giving rating scoring resume analysis,1.0,1.0,12,52,4.0,0,0,0,0,0,0,0,0
1192,need answer for one basic problem on linear regression,Techniques,need answer for one basic problem on linear regression,"['need', 'answer', 'for', 'one', 'basic', 'problem', 'on', 'linear', 'regression']",0,"['need', 'answer', 'for', 'one', 'basic', 'problem', 'on', 'linear', 'regression']","['need', 'answer', 'one', 'basic', 'problem', 'linear', 'regression']",need answer one basic problem linear regression,0.0,0.0,9,47,4.7,0,0,0,0,0,0,0,0
1193,best item recommendation system algorithm for production level,Techniques,best item recommendation system algorithm for production level,"['best', 'item', 'recommendation', 'system', 'algorithm', 'for', 'production', 'level']",0,"['best', 'item', 'recommendation', 'system', 'algorithm', 'for', 'production', 'level']","['best', 'item', 'recommendation', 'system', 'algorithm', 'production', 'level']",best item recommendation system algorithm production level,1.0,1.0,8,58,6.444444444444445,0,0,0,0,0,0,0,0
1194,understanding and building an object detection model from scratch in python,Techniques,understanding and building an object detection model from scratch in python,"['understanding', 'and', 'building', 'an', 'object', 'detection', 'model', 'from', 'scratch', 'in', 'python']",0,"['understanding', 'and', 'building', 'an', 'object', 'detection', 'model', 'from', 'scratch', 'in', 'python']","['understanding', 'building', 'object', 'detection', 'model', 'scratch', 'python']",understanding building object detection model scratch python,0.0,0.0,11,60,5.0,0,0,0,0,0,0,0,0
1195,how to tune c parameter in svm in r,Tools,how to tune c parameter in svm in r,"['how', 'to', 'tune', 'c', 'parameter', 'in', 'svm', 'in', 'r']",0,"['how', 'to', 'tune', 'c', 'parameter', 'in', 'svm', 'in', 'r']","['tune', 'c', 'parameter', 'svm', 'r']",tune c parameter svm r,0.0,0.0,9,22,2.2,0,0,0,0,0,0,0,0
1196,resources  linear algebra and statistics,Resources,resources  linear algebra and statistics,"['resources', 'linear', 'algebra', 'and', 'statistics']",0,"['resource', 'linear', 'algebra', 'and', 'statistic']","['resource', 'linear', 'algebra', 'statistic']",resource linear algebra statistic,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
1197,transfer learning vs fine tuning in deep learning,Techniques,transfer learning vs fine tuning in deep learning,"['transfer', 'learning', 'vs', 'fine', 'tuning', 'in', 'deep', 'learning']",0,"['transfer', 'learning', 'v', 'fine', 'tuning', 'in', 'deep', 'learning']","['transfer', 'learning', 'v', 'fine', 'tuning', 'deep', 'learning']",transfer learning v fine tuning deep learning,0.2083333333333333,0.2083333333333333,8,45,5.0,0,0,0,0,0,0,0,0
1198,how to make bins for a continuous variable by looking at its distribution with the required variable,Techniques,how to make bins for a continuous variable by looking at its distribution with the required variable,"['how', 'to', 'make', 'bins', 'for', 'a', 'continuous', 'variable', 'by', 'looking', 'at', 'its', 'distribution', 'with', 'the', 'required', 'variable']",0,"['how', 'to', 'make', 'bin', 'for', 'a', 'continuous', 'variable', 'by', 'looking', 'at', 'it', 'distribution', 'with', 'the', 'required', 'variable']","['make', 'bin', 'continuous', 'variable', 'looking', 'distribution', 'required', 'variable']",make bin continuous variable looking distribution required variable,0.0,0.0,17,67,3.7222222222222223,0,0,0,0,0,0,0,0
1199,low train accuracy but high test accuracy,Techniques,low train accuracy but high test accuracy,"['low', 'train', 'accuracy', 'but', 'high', 'test', 'accuracy']",0,"['low', 'train', 'accuracy', 'but', 'high', 'test', 'accuracy']","['low', 'train', 'accuracy', 'high', 'test', 'accuracy']",low train accuracy high test accuracy,0.08,0.08,7,37,4.625,0,0,0,0,0,0,0,0
1200,error librosa no backenderror,Techniques,error librosa no backenderror,"['error', 'librosa', 'no', 'backenderror']",0,"['error', 'librosa', 'no', 'backenderror']","['error', 'librosa', 'backenderror']",error librosa backenderror,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
1201,is analytics hyped nowadays,Misc,is analytics hyped nowadays,"['is', 'analytics', 'hyped', 'nowadays']",0,"['is', 'analytics', 'hyped', 'nowadays']","['analytics', 'hyped', 'nowadays']",analytics hyped nowadays,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
1202,error unexpected symbol in,Techniques,error unexpected symbol in,"['error', 'unexpected', 'symbol', 'in']",0,"['error', 'unexpected', 'symbol', 'in']","['error', 'unexpected', 'symbol']",error unexpected symbol,0.1,0.1,4,23,4.6,0,0,0,0,0,0,0,0
1203,upsampling of data in machine learning hackathons,Techniques,upsampling of data in machine learning hackathons,"['upsampling', 'of', 'data', 'in', 'machine', 'learning', 'hackathons']",0,"['upsampling', 'of', 'data', 'in', 'machine', 'learning', 'hackathons']","['upsampling', 'data', 'machine', 'learning', 'hackathons']",upsampling data machine learning hackathons,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
1204,text preparation in neural networks,Techniques,text preparation in neural networks,"['text', 'preparation', 'in', 'neural', 'networks']",0,"['text', 'preparation', 'in', 'neural', 'network']","['text', 'preparation', 'neural', 'network']",text preparation neural network,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1205,what is the difference between uncertainty and stochasticity,Techniques,what is the difference between uncertainty and stochasticity,"['what', 'is', 'the', 'difference', 'between', 'uncertainty', 'and', 'stochasticity']",0,"['what', 'is', 'the', 'difference', 'between', 'uncertainty', 'and', 'stochasticity']","['difference', 'uncertainty', 'stochasticity']",difference uncertainty stochasticity,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
1206,healthcare analytics vs retail and cpg,Career,healthcare analytics vs retail and cpg,"['healthcare', 'analytics', 'vs', 'retail', 'and', 'cpg']",0,"['healthcare', 'analytics', 'v', 'retail', 'and', 'cpg']","['healthcare', 'analytics', 'v', 'retail', 'cpg']",healthcare analytics v retail cpg,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
1207,how does the variancebias tradeoff in ensembles work,Techniques,how does the variancebias tradeoff in ensembles work,"['how', 'does', 'the', 'variancebias', 'tradeoff', 'in', 'ensembles', 'work']",0,"['how', 'doe', 'the', 'variancebias', 'tradeoff', 'in', 'ensemble', 'work']","['doe', 'variancebias', 'tradeoff', 'ensemble', 'work']",doe variancebias tradeoff ensemble work,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
1208, years exp in javahow to approach learning machine learning,Techniques, years exp in javahow to approach learning machine learning,"['years', 'exp', 'in', 'javahow', 'to', 'approach', 'learning', 'machine', 'learning']",1,"['year', 'exp', 'in', 'javahow', 'to', 'approach', 'learning', 'machine', 'learning']","['year', 'exp', 'javahow', 'approach', 'learning', 'machine', 'learning']",year exp javahow approach learning machine learning,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
1209,which algorithm should be use for both classification and regression,Techniques,which algorithm should be use for both classification and regression,"['which', 'algorithm', 'should', 'be', 'use', 'for', 'both', 'classification', 'and', 'regression']",0,"['which', 'algorithm', 'should', 'be', 'use', 'for', 'both', 'classification', 'and', 'regression']","['algorithm', 'use', 'classification', 'regression']",algorithm use classification regression,0.0,0.0,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
1210,how to remove na value in r,Tools,how to remove na value in r,"['how', 'to', 'remove', 'na', 'value', 'in', 'r']",0,"['how', 'to', 'remove', 'na', 'value', 'in', 'r']","['remove', 'na', 'value', 'r']",remove na value r,0.0,0.0,7,17,2.125,0,0,0,0,0,0,0,0
1211,do freshers get placed as databusiness analyst,Career,do freshers get placed as databusiness analyst,"['do', 'freshers', 'get', 'placed', 'as', 'databusiness', 'analyst']",0,"['do', 'fresher', 'get', 'placed', 'a', 'databusiness', 'analyst']","['fresher', 'get', 'placed', 'databusiness', 'analyst']",fresher get placed databusiness analyst,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
1212,business analytics interview questions,Career,business analytics interview questions,"['business', 'analytics', 'interview', 'questions']",0,"['business', 'analytics', 'interview', 'question']","['business', 'analytics', 'interview', 'question']",business analytics interview question,0.0,0.0,4,37,7.4,0,0,0,0,0,0,0,0
1213,help needed in doing a few operations in the following data setr,Tools,help needed in doing a few operations in the following data setr,"['help', 'needed', 'in', 'doing', 'a', 'few', 'operations', 'in', 'the', 'following', 'data', 'setr']",0,"['help', 'needed', 'in', 'doing', 'a', 'few', 'operation', 'in', 'the', 'following', 'data', 'setr']","['help', 'needed', 'operation', 'following', 'data', 'setr']",help needed operation following data setr,-0.1,0.0,12,41,3.1538461538461537,0,0,0,0,0,0,0,0
1214,short text classification  training data,Techniques,short text classification  training data,"['short', 'text', 'classification', 'training', 'data']",0,"['short', 'text', 'classification', 'training', 'data']","['short', 'text', 'classification', 'training', 'data']",short text classification training data,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
1215,how to change my technology,Career,how to change my technology,"['how', 'to', 'change', 'my', 'technology']",0,"['how', 'to', 'change', 'my', 'technology']","['change', 'technology']",change technology,0.0,0.0,5,17,2.8333333333333335,0,0,0,0,0,0,0,0
1216,data for tutorial on essential machine learning algorithms with python  r codes,Other,data for tutorial on essential machine learning algorithms with python  r codes,"['data', 'for', 'tutorial', 'on', 'essential', 'machine', 'learning', 'algorithms', 'with', 'python', 'r', 'codes']",0,"['data', 'for', 'tutorial', 'on', 'essential', 'machine', 'learning', 'algorithm', 'with', 'python', 'r', 'code']","['data', 'tutorial', 'essential', 'machine', 'learning', 'algorithm', 'python', 'r', 'code']",data tutorial essential machine learning algorithm python r code,0.0,0.0,12,64,4.923076923076923,0,0,0,0,0,0,0,0
1217,pgp babi or bda from great lakes,Career,pgp babi or bda from great lakes,"['pgp', 'babi', 'or', 'bda', 'from', 'great', 'lakes']",0,"['pgp', 'babi', 'or', 'bda', 'from', 'great', 'lake']","['pgp', 'babi', 'bda', 'great', 'lake']",pgp babi bda great lake,0.8,0.8,7,23,2.875,0,0,0,0,0,0,0,0
1218,r code for incident ticket management,Techniques,r code for incident ticket management,"['r', 'code', 'for', 'incident', 'ticket', 'management']",0,"['r', 'code', 'for', 'incident', 'ticket', 'management']","['r', 'code', 'incident', 'ticket', 'management']",r code incident ticket management,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
1219,did god use machine learning,Other,did god use machine learning,"['did', 'god', 'use', 'machine', 'learning']",0,"['did', 'god', 'use', 'machine', 'learning']","['god', 'use', 'machine', 'learning']",god use machine learning,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
1220, ways to improve your plots in r,Resources, ways to improve your plots in r,"['ways', 'to', 'improve', 'your', 'plots', 'in', 'r']",1,"['way', 'to', 'improve', 'your', 'plot', 'in', 'r']","['way', 'improve', 'plot', 'r']",way improve plot r,0.0,0.0,7,18,2.25,0,0,0,0,0,0,0,0
1221,best ml toollarge datasets  gb,Tools,best ml toollarge datasets  gb,"['best', 'ml', 'toollarge', 'datasets', 'gb']",1,"['best', 'ml', 'toollarge', 'datasets', 'gb']","['best', 'ml', 'toollarge', 'datasets', 'gb']",best ml toollarge datasets gb,1.0,1.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
1222,how to verify that the data is random in data science,Techniques,how to verify that the data is random in data science,"['how', 'to', 'verify', 'that', 'the', 'data', 'is', 'random', 'in', 'data', 'science']",0,"['how', 'to', 'verify', 'that', 'the', 'data', 'is', 'random', 'in', 'data', 'science']","['verify', 'data', 'random', 'data', 'science']",verify data random data science,-0.5,-0.5,11,31,2.5833333333333335,0,0,0,0,0,0,0,0
1223,multiplying probabilities,Techniques,multiplying probabilities,"['multiplying', 'probabilities']",0,"['multiplying', 'probability']","['multiplying', 'probability']",multiplying probability,0.0,0.0,2,23,7.666666666666667,0,0,0,0,0,0,0,0
1224,why use training set in xgboost parameter tuning,Techniques,why use training set in xgboost parameter tuning,"['why', 'use', 'training', 'set', 'in', 'xgboost', 'parameter', 'tuning']",0,"['why', 'use', 'training', 'set', 'in', 'xgboost', 'parameter', 'tuning']","['use', 'training', 'set', 'xgboost', 'parameter', 'tuning']",use training set xgboost parameter tuning,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
1225,pd model in credit risk analytics,Techniques,pd model in credit risk analytics,"['pd', 'model', 'in', 'credit', 'risk', 'analytics']",0,"['pd', 'model', 'in', 'credit', 'risk', 'analytics']","['pd', 'model', 'credit', 'risk', 'analytics']",pd model credit risk analytics,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
1226,r na in factor level  unable to use as isna for manipulation,Tools,r na in factor level  unable to use as isna for manipulation,"['r', 'na', 'in', 'factor', 'level', 'unable', 'to', 'use', 'as', 'isna', 'for', 'manipulation']",0,"['r', 'na', 'in', 'factor', 'level', 'unable', 'to', 'use', 'a', 'isna', 'for', 'manipulation']","['r', 'na', 'factor', 'level', 'unable', 'use', 'isna', 'manipulation']",r na factor level unable use isna manipulation,-0.5,-0.5,12,46,3.5384615384615383,0,0,0,0,0,0,0,0
1227,use of dfsub in pandas in python,Tools,use of dfsub in pandas in python,"['use', 'of', 'dfsub', 'in', 'pandas', 'in', 'python']",0,"['use', 'of', 'dfsub', 'in', 'panda', 'in', 'python']","['use', 'dfsub', 'panda', 'python']",use dfsub panda python,0.0,0.0,7,22,2.75,0,0,0,0,0,0,0,0
1228,aws machine learning certification,Resources,aws machine learning certification,"['aws', 'machine', 'learning', 'certification']",0,"['aws', 'machine', 'learning', 'certification']","['aws', 'machine', 'learning', 'certification']",aws machine learning certification,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
1229,new paper on automatically detecting label errors in entity recognition data,Tools,new paper on automatically detecting label errors in entity recognition data,"['new', 'paper', 'on', 'automatically', 'detecting', 'label', 'errors', 'in', 'entity', 'recognition', 'data']",0,"['new', 'paper', 'on', 'automatically', 'detecting', 'label', 'error', 'in', 'entity', 'recognition', 'data']","['new', 'paper', 'automatically', 'detecting', 'label', 'error', 'entity', 'recognition', 'data']",new paper automatically detecting label error entity recognition data,0.1363636363636363,0.1363636363636363,11,69,5.75,0,0,0,0,0,0,0,0
1230, interview questions,Techniques, interview questions,"['interview', 'questions']",1,"['interview', 'question']","['interview', 'question']",interview question,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
1231,calculate probability in logistic regression,Techniques,calculate probability in logistic regression,"['calculate', 'probability', 'in', 'logistic', 'regression']",0,"['calculate', 'probability', 'in', 'logistic', 'regression']","['calculate', 'probability', 'logistic', 'regression']",calculate probability logistic regression,0.0,0.0,5,41,6.833333333333333,0,0,0,0,0,0,0,0
1232,what are the simple and best ways to productionizemonitor and evaluate ml models in r,Techniques,what are the simple and best ways to productionizemonitor and evaluate ml models in r,"['what', 'are', 'the', 'simple', 'and', 'best', 'ways', 'to', 'productionizemonitor', 'and', 'evaluate', 'ml', 'models', 'in', 'r']",0,"['what', 'are', 'the', 'simple', 'and', 'best', 'way', 'to', 'productionizemonitor', 'and', 'evaluate', 'ml', 'model', 'in', 'r']","['simple', 'best', 'way', 'productionizemonitor', 'evaluate', 'ml', 'model', 'r']",simple best way productionizemonitor evaluate ml model r,0.5,0.5,15,56,3.5,0,0,0,0,0,0,0,0
1233,no numeric types to aggregate  big mart sales intro code error  i av blog for big mart sales below code  is getting an error,Techniques,no numeric types to aggregate  big mart sales intro code error  i av blog for big mart sales below code  is getting an error,"['no', 'numeric', 'types', 'to', 'aggregate', 'big', 'mart', 'sales', 'intro', 'code', 'error', 'i', 'av', 'blog', 'for', 'big', 'mart', 'sales', 'below', 'code', 'is', 'getting', 'an', 'error']",0,"['no', 'numeric', 'type', 'to', 'aggregate', 'big', 'mart', 'sale', 'intro', 'code', 'error', 'i', 'av', 'blog', 'for', 'big', 'mart', 'sale', 'below', 'code', 'is', 'getting', 'an', 'error']","['numeric', 'type', 'aggregate', 'big', 'mart', 'sale', 'intro', 'code', 'error', 'av', 'blog', 'big', 'mart', 'sale', 'code', 'getting', 'error']",numeric type aggregate big mart sale intro code error av blog big mart sale code getting error,0.0,0.0,24,94,3.76,0,0,0,0,0,0,0,0
1234,logistic regression in loan prediction,Hackathons,logistic regression in loan prediction,"['logistic', 'regression', 'in', 'loan', 'prediction']",0,"['logistic', 'regression', 'in', 'loan', 'prediction']","['logistic', 'regression', 'loan', 'prediction']",logistic regression loan prediction,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
1235,how to get the text content of a html while scraping using beautifulsoup in python,Tools,how to get the text content of a html while scraping using beautifulsoup in python,"['how', 'to', 'get', 'the', 'text', 'content', 'of', 'a', 'html', 'while', 'scraping', 'using', 'beautifulsoup', 'in', 'python']",0,"['how', 'to', 'get', 'the', 'text', 'content', 'of', 'a', 'html', 'while', 'scraping', 'using', 'beautifulsoup', 'in', 'python']","['get', 'text', 'content', 'html', 'scraping', 'using', 'beautifulsoup', 'python']",get text content html scraping using beautifulsoup python,0.0,0.0,15,57,3.5625,0,0,0,0,0,0,0,0
1236,you have a new project at workgrad school how do you plan the projects execution,Career,you have a new project at workgrad school how do you plan the projects execution,"['you', 'have', 'a', 'new', 'project', 'at', 'workgrad', 'school', 'how', 'do', 'you', 'plan', 'the', 'projects', 'execution']",0,"['you', 'have', 'a', 'new', 'project', 'at', 'workgrad', 'school', 'how', 'do', 'you', 'plan', 'the', 'project', 'execution']","['new', 'project', 'workgrad', 'school', 'plan', 'project', 'execution']",new project workgrad school plan project execution,0.1363636363636363,0.1363636363636363,15,50,3.125,0,0,0,0,0,0,0,0
1237,python survival model cox phm,Techniques,python survival model cox phm,"['python', 'survival', 'model', 'cox', 'phm']",0,"['python', 'survival', 'model', 'cox', 'phm']","['python', 'survival', 'model', 'cox', 'phm']",python survival model cox phm,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
1238,masking py file for deployment,Techniques,masking py file for deployment,"['masking', 'py', 'file', 'for', 'deployment']",0,"['masking', 'py', 'file', 'for', 'deployment']","['masking', 'py', 'file', 'deployment']",masking py file deployment,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
1239,error in neural network with one hidden layer,Techniques,error in neural network with one hidden layer,"['error', 'in', 'neural', 'network', 'with', 'one', 'hidden', 'layer']",0,"['error', 'in', 'neural', 'network', 'with', 'one', 'hidden', 'layer']","['error', 'neural', 'network', 'one', 'hidden', 'layer']",error neural network one hidden layer,-0.1666666666666666,-0.1666666666666666,8,37,4.111111111111111,0,0,0,0,0,0,0,0
1240,script in ho in r to get you into top  percentile for the digit recognizer competition,Tools,script in ho in r to get you into top  percentile for the digit recognizer competition,"['script', 'in', 'ho', 'in', 'r', 'to', 'get', 'you', 'into', 'top', 'percentile', 'for', 'the', 'digit', 'recognizer', 'competition']",1,"['script', 'in', 'ho', 'in', 'r', 'to', 'get', 'you', 'into', 'top', 'percentile', 'for', 'the', 'digit', 'recognizer', 'competition']","['script', 'ho', 'r', 'get', 'top', 'percentile', 'digit', 'recognizer', 'competition']",script ho r get top percentile digit recognizer competition,0.5,0.5,16,59,3.4705882352941178,0,0,0,0,0,0,0,0
1241,how important understanding the evaluation metric in data science competitions,Techniques,how important understanding the evaluation metric in data science competitions,"['how', 'important', 'understanding', 'the', 'evaluation', 'metric', 'in', 'data', 'science', 'competitions']",0,"['how', 'important', 'understanding', 'the', 'evaluation', 'metric', 'in', 'data', 'science', 'competition']","['important', 'understanding', 'evaluation', 'metric', 'data', 'science', 'competition']",important understanding evaluation metric data science competition,0.4,0.4,10,66,6.0,0,0,0,0,0,0,0,0
1242,less data set is present,Techniques,less data set is present,"['less', 'data', 'set', 'is', 'present']",0,"['le', 'data', 'set', 'is', 'present']","['le', 'data', 'set', 'present']",le data set present,-0.0833333333333333,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
1243,how to arrive at the expression nck for selection of k objects from n objects using the counting principle,Techniques,how to arrive at the expression nck for selection of k objects from n objects using the counting principle,"['how', 'to', 'arrive', 'at', 'the', 'expression', 'nck', 'for', 'selection', 'of', 'k', 'objects', 'from', 'n', 'objects', 'using', 'the', 'counting', 'principle']",0,"['how', 'to', 'arrive', 'at', 'the', 'expression', 'nck', 'for', 'selection', 'of', 'k', 'object', 'from', 'n', 'object', 'using', 'the', 'counting', 'principle']","['arrive', 'expression', 'nck', 'selection', 'k', 'object', 'n', 'object', 'using', 'counting', 'principle']",arrive expression nck selection k object n object using counting principle,0.0,0.0,19,74,3.7,0,0,0,0,0,0,0,0
1244,certificateworkshop,Hackathons,certificateworkshop,['certificateworkshop'],0,['certificateworkshop'],['certificateworkshop'],certificateworkshop,0.0,0.0,1,19,9.5,0,0,0,0,0,0,0,0
1245,text analytics stemming vs lemmatization,Techniques,text analytics stemming vs lemmatization,"['text', 'analytics', 'stemming', 'vs', 'lemmatization']",0,"['text', 'analytics', 'stemming', 'v', 'lemmatization']","['text', 'analytics', 'stemming', 'v', 'lemmatization']",text analytics stemming v lemmatization,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
1246,what is meaning of overfitting and underfitting,Techniques,what is meaning of overfitting and underfitting,"['what', 'is', 'meaning', 'of', 'overfitting', 'and', 'underfitting']",0,"['what', 'is', 'meaning', 'of', 'overfitting', 'and', 'underfitting']","['meaning', 'overfitting', 'underfitting']",meaning overfitting underfitting,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
1247,predictive models to be used,Other,predictive models to be used,"['predictive', 'models', 'to', 'be', 'used']",0,"['predictive', 'model', 'to', 'be', 'used']","['predictive', 'model', 'used']",predictive model used,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
1248,date your datahow to improve model accuracy,Hackathons,date your datahow to improve model accuracy,"['date', 'your', 'datahow', 'to', 'improve', 'model', 'accuracy']",0,"['date', 'your', 'datahow', 'to', 'improve', 'model', 'accuracy']","['date', 'datahow', 'improve', 'model', 'accuracy']",date datahow improve model accuracy,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
1249,how to resolve na error while using svmbag in r,Tools,how to resolve na error while using svmbag in r,"['how', 'to', 'resolve', 'na', 'error', 'while', 'using', 'svmbag', 'in', 'r']",0,"['how', 'to', 'resolve', 'na', 'error', 'while', 'using', 'svmbag', 'in', 'r']","['resolve', 'na', 'error', 'using', 'svmbag', 'r']",resolve na error using svmbag r,0.0,0.0,10,31,2.8181818181818183,0,0,0,0,0,0,0,0
1250,how to determine the distributions in naive bayes,Techniques,how to determine the distributions in naive bayes,"['how', 'to', 'determine', 'the', 'distributions', 'in', 'naive', 'bayes']",0,"['how', 'to', 'determine', 'the', 'distribution', 'in', 'naive', 'bayes']","['determine', 'distribution', 'naive', 'bayes']",determine distribution naive bayes,-0.3,-0.3,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
1251,course on predictive modeling,Career,course on predictive modeling,"['course', 'on', 'predictive', 'modeling']",0,"['course', 'on', 'predictive', 'modeling']","['course', 'predictive', 'modeling']",course predictive modeling,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
1252,not able to create the environment ,Tools,not able to create the environment ,"['not', 'able', 'to', 'create', 'the', 'environment']",0,"['not', 'able', 'to', 'create', 'the', 'environment']","['able', 'create', 'environment']",able create environment,-0.25,0.5,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
1253,text mining nlp or nn,Techniques,text mining nlp or nn,"['text', 'mining', 'nlp', 'or', 'nn']",0,"['text', 'mining', 'nlp', 'or', 'nn']","['text', 'mining', 'nlp', 'nn']",text mining nlp nn,0.0,0.0,5,18,3.0,0,0,0,0,0,0,0,0
1254,create all possible combination in sequential order in r,Tools,create all possible combination in sequential order in r,"['create', 'all', 'possible', 'combination', 'in', 'sequential', 'order', 'in', 'r']",0,"['create', 'all', 'possible', 'combination', 'in', 'sequential', 'order', 'in', 'r']","['create', 'possible', 'combination', 'sequential', 'order', 'r']",create possible combination sequential order r,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
1255,practice recommendation  problem data dataset,Hackathons,practice recommendation  problem data dataset,"['practice', 'recommendation', 'problem', 'data', 'dataset']",0,"['practice', 'recommendation', 'problem', 'data', 'dataset']","['practice', 'recommendation', 'problem', 'data', 'dataset']",practice recommendation problem data dataset,0.0,0.0,5,44,7.333333333333333,0,0,0,0,0,0,0,0
1256,chatbot using rasa,Tools,chatbot using rasa,"['chatbot', 'using', 'rasa']",0,"['chatbot', 'using', 'rasa']","['chatbot', 'using', 'rasa']",chatbot using rasa,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
1257,pgp business analytics and big data offered by ibm and aegis school of business and telecom,Career,pgp business analytics and big data offered by ibm and aegis school of business and telecom,"['pgp', 'business', 'analytics', 'and', 'big', 'data', 'offered', 'by', 'ibm', 'and', 'aegis', 'school', 'of', 'business', 'and', 'telecom']",0,"['pgp', 'business', 'analytics', 'and', 'big', 'data', 'offered', 'by', 'ibm', 'and', 'aegis', 'school', 'of', 'business', 'and', 'telecom']","['pgp', 'business', 'analytics', 'big', 'data', 'offered', 'ibm', 'aegis', 'school', 'business', 'telecom']",pgp business analytics big data offered ibm aegis school business telecom,0.0,0.0,16,73,4.294117647058823,0,0,0,0,0,0,0,0
1258,what are the methods to replace one value of list with value of another list in python,Tools,what are the methods to replace one value of list with value of another list in python,"['what', 'are', 'the', 'methods', 'to', 'replace', 'one', 'value', 'of', 'list', 'with', 'value', 'of', 'another', 'list', 'in', 'python']",0,"['what', 'are', 'the', 'method', 'to', 'replace', 'one', 'value', 'of', 'list', 'with', 'value', 'of', 'another', 'list', 'in', 'python']","['method', 'replace', 'one', 'value', 'list', 'value', 'another', 'list', 'python']",method replace one value list value another list python,0.0,0.0,17,55,3.0555555555555554,0,0,0,0,0,0,0,0
1259,how can i treat missing values of pandas dataframe and apply defined functions for other dataframes in python,Tools,how can i treat missing values of pandas dataframe and apply defined functions for other dataframes in python,"['how', 'can', 'i', 'treat', 'missing', 'values', 'of', 'pandas', 'dataframe', 'and', 'apply', 'defined', 'functions', 'for', 'other', 'dataframes', 'in', 'python']",0,"['how', 'can', 'i', 'treat', 'missing', 'value', 'of', 'panda', 'dataframe', 'and', 'apply', 'defined', 'function', 'for', 'other', 'dataframes', 'in', 'python']","['treat', 'missing', 'value', 'panda', 'dataframe', 'apply', 'defined', 'function', 'dataframes', 'python']",treat missing value panda dataframe apply defined function dataframes python,-0.1625,-0.2,18,76,4.0,0,0,0,0,0,0,0,0
1260,how to change the transparency of the plot in r,Tools,how to change the transparency of the plot in r,"['how', 'to', 'change', 'the', 'transparency', 'of', 'the', 'plot', 'in', 'r']",0,"['how', 'to', 'change', 'the', 'transparency', 'of', 'the', 'plot', 'in', 'r']","['change', 'transparency', 'plot', 'r']",change transparency plot r,0.0,0.0,10,26,2.3636363636363638,0,0,0,0,0,0,0,0
1261,high rscore on training data and very low on test data,Techniques,high rscore on training data and very low on test data,"['high', 'rscore', 'on', 'training', 'data', 'and', 'very', 'low', 'on', 'test', 'data']",0,"['high', 'rscore', 'on', 'training', 'data', 'and', 'very', 'low', 'on', 'test', 'data']","['high', 'rscore', 'training', 'data', 'low', 'test', 'data']",high rscore training data low test data,0.08,0.08,11,39,3.25,0,0,0,0,0,0,0,0
1262,pca interpretation with biplot function,Techniques,pca interpretation with biplot function,"['pca', 'interpretation', 'with', 'biplot', 'function']",0,"['pca', 'interpretation', 'with', 'biplot', 'function']","['pca', 'interpretation', 'biplot', 'function']",pca interpretation biplot function,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
1263,which is the best library to look at descriptive and inferential statistics metrics in python,Tools,which is the best library to look at descriptive and inferential statistics metrics in python,"['which', 'is', 'the', 'best', 'library', 'to', 'look', 'at', 'descriptive', 'and', 'inferential', 'statistics', 'metrics', 'in', 'python']",0,"['which', 'is', 'the', 'best', 'library', 'to', 'look', 'at', 'descriptive', 'and', 'inferential', 'statistic', 'metric', 'in', 'python']","['best', 'library', 'look', 'descriptive', 'inferential', 'statistic', 'metric', 'python']",best library look descriptive inferential statistic metric python,1.0,1.0,15,65,4.0625,0,0,0,0,0,0,0,0
1264,regarding data science internship opportunities,Career,regarding data science internship opportunities,"['regarding', 'data', 'science', 'internship', 'opportunities']",0,"['regarding', 'data', 'science', 'internship', 'opportunity']","['regarding', 'data', 'science', 'internship', 'opportunity']",regarding data science internship opportunity,0.0,0.0,5,45,7.5,0,0,0,0,0,0,0,0
1265,how to generate all frequent itemset generation using r,Techniques,how to generate all frequent itemset generation using r,"['how', 'to', 'generate', 'all', 'frequent', 'itemset', 'generation', 'using', 'r']",0,"['how', 'to', 'generate', 'all', 'frequent', 'itemset', 'generation', 'using', 'r']","['generate', 'frequent', 'itemset', 'generation', 'using', 'r']",generate frequent itemset generation using r,0.1,0.1,9,44,4.4,0,0,0,0,0,0,0,0
1267,life of a consumer durable product,Techniques,life of a consumer durable product,"['life', 'of', 'a', 'consumer', 'durable', 'product']",0,"['life', 'of', 'a', 'consumer', 'durable', 'product']","['life', 'consumer', 'durable', 'product']",life consumer durable product,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
1268,how to change multiple date formats,Techniques,how to change multiple date formats,"['how', 'to', 'change', 'multiple', 'date', 'formats']",0,"['how', 'to', 'change', 'multiple', 'date', 'format']","['change', 'multiple', 'date', 'format']",change multiple date format,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
1269,help to read windows media player database,Techniques,help to read windows media player database,"['help', 'to', 'read', 'windows', 'media', 'player', 'database']",0,"['help', 'to', 'read', 'window', 'medium', 'player', 'database']","['help', 'read', 'window', 'medium', 'player', 'database']",help read window medium player database,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
1270,solutions of the skilltest,Hackathons,solutions of the skilltest,"['solutions', 'of', 'the', 'skilltest']",0,"['solution', 'of', 'the', 'skilltest']","['solution', 'skilltest']",solution skilltest,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
1271,how to handle missing values of categorical variables,Techniques,how to handle missing values of categorical variables,"['how', 'to', 'handle', 'missing', 'values', 'of', 'categorical', 'variables']",0,"['how', 'to', 'handle', 'missing', 'value', 'of', 'categorical', 'variable']","['handle', 'missing', 'value', 'categorical', 'variable']",handle missing value categorical variable,-0.2,-0.2,8,41,4.555555555555555,0,0,0,0,0,0,0,0
1272,read data from multiple csv files to analyze data,Techniques,read data from multiple csv files to analyze data,"['read', 'data', 'from', 'multiple', 'csv', 'files', 'to', 'analyze', 'data']",0,"['read', 'data', 'from', 'multiple', 'csv', 'file', 'to', 'analyze', 'data']","['read', 'data', 'multiple', 'csv', 'file', 'analyze', 'data']",read data multiple csv file analyze data,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
1273,clustering and mapping,Techniques,clustering and mapping,"['clustering', 'and', 'mapping']",0,"['clustering', 'and', 'mapping']","['clustering', 'mapping']",clustering mapping,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
1274,books for natural language processing nlp,Resources,books for natural language processing nlp,"['books', 'for', 'natural', 'language', 'processing', 'nlp']",0,"['book', 'for', 'natural', 'language', 'processing', 'nlp']","['book', 'natural', 'language', 'processing', 'nlp']",book natural language processing nlp,0.1,0.1,6,36,5.142857142857143,0,0,0,0,0,0,0,0
1275,introductions  new members for june ,Misc,introductions  new members for june ,"['introductions', 'new', 'members', 'for', 'june']",1,"['introduction', 'new', 'member', 'for', 'june']","['introduction', 'new', 'member', 'june']",introduction new member june,0.1363636363636363,0.1363636363636363,5,28,4.666666666666667,0,0,0,0,0,0,0,0
1276,predictive power of regression models,Techniques,predictive power of regression models,"['predictive', 'power', 'of', 'regression', 'models']",0,"['predictive', 'power', 'of', 'regression', 'model']","['predictive', 'power', 'regression', 'model']",predictive power regression model,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
1277,which ones better for career  msc data analytics at strathclyde business school or msc business analytics from alliance manchester business school ,Career,which ones better for career  msc data analytics at strathclyde business school or msc business analytics from alliance manchester business school ,"['which', 'ones', 'better', 'for', 'career', 'msc', 'data', 'analytics', 'at', 'strathclyde', 'business', 'school', 'or', 'msc', 'business', 'analytics', 'from', 'alliance', 'manchester', 'business', 'school']",0,"['which', 'one', 'better', 'for', 'career', 'msc', 'data', 'analytics', 'at', 'strathclyde', 'business', 'school', 'or', 'msc', 'business', 'analytics', 'from', 'alliance', 'manchester', 'business', 'school']","['one', 'better', 'career', 'msc', 'data', 'analytics', 'strathclyde', 'business', 'school', 'msc', 'business', 'analytics', 'alliance', 'manchester', 'business', 'school']",one better career msc data analytics strathclyde business school msc business analytics alliance manchester business school,0.5,0.5,21,123,5.590909090909091,0,0,0,0,0,0,0,0
1278,how can i convert a date field to quarter in qlikview,Tools,how can i convert a date field to quarter in qlikview,"['how', 'can', 'i', 'convert', 'a', 'date', 'field', 'to', 'quarter', 'in', 'qlikview']",0,"['how', 'can', 'i', 'convert', 'a', 'date', 'field', 'to', 'quarter', 'in', 'qlikview']","['convert', 'date', 'field', 'quarter', 'qlikview']",convert date field quarter qlikview,0.0,0.0,11,35,2.9166666666666665,0,0,0,0,0,0,0,0
1279,how to find over model is overfitting or not,Techniques,how to find over model is overfitting or not,"['how', 'to', 'find', 'over', 'model', 'is', 'overfitting', 'or', 'not']",0,"['how', 'to', 'find', 'over', 'model', 'is', 'overfitting', 'or', 'not']","['find', 'model', 'overfitting']",find model overfitting,0.0,0.0,9,22,2.2,0,0,0,0,0,0,0,0
1280,not able to apply for the final round of data science intern challange,Career,not able to apply for the final round of data science intern challange,"['not', 'able', 'to', 'apply', 'for', 'the', 'final', 'round', 'of', 'data', 'science', 'intern', 'challange']",0,"['not', 'able', 'to', 'apply', 'for', 'the', 'final', 'round', 'of', 'data', 'science', 'intern', 'challange']","['able', 'apply', 'final', 'round', 'data', 'science', 'intern', 'challange']",able apply final round data science intern challange,-0.15,0.0999999999999999,13,52,3.7142857142857144,0,0,0,0,0,0,0,0
1281,how to extract the best decision tree from a random forest in r,Tools,how to extract the best decision tree from a random forest in r,"['how', 'to', 'extract', 'the', 'best', 'decision', 'tree', 'from', 'a', 'random', 'forest', 'in', 'r']",0,"['how', 'to', 'extract', 'the', 'best', 'decision', 'tree', 'from', 'a', 'random', 'forest', 'in', 'r']","['extract', 'best', 'decision', 'tree', 'random', 'forest', 'r']",extract best decision tree random forest r,0.25,0.25,13,42,3.0,0,0,0,0,0,0,0,0
1282,which sas course to choose,Career,which sas course to choose,"['which', 'sas', 'course', 'to', 'choose']",0,"['which', 'sa', 'course', 'to', 'choose']","['sa', 'course', 'choose']",sa course choose,0.0,0.0,5,16,2.6666666666666665,0,0,0,0,0,0,0,0
1283,right analytic course for banking sales professional,Career,right analytic course for banking sales professional,"['right', 'analytic', 'course', 'for', 'banking', 'sales', 'professional']",0,"['right', 'analytic', 'course', 'for', 'banking', 'sale', 'professional']","['right', 'analytic', 'course', 'banking', 'sale', 'professional']",right analytic course banking sale professional,0.1928571428571428,0.1928571428571428,7,47,5.875,0,0,0,0,0,0,0,0
1284,help needed with preparing data for analysis,Techniques,help needed with preparing data for analysis,"['help', 'needed', 'with', 'preparing', 'data', 'for', 'analysis']",0,"['help', 'needed', 'with', 'preparing', 'data', 'for', 'analysis']","['help', 'needed', 'preparing', 'data', 'analysis']",help needed preparing data analysis,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
1285,data science career start,Career,data science career start,"['data', 'science', 'career', 'start']",0,"['data', 'science', 'career', 'start']","['data', 'science', 'career', 'start']",data science career start,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
1286,balance forecasting,Techniques,balance forecasting,"['balance', 'forecasting']",0,"['balance', 'forecasting']","['balance', 'forecasting']",balance forecasting,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
1287,aws hadoop json data processing,Techniques,aws hadoop json data processing,"['aws', 'hadoop', 'json', 'data', 'processing']",0,"['aws', 'hadoop', 'json', 'data', 'processing']","['aws', 'hadoop', 'json', 'data', 'processing']",aws hadoop json data processing,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1288,problem in aggregate function implementation in r,Techniques,problem in aggregate function implementation in r,"['problem', 'in', 'aggregate', 'function', 'implementation', 'in', 'r']",0,"['problem', 'in', 'aggregate', 'function', 'implementation', 'in', 'r']","['problem', 'aggregate', 'function', 'implementation', 'r']",problem aggregate function implementation r,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
1289,unable to read boston as a dataset in r,Tools,unable to read boston as a dataset in r,"['unable', 'to', 'read', 'boston', 'as', 'a', 'dataset', 'in', 'r']",0,"['unable', 'to', 'read', 'boston', 'a', 'a', 'dataset', 'in', 'r']","['unable', 'read', 'boston', 'dataset', 'r']",unable read boston dataset r,-0.5,-0.5,9,28,2.8,0,0,0,0,0,0,0,0
1290,course content for ms in business analytics,Career,course content for ms in business analytics,"['course', 'content', 'for', 'ms', 'in', 'business', 'analytics']",0,"['course', 'content', 'for', 'm', 'in', 'business', 'analytics']","['course', 'content', 'business', 'analytics']",course content business analytics,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
1291,loanprediction practice problem  how to improve the model,Hackathons,loanprediction practice problem  how to improve the model,"['loanprediction', 'practice', 'problem', 'how', 'to', 'improve', 'the', 'model']",0,"['loanprediction', 'practice', 'problem', 'how', 'to', 'improve', 'the', 'model']","['loanprediction', 'practice', 'problem', 'improve', 'model']",loanprediction practice problem improve model,0.0,0.0,8,45,5.0,0,0,0,0,0,0,0,0
1292,pythons dplyr,Tools,pythons dplyr,"['pythons', 'dplyr']",0,"['python', 'dplyr']","['python', 'dplyr']",python dplyr,0.0,0.0,2,12,4.0,0,0,0,0,0,0,0,0
1293,how to create a empty vector with fixed length in r,Techniques,how to create a empty vector with fixed length in r,"['how', 'to', 'create', 'a', 'empty', 'vector', 'with', 'fixed', 'length', 'in', 'r']",0,"['how', 'to', 'create', 'a', 'empty', 'vector', 'with', 'fixed', 'length', 'in', 'r']","['create', 'empty', 'vector', 'fixed', 'length', 'r']",create empty vector fixed length r,0.0,0.0,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
1294,dealing with imbalanced categorical data for machine learning predictions,Techniques,dealing with imbalanced categorical data for machine learning predictions,"['dealing', 'with', 'imbalanced', 'categorical', 'data', 'for', 'machine', 'learning', 'predictions']",0,"['dealing', 'with', 'imbalanced', 'categorical', 'data', 'for', 'machine', 'learning', 'prediction']","['dealing', 'imbalanced', 'categorical', 'data', 'machine', 'learning', 'prediction']",dealing imbalanced categorical data machine learning prediction,0.0,0.0,9,63,6.3,0,0,0,0,0,0,0,0
1295,how can i create box plot chart in excel,Tools,how can i create box plot chart in excel,"['how', 'can', 'i', 'create', 'box', 'plot', 'chart', 'in', 'excel']",0,"['how', 'can', 'i', 'create', 'box', 'plot', 'chart', 'in', 'excel']","['create', 'box', 'plot', 'chart', 'excel']",create box plot chart excel,0.0,0.0,9,27,2.7,0,0,0,0,0,0,0,0
1296,tsne with a classifier,Techniques,tsne with a classifier,"['tsne', 'with', 'a', 'classifier']",0,"['tsne', 'with', 'a', 'classifier']","['tsne', 'classifier']",tsne classifier,0.0,0.0,4,15,3.0,0,0,0,0,0,0,0,0
1297,which are the functions used to convert string date to date format in qlikview,Techniques,which are the functions used to convert string date to date format in qlikview,"['which', 'are', 'the', 'functions', 'used', 'to', 'convert', 'string', 'date', 'to', 'date', 'format', 'in', 'qlikview']",0,"['which', 'are', 'the', 'function', 'used', 'to', 'convert', 'string', 'date', 'to', 'date', 'format', 'in', 'qlikview']","['function', 'used', 'convert', 'string', 'date', 'date', 'format', 'qlikview']",function used convert string date date format qlikview,0.0,0.0,14,54,3.6,0,0,0,0,0,0,0,0
1298,forecasting active users,Techniques,forecasting active users,"['forecasting', 'active', 'users']",0,"['forecasting', 'active', 'user']","['forecasting', 'active', 'user']",forecasting active user,-0.1333333333333333,-0.1333333333333333,3,23,5.75,0,0,0,0,0,0,0,0
1299,scorecard using visualization in r,Techniques,scorecard using visualization in r,"['scorecard', 'using', 'visualization', 'in', 'r']",0,"['scorecard', 'using', 'visualization', 'in', 'r']","['scorecard', 'using', 'visualization', 'r']",scorecard using visualization r,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1300,is python faster than r,Tools,is python faster than r,"['is', 'python', 'faster', 'than', 'r']",0,"['is', 'python', 'faster', 'than', 'r']","['python', 'faster', 'r']",python faster r,0.0,0.0,5,15,2.5,0,0,0,0,0,0,0,0
1301,loan prediction problem  understanding the target variable,Techniques,loan prediction problem  understanding the target variable,"['loan', 'prediction', 'problem', 'understanding', 'the', 'target', 'variable']",0,"['loan', 'prediction', 'problem', 'understanding', 'the', 'target', 'variable']","['loan', 'prediction', 'problem', 'understanding', 'target', 'variable']",loan prediction problem understanding target variable,0.0,0.0,7,53,6.625,0,0,0,0,0,0,0,0
1302,analytics course for sales professional,Career,analytics course for sales professional,"['analytics', 'course', 'for', 'sales', 'professional']",0,"['analytics', 'course', 'for', 'sale', 'professional']","['analytics', 'course', 'sale', 'professional']",analytics course sale professional,0.1,0.1,5,34,5.666666666666667,0,0,0,0,0,0,0,0
1303,facebook prophet bayesian curve fitting,Techniques,facebook prophet bayesian curve fitting,"['facebook', 'prophet', 'bayesian', 'curve', 'fitting']",0,"['facebook', 'prophet', 'bayesian', 'curve', 'fitting']","['facebook', 'prophet', 'bayesian', 'curve', 'fitting']",facebook prophet bayesian curve fitting,0.5,0.5,5,39,6.5,0,0,0,0,0,0,0,0
1304,vietorisrips complex for ndimensional point cloud,Techniques,vietorisrips complex for ndimensional point cloud,"['vietorisrips', 'complex', 'for', 'ndimensional', 'point', 'cloud']",0,"['vietorisrips', 'complex', 'for', 'ndimensional', 'point', 'cloud']","['vietorisrips', 'complex', 'ndimensional', 'point', 'cloud']",vietorisrips complex ndimensional point cloud,-0.3,-0.3,6,45,6.428571428571429,0,0,0,0,0,0,0,0
1305,how to create columns from sublist,Tools,how to create columns from sublist,"['how', 'to', 'create', 'columns', 'from', 'sublist']",0,"['how', 'to', 'create', 'column', 'from', 'sublist']","['create', 'column', 'sublist']",create column sublist,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
1306,how to find correlation among multiple attributes in group by dataframe object,Techniques,how to find correlation among multiple attributes in group by dataframe object,"['how', 'to', 'find', 'correlation', 'among', 'multiple', 'attributes', 'in', 'group', 'by', 'dataframe', 'object']",0,"['how', 'to', 'find', 'correlation', 'among', 'multiple', 'attribute', 'in', 'group', 'by', 'dataframe', 'object']","['find', 'correlation', 'among', 'multiple', 'attribute', 'group', 'dataframe', 'object']",find correlation among multiple attribute group dataframe object,0.0,0.0,12,64,4.923076923076923,0,0,0,0,0,0,0,0
1307,is percentage a continuous variable or discrete variable,Other,is percentage a continuous variable or discrete variable,"['is', 'percentage', 'a', 'continuous', 'variable', 'or', 'discrete', 'variable']",0,"['is', 'percentage', 'a', 'continuous', 'variable', 'or', 'discrete', 'variable']","['percentage', 'continuous', 'variable', 'discrete', 'variable']",percentage continuous variable discrete variable,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
1308,how to solve valueerror error when checking target expected dense to have shape  but got array with shape ,Techniques,how to solve valueerror error when checking target expected dense to have shape  but got array with shape ,"['how', 'to', 'solve', 'valueerror', 'error', 'when', 'checking', 'target', 'expected', 'dense', 'to', 'have', 'shape', 'but', 'got', 'array', 'with', 'shape']",2,"['how', 'to', 'solve', 'valueerror', 'error', 'when', 'checking', 'target', 'expected', 'dense', 'to', 'have', 'shape', 'but', 'got', 'array', 'with', 'shape']","['solve', 'valueerror', 'error', 'checking', 'target', 'expected', 'dense', 'shape', 'got', 'array', 'shape']",solve valueerror error checking target expected dense shape got array shape,-0.1,-0.1,18,75,3.9473684210526314,0,0,0,0,0,0,0,0
1309,open source reporting tool with following requirements,Tools,open source reporting tool with following requirements,"['open', 'source', 'reporting', 'tool', 'with', 'following', 'requirements']",0,"['open', 'source', 'reporting', 'tool', 'with', 'following', 'requirement']","['open', 'source', 'reporting', 'tool', 'following', 'requirement']",open source reporting tool following requirement,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
1310,sarimax valueerror xnames and params do not have the same length,Tools,sarimax valueerror xnames and params do not have the same length,"['sarimax', 'valueerror', 'xnames', 'and', 'params', 'do', 'not', 'have', 'the', 'same', 'length']",0,"['sarimax', 'valueerror', 'xnames', 'and', 'params', 'do', 'not', 'have', 'the', 'same', 'length']","['sarimax', 'valueerror', 'xnames', 'params', 'length']",sarimax valueerror xnames params length,0.0,0.0,11,39,3.25,0,0,0,0,0,0,0,0
1311,decreasing training time for svm,Techniques,decreasing training time for svm,"['decreasing', 'training', 'time', 'for', 'svm']",0,"['decreasing', 'training', 'time', 'for', 'svm']","['decreasing', 'training', 'time', 'svm']",decreasing training time svm,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
1312,how to save images in hadoop hive tableand then access via tableau,Techniques,how to save images in hadoop hive tableand then access via tableau,"['how', 'to', 'save', 'images', 'in', 'hadoop', 'hive', 'tableand', 'then', 'access', 'via', 'tableau']",0,"['how', 'to', 'save', 'image', 'in', 'hadoop', 'hive', 'tableand', 'then', 'access', 'via', 'tableau']","['save', 'image', 'hadoop', 'hive', 'tableand', 'access', 'via', 'tableau']",save image hadoop hive tableand access via tableau,0.0,0.0,12,50,3.8461538461538463,0,0,0,0,0,0,0,0
1313,are there plans to introduce ipython for use in discussion forums,Other,are there plans to introduce ipython for use in discussion forums,"['are', 'there', 'plans', 'to', 'introduce', 'ipython', 'for', 'use', 'in', 'discussion', 'forums']",0,"['are', 'there', 'plan', 'to', 'introduce', 'ipython', 'for', 'use', 'in', 'discussion', 'forum']","['plan', 'introduce', 'ipython', 'use', 'discussion', 'forum']",plan introduce ipython use discussion forum,0.0,0.0,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
1314,time series forecasting with categorical variables,Techniques,time series forecasting with categorical variables,"['time', 'series', 'forecasting', 'with', 'categorical', 'variables']",0,"['time', 'series', 'forecasting', 'with', 'categorical', 'variable']","['time', 'series', 'forecasting', 'categorical', 'variable']",time series forecasting categorical variable,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
1315,using scrapy to extract webpages,Tools,using scrapy to extract webpages,"['using', 'scrapy', 'to', 'extract', 'webpages']",0,"['using', 'scrapy', 'to', 'extract', 'webpage']","['using', 'scrapy', 'extract', 'webpage']",using scrapy extract webpage,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
1316,videos from pycon  now available,Resources,videos from pycon  now available,"['videos', 'from', 'pycon', 'now', 'available']",1,"['video', 'from', 'pycon', 'now', 'available']","['video', 'pycon', 'available']",video pycon available,0.4,0.4,5,21,3.5,0,0,0,0,0,0,0,0
1317,error while reading csv file using readtable function in r,Tools,error while reading csv file using readtable function in r,"['error', 'while', 'reading', 'csv', 'file', 'using', 'readtable', 'function', 'in', 'r']",0,"['error', 'while', 'reading', 'csv', 'file', 'using', 'readtable', 'function', 'in', 'r']","['error', 'reading', 'csv', 'file', 'using', 'readtable', 'function', 'r']",error reading csv file using readtable function r,0.0,0.0,10,49,4.454545454545454,0,0,0,0,0,0,0,0
1318,introduce yourself here,Misc,introduce yourself here,"['introduce', 'yourself', 'here']",0,"['introduce', 'yourself', 'here']",['introduce'],introduce,0.0,0.0,3,9,2.25,0,0,0,0,0,0,0,0
1319,validation techniques fro logistic regression,Techniques,validation techniques fro logistic regression,"['validation', 'techniques', 'fro', 'logistic', 'regression']",0,"['validation', 'technique', 'fro', 'logistic', 'regression']","['validation', 'technique', 'fro', 'logistic', 'regression']",validation technique fro logistic regression,0.0,0.0,5,44,7.333333333333333,0,0,0,0,0,0,0,0
1320,why ashodataframe takes long time to send data to cloud and breaks rstudio,Techniques,why ashodataframe takes long time to send data to cloud and breaks rstudio,"['why', 'ashodataframe', 'takes', 'long', 'time', 'to', 'send', 'data', 'to', 'cloud', 'and', 'breaks', 'rstudio']",0,"['why', 'ashodataframe', 'take', 'long', 'time', 'to', 'send', 'data', 'to', 'cloud', 'and', 'break', 'rstudio']","['ashodataframe', 'take', 'long', 'time', 'send', 'data', 'cloud', 'break', 'rstudio']",ashodataframe take long time send data cloud break rstudio,-0.05,-0.05,13,58,4.142857142857143,0,0,0,0,0,0,0,0
1321,missing values for age in training dataset,Hackathons,missing values for age in training dataset,"['missing', 'values', 'for', 'age', 'in', 'training', 'dataset']",0,"['missing', 'value', 'for', 'age', 'in', 'training', 'dataset']","['missing', 'value', 'age', 'training', 'dataset']",missing value age training dataset,-0.2,-0.2,7,34,4.25,0,0,0,0,0,0,0,0
1322,predictive model accuracy calculation format,Techniques,predictive model accuracy calculation format,"['predictive', 'model', 'accuracy', 'calculation', 'format']",0,"['predictive', 'model', 'accuracy', 'calculation', 'format']","['predictive', 'model', 'accuracy', 'calculation', 'format']",predictive model accuracy calculation format,0.0,0.0,5,44,7.333333333333333,0,0,0,0,0,0,0,0
1323,how to set the ticks of a plot in python,Tools,how to set the ticks of a plot in python,"['how', 'to', 'set', 'the', 'ticks', 'of', 'a', 'plot', 'in', 'python']",0,"['how', 'to', 'set', 'the', 'tick', 'of', 'a', 'plot', 'in', 'python']","['set', 'tick', 'plot', 'python']",set tick plot python,0.0,0.0,10,20,1.8181818181818181,0,0,0,0,0,0,0,0
1324,questions related to r,Tools,questions related to r,"['questions', 'related', 'to', 'r']",0,"['question', 'related', 'to', 'r']","['question', 'related', 'r']",question related r,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
1325,extract row  column from dataframe using box plot,Tools,extract row  column from dataframe using box plot,"['extract', 'row', 'column', 'from', 'dataframe', 'using', 'box', 'plot']",0,"['extract', 'row', 'column', 'from', 'dataframe', 'using', 'box', 'plot']","['extract', 'row', 'column', 'dataframe', 'using', 'box', 'plot']",extract row column dataframe using box plot,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
1326,how to import raw data file in sas,Tools,how to import raw data file in sas,"['how', 'to', 'import', 'raw', 'data', 'file', 'in', 'sas']",0,"['how', 'to', 'import', 'raw', 'data', 'file', 'in', 'sa']","['import', 'raw', 'data', 'file', 'sa']",import raw data file sa,-0.2307692307692307,-0.2307692307692307,8,23,2.5555555555555554,0,0,0,0,0,0,0,0
1327,pdf needed for cheatsheet – python  r codes for common machine learning algorithms,Resources,pdf needed for cheatsheet – python  r codes for common machine learning algorithms,"['pdf', 'needed', 'for', 'cheatsheet', '–', 'python', 'r', 'codes', 'for', 'common', 'machine', 'learning', 'algorithms']",0,"['pdf', 'needed', 'for', 'cheatsheet', '–', 'python', 'r', 'code', 'for', 'common', 'machine', 'learning', 'algorithm']","['pdf', 'needed', 'cheatsheet', '–', 'python', 'r', 'code', 'common', 'machine', 'learning', 'algorithm']",pdf needed cheatsheet – python r code common machine learning algorithm,-0.3,-0.3,13,71,5.071428571428571,0,0,0,0,0,0,0,0
1328,reading docx in r,Tools,reading docx in r,"['reading', 'docx', 'in', 'r']",0,"['reading', 'docx', 'in', 'r']","['reading', 'docx', 'r']",reading docx r,0.0,0.0,4,14,2.8,0,0,0,0,0,0,0,0
1329,does ifmr have a data science course,Career,does ifmr have a data science course,"['does', 'ifmr', 'have', 'a', 'data', 'science', 'course']",0,"['doe', 'ifmr', 'have', 'a', 'data', 'science', 'course']","['doe', 'ifmr', 'data', 'science', 'course']",doe ifmr data science course,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
1330,best time series model,Techniques,best time series model,"['best', 'time', 'series', 'model']",0,"['best', 'time', 'series', 'model']","['best', 'time', 'series', 'model']",best time series model,1.0,1.0,4,22,4.4,0,0,0,0,0,0,0,0
1331,why we need ungroup function while grouping more than one variable in dplyr package,Techniques,why we need ungroup function while grouping more than one variable in dplyr package,"['why', 'we', 'need', 'ungroup', 'function', 'while', 'grouping', 'more', 'than', 'one', 'variable', 'in', 'dplyr', 'package']",0,"['why', 'we', 'need', 'ungroup', 'function', 'while', 'grouping', 'more', 'than', 'one', 'variable', 'in', 'dplyr', 'package']","['need', 'ungroup', 'function', 'grouping', 'one', 'variable', 'dplyr', 'package']",need ungroup function grouping one variable dplyr package,0.5,0.0,14,57,3.8,0,0,0,0,0,0,0,0
1332,how can i create user personas using machine learning,Techniques,how can i create user personas using machine learning,"['how', 'can', 'i', 'create', 'user', 'personas', 'using', 'machine', 'learning']",0,"['how', 'can', 'i', 'create', 'user', 'persona', 'using', 'machine', 'learning']","['create', 'user', 'persona', 'using', 'machine', 'learning']",create user persona using machine learning,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
1333,how is the final part after model building is presented to business,Other,how is the final part after model building is presented to business,"['how', 'is', 'the', 'final', 'part', 'after', 'model', 'building', 'is', 'presented', 'to', 'business']",0,"['how', 'is', 'the', 'final', 'part', 'after', 'model', 'building', 'is', 'presented', 'to', 'business']","['final', 'part', 'model', 'building', 'presented', 'business']",final part model building presented business,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
1334,support vector regression scikit learn giving the same value,Techniques,support vector regression scikit learn giving the same value,"['support', 'vector', 'regression', 'scikit', 'learn', 'giving', 'the', 'same', 'value']",0,"['support', 'vector', 'regression', 'scikit', 'learn', 'giving', 'the', 'same', 'value']","['support', 'vector', 'regression', 'scikit', 'learn', 'giving', 'value']",support vector regression scikit learn giving value,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
1335,which metric to consider for regression r or rmse,Techniques,which metric to consider for regression r or rmse,"['which', 'metric', 'to', 'consider', 'for', 'regression', 'r', 'or', 'rmse']",0,"['which', 'metric', 'to', 'consider', 'for', 'regression', 'r', 'or', 'rmse']","['metric', 'consider', 'regression', 'r', 'rmse']",metric consider regression r rmse,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
1336,qwe asd zxc qwe asfg zxcscript,Other,qwe asd zxc qwe asfg zxcscript,"['qwe', 'asd', 'zxc', 'qwe', 'asfg', 'zxcscript']",0,"['qwe', 'asd', 'zxc', 'qwe', 'asfg', 'zxcscript']","['qwe', 'asd', 'zxc', 'qwe', 'asfg', 'zxcscript']",qwe asd zxc qwe asfg zxcscript,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
1337,is knowledge of tableau sufficient to be a data analyst,Career,is knowledge of tableau sufficient to be a data analyst,"['is', 'knowledge', 'of', 'tableau', 'sufficient', 'to', 'be', 'a', 'data', 'analyst']",0,"['is', 'knowledge', 'of', 'tableau', 'sufficient', 'to', 'be', 'a', 'data', 'analyst']","['knowledge', 'tableau', 'sufficient', 'data', 'analyst']",knowledge tableau sufficient data analyst,0.0,0.0,10,41,3.727272727272727,0,0,0,0,0,0,0,0
1338,what is logic behind getting the string with max length from the strings that even length in r,Techniques,what is logic behind getting the string with max length from the strings that even length in r,"['what', 'is', 'logic', 'behind', 'getting', 'the', 'string', 'with', 'max', 'length', 'from', 'the', 'strings', 'that', 'even', 'length', 'in', 'r']",0,"['what', 'is', 'logic', 'behind', 'getting', 'the', 'string', 'with', 'max', 'length', 'from', 'the', 'string', 'that', 'even', 'length', 'in', 'r']","['logic', 'behind', 'getting', 'string', 'max', 'length', 'string', 'even', 'length', 'r']",logic behind getting string max length string even length r,-0.4,-0.4,18,59,3.1052631578947367,0,0,0,0,0,0,0,0
1339,download pdf version of cheat sheet on data exploration in python,Tools,download pdf version of cheat sheet on data exploration in python,"['download', 'pdf', 'version', 'of', 'cheat', 'sheet', 'on', 'data', 'exploration', 'in', 'python']",0,"['download', 'pdf', 'version', 'of', 'cheat', 'sheet', 'on', 'data', 'exploration', 'in', 'python']","['download', 'pdf', 'version', 'cheat', 'sheet', 'data', 'exploration', 'python']",download pdf version cheat sheet data exploration python,0.0,0.0,11,56,4.666666666666667,0,0,0,0,0,0,0,0
1340,how to return original string after measuring distance,Techniques,how to return original string after measuring distance,"['how', 'to', 'return', 'original', 'string', 'after', 'measuring', 'distance']",0,"['how', 'to', 'return', 'original', 'string', 'after', 'measuring', 'distance']","['return', 'original', 'string', 'measuring', 'distance']",return original string measuring distance,0.375,0.375,8,41,4.555555555555555,0,0,0,0,0,0,0,0
1341,genetic algorithms,Other,genetic algorithms,"['genetic', 'algorithms']",0,"['genetic', 'algorithm']","['genetic', 'algorithm']",genetic algorithm,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
1342,difference between seasonal  nonseasonal ordering,Techniques,difference between seasonal  nonseasonal ordering,"['difference', 'between', 'seasonal', 'nonseasonal', 'ordering']",0,"['difference', 'between', 'seasonal', 'nonseasonal', 'ordering']","['difference', 'seasonal', 'nonseasonal', 'ordering']",difference seasonal nonseasonal ordering,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
1343,how to convert a ratings data frame to a ratings matrix in r,Tools,how to convert a ratings data frame to a ratings matrix in r,"['how', 'to', 'convert', 'a', 'ratings', 'data', 'frame', 'to', 'a', 'ratings', 'matrix', 'in', 'r']",0,"['how', 'to', 'convert', 'a', 'rating', 'data', 'frame', 'to', 'a', 'rating', 'matrix', 'in', 'r']","['convert', 'rating', 'data', 'frame', 'rating', 'matrix', 'r']",convert rating data frame rating matrix r,0.0,0.0,13,41,2.9285714285714284,0,0,0,0,0,0,0,0
1344,time delay neural netwroks,Techniques,time delay neural netwroks,"['time', 'delay', 'neural', 'netwroks']",0,"['time', 'delay', 'neural', 'netwroks']","['time', 'delay', 'neural', 'netwroks']",time delay neural netwroks,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
1345,feedback  online hackathon,Hackathons,feedback  online hackathon,"['feedback', 'online', 'hackathon']",0,"['feedback', 'online', 'hackathon']","['feedback', 'online', 'hackathon']",feedback online hackathon,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
1346,what are the advantages and disadvantages of arima model,Techniques,what are the advantages and disadvantages of arima model,"['what', 'are', 'the', 'advantages', 'and', 'disadvantages', 'of', 'arima', 'model']",0,"['what', 'are', 'the', 'advantage', 'and', 'disadvantage', 'of', 'arima', 'model']","['advantage', 'disadvantage', 'arima', 'model']",advantage disadvantage arima model,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
1347,how to deal with missing values in predicted data in confusion matrix,Techniques,how to deal with missing values in predicted data in confusion matrix,"['how', 'to', 'deal', 'with', 'missing', 'values', 'in', 'predicted', 'data', 'in', 'confusion', 'matrix']",0,"['how', 'to', 'deal', 'with', 'missing', 'value', 'in', 'predicted', 'data', 'in', 'confusion', 'matrix']","['deal', 'missing', 'value', 'predicted', 'data', 'confusion', 'matrix']",deal missing value predicted data confusion matrix,-0.2,-0.2,12,50,3.8461538461538463,0,0,0,0,0,0,0,0
1348,boolean indexing pandas,Techniques,boolean indexing pandas,"['boolean', 'indexing', 'pandas']",0,"['boolean', 'indexing', 'panda']","['boolean', 'indexing', 'panda']",boolean indexing panda,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
1349,how to find a right machine learning algorithm for the given problem,Techniques,how to find a right machine learning algorithm for the given problem,"['how', 'to', 'find', 'a', 'right', 'machine', 'learning', 'algorithm', 'for', 'the', 'given', 'problem']",0,"['how', 'to', 'find', 'a', 'right', 'machine', 'learning', 'algorithm', 'for', 'the', 'given', 'problem']","['find', 'right', 'machine', 'learning', 'algorithm', 'given', 'problem']",find right machine learning algorithm given problem,0.2857142857142857,0.2857142857142857,12,51,3.923076923076923,0,0,0,0,0,0,0,0
1350,knowledge about business analyst as a career and difference between data analyst and business analyst,Career,knowledge about business analyst as a career and difference between data analyst and business analyst,"['knowledge', 'about', 'business', 'analyst', 'as', 'a', 'career', 'and', 'difference', 'between', 'data', 'analyst', 'and', 'business', 'analyst']",0,"['knowledge', 'about', 'business', 'analyst', 'a', 'a', 'career', 'and', 'difference', 'between', 'data', 'analyst', 'and', 'business', 'analyst']","['knowledge', 'business', 'analyst', 'career', 'difference', 'data', 'analyst', 'business', 'analyst']",knowledge business analyst career difference data analyst business analyst,0.0,0.0,15,74,4.625,0,0,0,0,0,0,0,0
1351,advice required from ds experts,Career,advice required from ds experts,"['advice', 'required', 'from', 'ds', 'experts']",0,"['advice', 'required', 'from', 'd', 'expert']","['advice', 'required', 'expert']",advice required expert,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
1352,masters in data science,Career,masters in data science,"['masters', 'in', 'data', 'science']",0,"['master', 'in', 'data', 'science']","['master', 'data', 'science']",master data science,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
1353,how to parse large xml files,Tools,how to parse large xml files,"['how', 'to', 'parse', 'large', 'xml', 'files']",0,"['how', 'to', 'parse', 'large', 'xml', 'file']","['parse', 'large', 'xml', 'file']",parse large xml file,0.2142857142857142,0.2142857142857142,6,20,2.857142857142857,0,0,0,0,0,0,0,0
1354,how to handle an unbalanced dataset,Techniques,how to handle an unbalanced dataset,"['how', 'to', 'handle', 'an', 'unbalanced', 'dataset']",0,"['how', 'to', 'handle', 'an', 'unbalanced', 'dataset']","['handle', 'unbalanced', 'dataset']",handle unbalanced dataset,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
1355,thread for recommendation engine challenge by ibm,Hackathons,thread for recommendation engine challenge by ibm,"['thread', 'for', 'recommendation', 'engine', 'challenge', 'by', 'ibm']",0,"['thread', 'for', 'recommendation', 'engine', 'challenge', 'by', 'ibm']","['thread', 'recommendation', 'engine', 'challenge', 'ibm']",thread recommendation engine challenge ibm,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
1356,how to subset a sas dataset,Tools,how to subset a sas dataset,"['how', 'to', 'subset', 'a', 'sas', 'dataset']",0,"['how', 'to', 'subset', 'a', 'sa', 'dataset']","['subset', 'sa', 'dataset']",subset sa dataset,0.0,0.0,6,17,2.4285714285714284,0,0,0,0,0,0,0,0
1357,how to start with python,Tools,how to start with python,"['how', 'to', 'start', 'with', 'python']",0,"['how', 'to', 'start', 'with', 'python']","['start', 'python']",start python,0.0,0.0,5,12,2.0,0,0,0,0,0,0,0,0
1358,what does the oob estimate of error in a randomforest model imply,Techniques,what does the oob estimate of error in a randomforest model imply,"['what', 'does', 'the', 'oob', 'estimate', 'of', 'error', 'in', 'a', 'randomforest', 'model', 'imply']",0,"['what', 'doe', 'the', 'oob', 'estimate', 'of', 'error', 'in', 'a', 'randomforest', 'model', 'imply']","['doe', 'oob', 'estimate', 'error', 'randomforest', 'model', 'imply']",doe oob estimate error randomforest model imply,0.0,0.0,12,47,3.6153846153846154,0,0,0,0,0,0,0,0
1359,is india ready for cyber revolution especially security wise,Misc,is india ready for cyber revolution especially security wise,"['is', 'india', 'ready', 'for', 'cyber', 'revolution', 'especially', 'security', 'wise']",0,"['is', 'india', 'ready', 'for', 'cyber', 'revolution', 'especially', 'security', 'wise']","['india', 'ready', 'cyber', 'revolution', 'especially', 'security', 'wise']",india ready cyber revolution especially security wise,0.3,0.3,9,53,5.3,0,0,0,0,0,0,0,0
1360,image processing using cnn,Tools,image processing using cnn,"['image', 'processing', 'using', 'cnn']",0,"['image', 'processing', 'using', 'cnn']","['image', 'processing', 'using', 'cnn']",image processing using cnn,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
1361,how to interpret the scores generated from factor analysis in r,Techniques,how to interpret the scores generated from factor analysis in r,"['how', 'to', 'interpret', 'the', 'scores', 'generated', 'from', 'factor', 'analysis', 'in', 'r']",0,"['how', 'to', 'interpret', 'the', 'score', 'generated', 'from', 'factor', 'analysis', 'in', 'r']","['interpret', 'score', 'generated', 'factor', 'analysis', 'r']",interpret score generated factor analysis r,0.0,0.0,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
1362,need help how to create a histogram for certain conditional statements,Techniques,need help how to create a histogram for certain conditional statements,"['need', 'help', 'how', 'to', 'create', 'a', 'histogram', 'for', 'certain', 'conditional', 'statements']",0,"['need', 'help', 'how', 'to', 'create', 'a', 'histogram', 'for', 'certain', 'conditional', 'statement']","['need', 'help', 'create', 'histogram', 'certain', 'conditional', 'statement']",need help create histogram certain conditional statement,0.2142857142857142,0.2142857142857142,11,56,4.666666666666667,0,0,0,0,0,0,0,0
1363,calculating the  of records correctly identified by random forests in r,Tools,calculating the  of records correctly identified by random forests in r,"['calculating', 'the', 'of', 'records', 'correctly', 'identified', 'by', 'random', 'forests', 'in', 'r']",0,"['calculating', 'the', 'of', 'record', 'correctly', 'identified', 'by', 'random', 'forest', 'in', 'r']","['calculating', 'record', 'correctly', 'identified', 'random', 'forest', 'r']",calculating record correctly identified random forest r,-0.5,-0.5,11,55,4.583333333333333,0,0,0,0,0,0,0,0
1364,facing error while implementing xgboost model on a classification problem,Techniques,facing error while implementing xgboost model on a classification problem,"['facing', 'error', 'while', 'implementing', 'xgboost', 'model', 'on', 'a', 'classification', 'problem']",0,"['facing', 'error', 'while', 'implementing', 'xgboost', 'model', 'on', 'a', 'classification', 'problem']","['facing', 'error', 'implementing', 'xgboost', 'model', 'classification', 'problem']",facing error implementing xgboost model classification problem,0.0,0.0,10,62,5.636363636363637,0,0,0,0,0,0,0,0
1365,how to create an ensemble of naive bayes models,Techniques,how to create an ensemble of naive bayes models,"['how', 'to', 'create', 'an', 'ensemble', 'of', 'naive', 'bayes', 'models']",0,"['how', 'to', 'create', 'an', 'ensemble', 'of', 'naive', 'bayes', 'model']","['create', 'ensemble', 'naive', 'bayes', 'model']",create ensemble naive bayes model,-0.3,-0.3,9,33,3.3,0,0,0,0,0,0,0,0
1366,open data base for data analysis,Resources,open data base for data analysis,"['open', 'data', 'base', 'for', 'data', 'analysis']",0,"['open', 'data', 'base', 'for', 'data', 'analysis']","['open', 'data', 'base', 'data', 'analysis']",open data base data analysis,-0.4,-0.4,6,28,4.0,0,0,0,0,0,0,0,0
1367,how to deal with errors regression which are not following normal distribution,Techniques,how to deal with errors regression which are not following normal distribution,"['how', 'to', 'deal', 'with', 'errors', 'regression', 'which', 'are', 'not', 'following', 'normal', 'distribution']",0,"['how', 'to', 'deal', 'with', 'error', 'regression', 'which', 'are', 'not', 'following', 'normal', 'distribution']","['deal', 'error', 'regression', 'following', 'normal', 'distribution']",deal error regression following normal distribution,0.075,0.075,12,51,3.923076923076923,0,0,0,0,0,0,0,0
1368,technical question asked in an analytics interview,Career,technical question asked in an analytics interview,"['technical', 'question', 'asked', 'in', 'an', 'analytics', 'interview']",0,"['technical', 'question', 'asked', 'in', 'an', 'analytics', 'interview']","['technical', 'question', 'asked', 'analytics', 'interview']",technical question asked analytics interview,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
1369,how to pass an ho object to model in r using the ho library,Tools,how to pass an ho object to model in r using the ho library,"['how', 'to', 'pass', 'an', 'ho', 'object', 'to', 'model', 'in', 'r', 'using', 'the', 'ho', 'library']",0,"['how', 'to', 'pas', 'an', 'ho', 'object', 'to', 'model', 'in', 'r', 'using', 'the', 'ho', 'library']","['pas', 'ho', 'object', 'model', 'r', 'using', 'ho', 'library']",pas ho object model r using ho library,0.0,0.0,14,38,2.533333333333333,0,0,0,0,0,0,0,0
1370,accuracy of point and interval estimator,Techniques,accuracy of point and interval estimator,"['accuracy', 'of', 'point', 'and', 'interval', 'estimator']",0,"['accuracy', 'of', 'point', 'and', 'interval', 'estimator']","['accuracy', 'point', 'interval', 'estimator']",accuracy point interval estimator,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
1371,web scraping in python,Tools,web scraping in python,"['web', 'scraping', 'in', 'python']",0,"['web', 'scraping', 'in', 'python']","['web', 'scraping', 'python']",web scraping python,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
1372,regular intervals  time series analysis,Techniques,regular intervals  time series analysis,"['regular', 'intervals', 'time', 'series', 'analysis']",0,"['regular', 'interval', 'time', 'series', 'analysis']","['regular', 'interval', 'time', 'series', 'analysis']",regular interval time series analysis,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
1373,arima for discrete data,Techniques,arima for discrete data,"['arima', 'for', 'discrete', 'data']",0,"['arima', 'for', 'discrete', 'data']","['arima', 'discrete', 'data']",arima discrete data,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
1374,advice on which subjects to choose during phd curriculam,Career,advice on which subjects to choose during phd curriculam,"['advice', 'on', 'which', 'subjects', 'to', 'choose', 'during', 'phd', 'curriculam']",0,"['advice', 'on', 'which', 'subject', 'to', 'choose', 'during', 'phd', 'curriculam']","['advice', 'subject', 'choose', 'phd', 'curriculam']",advice subject choose phd curriculam,0.0,-0.1666666666666666,9,36,3.6,0,0,0,0,0,0,0,0
1375,warning while passing the arguments in traincontrol,Techniques,warning while passing the arguments in traincontrol,"['warning', 'while', 'passing', 'the', 'arguments', 'in', 'traincontrol']",0,"['warning', 'while', 'passing', 'the', 'argument', 'in', 'traincontrol']","['warning', 'passing', 'argument', 'traincontrol']",warning passing argument traincontrol,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
1376,getting na values while converting a variable into date and time format,Tools,getting na values while converting a variable into date and time format,"['getting', 'na', 'values', 'while', 'converting', 'a', 'variable', 'into', 'date', 'and', 'time', 'format']",0,"['getting', 'na', 'value', 'while', 'converting', 'a', 'variable', 'into', 'date', 'and', 'time', 'format']","['getting', 'na', 'value', 'converting', 'variable', 'date', 'time', 'format']",getting na value converting variable date time format,0.0,0.0,12,53,4.076923076923077,0,0,0,0,0,0,0,0
1377,sparkjson file reading problem,Techniques,sparkjson file reading problem,"['sparkjson', 'file', 'reading', 'problem']",0,"['sparkjson', 'file', 'reading', 'problem']","['sparkjson', 'file', 'reading', 'problem']",sparkjson file reading problem,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
1378,need some assistance with data wrangling in r,Tools,need some assistance with data wrangling in r,"['need', 'some', 'assistance', 'with', 'data', 'wrangling', 'in', 'r']",0,"['need', 'some', 'assistance', 'with', 'data', 'wrangling', 'in', 'r']","['need', 'assistance', 'data', 'wrangling', 'r']",need assistance data wrangling r,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
1379,how do i process new data and mark it as fraud or not fraud in random forest model,Techniques,how do i process new data and mark it as fraud or not fraud in random forest model,"['how', 'do', 'i', 'process', 'new', 'data', 'and', 'mark', 'it', 'as', 'fraud', 'or', 'not', 'fraud', 'in', 'random', 'forest', 'model']",0,"['how', 'do', 'i', 'process', 'new', 'data', 'and', 'mark', 'it', 'a', 'fraud', 'or', 'not', 'fraud', 'in', 'random', 'forest', 'model']","['process', 'new', 'data', 'mark', 'fraud', 'fraud', 'random', 'forest', 'model']",process new data mark fraud fraud random forest model,-0.1818181818181818,-0.1818181818181818,18,53,2.789473684210526,0,0,0,0,0,0,0,0
1380,what is difference between systime and rprofiler in r,Tools,what is difference between systime and rprofiler in r,"['what', 'is', 'difference', 'between', 'systime', 'and', 'rprofiler', 'in', 'r']",0,"['what', 'is', 'difference', 'between', 'systime', 'and', 'rprofiler', 'in', 'r']","['difference', 'systime', 'rprofiler', 'r']",difference systime rprofiler r,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
1381,building a regression model with all independent variables being cataegorical,Techniques,building a regression model with all independent variables being cataegorical,"['building', 'a', 'regression', 'model', 'with', 'all', 'independent', 'variables', 'being', 'cataegorical']",0,"['building', 'a', 'regression', 'model', 'with', 'all', 'independent', 'variable', 'being', 'cataegorical']","['building', 'regression', 'model', 'independent', 'variable', 'cataegorical']",building regression model independent variable cataegorical,0.0,0.0,10,59,5.363636363636363,0,0,0,0,0,0,0,0
1382,machine learning model to detect items related to nature,Techniques,machine learning model to detect items related to nature,"['machine', 'learning', 'model', 'to', 'detect', 'items', 'related', 'to', 'nature']",0,"['machine', 'learning', 'model', 'to', 'detect', 'item', 'related', 'to', 'nature']","['machine', 'learning', 'model', 'detect', 'item', 'related', 'nature']",machine learning model detect item related nature,0.0,0.0,9,49,4.9,0,0,0,0,0,0,0,0
1383,how can i link pivot table in excel with sas data set,Tools,how can i link pivot table in excel with sas data set,"['how', 'can', 'i', 'link', 'pivot', 'table', 'in', 'excel', 'with', 'sas', 'data', 'set']",0,"['how', 'can', 'i', 'link', 'pivot', 'table', 'in', 'excel', 'with', 'sa', 'data', 'set']","['link', 'pivot', 'table', 'excel', 'sa', 'data', 'set']",link pivot table excel sa data set,0.0,0.0,12,34,2.6153846153846154,0,0,0,0,0,0,0,0
1384,multivariate data analysis,Techniques,multivariate data analysis,"['multivariate', 'data', 'analysis']",0,"['multivariate', 'data', 'analysis']","['multivariate', 'data', 'analysis']",multivariate data analysis,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
1385,what should a fresher planing a career in analytics opt from these elite institutes,Career,what should a fresher planing a career in analytics opt from these elite institutes,"['what', 'should', 'a', 'fresher', 'planing', 'a', 'career', 'in', 'analytics', 'opt', 'from', 'these', 'elite', 'institutes']",0,"['what', 'should', 'a', 'fresher', 'planing', 'a', 'career', 'in', 'analytics', 'opt', 'from', 'these', 'elite', 'institute']","['fresher', 'planing', 'career', 'analytics', 'opt', 'elite', 'institute']",fresher planing career analytics opt elite institute,0.0,0.0,14,52,3.466666666666667,0,0,0,0,0,0,0,0
1386,boruta feature selection package  implementation,Tools,boruta feature selection package  implementation,"['boruta', 'feature', 'selection', 'package', 'implementation']",0,"['boruta', 'feature', 'selection', 'package', 'implementation']","['boruta', 'feature', 'selection', 'package', 'implementation']",boruta feature selection package implementation,0.0,0.0,5,47,7.833333333333333,0,0,0,0,0,0,0,0
1387,pseudo labeling  semi supervised learning,Hackathons,pseudo labeling  semi supervised learning,"['pseudo', 'labeling', 'semi', 'supervised', 'learning']",0,"['pseudo', 'labeling', 'semi', 'supervised', 'learning']","['pseudo', 'labeling', 'semi', 'supervised', 'learning']",pseudo labeling semi supervised learning,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
1388,test to find similar products,Techniques,test to find similar products,"['test', 'to', 'find', 'similar', 'products']",0,"['test', 'to', 'find', 'similar', 'product']","['test', 'find', 'similar', 'product']",test find similar product,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
1389,data merging in pythondata minig,Techniques,data merging in pythondata minig,"['data', 'merging', 'in', 'pythondata', 'minig']",0,"['data', 'merging', 'in', 'pythondata', 'minig']","['data', 'merging', 'pythondata', 'minig']",data merging pythondata minig,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
1390,count distinct using over clause,Tools,count distinct using over clause,"['count', 'distinct', 'using', 'over', 'clause']",0,"['count', 'distinct', 'using', 'over', 'clause']","['count', 'distinct', 'using', 'clause']",count distinct using clause,0.3,0.3,5,27,4.5,0,0,0,0,0,0,0,0
1391,how to build sas type custom formats in r,Tools,how to build sas type custom formats in r,"['how', 'to', 'build', 'sas', 'type', 'custom', 'formats', 'in', 'r']",0,"['how', 'to', 'build', 'sa', 'type', 'custom', 'format', 'in', 'r']","['build', 'sa', 'type', 'custom', 'format', 'r']",build sa type custom format r,0.0,0.0,9,29,2.9,0,0,0,0,0,0,0,0
1392,confusion matrix creation in predictive modeling in experiments with data,Other,confusion matrix creation in predictive modeling in experiments with data,"['confusion', 'matrix', 'creation', 'in', 'predictive', 'modeling', 'in', 'experiments', 'with', 'data']",0,"['confusion', 'matrix', 'creation', 'in', 'predictive', 'modeling', 'in', 'experiment', 'with', 'data']","['confusion', 'matrix', 'creation', 'predictive', 'modeling', 'experiment', 'data']",confusion matrix creation predictive modeling experiment data,0.0,0.0,10,61,5.545454545454546,0,0,0,0,0,0,0,0
1393,weekday training for data science in delhi ncrgurgaon,Career,weekday training for data science in delhi ncrgurgaon,"['weekday', 'training', 'for', 'data', 'science', 'in', 'delhi', 'ncrgurgaon']",0,"['weekday', 'training', 'for', 'data', 'science', 'in', 'delhi', 'ncrgurgaon']","['weekday', 'training', 'data', 'science', 'delhi', 'ncrgurgaon']",weekday training data science delhi ncrgurgaon,0.0,0.0,8,46,5.111111111111111,0,0,0,0,0,0,0,0
1394,how to calculate the length of whisker in a box plot,Techniques,how to calculate the length of whisker in a box plot,"['how', 'to', 'calculate', 'the', 'length', 'of', 'whisker', 'in', 'a', 'box', 'plot']",0,"['how', 'to', 'calculate', 'the', 'length', 'of', 'whisker', 'in', 'a', 'box', 'plot']","['calculate', 'length', 'whisker', 'box', 'plot']",calculate length whisker box plot,0.0,0.0,11,33,2.75,0,0,0,0,0,0,0,0
1395,why it is necessary that in svm the output should be a factor level,Techniques,why it is necessary that in svm the output should be a factor level,"['why', 'it', 'is', 'necessary', 'that', 'in', 'svm', 'the', 'output', 'should', 'be', 'a', 'factor', 'level']",0,"['why', 'it', 'is', 'necessary', 'that', 'in', 'svm', 'the', 'output', 'should', 'be', 'a', 'factor', 'level']","['necessary', 'svm', 'output', 'factor', 'level']",necessary svm output factor level,0.0,0.0,14,33,2.2,0,0,0,0,0,0,0,0
1396,creating predictive modelling in knime,Tools,creating predictive modelling in knime,"['creating', 'predictive', 'modelling', 'in', 'knime']",0,"['creating', 'predictive', 'modelling', 'in', 'knime']","['creating', 'predictive', 'modelling', 'knime']",creating predictive modelling knime,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
1397,need help in getting any endtoend big data analytics case studies,Resources,need help in getting any endtoend big data analytics case studies,"['need', 'help', 'in', 'getting', 'any', 'endtoend', 'big', 'data', 'analytics', 'case', 'studies']",0,"['need', 'help', 'in', 'getting', 'any', 'endtoend', 'big', 'data', 'analytics', 'case', 'study']","['need', 'help', 'getting', 'endtoend', 'big', 'data', 'analytics', 'case', 'study']",need help getting endtoend big data analytics case study,0.0,0.0,11,56,4.666666666666667,0,0,0,0,0,0,0,0
1398,how to fill nan values,Hackathons,how to fill nan values,"['how', 'to', 'fill', 'nan', 'values']",0,"['how', 'to', 'fill', 'nan', 'value']","['fill', 'nan', 'value']",fill nan value,0.0,0.0,5,14,2.3333333333333335,0,0,0,0,0,0,0,0
1399,best way to obtain data from a nested json dataset,Techniques,best way to obtain data from a nested json dataset,"['best', 'way', 'to', 'obtain', 'data', 'from', 'a', 'nested', 'json', 'dataset']",0,"['best', 'way', 'to', 'obtain', 'data', 'from', 'a', 'nested', 'json', 'dataset']","['best', 'way', 'obtain', 'data', 'nested', 'json', 'dataset']",best way obtain data nested json dataset,1.0,1.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
1400,error in colmeansx narm  true  x must be numeric,Techniques,error in colmeansx narm  true  x must be numeric,"['error', 'in', 'colmeansx', 'narm', 'true', 'x', 'must', 'be', 'numeric']",0,"['error', 'in', 'colmeansx', 'narm', 'true', 'x', 'must', 'be', 'numeric']","['error', 'colmeansx', 'narm', 'true', 'x', 'must', 'numeric']",error colmeansx narm true x must numeric,0.35,0.35,9,40,4.0,0,0,0,0,0,0,0,0
1401,xgboosterror label set cannot be empty,Tools,xgboosterror label set cannot be empty,"['xgboosterror', 'label', 'set', 'can', 'not', 'be', 'empty']",0,"['xgboosterror', 'label', 'set', 'can', 'not', 'be', 'empty']","['xgboosterror', 'label', 'set', 'empty']",xgboosterror label set empty,-0.1,-0.1,7,28,3.5,0,0,0,0,0,0,0,0
1402,syntax issue  responsecsstitletextextract is returning a null set,Techniques,syntax issue  responsecsstitletextextract is returning a null set,"['syntax', 'issue', 'responsecsstitletextextract', 'is', 'returning', 'a', 'null', 'set']",0,"['syntax', 'issue', 'responsecsstitletextextract', 'is', 'returning', 'a', 'null', 'set']","['syntax', 'issue', 'responsecsstitletextextract', 'returning', 'null', 'set']",syntax issue responsecsstitletextextract returning null set,0.0,0.0,8,59,6.555555555555555,0,0,0,0,0,0,0,0
1403,what is the difference between pca and variable selection,Techniques,what is the difference between pca and variable selection,"['what', 'is', 'the', 'difference', 'between', 'pca', 'and', 'variable', 'selection']",0,"['what', 'is', 'the', 'difference', 'between', 'pca', 'and', 'variable', 'selection']","['difference', 'pca', 'variable', 'selection']",difference pca variable selection,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
1404,what is the difference between various methods used for correlation in r,Tools,what is the difference between various methods used for correlation in r,"['what', 'is', 'the', 'difference', 'between', 'various', 'methods', 'used', 'for', 'correlation', 'in', 'r']",0,"['what', 'is', 'the', 'difference', 'between', 'various', 'method', 'used', 'for', 'correlation', 'in', 'r']","['difference', 'various', 'method', 'used', 'correlation', 'r']",difference various method used correlation r,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
1405,resume screening,Techniques,resume screening,"['resume', 'screening']",0,"['resume', 'screening']","['resume', 'screening']",resume screening,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
1406,neural networks in r,Tools,neural networks in r,"['neural', 'networks', 'in', 'r']",0,"['neural', 'network', 'in', 'r']","['neural', 'network', 'r']",neural network r,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
1407,correlated predictors in a multiple regression model,Techniques,correlated predictors in a multiple regression model,"['correlated', 'predictors', 'in', 'a', 'multiple', 'regression', 'model']",0,"['correlated', 'predictor', 'in', 'a', 'multiple', 'regression', 'model']","['correlated', 'predictor', 'multiple', 'regression', 'model']",correlated predictor multiple regression model,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
1408,what should be number of components in pca,Techniques,what should be number of components in pca,"['what', 'should', 'be', 'number', 'of', 'components', 'in', 'pca']",0,"['what', 'should', 'be', 'number', 'of', 'component', 'in', 'pca']","['number', 'component', 'pca']",number component pca,0.0,0.0,8,20,2.2222222222222223,0,0,0,0,0,0,0,0
1409,how to proceed with analysis from a single data file  variablescolumns and without proper information about the variables,Techniques,how to proceed with analysis from a single data file  variablescolumns and without proper information about the variables,"['how', 'to', 'proceed', 'with', 'analysis', 'from', 'a', 'single', 'data', 'file', 'variablescolumns', 'and', 'without', 'proper', 'information', 'about', 'the', 'variables']",1,"['how', 'to', 'proceed', 'with', 'analysis', 'from', 'a', 'single', 'data', 'file', 'variablescolumns', 'and', 'without', 'proper', 'information', 'about', 'the', 'variable']","['proceed', 'analysis', 'single', 'data', 'file', 'variablescolumns', 'without', 'proper', 'information', 'variable']",proceed analysis single data file variablescolumns without proper information variable,-0.0357142857142857,-0.0357142857142857,18,86,4.526315789473684,0,0,0,0,0,0,0,0
1410,what are most sought after certifications in data science,Career,what are most sought after certifications in data science,"['what', 'are', 'most', 'sought', 'after', 'certifications', 'in', 'data', 'science']",0,"['what', 'are', 'most', 'sought', 'after', 'certification', 'in', 'data', 'science']","['sought', 'certification', 'data', 'science']",sought certification data science,0.5,0.0,9,33,3.3,0,0,0,0,0,0,0,0
1411,how to get into the analytics field,Career,how to get into the analytics field,"['how', 'to', 'get', 'into', 'the', 'analytics', 'field']",0,"['how', 'to', 'get', 'into', 'the', 'analytics', 'field']","['get', 'analytics', 'field']",get analytics field,0.0,0.0,7,19,2.375,0,0,0,0,0,0,0,0
1412,how to prove causation with confidence for telecommunications data,Techniques,how to prove causation with confidence for telecommunications data,"['how', 'to', 'prove', 'causation', 'with', 'confidence', 'for', 'telecommunications', 'data']",0,"['how', 'to', 'prove', 'causation', 'with', 'confidence', 'for', 'telecommunication', 'data']","['prove', 'causation', 'confidence', 'telecommunication', 'data']",prove causation confidence telecommunication data,0.0,0.0,9,49,4.9,0,0,0,0,0,0,0,0
1413,fresher to data science where to start from,Career,fresher to data science where to start from,"['fresher', 'to', 'data', 'science', 'where', 'to', 'start', 'from']",0,"['fresher', 'to', 'data', 'science', 'where', 'to', 'start', 'from']","['fresher', 'data', 'science', 'start']",fresher data science start,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
1414,what is the difference in type of recommendation engines and how to decide which one to use,Techniques,what is the difference in type of recommendation engines and how to decide which one to use,"['what', 'is', 'the', 'difference', 'in', 'type', 'of', 'recommendation', 'engines', 'and', 'how', 'to', 'decide', 'which', 'one', 'to', 'use']",0,"['what', 'is', 'the', 'difference', 'in', 'type', 'of', 'recommendation', 'engine', 'and', 'how', 'to', 'decide', 'which', 'one', 'to', 'use']","['difference', 'type', 'recommendation', 'engine', 'decide', 'one', 'use']",difference type recommendation engine decide one use,0.0,0.0,17,52,2.888888888888889,0,0,0,0,0,0,0,0
1415,api implementation with bigml how it works,Tools,api implementation with bigml how it works,"['api', 'implementation', 'with', 'bigml', 'how', 'it', 'works']",0,"['api', 'implementation', 'with', 'bigml', 'how', 'it', 'work']","['api', 'implementation', 'bigml', 'work']",api implementation bigml work,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
1416,best analytics program to make a career shift,Career,best analytics program to make a career shift,"['best', 'analytics', 'program', 'to', 'make', 'a', 'career', 'shift']",0,"['best', 'analytics', 'program', 'to', 'make', 'a', 'career', 'shift']","['best', 'analytics', 'program', 'make', 'career', 'shift']",best analytics program make career shift,1.0,1.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
1417,finding joint probabilities in multi label classification,Techniques,finding joint probabilities in multi label classification,"['finding', 'joint', 'probabilities', 'in', 'multi', 'label', 'classification']",0,"['finding', 'joint', 'probability', 'in', 'multi', 'label', 'classification']","['finding', 'joint', 'probability', 'multi', 'label', 'classification']",finding joint probability multi label classification,0.0,0.0,7,52,6.5,0,0,0,0,0,0,0,0
1418,building a guide for amazon redshift and need feedback,Resources,building a guide for amazon redshift and need feedback,"['building', 'a', 'guide', 'for', 'amazon', 'redshift', 'and', 'need', 'feedback']",0,"['building', 'a', 'guide', 'for', 'amazon', 'redshift', 'and', 'need', 'feedback']","['building', 'guide', 'amazon', 'redshift', 'need', 'feedback']",building guide amazon redshift need feedback,0.0,0.0,9,44,4.4,0,0,0,0,0,0,0,0
1419,a guide for those trying to find whats the best course for you,Career,a guide for those trying to find whats the best course for you,"['a', 'guide', 'for', 'those', 'trying', 'to', 'find', 'whats', 'the', 'best', 'course', 'for', 'you']",0,"['a', 'guide', 'for', 'those', 'trying', 'to', 'find', 'whats', 'the', 'best', 'course', 'for', 'you']","['guide', 'trying', 'find', 'whats', 'best', 'course']",guide trying find whats best course,1.0,1.0,13,35,2.5,0,0,0,0,0,0,0,0
1420,error converting string to float using fittransform,Techniques,error converting string to float using fittransform,"['error', 'converting', 'string', 'to', 'float', 'using', 'fittransform']",0,"['error', 'converting', 'string', 'to', 'float', 'using', 'fittransform']","['error', 'converting', 'string', 'float', 'using', 'fittransform']",error converting string float using fittransform,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
1421,how to compute ma coefficients when it is an ma model,Techniques,how to compute ma coefficients when it is an ma model,"['how', 'to', 'compute', 'ma', 'coefficients', 'when', 'it', 'is', 'an', 'ma', 'model']",0,"['how', 'to', 'compute', 'ma', 'coefficient', 'when', 'it', 'is', 'an', 'ma', 'model']","['compute', 'coefficient', 'model']",compute coefficient model,0.0,0.0,11,25,2.0833333333333335,0,0,0,0,0,0,0,0
1422,improving model score apart from gbm and randomforest,Hackathons,improving model score apart from gbm and randomforest,"['improving', 'model', 'score', 'apart', 'from', 'gbm', 'and', 'randomforest']",0,"['improving', 'model', 'score', 'apart', 'from', 'gbm', 'and', 'randomforest']","['improving', 'model', 'score', 'apart', 'gbm', 'randomforest']",improving model score apart gbm randomforest,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
1423,slack url does not work in my pc,Hackathons,slack url does not work in my pc,"['slack', 'url', 'does', 'not', 'work', 'in', 'my', 'pc']",0,"['slack', 'url', 'doe', 'not', 'work', 'in', 'my', 'pc']","['slack', 'url', 'doe', 'work', 'pc']",slack url doe work pc,0.0,0.0,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
1424,which algorithm and framework i have to use for building job recommendation system,Techniques,which algorithm and framework i have to use for building job recommendation system,"['which', 'algorithm', 'and', 'framework', 'i', 'have', 'to', 'use', 'for', 'building', 'job', 'recommendation', 'system']",0,"['which', 'algorithm', 'and', 'framework', 'i', 'have', 'to', 'use', 'for', 'building', 'job', 'recommendation', 'system']","['algorithm', 'framework', 'use', 'building', 'job', 'recommendation', 'system']",algorithm framework use building job recommendation system,0.0,0.0,13,58,4.142857142857143,0,0,0,0,0,0,0,0
1425, inspiring examples of data intelligence marketing in action,Resources, inspiring examples of data intelligence marketing in action,"['inspiring', 'examples', 'of', 'data', 'intelligence', 'marketing', 'in', 'action']",1,"['inspiring', 'example', 'of', 'data', 'intelligence', 'marketing', 'in', 'action']","['inspiring', 'example', 'data', 'intelligence', 'marketing', 'action']",inspiring example data intelligence marketing action,0.3,0.3,8,52,5.777777777777778,0,0,0,0,0,0,0,0
1427,guidelines and advice for possible way to catch job in analytics,Career,guidelines and advice for possible way to catch job in analytics,"['guidelines', 'and', 'advice', 'for', 'possible', 'way', 'to', 'catch', 'job', 'in', 'analytics']",0,"['guideline', 'and', 'advice', 'for', 'possible', 'way', 'to', 'catch', 'job', 'in', 'analytics']","['guideline', 'advice', 'possible', 'way', 'catch', 'job', 'analytics']",guideline advice possible way catch job analytics,0.0,0.0,11,49,4.083333333333333,0,0,0,0,0,0,0,0
1428,why we should go with binary load,Tools,why we should go with binary load,"['why', 'we', 'should', 'go', 'with', 'binary', 'load']",0,"['why', 'we', 'should', 'go', 'with', 'binary', 'load']","['go', 'binary', 'load']",go binary load,0.0,0.0,7,14,1.75,0,0,0,0,0,0,0,0
1429,how to classify the data in svm when the data is not linearly separable,Techniques,how to classify the data in svm when the data is not linearly separable,"['how', 'to', 'classify', 'the', 'data', 'in', 'svm', 'when', 'the', 'data', 'is', 'not', 'linearly', 'separable']",0,"['how', 'to', 'classify', 'the', 'data', 'in', 'svm', 'when', 'the', 'data', 'is', 'not', 'linearly', 'separable']","['classify', 'data', 'svm', 'data', 'linearly', 'separable']",classify data svm data linearly separable,0.0,0.0,14,41,2.7333333333333334,0,0,0,0,0,0,0,0
1430,unbalanced classes,Other,unbalanced classes,"['unbalanced', 'classes']",0,"['unbalanced', 'class']","['unbalanced', 'class']",unbalanced class,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
1431,combining the segmented models,Techniques,combining the segmented models,"['combining', 'the', 'segmented', 'models']",0,"['combining', 'the', 'segmented', 'model']","['combining', 'segmented', 'model']",combining segmented model,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
1432,extract all words with characters nn from tags obtained in r,Tools,extract all words with characters nn from tags obtained in r,"['extract', 'all', 'words', 'with', 'characters', 'nn', 'from', 'tags', 'obtained', 'in', 'r']",0,"['extract', 'all', 'word', 'with', 'character', 'nn', 'from', 'tag', 'obtained', 'in', 'r']","['extract', 'word', 'character', 'nn', 'tag', 'obtained', 'r']",extract word character nn tag obtained r,0.0,0.0,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
1433,errorno applicable method for quinlanattributes applied to an object of class logical,Techniques,errorno applicable method for quinlanattributes applied to an object of class logical,"['errorno', 'applicable', 'method', 'for', 'quinlanattributes', 'applied', 'to', 'an', 'object', 'of', 'class', 'logical']",0,"['errorno', 'applicable', 'method', 'for', 'quinlanattributes', 'applied', 'to', 'an', 'object', 'of', 'class', 'logical']","['errorno', 'applicable', 'method', 'quinlanattributes', 'applied', 'object', 'class', 'logical']",errorno applicable method quinlanattributes applied object class logical,0.25,0.25,12,72,5.538461538461538,0,0,0,0,0,0,0,0
1434,how to find behaviour patterns in banking transactional level data and how to extract rules of behaviour,Techniques,how to find behaviour patterns in banking transactional level data and how to extract rules of behaviour,"['how', 'to', 'find', 'behaviour', 'patterns', 'in', 'banking', 'transactional', 'level', 'data', 'and', 'how', 'to', 'extract', 'rules', 'of', 'behaviour']",0,"['how', 'to', 'find', 'behaviour', 'pattern', 'in', 'banking', 'transactional', 'level', 'data', 'and', 'how', 'to', 'extract', 'rule', 'of', 'behaviour']","['find', 'behaviour', 'pattern', 'banking', 'transactional', 'level', 'data', 'extract', 'rule', 'behaviour']",find behaviour pattern banking transactional level data extract rule behaviour,0.0,0.0,17,78,4.333333333333333,0,0,0,0,0,0,0,0
1435,automated data modeling tools,Tools,automated data modeling tools,"['automated', 'data', 'modeling', 'tools']",0,"['automated', 'data', 'modeling', 'tool']","['automated', 'data', 'modeling', 'tool']",automated data modeling tool,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
1436,a multivariate time series guide to forecasting and modeling,Techniques,a multivariate time series guide to forecasting and modeling,"['a', 'multivariate', 'time', 'series', 'guide', 'to', 'forecasting', 'and', 'modeling']",0,"['a', 'multivariate', 'time', 'series', 'guide', 'to', 'forecasting', 'and', 'modeling']","['multivariate', 'time', 'series', 'guide', 'forecasting', 'modeling']",multivariate time series guide forecasting modeling,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
1437,university of leeds or university of southampton,Career,university of leeds or university of southampton,"['university', 'of', 'leeds', 'or', 'university', 'of', 'southampton']",0,"['university', 'of', 'leeds', 'or', 'university', 'of', 'southampton']","['university', 'leeds', 'university', 'southampton']",university leeds university southampton,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
1438,in wordcharacter embedding what is being represent in vectors values of a single word,Techniques,in wordcharacter embedding what is being represent in vectors values of a single word,"['in', 'wordcharacter', 'embedding', 'what', 'is', 'being', 'represent', 'in', 'vectors', 'values', 'of', 'a', 'single', 'word']",0,"['in', 'wordcharacter', 'embedding', 'what', 'is', 'being', 'represent', 'in', 'vector', 'value', 'of', 'a', 'single', 'word']","['wordcharacter', 'embedding', 'represent', 'vector', 'value', 'single', 'word']",wordcharacter embedding represent vector value single word,-0.0714285714285714,-0.0714285714285714,14,58,3.8666666666666667,0,0,0,0,0,0,0,0
1439,decision making in marketing using monte carlo,Other,decision making in marketing using monte carlo,"['decision', 'making', 'in', 'marketing', 'using', 'monte', 'carlo']",0,"['decision', 'making', 'in', 'marketing', 'using', 'monte', 'carlo']","['decision', 'making', 'marketing', 'using', 'monte', 'carlo']",decision making marketing using monte carlo,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
1440,distance measure used by knn algorithm,Techniques,distance measure used by knn algorithm,"['distance', 'measure', 'used', 'by', 'knn', 'algorithm']",0,"['distance', 'measure', 'used', 'by', 'knn', 'algorithm']","['distance', 'measure', 'used', 'knn', 'algorithm']",distance measure used knn algorithm,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
1441,counting unique combination of columns in a data frame for each country in r,Techniques,counting unique combination of columns in a data frame for each country in r,"['counting', 'unique', 'combination', 'of', 'columns', 'in', 'a', 'data', 'frame', 'for', 'each', 'country', 'in', 'r']",0,"['counting', 'unique', 'combination', 'of', 'column', 'in', 'a', 'data', 'frame', 'for', 'each', 'country', 'in', 'r']","['counting', 'unique', 'combination', 'column', 'data', 'frame', 'country', 'r']",counting unique combination column data frame country r,0.375,0.375,14,55,3.6666666666666665,0,0,0,0,0,0,0,0
1442,data exploration and machine learning app using r shiny,Tools,data exploration and machine learning app using r shiny,"['data', 'exploration', 'and', 'machine', 'learning', 'app', 'using', 'r', 'shiny']",0,"['data', 'exploration', 'and', 'machine', 'learning', 'app', 'using', 'r', 'shiny']","['data', 'exploration', 'machine', 'learning', 'app', 'using', 'r', 'shiny']",data exploration machine learning app using r shiny,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
1443,how to access vector elements in a for loop using r,Tools,how to access vector elements in a for loop using r,"['how', 'to', 'access', 'vector', 'elements', 'in', 'a', 'for', 'loop', 'using', 'r']",0,"['how', 'to', 'access', 'vector', 'element', 'in', 'a', 'for', 'loop', 'using', 'r']","['access', 'vector', 'element', 'loop', 'using', 'r']",access vector element loop using r,0.0,0.0,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
1444,how to use slack live chat,Techniques,how to use slack live chat,"['how', 'to', 'use', 'slack', 'live', 'chat']",0,"['how', 'to', 'use', 'slack', 'live', 'chat']","['use', 'slack', 'live', 'chat']",use slack live chat,0.1363636363636363,0.1363636363636363,6,19,2.7142857142857144,0,0,0,0,0,0,0,0
1445,course in python like analytics edge for r,Tools,course in python like analytics edge for r,"['course', 'in', 'python', 'like', 'analytics', 'edge', 'for', 'r']",0,"['course', 'in', 'python', 'like', 'analytics', 'edge', 'for', 'r']","['course', 'python', 'like', 'analytics', 'edge', 'r']",course python like analytics edge r,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
1446,pg diploma in applied statistics,Career,pg diploma in applied statistics,"['pg', 'diploma', 'in', 'applied', 'statistics']",0,"['pg', 'diploma', 'in', 'applied', 'statistic']","['pg', 'diploma', 'applied', 'statistic']",pg diploma applied statistic,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
1447,how to find correlation between continuous variable and categorical ordinal variables,Techniques,how to find correlation between continuous variable and categorical ordinal variables,"['how', 'to', 'find', 'correlation', 'between', 'continuous', 'variable', 'and', 'categorical', 'ordinal', 'variables']",0,"['how', 'to', 'find', 'correlation', 'between', 'continuous', 'variable', 'and', 'categorical', 'ordinal', 'variable']","['find', 'correlation', 'continuous', 'variable', 'categorical', 'ordinal', 'variable']",find correlation continuous variable categorical ordinal variable,0.0,0.0,11,65,5.416666666666667,0,0,0,0,0,0,0,0
1448,how to use substr function in r to extract a specific part of a character string,Tools,how to use substr function in r to extract a specific part of a character string,"['how', 'to', 'use', 'substr', 'function', 'in', 'r', 'to', 'extract', 'a', 'specific', 'part', 'of', 'a', 'character', 'string']",0,"['how', 'to', 'use', 'substr', 'function', 'in', 'r', 'to', 'extract', 'a', 'specific', 'part', 'of', 'a', 'character', 'string']","['use', 'substr', 'function', 'r', 'extract', 'specific', 'part', 'character', 'string']",use substr function r extract specific part character string,0.0,0.0,16,60,3.5294117647058822,0,0,0,0,0,0,0,0
1449,how to know which variables are the best for predicting using logistic regression,Techniques,how to know which variables are the best for predicting using logistic regression,"['how', 'to', 'know', 'which', 'variables', 'are', 'the', 'best', 'for', 'predicting', 'using', 'logistic', 'regression']",0,"['how', 'to', 'know', 'which', 'variable', 'are', 'the', 'best', 'for', 'predicting', 'using', 'logistic', 'regression']","['know', 'variable', 'best', 'predicting', 'using', 'logistic', 'regression']",know variable best predicting using logistic regression,1.0,1.0,13,55,3.9285714285714284,0,0,0,0,0,0,0,0
1450,warning message nas introduced by coercion,Techniques,warning message nas introduced by coercion,"['warning', 'message', 'nas', 'introduced', 'by', 'coercion']",0,"['warning', 'message', 'na', 'introduced', 'by', 'coercion']","['warning', 'message', 'na', 'introduced', 'coercion']",warning message na introduced coercion,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
1451,q why to remove outliers value from the variable,Techniques,q why to remove outliers value from the variable,"['q', 'why', 'to', 'remove', 'outliers', 'value', 'from', 'the', 'variable']",0,"['q', 'why', 'to', 'remove', 'outlier', 'value', 'from', 'the', 'variable']","['q', 'remove', 'outlier', 'value', 'variable']",q remove outlier value variable,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
1452,chatbot creation and gui,Techniques,chatbot creation and gui,"['chatbot', 'creation', 'and', 'gui']",0,"['chatbot', 'creation', 'and', 'gui']","['chatbot', 'creation', 'gui']",chatbot creation gui,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
1453,how can i capture the node label or value at runtime for bubbles chart using bubblerenderbubbles,Tools,how can i capture the node label or value at runtime for bubbles chart using bubblerenderbubbles,"['how', 'can', 'i', 'capture', 'the', 'node', 'label', 'or', 'value', 'at', 'runtime', 'for', 'bubbles', 'chart', 'using', 'bubblerenderbubbles']",0,"['how', 'can', 'i', 'capture', 'the', 'node', 'label', 'or', 'value', 'at', 'runtime', 'for', 'bubble', 'chart', 'using', 'bubblerenderbubbles']","['capture', 'node', 'label', 'value', 'runtime', 'bubble', 'chart', 'using', 'bubblerenderbubbles']",capture node label value runtime bubble chart using bubblerenderbubbles,0.0,0.0,16,71,4.176470588235294,0,0,0,0,0,0,0,0
1454,beginner  learning cloudera data science certification  would like to install cloudera data science toolkit without vm on ubuntu os,Career,beginner  learning cloudera data science certification  would like to install cloudera data science toolkit without vm on ubuntu os,"['beginner', 'learning', 'cloudera', 'data', 'science', 'certification', 'would', 'like', 'to', 'install', 'cloudera', 'data', 'science', 'toolkit', 'without', 'vm', 'on', 'ubuntu', 'os']",0,"['beginner', 'learning', 'cloudera', 'data', 'science', 'certification', 'would', 'like', 'to', 'install', 'cloudera', 'data', 'science', 'toolkit', 'without', 'vm', 'on', 'ubuntu', 'o']","['beginner', 'learning', 'cloudera', 'data', 'science', 'certification', 'would', 'like', 'install', 'cloudera', 'data', 'science', 'toolkit', 'without', 'vm', 'ubuntu']",beginner learning cloudera data science certification would like install cloudera data science toolkit without vm ubuntu,0.0,0.0,19,120,6.0,0,0,0,0,0,0,0,0
1455,need suggestions on  data scientist role in quality cmmi dmm using r  sql,Career,need suggestions on  data scientist role in quality cmmi dmm using r  sql,"['need', 'suggestions', 'on', 'data', 'scientist', 'role', 'in', 'quality', 'cmmi', 'dmm', 'using', 'r', 'sql']",0,"['need', 'suggestion', 'on', 'data', 'scientist', 'role', 'in', 'quality', 'cmmi', 'dmm', 'using', 'r', 'sql']","['need', 'suggestion', 'data', 'scientist', 'role', 'quality', 'cmmi', 'dmm', 'using', 'r', 'sql']",need suggestion data scientist role quality cmmi dmm using r sql,0.0,0.0,13,64,4.571428571428571,0,0,0,0,0,0,0,0
1456,how digital marketing and data science can be combined,Other,how digital marketing and data science can be combined,"['how', 'digital', 'marketing', 'and', 'data', 'science', 'can', 'be', 'combined']",0,"['how', 'digital', 'marketing', 'and', 'data', 'science', 'can', 'be', 'combined']","['digital', 'marketing', 'data', 'science', 'combined']",digital marketing data science combined,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
1457,kaggle german credit risk classification,Techniques,kaggle german credit risk classification,"['kaggle', 'german', 'credit', 'risk', 'classification']",0,"['kaggle', 'german', 'credit', 'risk', 'classification']","['kaggle', 'german', 'credit', 'risk', 'classification']",kaggle german credit risk classification,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
1458,research and business analytics program in empi bschool,Career,research and business analytics program in empi bschool,"['research', 'and', 'business', 'analytics', 'program', 'in', 'empi', 'bschool']",0,"['research', 'and', 'business', 'analytics', 'program', 'in', 'empi', 'bschool']","['research', 'business', 'analytics', 'program', 'empi', 'bschool']",research business analytics program empi bschool,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
1459,to the admins submission of code,Hackathons,to the admins submission of code,"['to', 'the', 'admins', 'submission', 'of', 'code']",0,"['to', 'the', 'admins', 'submission', 'of', 'code']","['admins', 'submission', 'code']",admins submission code,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
1460,where to download the data sets,Resources,where to download the data sets,"['where', 'to', 'download', 'the', 'data', 'sets']",0,"['where', 'to', 'download', 'the', 'data', 'set']","['download', 'data', 'set']",download data set,0.0,0.0,6,17,2.4285714285714284,0,0,0,0,0,0,0,0
1461,use of aaply function from plyr package in r,Tools,use of aaply function from plyr package in r,"['use', 'of', 'aaply', 'function', 'from', 'plyr', 'package', 'in', 'r']",0,"['use', 'of', 'aaply', 'function', 'from', 'plyr', 'package', 'in', 'r']","['use', 'aaply', 'function', 'plyr', 'package', 'r']",use aaply function plyr package r,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
1462,how to fit  roc curves into  graph,Tools,how to fit  roc curves into  graph,"['how', 'to', 'fit', 'roc', 'curves', 'into', 'graph']",2,"['how', 'to', 'fit', 'roc', 'curve', 'into', 'graph']","['fit', 'roc', 'curve', 'graph']",fit roc curve graph,0.4,0.4,7,19,2.375,0,0,0,0,0,0,0,0
1463,help required on data analysis with excel,Career,help required on data analysis with excel,"['help', 'required', 'on', 'data', 'analysis', 'with', 'excel']",0,"['help', 'required', 'on', 'data', 'analysis', 'with', 'excel']","['help', 'required', 'data', 'analysis', 'excel']",help required data analysis excel,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
1464,awesome tips and tricks in excel,Tools,awesome tips and tricks in excel,"['awesome', 'tips', 'and', 'tricks', 'in', 'excel']",0,"['awesome', 'tip', 'and', 'trick', 'in', 'excel']","['awesome', 'tip', 'trick', 'excel']",awesome tip trick excel,1.0,1.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
1465,issue with name on certificate,Misc,issue with name on certificate,"['issue', 'with', 'name', 'on', 'certificate']",0,"['issue', 'with', 'name', 'on', 'certificate']","['issue', 'name', 'certificate']",issue name certificate,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
1466,analysis of indian power prices,Career,analysis of indian power prices,"['analysis', 'of', 'indian', 'power', 'prices']",0,"['analysis', 'of', 'indian', 'power', 'price']","['analysis', 'indian', 'power', 'price']",analysis indian power price,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
1467,how to plot a sample tree from random forest in r,Tools,how to plot a sample tree from random forest in r,"['how', 'to', 'plot', 'a', 'sample', 'tree', 'from', 'random', 'forest', 'in', 'r']",0,"['how', 'to', 'plot', 'a', 'sample', 'tree', 'from', 'random', 'forest', 'in', 'r']","['plot', 'sample', 'tree', 'random', 'forest', 'r']",plot sample tree random forest r,-0.5,-0.5,11,32,2.6666666666666665,0,0,0,0,0,0,0,0
1468,how to plot points over a given plot in r,Techniques,how to plot points over a given plot in r,"['how', 'to', 'plot', 'points', 'over', 'a', 'given', 'plot', 'in', 'r']",0,"['how', 'to', 'plot', 'point', 'over', 'a', 'given', 'plot', 'in', 'r']","['plot', 'point', 'given', 'plot', 'r']",plot point given plot r,0.0,0.0,10,23,2.090909090909091,0,0,0,0,0,0,0,0
1469,web scraping using rvest and rselenium,Techniques,web scraping using rvest and rselenium,"['web', 'scraping', 'using', 'rvest', 'and', 'rselenium']",0,"['web', 'scraping', 'using', 'rvest', 'and', 'rselenium']","['web', 'scraping', 'using', 'rvest', 'rselenium']",web scraping using rvest rselenium,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
1470,model evaluation vs model validation,Techniques,model evaluation vs model validation,"['model', 'evaluation', 'vs', 'model', 'validation']",0,"['model', 'evaluation', 'v', 'model', 'validation']","['model', 'evaluation', 'v', 'model', 'validation']",model evaluation v model validation,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
1471,how can non linear relationships be converted into linear ones using transformations,Techniques,how can non linear relationships be converted into linear ones using transformations,"['how', 'can', 'non', 'linear', 'relationships', 'be', 'converted', 'into', 'linear', 'ones', 'using', 'transformations']",0,"['how', 'can', 'non', 'linear', 'relationship', 'be', 'converted', 'into', 'linear', 'one', 'using', 'transformation']","['non', 'linear', 'relationship', 'converted', 'linear', 'one', 'using', 'transformation']",non linear relationship converted linear one using transformation,0.0,0.0,12,65,5.0,0,0,0,0,0,0,0,0
1472,how can i find topic distribution of a paragraph using bilstm and attention,Techniques,how can i find topic distribution of a paragraph using bilstm and attention,"['how', 'can', 'i', 'find', 'topic', 'distribution', 'of', 'a', 'paragraph', 'using', 'bilstm', 'and', 'attention']",0,"['how', 'can', 'i', 'find', 'topic', 'distribution', 'of', 'a', 'paragraph', 'using', 'bilstm', 'and', 'attention']","['find', 'topic', 'distribution', 'paragraph', 'using', 'bilstm', 'attention']",find topic distribution paragraph using bilstm attention,0.0,0.0,13,56,4.0,0,0,0,0,0,0,0,0
1473,when manhattan distance is preffered over euclidean distance,Techniques,when manhattan distance is preffered over euclidean distance,"['when', 'manhattan', 'distance', 'is', 'preffered', 'over', 'euclidean', 'distance']",0,"['when', 'manhattan', 'distance', 'is', 'preffered', 'over', 'euclidean', 'distance']","['manhattan', 'distance', 'preffered', 'euclidean', 'distance']",manhattan distance preffered euclidean distance,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
1474,evaluation metric in recommender systems,Techniques,evaluation metric in recommender systems,"['evaluation', 'metric', 'in', 'recommender', 'systems']",0,"['evaluation', 'metric', 'in', 'recommender', 'system']","['evaluation', 'metric', 'recommender', 'system']",evaluation metric recommender system,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
1475,multi dimensional scaling for dimension reduction,Techniques,multi dimensional scaling for dimension reduction,"['multi', 'dimensional', 'scaling', 'for', 'dimension', 'reduction']",0,"['multi', 'dimensional', 'scaling', 'for', 'dimension', 'reduction']","['multi', 'dimensional', 'scaling', 'dimension', 'reduction']",multi dimensional scaling dimension reduction,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
1476,how to get started with machine learning in log analysis elk project,Other,how to get started with machine learning in log analysis elk project,"['how', 'to', 'get', 'started', 'with', 'machine', 'learning', 'in', 'log', 'analysis', 'elk', 'project']",0,"['how', 'to', 'get', 'started', 'with', 'machine', 'learning', 'in', 'log', 'analysis', 'elk', 'project']","['get', 'started', 'machine', 'learning', 'log', 'analysis', 'elk', 'project']",get started machine learning log analysis elk project,0.0,0.0,12,53,4.076923076923077,0,0,0,0,0,0,0,0
1477,how to access any value of list which is nested under another list in r,Tools,how to access any value of list which is nested under another list in r,"['how', 'to', 'access', 'any', 'value', 'of', 'list', 'which', 'is', 'nested', 'under', 'another', 'list', 'in', 'r']",0,"['how', 'to', 'access', 'any', 'value', 'of', 'list', 'which', 'is', 'nested', 'under', 'another', 'list', 'in', 'r']","['access', 'value', 'list', 'nested', 'another', 'list', 'r']",access value list nested another list r,0.0,0.0,15,39,2.4375,0,0,0,0,0,0,0,0
1478,panel data and time series data,Techniques,panel data and time series data,"['panel', 'data', 'and', 'time', 'series', 'data']",0,"['panel', 'data', 'and', 'time', 'series', 'data']","['panel', 'data', 'time', 'series', 'data']",panel data time series data,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
1479,correlation equivalent to find trend within one variable,Techniques,correlation equivalent to find trend within one variable,"['correlation', 'equivalent', 'to', 'find', 'trend', 'within', 'one', 'variable']",0,"['correlation', 'equivalent', 'to', 'find', 'trend', 'within', 'one', 'variable']","['correlation', 'equivalent', 'find', 'trend', 'within', 'one', 'variable']",correlation equivalent find trend within one variable,0.0,0.0,8,53,5.888888888888889,0,0,0,0,0,0,0,0
1480,using data from a website in r,Techniques,using data from a website in r,"['using', 'data', 'from', 'a', 'website', 'in', 'r']",0,"['using', 'data', 'from', 'a', 'website', 'in', 'r']","['using', 'data', 'website', 'r']",using data website r,0.0,0.0,7,20,2.5,0,0,0,0,0,0,0,0
1481,pgpba from great lakes or pgpba from praxis business school or moocs,Career,pgpba from great lakes or pgpba from praxis business school or moocs,"['pgpba', 'from', 'great', 'lakes', 'or', 'pgpba', 'from', 'praxis', 'business', 'school', 'or', 'moocs']",0,"['pgpba', 'from', 'great', 'lake', 'or', 'pgpba', 'from', 'praxis', 'business', 'school', 'or', 'moocs']","['pgpba', 'great', 'lake', 'pgpba', 'praxis', 'business', 'school', 'moocs']",pgpba great lake pgpba praxis business school moocs,0.8,0.8,12,51,3.923076923076923,0,0,0,0,0,0,0,0
1482,optimization from excel to r,Techniques,optimization from excel to r,"['optimization', 'from', 'excel', 'to', 'r']",0,"['optimization', 'from', 'excel', 'to', 'r']","['optimization', 'excel', 'r']",optimization excel r,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
1483,can anyone suggest a good platform for storing analytical data for structured databases like mysql,Tools,can anyone suggest a good platform for storing analytical data for structured databases like mysql,"['can', 'anyone', 'suggest', 'a', 'good', 'platform', 'for', 'storing', 'analytical', 'data', 'for', 'structured', 'databases', 'like', 'mysql']",0,"['can', 'anyone', 'suggest', 'a', 'good', 'platform', 'for', 'storing', 'analytical', 'data', 'for', 'structured', 'database', 'like', 'mysql']","['anyone', 'suggest', 'good', 'platform', 'storing', 'analytical', 'data', 'structured', 'database', 'like', 'mysql']",anyone suggest good platform storing analytical data structured database like mysql,0.7,0.7,15,83,5.1875,0,0,0,0,0,0,0,0
1484,data mining with r  is learning rattle sufficient,Tools,data mining with r  is learning rattle sufficient,"['data', 'mining', 'with', 'r', 'is', 'learning', 'rattle', 'sufficient']",0,"['data', 'mining', 'with', 'r', 'is', 'learning', 'rattle', 'sufficient']","['data', 'mining', 'r', 'learning', 'rattle', 'sufficient']",data mining r learning rattle sufficient,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
1485,projects for final year related to ml and cyber security,Resources,projects for final year related to ml and cyber security,"['projects', 'for', 'final', 'year', 'related', 'to', 'ml', 'and', 'cyber', 'security']",0,"['project', 'for', 'final', 'year', 'related', 'to', 'ml', 'and', 'cyber', 'security']","['project', 'final', 'year', 'related', 'ml', 'cyber', 'security']",project final year related ml cyber security,0.0,0.0,10,44,4.0,0,0,0,0,0,0,0,0
1486,can we create a bins of numerical variable in qlikview,Tools,can we create a bins of numerical variable in qlikview,"['can', 'we', 'create', 'a', 'bins', 'of', 'numerical', 'variable', 'in', 'qlikview']",0,"['can', 'we', 'create', 'a', 'bin', 'of', 'numerical', 'variable', 'in', 'qlikview']","['create', 'bin', 'numerical', 'variable', 'qlikview']",create bin numerical variable qlikview,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
1487,huge dataset with more than k obs,Misc,huge dataset with more than k obs,"['huge', 'dataset', 'with', 'more', 'than', 'k', 'obs']",0,"['huge', 'dataset', 'with', 'more', 'than', 'k', 'ob']","['huge', 'dataset', 'k', 'ob']",huge dataset k ob,0.45,0.4000000000000001,7,17,2.125,0,0,0,0,0,0,0,0
1488,excel requirement for data science,Tools,excel requirement for data science,"['excel', 'requirement', 'for', 'data', 'science']",0,"['excel', 'requirement', 'for', 'data', 'science']","['excel', 'requirement', 'data', 'science']",excel requirement data science,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
1489,being a btech student at iitr and analytics aspiranthow will i be hired for data scientistanalyst job,Career,being a btech student at iitr and analytics aspiranthow will i be hired for data scientistanalyst job,"['being', 'a', 'btech', 'student', 'at', 'iitr', 'and', 'analytics', 'aspiranthow', 'will', 'i', 'be', 'hired', 'for', 'data', 'scientistanalyst', 'job']",0,"['being', 'a', 'btech', 'student', 'at', 'iitr', 'and', 'analytics', 'aspiranthow', 'will', 'i', 'be', 'hired', 'for', 'data', 'scientistanalyst', 'job']","['btech', 'student', 'iitr', 'analytics', 'aspiranthow', 'hired', 'data', 'scientistanalyst', 'job']",btech student iitr analytics aspiranthow hired data scientistanalyst job,0.0,0.0,17,72,4.0,0,0,0,0,0,0,0,0
1490,what are the data analysis tools that support data extraction from word documents,Tools,what are the data analysis tools that support data extraction from word documents,"['what', 'are', 'the', 'data', 'analysis', 'tools', 'that', 'support', 'data', 'extraction', 'from', 'word', 'documents']",0,"['what', 'are', 'the', 'data', 'analysis', 'tool', 'that', 'support', 'data', 'extraction', 'from', 'word', 'document']","['data', 'analysis', 'tool', 'support', 'data', 'extraction', 'word', 'document']",data analysis tool support data extraction word document,0.0,0.0,13,56,4.0,0,0,0,0,0,0,0,0
1491,which is the best statistics and analytics book,Techniques,which is the best statistics and analytics book,"['which', 'is', 'the', 'best', 'statistics', 'and', 'analytics', 'book']",0,"['which', 'is', 'the', 'best', 'statistic', 'and', 'analytics', 'book']","['best', 'statistic', 'analytics', 'book']",best statistic analytics book,1.0,1.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
1492,how to interpret margin plot in r,Tools,how to interpret margin plot in r,"['how', 'to', 'interpret', 'margin', 'plot', 'in', 'r']",0,"['how', 'to', 'interpret', 'margin', 'plot', 'in', 'r']","['interpret', 'margin', 'plot', 'r']",interpret margin plot r,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
1493,creating network graphs using multiple nodes,Tools,creating network graphs using multiple nodes,"['creating', 'network', 'graphs', 'using', 'multiple', 'nodes']",0,"['creating', 'network', 'graph', 'using', 'multiple', 'node']","['creating', 'network', 'graph', 'using', 'multiple', 'node']",creating network graph using multiple node,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
1494,difference between visualization tools,Tools,difference between visualization tools,"['difference', 'between', 'visualization', 'tools']",0,"['difference', 'between', 'visualization', 'tool']","['difference', 'visualization', 'tool']",difference visualization tool,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
1495,business analytics case study and solved by r,Tools,business analytics case study and solved by r,"['business', 'analytics', 'case', 'study', 'and', 'solved', 'by', 'r']",0,"['business', 'analytics', 'case', 'study', 'and', 'solved', 'by', 'r']","['business', 'analytics', 'case', 'study', 'solved', 'r']",business analytics case study solved r,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
1496,acceptance criteria for  of missing values,Techniques,acceptance criteria for  of missing values,"['acceptance', 'criteria', 'for', 'of', 'missing', 'values']",0,"['acceptance', 'criterion', 'for', 'of', 'missing', 'value']","['acceptance', 'criterion', 'missing', 'value']",acceptance criterion missing value,-0.2,-0.2,6,34,4.857142857142857,0,0,0,0,0,0,0,0
1497,necessity of dimensionality reduction for predictive modelling,Techniques,necessity of dimensionality reduction for predictive modelling,"['necessity', 'of', 'dimensionality', 'reduction', 'for', 'predictive', 'modelling']",0,"['necessity', 'of', 'dimensionality', 'reduction', 'for', 'predictive', 'modelling']","['necessity', 'dimensionality', 'reduction', 'predictive', 'modelling']",necessity dimensionality reduction predictive modelling,0.0,0.0,7,55,6.875,0,0,0,0,0,0,0,0
1498,generating music with machine learning  error in the tutorial using music library,Tools,generating music with machine learning  error in the tutorial using music library,"['generating', 'music', 'with', 'machine', 'learning', 'error', 'in', 'the', 'tutorial', 'using', 'music', 'library']",0,"['generating', 'music', 'with', 'machine', 'learning', 'error', 'in', 'the', 'tutorial', 'using', 'music', 'library']","['generating', 'music', 'machine', 'learning', 'error', 'tutorial', 'using', 'music', 'library']",generating music machine learning error tutorial using music library,0.0,0.0,12,68,5.230769230769231,0,0,0,0,0,0,0,0
1499,tutorials for data analytics using python,Techniques,tutorials for data analytics using python,"['tutorials', 'for', 'data', 'analytics', 'using', 'python']",0,"['tutorial', 'for', 'data', 'analytics', 'using', 'python']","['tutorial', 'data', 'analytics', 'using', 'python']",tutorial data analytics using python,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
1500,time series analysis with python,Tools,time series analysis with python,"['time', 'series', 'analysis', 'with', 'python']",0,"['time', 'series', 'analysis', 'with', 'python']","['time', 'series', 'analysis', 'python']",time series analysis python,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
1501,titanic solution,Techniques,titanic solution,"['titanic', 'solution']",0,"['titanic', 'solution']","['titanic', 'solution']",titanic solution,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
1502,career transition from mechanical to business analytics,Career,career transition from mechanical to business analytics,"['career', 'transition', 'from', 'mechanical', 'to', 'business', 'analytics']",0,"['career', 'transition', 'from', 'mechanical', 'to', 'business', 'analytics']","['career', 'transition', 'mechanical', 'business', 'analytics']",career transition mechanical business analytics,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
1503,which library should i look at to find the statistical significance of relationship bw two variables,Tools,which library should i look at to find the statistical significance of relationship bw two variables,"['which', 'library', 'should', 'i', 'look', 'at', 'to', 'find', 'the', 'statistical', 'significance', 'of', 'relationship', 'bw', 'two', 'variables']",0,"['which', 'library', 'should', 'i', 'look', 'at', 'to', 'find', 'the', 'statistical', 'significance', 'of', 'relationship', 'bw', 'two', 'variable']","['library', 'look', 'find', 'statistical', 'significance', 'relationship', 'bw', 'two', 'variable']",library look find statistical significance relationship bw two variable,0.0,0.0,16,71,4.176470588235294,0,0,0,0,0,0,0,0
1504,datascience newbie  advice required,Resources,datascience newbie  advice required,"['datascience', 'newbie', 'advice', 'required']",0,"['datascience', 'newbie', 'advice', 'required']","['datascience', 'newbie', 'advice', 'required']",datascience newbie advice required,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
1505,test data in practice problem urban sound classification,Hackathons,test data in practice problem urban sound classification,"['test', 'data', 'in', 'practice', 'problem', 'urban', 'sound', 'classification']",0,"['test', 'data', 'in', 'practice', 'problem', 'urban', 'sound', 'classification']","['test', 'data', 'practice', 'problem', 'urban', 'sound', 'classification']",test data practice problem urban sound classification,0.2,0.2,8,53,5.888888888888889,0,0,0,0,0,0,0,0
1506,how to get numpy array of subplot in python,Tools,how to get numpy array of subplot in python,"['how', 'to', 'get', 'numpy', 'array', 'of', 'subplot', 'in', 'python']",0,"['how', 'to', 'get', 'numpy', 'array', 'of', 'subplot', 'in', 'python']","['get', 'numpy', 'array', 'subplot', 'python']",get numpy array subplot python,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
1507,parallel execution of loop in r,Tools,parallel execution of loop in r,"['parallel', 'execution', 'of', 'loop', 'in', 'r']",0,"['parallel', 'execution', 'of', 'loop', 'in', 'r']","['parallel', 'execution', 'loop', 'r']",parallel execution loop r,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
1508,what are the job responsibilities of a data analyst who do not have much programing knowladge,Career,what are the job responsibilities of a data analyst who do not have much programing knowladge,"['what', 'are', 'the', 'job', 'responsibilities', 'of', 'a', 'data', 'analyst', 'who', 'do', 'not', 'have', 'much', 'programing', 'knowladge']",0,"['what', 'are', 'the', 'job', 'responsibility', 'of', 'a', 'data', 'analyst', 'who', 'do', 'not', 'have', 'much', 'programing', 'knowladge']","['job', 'responsibility', 'data', 'analyst', 'much', 'programing', 'knowladge']",job responsibility data analyst much programing knowladge,0.2,0.2,16,57,3.3529411764705883,0,0,0,0,0,0,0,0
1509,how to calculate intermodel correlation for an ensemble in r,Techniques,how to calculate intermodel correlation for an ensemble in r,"['how', 'to', 'calculate', 'intermodel', 'correlation', 'for', 'an', 'ensemble', 'in', 'r']",0,"['how', 'to', 'calculate', 'intermodel', 'correlation', 'for', 'an', 'ensemble', 'in', 'r']","['calculate', 'intermodel', 'correlation', 'ensemble', 'r']",calculate intermodel correlation ensemble r,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
1510,statistical summarizing data,Other,statistical summarizing data,"['statistical', 'summarizing', 'data']",0,"['statistical', 'summarizing', 'data']","['statistical', 'summarizing', 'data']",statistical summarizing data,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
1511,stationarity of time series,Techniques,stationarity of time series,"['stationarity', 'of', 'time', 'series']",0,"['stationarity', 'of', 'time', 'series']","['stationarity', 'time', 'series']",stationarity time series,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
1512,zero being encoded as one after conversion from factor to numeric,Tools,zero being encoded as one after conversion from factor to numeric,"['zero', 'being', 'encoded', 'as', 'one', 'after', 'conversion', 'from', 'factor', 'to', 'numeric']",0,"['zero', 'being', 'encoded', 'a', 'one', 'after', 'conversion', 'from', 'factor', 'to', 'numeric']","['zero', 'encoded', 'one', 'conversion', 'factor', 'numeric']",zero encoded one conversion factor numeric,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
1513,can we run the data science course with python on ipad or any other tabs,Techniques,can we run the data science course with python on ipad or any other tabs,"['can', 'we', 'run', 'the', 'data', 'science', 'course', 'with', 'python', 'on', 'ipad', 'or', 'any', 'other', 'tabs']",0,"['can', 'we', 'run', 'the', 'data', 'science', 'course', 'with', 'python', 'on', 'ipad', 'or', 'any', 'other', 'tab']","['run', 'data', 'science', 'course', 'python', 'ipad', 'tab']",run data science course python ipad tab,-0.125,0.0,15,39,2.4375,0,0,0,0,0,0,0,0
1514,what are some good ideas to do a major project machine learning,Techniques,what are some good ideas to do a major project machine learning,"['what', 'are', 'some', 'good', 'ideas', 'to', 'do', 'a', 'major', 'project', 'machine', 'learning']",0,"['what', 'are', 'some', 'good', 'idea', 'to', 'do', 'a', 'major', 'project', 'machine', 'learning']","['good', 'idea', 'major', 'project', 'machine', 'learning']",good idea major project machine learning,0.38125,0.38125,12,40,3.076923076923077,0,0,0,0,0,0,0,0
1515,why is the sum of squared coefficients of xs across all the principal components ,Techniques,why is the sum of squared coefficients of xs across all the principal components ,"['why', 'is', 'the', 'sum', 'of', 'squared', 'coefficients', 'of', 'xs', 'across', 'all', 'the', 'principal', 'components']",1,"['why', 'is', 'the', 'sum', 'of', 'squared', 'coefficient', 'of', 'x', 'across', 'all', 'the', 'principal', 'component']","['sum', 'squared', 'coefficient', 'x', 'across', 'principal', 'component']",sum squared coefficient x across principal component,0.0,0.0,14,52,3.466666666666667,0,0,0,0,0,0,0,0
1516,how to visualise the voronoi centers in the voronoi plot in r,Tools,how to visualise the voronoi centers in the voronoi plot in r,"['how', 'to', 'visualise', 'the', 'voronoi', 'centers', 'in', 'the', 'voronoi', 'plot', 'in', 'r']",0,"['how', 'to', 'visualise', 'the', 'voronoi', 'center', 'in', 'the', 'voronoi', 'plot', 'in', 'r']","['visualise', 'voronoi', 'center', 'voronoi', 'plot', 'r']",visualise voronoi center voronoi plot r,0.0,-0.1,12,39,3.0,0,0,0,0,0,0,0,0
1517,proper use of getdummies function in pandas,Tools,proper use of getdummies function in pandas,"['proper', 'use', 'of', 'getdummies', 'function', 'in', 'pandas']",0,"['proper', 'use', 'of', 'getdummies', 'function', 'in', 'panda']","['proper', 'use', 'getdummies', 'function', 'panda']",proper use getdummies function panda,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
1518,keeping insignificant variables in a model,Techniques,keeping insignificant variables in a model,"['keeping', 'insignificant', 'variables', 'in', 'a', 'model']",0,"['keeping', 'insignificant', 'variable', 'in', 'a', 'model']","['keeping', 'insignificant', 'variable', 'model']",keeping insignificant variable model,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
1519,best open course to learn python for data science,Tools,best open course to learn python for data science,"['best', 'open', 'course', 'to', 'learn', 'python', 'for', 'data', 'science']",0,"['best', 'open', 'course', 'to', 'learn', 'python', 'for', 'data', 'science']","['best', 'open', 'course', 'learn', 'python', 'data', 'science']",best open course learn python data science,0.5,0.5,9,42,4.2,0,0,0,0,0,0,0,0
1520,feature selection for incremental kmeans clustering,Techniques,feature selection for incremental kmeans clustering,"['feature', 'selection', 'for', 'incremental', 'kmeans', 'clustering']",0,"['feature', 'selection', 'for', 'incremental', 'kmeans', 'clustering']","['feature', 'selection', 'incremental', 'kmeans', 'clustering']",feature selection incremental kmeans clustering,0.0,0.0,6,47,6.714285714285714,0,0,0,0,0,0,0,0
1521,i want to add bar values on top of each stacked bar in the bar plot with geomtext of titanic dataset,Techniques,i want to add bar values on top of each stacked bar in the bar plot with geomtext of titanic dataset,"['i', 'want', 'to', 'add', 'bar', 'values', 'on', 'top', 'of', 'each', 'stacked', 'bar', 'in', 'the', 'bar', 'plot', 'with', 'geomtext', 'of', 'titanic', 'dataset']",0,"['i', 'want', 'to', 'add', 'bar', 'value', 'on', 'top', 'of', 'each', 'stacked', 'bar', 'in', 'the', 'bar', 'plot', 'with', 'geomtext', 'of', 'titanic', 'dataset']","['want', 'add', 'bar', 'value', 'top', 'stacked', 'bar', 'bar', 'plot', 'geomtext', 'titanic', 'dataset']",want add bar value top stacked bar bar plot geomtext titanic dataset,0.5,0.5,21,68,3.090909090909091,0,0,0,0,0,0,0,0
1522,error while making submission in abc loan prediction ,Hackathons,error while making submission in abc loan prediction ,"['error', 'while', 'making', 'submission', 'in', 'abc', 'loan', 'prediction']",1,"['error', 'while', 'making', 'submission', 'in', 'abc', 'loan', 'prediction']","['error', 'making', 'submission', 'abc', 'loan', 'prediction']",error making submission abc loan prediction,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
1523,ccp in data science,Career,ccp in data science,"['ccp', 'in', 'data', 'science']",0,"['ccp', 'in', 'data', 'science']","['ccp', 'data', 'science']",ccp data science,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
1524,top companies in world hiring data scientist,Career,top companies in world hiring data scientist,"['top', 'companies', 'in', 'world', 'hiring', 'data', 'scientist']",0,"['top', 'company', 'in', 'world', 'hiring', 'data', 'scientist']","['top', 'company', 'world', 'hiring', 'data', 'scientist']",top company world hiring data scientist,0.5,0.5,7,39,4.875,0,0,0,0,0,0,0,0
1525,predictor variables in my data are dependent on each other how to build an efficient model,Techniques,predictor variables in my data are dependent on each other how to build an efficient model,"['predictor', 'variables', 'in', 'my', 'data', 'are', 'dependent', 'on', 'each', 'other', 'how', 'to', 'build', 'an', 'efficient', 'model']",0,"['predictor', 'variable', 'in', 'my', 'data', 'are', 'dependent', 'on', 'each', 'other', 'how', 'to', 'build', 'an', 'efficient', 'model']","['predictor', 'variable', 'data', 'dependent', 'build', 'efficient', 'model']",predictor variable data dependent build efficient model,-0.125,0.0,16,55,3.235294117647059,0,0,0,0,0,0,0,0
1526,what is machine learning and how is it different from big data and business analytics,Techniques,what is machine learning and how is it different from big data and business analytics,"['what', 'is', 'machine', 'learning', 'and', 'how', 'is', 'it', 'different', 'from', 'big', 'data', 'and', 'business', 'analytics']",0,"['what', 'is', 'machine', 'learning', 'and', 'how', 'is', 'it', 'different', 'from', 'big', 'data', 'and', 'business', 'analytics']","['machine', 'learning', 'different', 'big', 'data', 'business', 'analytics']",machine learning different big data business analytics,0.0,0.0,15,54,3.375,0,0,0,0,0,0,0,0
1527,to the admins ratio of public and private lb,Hackathons,to the admins ratio of public and private lb,"['to', 'the', 'admins', 'ratio', 'of', 'public', 'and', 'private', 'lb']",0,"['to', 'the', 'admins', 'ratio', 'of', 'public', 'and', 'private', 'lb']","['admins', 'ratio', 'public', 'private', 'lb']",admins ratio public private lb,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
1528,error in datatabledata target  in r,Tools,error in datatabledata target  in r,"['error', 'in', 'datatabledata', 'target', 'in', 'r']",0,"['error', 'in', 'datatabledata', 'target', 'in', 'r']","['error', 'datatabledata', 'target', 'r']",error datatabledata target r,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
1529,air quality index prediction,Tools,air quality index prediction,"['air', 'quality', 'index', 'prediction']",0,"['air', 'quality', 'index', 'prediction']","['air', 'quality', 'index', 'prediction']",air quality index prediction,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
1530,assumptions for classification algorithms,Techniques,assumptions for classification algorithms,"['assumptions', 'for', 'classification', 'algorithms']",0,"['assumption', 'for', 'classification', 'algorithm']","['assumption', 'classification', 'algorithm']",assumption classification algorithm,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
1531,recommendation engine  which algorithm is suitable for long string of text as input,Techniques,recommendation engine  which algorithm is suitable for long string of text as input,"['recommendation', 'engine', 'which', 'algorithm', 'is', 'suitable', 'for', 'long', 'string', 'of', 'text', 'as', 'input']",0,"['recommendation', 'engine', 'which', 'algorithm', 'is', 'suitable', 'for', 'long', 'string', 'of', 'text', 'a', 'input']","['recommendation', 'engine', 'algorithm', 'suitable', 'long', 'string', 'text', 'input']",recommendation engine algorithm suitable long string text input,0.25,0.25,13,63,4.5,0,0,0,0,0,0,0,0
1532,tuning parameters in xgboost however same rmse score while submitting solution,Hackathons,tuning parameters in xgboost however same rmse score while submitting solution,"['tuning', 'parameters', 'in', 'xgboost', 'however', 'same', 'rmse', 'score', 'while', 'submitting', 'solution']",0,"['tuning', 'parameter', 'in', 'xgboost', 'however', 'same', 'rmse', 'score', 'while', 'submitting', 'solution']","['tuning', 'parameter', 'xgboost', 'however', 'rmse', 'score', 'submitting', 'solution']",tuning parameter xgboost however rmse score submitting solution,0.0,0.0,11,63,5.25,0,0,0,0,0,0,0,0
1533,learning to learn machine learning,Misc,learning to learn machine learning,"['learning', 'to', 'learn', 'machine', 'learning']",0,"['learning', 'to', 'learn', 'machine', 'learning']","['learning', 'learn', 'machine', 'learning']",learning learn machine learning,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1534,acf plot in arima,Techniques,acf plot in arima,"['acf', 'plot', 'in', 'arima']",0,"['acf', 'plot', 'in', 'arima']","['acf', 'plot', 'arima']",acf plot arima,0.0,0.0,4,14,2.8,0,0,0,0,0,0,0,0
1535,error while using fileinput in shiny,Tools,error while using fileinput in shiny,"['error', 'while', 'using', 'fileinput', 'in', 'shiny']",0,"['error', 'while', 'using', 'fileinput', 'in', 'shiny']","['error', 'using', 'fileinput', 'shiny']",error using fileinput shiny,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
1536,what is the johnson lindenstrauss theorem,Techniques,what is the johnson lindenstrauss theorem,"['what', 'is', 'the', 'johnson', 'lindenstrauss', 'theorem']",0,"['what', 'is', 'the', 'johnson', 'lindenstrauss', 'theorem']","['johnson', 'lindenstrauss', 'theorem']",johnson lindenstrauss theorem,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
1537,learning math in datascience,Resources,learning math in datascience,"['learning', 'math', 'in', 'datascience']",0,"['learning', 'math', 'in', 'datascience']","['learning', 'math', 'datascience']",learning math datascience,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
1538,help on plotting in r,Tools,help on plotting in r,"['help', 'on', 'plotting', 'in', 'r']",0,"['help', 'on', 'plotting', 'in', 'r']","['help', 'plotting', 'r']",help plotting r,0.0,0.0,5,15,2.5,0,0,0,0,0,0,0,0
1539,how to apply machine learning algorithms to a travel and tourism brand,Resources,how to apply machine learning algorithms to a travel and tourism brand,"['how', 'to', 'apply', 'machine', 'learning', 'algorithms', 'to', 'a', 'travel', 'and', 'tourism', 'brand']",0,"['how', 'to', 'apply', 'machine', 'learning', 'algorithm', 'to', 'a', 'travel', 'and', 'tourism', 'brand']","['apply', 'machine', 'learning', 'algorithm', 'travel', 'tourism', 'brand']",apply machine learning algorithm travel tourism brand,0.0,0.0,12,53,4.076923076923077,0,0,0,0,0,0,0,0
1540,how to convert string to float  data is in csv error is  valueerror could not convert string to float unknown,Techniques,how to convert string to float  data is in csv error is  valueerror could not convert string to float unknown,"['how', 'to', 'convert', 'string', 'to', 'float', 'data', 'is', 'in', 'csv', 'error', 'is', 'valueerror', 'could', 'not', 'convert', 'string', 'to', 'float', 'unknown']",0,"['how', 'to', 'convert', 'string', 'to', 'float', 'data', 'is', 'in', 'csv', 'error', 'is', 'valueerror', 'could', 'not', 'convert', 'string', 'to', 'float', 'unknown']","['convert', 'string', 'float', 'data', 'csv', 'error', 'valueerror', 'could', 'convert', 'string', 'float', 'unknown']",convert string float data csv error valueerror could convert string float unknown,-0.1,-0.1,20,81,3.857142857142857,0,0,0,0,0,0,0,0
1541,transposing data set in sas,Tools,transposing data set in sas,"['transposing', 'data', 'set', 'in', 'sas']",0,"['transposing', 'data', 'set', 'in', 'sa']","['transposing', 'data', 'set', 'sa']",transposing data set sa,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
1542,difference between fit transform and fittransform,Techniques,difference between fit transform and fittransform,"['difference', 'between', 'fit', 'transform', 'and', 'fittransform']",0,"['difference', 'between', 'fit', 'transform', 'and', 'fittransform']","['difference', 'fit', 'transform', 'fittransform']",difference fit transform fittransform,0.4,0.4,6,37,5.285714285714286,0,0,0,0,0,0,0,0
1543,read a large json dataset in pandas,Tools,read a large json dataset in pandas,"['read', 'a', 'large', 'json', 'dataset', 'in', 'pandas']",0,"['read', 'a', 'large', 'json', 'dataset', 'in', 'panda']","['read', 'large', 'json', 'dataset', 'panda']",read large json dataset panda,0.2142857142857142,0.2142857142857142,7,29,3.625,0,0,0,0,0,0,0,0
1544,how are rows increasing when i try to do feature engineering,Hackathons,how are rows increasing when i try to do feature engineering,"['how', 'are', 'rows', 'increasing', 'when', 'i', 'try', 'to', 'do', 'feature', 'engineering']",0,"['how', 'are', 'row', 'increasing', 'when', 'i', 'try', 'to', 'do', 'feature', 'engineering']","['row', 'increasing', 'try', 'feature', 'engineering']",row increasing try feature engineering,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
1545,regarding variable selection for algorithms,Techniques,regarding variable selection for algorithms,"['regarding', 'variable', 'selection', 'for', 'algorithms']",0,"['regarding', 'variable', 'selection', 'for', 'algorithm']","['regarding', 'variable', 'selection', 'algorithm']",regarding variable selection algorithm,0.0,0.0,5,38,6.333333333333333,0,0,0,0,0,0,0,0
1546,svr predicted values are way off from the actual ones despite high rsquared and and low mse,Techniques,svr predicted values are way off from the actual ones despite high rsquared and and low mse,"['svr', 'predicted', 'values', 'are', 'way', 'off', 'from', 'the', 'actual', 'ones', 'despite', 'high', 'rsquared', 'and', 'and', 'low', 'mse']",0,"['svr', 'predicted', 'value', 'are', 'way', 'off', 'from', 'the', 'actual', 'one', 'despite', 'high', 'rsquared', 'and', 'and', 'low', 'mse']","['svr', 'predicted', 'value', 'way', 'actual', 'one', 'despite', 'high', 'rsquared', 'low', 'mse']",svr predicted value way actual one despite high rsquared low mse,0.0533333333333333,0.0533333333333333,17,64,3.5555555555555554,0,0,0,0,0,0,0,0
1547,dataset black friday,Hackathons,dataset black friday,"['dataset', 'black', 'friday']",0,"['dataset', 'black', 'friday']","['dataset', 'black', 'friday']",dataset black friday,-0.1666666666666666,-0.1666666666666666,3,20,5.0,0,0,0,0,0,0,0,0
1548,how to convert dates into days of week in r,Tools,how to convert dates into days of week in r,"['how', 'to', 'convert', 'dates', 'into', 'days', 'of', 'week', 'in', 'r']",0,"['how', 'to', 'convert', 'date', 'into', 'day', 'of', 'week', 'in', 'r']","['convert', 'date', 'day', 'week', 'r']",convert date day week r,0.0,0.0,10,23,2.090909090909091,0,0,0,0,0,0,0,0
1549,why random forest could not handle large number of categorical predicators,Techniques,why random forest could not handle large number of categorical predicators,"['why', 'random', 'forest', 'could', 'not', 'handle', 'large', 'number', 'of', 'categorical', 'predicators']",0,"['why', 'random', 'forest', 'could', 'not', 'handle', 'large', 'number', 'of', 'categorical', 'predicator']","['random', 'forest', 'could', 'handle', 'large', 'number', 'categorical', 'predicator']",random forest could handle large number categorical predicator,-0.1428571428571428,-0.1428571428571428,11,62,5.166666666666667,0,0,0,0,0,0,0,0
1550,transition from business intelligence etl to data analytics,Career,transition from business intelligence etl to data analytics,"['transition', 'from', 'business', 'intelligence', 'etl', 'to', 'data', 'analytics']",0,"['transition', 'from', 'business', 'intelligence', 'etl', 'to', 'data', 'analytics']","['transition', 'business', 'intelligence', 'etl', 'data', 'analytics']",transition business intelligence etl data analytics,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
1551,excel classification using some technique,Techniques,excel classification using some technique,"['excel', 'classification', 'using', 'some', 'technique']",0,"['excel', 'classification', 'using', 'some', 'technique']","['excel', 'classification', 'using', 'technique']",excel classification using technique,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
1552,converting loop to apply function,Tools,converting loop to apply function,"['converting', 'loop', 'to', 'apply', 'function']",0,"['converting', 'loop', 'to', 'apply', 'function']","['converting', 'loop', 'apply', 'function']",converting loop apply function,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
1553,where can one access the code for the lead solutions to mckinseys hackathons  july  ,Hackathons,where can one access the code for the lead solutions to mckinseys hackathons  july  ,"['where', 'can', 'one', 'access', 'the', 'code', 'for', 'the', 'lead', 'solutions', 'to', 'mckinseys', 'hackathons', 'july']",2,"['where', 'can', 'one', 'access', 'the', 'code', 'for', 'the', 'lead', 'solution', 'to', 'mckinseys', 'hackathons', 'july']","['one', 'access', 'code', 'lead', 'solution', 'mckinseys', 'hackathons', 'july']",one access code lead solution mckinseys hackathons july,0.0,0.0,14,55,3.6666666666666665,0,0,0,0,0,0,0,0
1554,how to train a model when train set and test contain different levels for a variable,Techniques,how to train a model when train set and test contain different levels for a variable,"['how', 'to', 'train', 'a', 'model', 'when', 'train', 'set', 'and', 'test', 'contain', 'different', 'levels', 'for', 'a', 'variable']",0,"['how', 'to', 'train', 'a', 'model', 'when', 'train', 'set', 'and', 'test', 'contain', 'different', 'level', 'for', 'a', 'variable']","['train', 'model', 'train', 'set', 'test', 'contain', 'different', 'level', 'variable']",train model train set test contain different level variable,0.0,0.0,16,59,3.4705882352941178,0,0,0,0,0,0,0,0
1555,resources for strategic thinking competitions,Resources,resources for strategic thinking competitions,"['resources', 'for', 'strategic', 'thinking', 'competitions']",0,"['resource', 'for', 'strategic', 'thinking', 'competition']","['resource', 'strategic', 'thinking', 'competition']",resource strategic thinking competition,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
1556,kfoldcv in regression splines,Techniques,kfoldcv in regression splines,"['kfoldcv', 'in', 'regression', 'splines']",0,"['kfoldcv', 'in', 'regression', 'spline']","['kfoldcv', 'regression', 'spline']",kfoldcv regression spline,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
1557,should i scale ordinal data to use in analysis,Techniques,should i scale ordinal data to use in analysis,"['should', 'i', 'scale', 'ordinal', 'data', 'to', 'use', 'in', 'analysis']",0,"['should', 'i', 'scale', 'ordinal', 'data', 'to', 'use', 'in', 'analysis']","['scale', 'ordinal', 'data', 'use', 'analysis']",scale ordinal data use analysis,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
1558,survival analysis model to predict next transaction,Techniques,survival analysis model to predict next transaction,"['survival', 'analysis', 'model', 'to', 'predict', 'next', 'transaction']",0,"['survival', 'analysis', 'model', 'to', 'predict', 'next', 'transaction']","['survival', 'analysis', 'model', 'predict', 'next', 'transaction']",survival analysis model predict next transaction,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
1559,post graduate program in big data analytics from great lakes,Career,post graduate program in big data analytics from great lakes,"['post', 'graduate', 'program', 'in', 'big', 'data', 'analytics', 'from', 'great', 'lakes']",0,"['post', 'graduate', 'program', 'in', 'big', 'data', 'analytics', 'from', 'great', 'lake']","['post', 'graduate', 'program', 'big', 'data', 'analytics', 'great', 'lake']",post graduate program big data analytics great lake,0.4,0.4,10,51,4.636363636363637,0,0,0,0,0,0,0,0
1560,when can you say a random forest is saturated and wont improve,Techniques,when can you say a random forest is saturated and wont improve,"['when', 'can', 'you', 'say', 'a', 'random', 'forest', 'is', 'saturated', 'and', 'wont', 'improve']",0,"['when', 'can', 'you', 'say', 'a', 'random', 'forest', 'is', 'saturated', 'and', 'wont', 'improve']","['say', 'random', 'forest', 'saturated', 'wont', 'improve']",say random forest saturated wont improve,-0.5,-0.5,12,40,3.076923076923077,0,0,0,0,0,0,0,0
1561,r and sql server connection,Tools,r and sql server connection,"['r', 'and', 'sql', 'server', 'connection']",0,"['r', 'and', 'sql', 'server', 'connection']","['r', 'sql', 'server', 'connection']",r sql server connection,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
1562,why high model accuracy compared to very low validation accuracy,Techniques,why high model accuracy compared to very low validation accuracy,"['why', 'high', 'model', 'accuracy', 'compared', 'to', 'very', 'low', 'validation', 'accuracy']",0,"['why', 'high', 'model', 'accuracy', 'compared', 'to', 'very', 'low', 'validation', 'accuracy']","['high', 'model', 'accuracy', 'compared', 'low', 'validation', 'accuracy']",high model accuracy compared low validation accuracy,0.08,0.08,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
1563,valueerrorcould not convert string to float rural,Hackathons,valueerrorcould not convert string to float rural,"['valueerrorcould', 'not', 'convert', 'string', 'to', 'float', 'rural']",0,"['valueerrorcould', 'not', 'convert', 'string', 'to', 'float', 'rural']","['valueerrorcould', 'convert', 'string', 'float', 'rural']",valueerrorcould convert string float rural,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
1564,what are q k and v vectors exactly in transformers,Techniques,what are q k and v vectors exactly in transformers,"['what', 'are', 'q', 'k', 'and', 'v', 'vectors', 'exactly', 'in', 'transformers']",0,"['what', 'are', 'q', 'k', 'and', 'v', 'vector', 'exactly', 'in', 'transformer']","['q', 'k', 'v', 'vector', 'exactly', 'transformer']",q k v vector exactly transformer,0.25,0.25,10,32,2.909090909090909,0,0,0,0,0,0,0,0
1565,how can i create confusion matrix in python,Tools,how can i create confusion matrix in python,"['how', 'can', 'i', 'create', 'confusion', 'matrix', 'in', 'python']",0,"['how', 'can', 'i', 'create', 'confusion', 'matrix', 'in', 'python']","['create', 'confusion', 'matrix', 'python']",create confusion matrix python,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
1566,from which material online can i get a good idea about principal component analysis,Techniques,from which material online can i get a good idea about principal component analysis,"['from', 'which', 'material', 'online', 'can', 'i', 'get', 'a', 'good', 'idea', 'about', 'principal', 'component', 'analysis']",0,"['from', 'which', 'material', 'online', 'can', 'i', 'get', 'a', 'good', 'idea', 'about', 'principal', 'component', 'analysis']","['material', 'online', 'get', 'good', 'idea', 'principal', 'component', 'analysis']",material online get good idea principal component analysis,0.7,0.7,14,58,3.8666666666666667,0,0,0,0,0,0,0,0
1567,which technique should we use in case target variable has no data,Techniques,which technique should we use in case target variable has no data,"['which', 'technique', 'should', 'we', 'use', 'in', 'case', 'target', 'variable', 'has', 'no', 'data']",0,"['which', 'technique', 'should', 'we', 'use', 'in', 'case', 'target', 'variable', 'ha', 'no', 'data']","['technique', 'use', 'case', 'target', 'variable', 'ha', 'data']",technique use case target variable ha data,0.0,0.0,12,42,3.230769230769231,0,0,0,0,0,0,0,0
1568,does big data analytics requires ms or mtech,Career,does big data analytics requires ms or mtech,"['does', 'big', 'data', 'analytics', 'requires', 'ms', 'or', 'mtech']",0,"['doe', 'big', 'data', 'analytics', 'requires', 'm', 'or', 'mtech']","['doe', 'big', 'data', 'analytics', 'requires', 'mtech']",doe big data analytics requires mtech,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
1569,what is the reason behind having orthogonal pcas,Techniques,what is the reason behind having orthogonal pcas,"['what', 'is', 'the', 'reason', 'behind', 'having', 'orthogonal', 'pcas']",0,"['what', 'is', 'the', 'reason', 'behind', 'having', 'orthogonal', 'pcas']","['reason', 'behind', 'orthogonal', 'pcas']",reason behind orthogonal pcas,-0.4,-0.4,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
1570,wrong output while checking pandas dtypes,Techniques,wrong output while checking pandas dtypes,"['wrong', 'output', 'while', 'checking', 'pandas', 'dtypes']",0,"['wrong', 'output', 'while', 'checking', 'panda', 'dtypes']","['wrong', 'output', 'checking', 'panda', 'dtypes']",wrong output checking panda dtypes,-0.5,-0.5,6,34,4.857142857142857,0,0,0,0,0,0,0,0
1571,what should be the value of k in knn,Techniques,what should be the value of k in knn,"['what', 'should', 'be', 'the', 'value', 'of', 'k', 'in', 'knn']",0,"['what', 'should', 'be', 'the', 'value', 'of', 'k', 'in', 'knn']","['value', 'k', 'knn']",value k knn,0.0,0.0,9,11,1.1,0,0,0,0,0,0,0,0
1572,how to interpret the output of a glmboost,Techniques,how to interpret the output of a glmboost,"['how', 'to', 'interpret', 'the', 'output', 'of', 'a', 'glmboost']",0,"['how', 'to', 'interpret', 'the', 'output', 'of', 'a', 'glmboost']","['interpret', 'output', 'glmboost']",interpret output glmboost,0.0,0.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
1573,how can i get a project to do on data analysis,Other,how can i get a project to do on data analysis,"['how', 'can', 'i', 'get', 'a', 'project', 'to', 'do', 'on', 'data', 'analysis']",0,"['how', 'can', 'i', 'get', 'a', 'project', 'to', 'do', 'on', 'data', 'analysis']","['get', 'project', 'data', 'analysis']",get project data analysis,0.0,0.0,11,25,2.0833333333333335,0,0,0,0,0,0,0,0
1574,when do we use kappa statistic as a measure of model performance vs accuracy,Techniques,when do we use kappa statistic as a measure of model performance vs accuracy,"['when', 'do', 'we', 'use', 'kappa', 'statistic', 'as', 'a', 'measure', 'of', 'model', 'performance', 'vs', 'accuracy']",0,"['when', 'do', 'we', 'use', 'kappa', 'statistic', 'a', 'a', 'measure', 'of', 'model', 'performance', 'v', 'accuracy']","['use', 'kappa', 'statistic', 'measure', 'model', 'performance', 'v', 'accuracy']",use kappa statistic measure model performance v accuracy,0.0,0.0,14,56,3.7333333333333334,0,0,0,0,0,0,0,0
1575,shape error while calculating r square,Techniques,shape error while calculating r square,"['shape', 'error', 'while', 'calculating', 'r', 'square']",0,"['shape', 'error', 'while', 'calculating', 'r', 'square']","['shape', 'error', 'calculating', 'r', 'square']",shape error calculating r square,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
1576,cool video for understanding neural networks,Resources,cool video for understanding neural networks,"['cool', 'video', 'for', 'understanding', 'neural', 'networks']",0,"['cool', 'video', 'for', 'understanding', 'neural', 'network']","['cool', 'video', 'understanding', 'neural', 'network']",cool video understanding neural network,0.35,0.35,6,39,5.571428571428571,0,0,0,0,0,0,0,0
1577,how to interpret roccurvetestpredictions in scikitlearn,Techniques,how to interpret roccurvetestpredictions in scikitlearn,"['how', 'to', 'interpret', 'roccurvetestpredictions', 'in', 'scikitlearn']",0,"['how', 'to', 'interpret', 'roccurvetestpredictions', 'in', 'scikitlearn']","['interpret', 'roccurvetestpredictions', 'scikitlearn']",interpret roccurvetestpredictions scikitlearn,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
1578,text classification or sentiment analysis using combination of different classifiers in python,Techniques,text classification or sentiment analysis using combination of different classifiers in python,"['text', 'classification', 'or', 'sentiment', 'analysis', 'using', 'combination', 'of', 'different', 'classifiers', 'in', 'python']",0,"['text', 'classification', 'or', 'sentiment', 'analysis', 'using', 'combination', 'of', 'different', 'classifier', 'in', 'python']","['text', 'classification', 'sentiment', 'analysis', 'using', 'combination', 'different', 'classifier', 'python']",text classification sentiment analysis using combination different classifier python,0.0,0.0,12,84,6.461538461538462,0,0,0,0,0,0,0,0
1579,setting cutoff on idf values while calculating cosine similarity between two documents,Techniques,setting cutoff on idf values while calculating cosine similarity between two documents,"['setting', 'cutoff', 'on', 'idf', 'values', 'while', 'calculating', 'cosine', 'similarity', 'between', 'two', 'documents']",0,"['setting', 'cutoff', 'on', 'idf', 'value', 'while', 'calculating', 'cosine', 'similarity', 'between', 'two', 'document']","['setting', 'cutoff', 'idf', 'value', 'calculating', 'cosine', 'similarity', 'two', 'document']",setting cutoff idf value calculating cosine similarity two document,0.0,0.0,12,67,5.153846153846154,0,0,0,0,0,0,0,0
1580,how to get the proportion in table command of r,Tools,how to get the proportion in table command of r,"['how', 'to', 'get', 'the', 'proportion', 'in', 'table', 'command', 'of', 'r']",0,"['how', 'to', 'get', 'the', 'proportion', 'in', 'table', 'command', 'of', 'r']","['get', 'proportion', 'table', 'command', 'r']",get proportion table command r,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
1581,how to apply condition statement using numpy library in ipython,Techniques,how to apply condition statement using numpy library in ipython,"['how', 'to', 'apply', 'condition', 'statement', 'using', 'numpy', 'library', 'in', 'ipython']",0,"['how', 'to', 'apply', 'condition', 'statement', 'using', 'numpy', 'library', 'in', 'ipython']","['apply', 'condition', 'statement', 'using', 'numpy', 'library', 'ipython']",apply condition statement using numpy library ipython,0.0,0.0,10,53,4.818181818181818,0,0,0,0,0,0,0,0
1582,factorization machines article,Resources,factorization machines article,"['factorization', 'machines', 'article']",0,"['factorization', 'machine', 'article']","['factorization', 'machine', 'article']",factorization machine article,0.0,0.0,3,29,7.25,0,0,0,0,0,0,0,0
1583,how to check the performance error of bagging model in r,Techniques,how to check the performance error of bagging model in r,"['how', 'to', 'check', 'the', 'performance', 'error', 'of', 'bagging', 'model', 'in', 'r']",0,"['how', 'to', 'check', 'the', 'performance', 'error', 'of', 'bagging', 'model', 'in', 'r']","['check', 'performance', 'error', 'bagging', 'model', 'r']",check performance error bagging model r,0.0,0.0,11,39,3.25,0,0,0,0,0,0,0,0
1584,feature engineering within the cross validation,Techniques,feature engineering within the cross validation,"['feature', 'engineering', 'within', 'the', 'cross', 'validation']",0,"['feature', 'engineering', 'within', 'the', 'cross', 'validation']","['feature', 'engineering', 'within', 'cross', 'validation']",feature engineering within cross validation,0.0,0.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
1585,why training time is not decreasing with increase in value of cost in a svm model,Techniques,why training time is not decreasing with increase in value of cost in a svm model,"['why', 'training', 'time', 'is', 'not', 'decreasing', 'with', 'increase', 'in', 'value', 'of', 'cost', 'in', 'a', 'svm', 'model']",0,"['why', 'training', 'time', 'is', 'not', 'decreasing', 'with', 'increase', 'in', 'value', 'of', 'cost', 'in', 'a', 'svm', 'model']","['training', 'time', 'decreasing', 'increase', 'value', 'cost', 'svm', 'model']",training time decreasing increase value cost svm model,0.0,0.0,16,54,3.176470588235294,0,0,0,0,0,0,0,0
1586,what is the function of stemmer in the nltk library of python,Tools,what is the function of stemmer in the nltk library of python,"['what', 'is', 'the', 'function', 'of', 'stemmer', 'in', 'the', 'nltk', 'library', 'of', 'python']",0,"['what', 'is', 'the', 'function', 'of', 'stemmer', 'in', 'the', 'nltk', 'library', 'of', 'python']","['function', 'stemmer', 'nltk', 'library', 'python']",function stemmer nltk library python,0.0,0.0,12,36,2.769230769230769,0,0,0,0,0,0,0,0
1587,can we get access to closed event resources,Other,can we get access to closed event resources,"['can', 'we', 'get', 'access', 'to', 'closed', 'event', 'resources']",0,"['can', 'we', 'get', 'access', 'to', 'closed', 'event', 'resource']","['get', 'access', 'closed', 'event', 'resource']",get access closed event resource,-0.1,-0.1,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
1588,how to go about continued education if i am in a financial crunch,Career,how to go about continued education if i am in a financial crunch,"['how', 'to', 'go', 'about', 'continued', 'education', 'if', 'i', 'am', 'in', 'a', 'financial', 'crunch']",0,"['how', 'to', 'go', 'about', 'continued', 'education', 'if', 'i', 'am', 'in', 'a', 'financial', 'crunch']","['go', 'continued', 'education', 'financial', 'crunch']",go continued education financial crunch,0.0,0.0,13,39,2.7857142857142856,0,0,0,0,0,0,0,0
1589,airline spend analytics,Techniques,airline spend analytics,"['airline', 'spend', 'analytics']",0,"['airline', 'spend', 'analytics']","['airline', 'spend', 'analytics']",airline spend analytics,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
1590,isb vs great lakes,Career,isb vs great lakes,"['isb', 'vs', 'great', 'lakes']",0,"['isb', 'v', 'great', 'lake']","['isb', 'v', 'great', 'lake']",isb v great lake,0.8,0.8,4,16,3.2,0,0,0,0,0,0,0,0
1591,ms in cs vs ms data science,Career,ms in cs vs ms data science,"['ms', 'in', 'cs', 'vs', 'ms', 'data', 'science']",0,"['m', 'in', 'c', 'v', 'm', 'data', 'science']","['c', 'v', 'data', 'science']",c v data science,0.0,0.0,7,16,2.0,0,0,0,0,0,0,0,0
1592,how to merge dat format files in r,Tools,how to merge dat format files in r,"['how', 'to', 'merge', 'dat', 'format', 'files', 'in', 'r']",0,"['how', 'to', 'merge', 'dat', 'format', 'file', 'in', 'r']","['merge', 'dat', 'format', 'file', 'r']",merge dat format file r,0.0,0.0,8,23,2.5555555555555554,0,0,0,0,0,0,0,0
1593,histogram in tableau desktop  free trail ,Tools,histogram in tableau desktop  free trail ,"['histogram', 'in', 'tableau', 'desktop', 'free', 'trail']",0,"['histogram', 'in', 'tableau', 'desktop', 'free', 'trail']","['histogram', 'tableau', 'desktop', 'free', 'trail']",histogram tableau desktop free trail,0.4,0.4,6,36,5.142857142857143,0,0,0,0,0,0,0,0
1594,advance text mining,Techniques,advance text mining,"['advance', 'text', 'mining']",0,"['advance', 'text', 'mining']","['advance', 'text', 'mining']",advance text mining,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
1595,installing libffm on ubuntu ,Tools,installing libffm on ubuntu ,"['installing', 'libffm', 'on', 'ubuntu']",1,"['installing', 'libffm', 'on', 'ubuntu']","['installing', 'libffm', 'ubuntu']",installing libffm ubuntu,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
1596,data science vs big data  career prospect wise is combination of both more attractive if one can apply right skills,Career,data science vs big data  career prospect wise is combination of both more attractive if one can apply right skills,"['data', 'science', 'vs', 'big', 'data', 'career', 'prospect', 'wise', 'is', 'combination', 'of', 'both', 'more', 'attractive', 'if', 'one', 'can', 'apply', 'right', 'skills']",0,"['data', 'science', 'v', 'big', 'data', 'career', 'prospect', 'wise', 'is', 'combination', 'of', 'both', 'more', 'attractive', 'if', 'one', 'can', 'apply', 'right', 'skill']","['data', 'science', 'v', 'big', 'data', 'career', 'prospect', 'wise', 'combination', 'attractive', 'one', 'apply', 'right', 'skill']",data science v big data career prospect wise combination attractive one apply right skill,0.4571428571428571,0.4464285714285714,20,89,4.238095238095238,0,0,0,0,0,0,0,0
1597,how to run decision tree algorithm on spark r,Techniques,how to run decision tree algorithm on spark r,"['how', 'to', 'run', 'decision', 'tree', 'algorithm', 'on', 'spark', 'r']",0,"['how', 'to', 'run', 'decision', 'tree', 'algorithm', 'on', 'spark', 'r']","['run', 'decision', 'tree', 'algorithm', 'spark', 'r']",run decision tree algorithm spark r,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
1598,how good is imarticus learning institute,Career,how good is imarticus learning institute,"['how', 'good', 'is', 'imarticus', 'learning', 'institute']",0,"['how', 'good', 'is', 'imarticus', 'learning', 'institute']","['good', 'imarticus', 'learning', 'institute']",good imarticus learning institute,0.7,0.7,6,33,4.714285714285714,0,0,0,0,0,0,0,0
1599,how to deal with constant variables,Techniques,how to deal with constant variables,"['how', 'to', 'deal', 'with', 'constant', 'variables']",0,"['how', 'to', 'deal', 'with', 'constant', 'variable']","['deal', 'constant', 'variable']",deal constant variable,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
1600,data scientist  year it professional,Career,data scientist  year it professional,"['data', 'scientist', 'year', 'it', 'professional']",1,"['data', 'scientist', 'year', 'it', 'professional']","['data', 'scientist', 'year', 'professional']",data scientist year professional,0.1,0.1,5,32,5.333333333333333,0,0,0,0,0,0,0,0
1601,loading data for joke rating prediction dataset,Hackathons,loading data for joke rating prediction dataset,"['loading', 'data', 'for', 'joke', 'rating', 'prediction', 'dataset']",0,"['loading', 'data', 'for', 'joke', 'rating', 'prediction', 'dataset']","['loading', 'data', 'joke', 'rating', 'prediction', 'dataset']",loading data joke rating prediction dataset,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
1602,post graduation in ananlytics,Career,post graduation in ananlytics,"['post', 'graduation', 'in', 'ananlytics']",0,"['post', 'graduation', 'in', 'ananlytics']","['post', 'graduation', 'ananlytics']",post graduation ananlytics,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
1603,what is difference between cyclic and drill down group in qlikview,Tools,what is difference between cyclic and drill down group in qlikview,"['what', 'is', 'difference', 'between', 'cyclic', 'and', 'drill', 'down', 'group', 'in', 'qlikview']",0,"['what', 'is', 'difference', 'between', 'cyclic', 'and', 'drill', 'down', 'group', 'in', 'qlikview']","['difference', 'cyclic', 'drill', 'group', 'qlikview']",difference cyclic drill group qlikview,-0.1555555555555555,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
1604,what does rotmat signifies in varimax function during pca,Techniques,what does rotmat signifies in varimax function during pca,"['what', 'does', 'rotmat', 'signifies', 'in', 'varimax', 'function', 'during', 'pca']",0,"['what', 'doe', 'rotmat', 'signifies', 'in', 'varimax', 'function', 'during', 'pca']","['doe', 'rotmat', 'signifies', 'varimax', 'function', 'pca']",doe rotmat signifies varimax function pca,0.0,0.0,9,41,4.1,0,0,0,0,0,0,0,0
1605,brand assortment,Techniques,brand assortment,"['brand', 'assortment']",0,"['brand', 'assortment']","['brand', 'assortment']",brand assortment,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
1606,data mapping using machine learning,Techniques,data mapping using machine learning,"['data', 'mapping', 'using', 'machine', 'learning']",0,"['data', 'mapping', 'using', 'machine', 'learning']","['data', 'mapping', 'using', 'machine', 'learning']",data mapping using machine learning,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
1607,getting into business analytics,Career,getting into business analytics,"['getting', 'into', 'business', 'analytics']",0,"['getting', 'into', 'business', 'analytics']","['getting', 'business', 'analytics']",getting business analytics,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
1608,how do unit vectors capture data in singular value decomposition,Techniques,how do unit vectors capture data in singular value decomposition,"['how', 'do', 'unit', 'vectors', 'capture', 'data', 'in', 'singular', 'value', 'decomposition']",0,"['how', 'do', 'unit', 'vector', 'capture', 'data', 'in', 'singular', 'value', 'decomposition']","['unit', 'vector', 'capture', 'data', 'singular', 'value', 'decomposition']",unit vector capture data singular value decomposition,0.0,0.0,10,53,4.818181818181818,0,0,0,0,0,0,0,0
1609,how to impute missing value in sas for charcter variable,Techniques,how to impute missing value in sas for charcter variable,"['how', 'to', 'impute', 'missing', 'value', 'in', 'sas', 'for', 'charcter', 'variable']",0,"['how', 'to', 'impute', 'missing', 'value', 'in', 'sa', 'for', 'charcter', 'variable']","['impute', 'missing', 'value', 'sa', 'charcter', 'variable']",impute missing value sa charcter variable,-0.2,-0.2,10,41,3.727272727272727,0,0,0,0,0,0,0,0
1610,identifying sarima parameters,Techniques,identifying sarima parameters,"['identifying', 'sarima', 'parameters']",0,"['identifying', 'sarima', 'parameter']","['identifying', 'sarima', 'parameter']",identifying sarima parameter,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
1611,how to improve performance of c decision tree,Techniques,how to improve performance of c decision tree,"['how', 'to', 'improve', 'performance', 'of', 'c', 'decision', 'tree']",0,"['how', 'to', 'improve', 'performance', 'of', 'c', 'decision', 'tree']","['improve', 'performance', 'c', 'decision', 'tree']",improve performance c decision tree,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
1612,what is the difference between hoglmwrapper and hoglm in ho,Tools,what is the difference between hoglmwrapper and hoglm in ho,"['what', 'is', 'the', 'difference', 'between', 'hoglmwrapper', 'and', 'hoglm', 'in', 'ho']",0,"['what', 'is', 'the', 'difference', 'between', 'hoglmwrapper', 'and', 'hoglm', 'in', 'ho']","['difference', 'hoglmwrapper', 'hoglm', 'ho']",difference hoglmwrapper hoglm ho,0.0,0.0,10,32,2.909090909090909,0,0,0,0,0,0,0,0
1613,plotting prediction model of multinomial gbm using r,Techniques,plotting prediction model of multinomial gbm using r,"['plotting', 'prediction', 'model', 'of', 'multinomial', 'gbm', 'using', 'r']",0,"['plotting', 'prediction', 'model', 'of', 'multinomial', 'gbm', 'using', 'r']","['plotting', 'prediction', 'model', 'multinomial', 'gbm', 'using', 'r']",plotting prediction model multinomial gbm using r,0.0,0.0,8,49,5.444444444444445,0,0,0,0,0,0,0,0
1614,supply chain management,Misc,supply chain management,"['supply', 'chain', 'management']",0,"['supply', 'chain', 'management']","['supply', 'chain', 'management']",supply chain management,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
1615,plotly bar graph in r,Tools,plotly bar graph in r,"['plotly', 'bar', 'graph', 'in', 'r']",0,"['plotly', 'bar', 'graph', 'in', 'r']","['plotly', 'bar', 'graph', 'r']",plotly bar graph r,0.0,0.0,5,18,3.0,0,0,0,0,0,0,0,0
1616,need information on different tests to be known for different models,Techniques,need information on different tests to be known for different models,"['need', 'information', 'on', 'different', 'tests', 'to', 'be', 'known', 'for', 'different', 'models']",0,"['need', 'information', 'on', 'different', 'test', 'to', 'be', 'known', 'for', 'different', 'model']","['need', 'information', 'different', 'test', 'known', 'different', 'model']",need information different test known different model,0.0,0.0,11,53,4.416666666666667,0,0,0,0,0,0,0,0
1617,project approach,Techniques,project approach,"['project', 'approach']",0,"['project', 'approach']","['project', 'approach']",project approach,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
1618,multiclass classification using logistic regression in python,Techniques,multiclass classification using logistic regression in python,"['multiclass', 'classification', 'using', 'logistic', 'regression', 'in', 'python']",0,"['multiclass', 'classification', 'using', 'logistic', 'regression', 'in', 'python']","['multiclass', 'classification', 'using', 'logistic', 'regression', 'python']",multiclass classification using logistic regression python,0.0,0.0,7,58,7.25,0,0,0,0,0,0,0,0
1619,how to do prediction using online arima algorithm,Techniques,how to do prediction using online arima algorithm,"['how', 'to', 'do', 'prediction', 'using', 'online', 'arima', 'algorithm']",0,"['how', 'to', 'do', 'prediction', 'using', 'online', 'arima', 'algorithm']","['prediction', 'using', 'online', 'arima', 'algorithm']",prediction using online arima algorithm,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
1620,what is the assumption of logistic regression,Techniques,what is the assumption of logistic regression,"['what', 'is', 'the', 'assumption', 'of', 'logistic', 'regression']",0,"['what', 'is', 'the', 'assumption', 'of', 'logistic', 'regression']","['assumption', 'logistic', 'regression']",assumption logistic regression,0.0,0.0,7,30,3.75,0,0,0,0,0,0,0,0
1621,data analytics career path,Career,data analytics career path,"['data', 'analytics', 'career', 'path']",0,"['data', 'analytics', 'career', 'path']","['data', 'analytics', 'career', 'path']",data analytics career path,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
1622,how to predict proportionate amounts of  in logistic regression,Techniques,how to predict proportionate amounts of  in logistic regression,"['how', 'to', 'predict', 'proportionate', 'amounts', 'of', 'in', 'logistic', 'regression']",1,"['how', 'to', 'predict', 'proportionate', 'amount', 'of', 'in', 'logistic', 'regression']","['predict', 'proportionate', 'amount', 'logistic', 'regression']",predict proportionate amount logistic regression,0.0,0.0,9,48,4.8,0,0,0,0,0,0,0,0
1623,how to visualize large number of categorical features as bar plot using matplotlib and python,Techniques,how to visualize large number of categorical features as bar plot using matplotlib and python,"['how', 'to', 'visualize', 'large', 'number', 'of', 'categorical', 'features', 'as', 'bar', 'plot', 'using', 'matplotlib', 'and', 'python']",0,"['how', 'to', 'visualize', 'large', 'number', 'of', 'categorical', 'feature', 'a', 'bar', 'plot', 'using', 'matplotlib', 'and', 'python']","['visualize', 'large', 'number', 'categorical', 'feature', 'bar', 'plot', 'using', 'matplotlib', 'python']",visualize large number categorical feature bar plot using matplotlib python,0.2142857142857142,0.2142857142857142,15,75,4.6875,0,0,0,0,0,0,0,0
1624,types of predictive modelling,Techniques,types of predictive modelling,"['types', 'of', 'predictive', 'modelling']",0,"['type', 'of', 'predictive', 'modelling']","['type', 'predictive', 'modelling']",type predictive modelling,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
1625,data analytics project ideas for b tech students,Career,data analytics project ideas for b tech students,"['data', 'analytics', 'project', 'ideas', 'for', 'b', 'tech', 'students']",0,"['data', 'analytics', 'project', 'idea', 'for', 'b', 'tech', 'student']","['data', 'analytics', 'project', 'idea', 'b', 'tech', 'student']",data analytics project idea b tech student,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
1626,how to import excel file in python excluding first data row,Tools,how to import excel file in python excluding first data row,"['how', 'to', 'import', 'excel', 'file', 'in', 'python', 'excluding', 'first', 'data', 'row']",0,"['how', 'to', 'import', 'excel', 'file', 'in', 'python', 'excluding', 'first', 'data', 'row']","['import', 'excel', 'file', 'python', 'excluding', 'first', 'data', 'row']",import excel file python excluding first data row,0.25,0.25,11,49,4.083333333333333,0,0,0,0,0,0,0,0
1627,how to exclude the elements from the legend in python,Tools,how to exclude the elements from the legend in python,"['how', 'to', 'exclude', 'the', 'elements', 'from', 'the', 'legend', 'in', 'python']",0,"['how', 'to', 'exclude', 'the', 'element', 'from', 'the', 'legend', 'in', 'python']","['exclude', 'element', 'legend', 'python']",exclude element legend python,0.0,0.0,10,29,2.6363636363636362,0,0,0,0,0,0,0,0
1628,how we can calculate the baseline prediction in a classification problem,Techniques,how we can calculate the baseline prediction in a classification problem,"['how', 'we', 'can', 'calculate', 'the', 'baseline', 'prediction', 'in', 'a', 'classification', 'problem']",0,"['how', 'we', 'can', 'calculate', 'the', 'baseline', 'prediction', 'in', 'a', 'classification', 'problem']","['calculate', 'baseline', 'prediction', 'classification', 'problem']",calculate baseline prediction classification problem,0.0,0.0,11,52,4.333333333333333,0,0,0,0,0,0,0,0
1629,chaid based random forest in python,Tools,chaid based random forest in python,"['chaid', 'based', 'random', 'forest', 'in', 'python']",0,"['chaid', 'based', 'random', 'forest', 'in', 'python']","['chaid', 'based', 'random', 'forest', 'python']",chaid based random forest python,-0.5,-0.5,6,32,4.571428571428571,0,0,0,0,0,0,0,0
1630,hiring data science intern in gurgaon,Career,hiring data science intern in gurgaon,"['hiring', 'data', 'science', 'intern', 'in', 'gurgaon']",0,"['hiring', 'data', 'science', 'intern', 'in', 'gurgaon']","['hiring', 'data', 'science', 'intern', 'gurgaon']",hiring data science intern gurgaon,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
1631,business analyst software requirement gathering vs data analyst which one to choose,Career,business analyst software requirement gathering vs data analyst which one to choose,"['business', 'analyst', 'software', 'requirement', 'gathering', 'vs', 'data', 'analyst', 'which', 'one', 'to', 'choose']",0,"['business', 'analyst', 'software', 'requirement', 'gathering', 'v', 'data', 'analyst', 'which', 'one', 'to', 'choose']","['business', 'analyst', 'software', 'requirement', 'gathering', 'v', 'data', 'analyst', 'one', 'choose']",business analyst software requirement gathering v data analyst one choose,0.0,0.0,12,73,5.615384615384615,0,0,0,0,0,0,0,0
1632,azure ml studio db connectivity,Techniques,azure ml studio db connectivity,"['azure', 'ml', 'studio', 'db', 'connectivity']",0,"['azure', 'ml', 'studio', 'db', 'connectivity']","['azure', 'ml', 'studio', 'db', 'connectivity']",azure ml studio db connectivity,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1633,generating sound effects for a particular scene in a video,Techniques,generating sound effects for a particular scene in a video,"['generating', 'sound', 'effects', 'for', 'a', 'particular', 'scene', 'in', 'a', 'video']",0,"['generating', 'sound', 'effect', 'for', 'a', 'particular', 'scene', 'in', 'a', 'video']","['generating', 'sound', 'effect', 'particular', 'scene', 'video']",generating sound effect particular scene video,0.2833333333333333,0.2833333333333333,10,46,4.181818181818182,0,0,0,0,0,0,0,0
1634,mini datahack  bigger than you think,Hackathons,mini datahack  bigger than you think,"['mini', 'datahack', 'bigger', 'than', 'you', 'think']",0,"['mini', 'datahack', 'bigger', 'than', 'you', 'think']","['mini', 'datahack', 'bigger', 'think']",mini datahack bigger think,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
1635,time series forecasting using ml techniques,Techniques,time series forecasting using ml techniques,"['time', 'series', 'forecasting', 'using', 'ml', 'techniques']",0,"['time', 'series', 'forecasting', 'using', 'ml', 'technique']","['time', 'series', 'forecasting', 'using', 'ml', 'technique']",time series forecasting using ml technique,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
1636,uploading code file for final solution with pretrained word vectors,Hackathons,uploading code file for final solution with pretrained word vectors,"['uploading', 'code', 'file', 'for', 'final', 'solution', 'with', 'pretrained', 'word', 'vectors']",0,"['uploading', 'code', 'file', 'for', 'final', 'solution', 'with', 'pretrained', 'word', 'vector']","['uploading', 'code', 'file', 'final', 'solution', 'pretrained', 'word', 'vector']",uploading code file final solution pretrained word vector,0.0,0.0,10,57,5.181818181818182,0,0,0,0,0,0,0,0
1637,time stamp as input variable for regression feature extraction,Techniques,time stamp as input variable for regression feature extraction,"['time', 'stamp', 'as', 'input', 'variable', 'for', 'regression', 'feature', 'extraction']",0,"['time', 'stamp', 'a', 'input', 'variable', 'for', 'regression', 'feature', 'extraction']","['time', 'stamp', 'input', 'variable', 'regression', 'feature', 'extraction']",time stamp input variable regression feature extraction,0.0,0.0,9,55,5.5,0,0,0,0,0,0,0,0
1638,integer categorical feature as both numeric and categorical,Techniques,integer categorical feature as both numeric and categorical,"['integer', 'categorical', 'feature', 'as', 'both', 'numeric', 'and', 'categorical']",0,"['integer', 'categorical', 'feature', 'a', 'both', 'numeric', 'and', 'categorical']","['integer', 'categorical', 'feature', 'numeric', 'categorical']",integer categorical feature numeric categorical,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
1639,using mean to forecast employee salary in time series,Techniques,using mean to forecast employee salary in time series,"['using', 'mean', 'to', 'forecast', 'employee', 'salary', 'in', 'time', 'series']",0,"['using', 'mean', 'to', 'forecast', 'employee', 'salary', 'in', 'time', 'series']","['using', 'mean', 'forecast', 'employee', 'salary', 'time', 'series']",using mean forecast employee salary time series,-0.3125,-0.3125,9,47,4.7,0,0,0,0,0,0,0,0
1640,what are advantages of loop function over normal for and while loop in r,Tools,what are advantages of loop function over normal for and while loop in r,"['what', 'are', 'advantages', 'of', 'loop', 'function', 'over', 'normal', 'for', 'and', 'while', 'loop', 'in', 'r']",0,"['what', 'are', 'advantage', 'of', 'loop', 'function', 'over', 'normal', 'for', 'and', 'while', 'loop', 'in', 'r']","['advantage', 'loop', 'function', 'normal', 'loop', 'r']",advantage loop function normal loop r,0.15,0.15,14,37,2.466666666666667,0,0,0,0,0,0,0,0
1641,please check with the test data set all ids are not available,Hackathons,please check with the test data set all ids are not available,"['please', 'check', 'with', 'the', 'test', 'data', 'set', 'all', 'ids', 'are', 'not', 'available']",0,"['please', 'check', 'with', 'the', 'test', 'data', 'set', 'all', 'id', 'are', 'not', 'available']","['please', 'check', 'test', 'data', 'set', 'id', 'available']",please check test data set id available,-0.2,0.4,12,39,3.0,0,0,0,0,0,0,0,0
1642,what are the prerequisites to run fasttext on ipython notebook,Tools,what are the prerequisites to run fasttext on ipython notebook,"['what', 'are', 'the', 'prerequisites', 'to', 'run', 'fasttext', 'on', 'ipython', 'notebook']",0,"['what', 'are', 'the', 'prerequisite', 'to', 'run', 'fasttext', 'on', 'ipython', 'notebook']","['prerequisite', 'run', 'fasttext', 'ipython', 'notebook']",prerequisite run fasttext ipython notebook,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
1643,can we use knn for predicting continuous target variable,Techniques,can we use knn for predicting continuous target variable,"['can', 'we', 'use', 'knn', 'for', 'predicting', 'continuous', 'target', 'variable']",0,"['can', 'we', 'use', 'knn', 'for', 'predicting', 'continuous', 'target', 'variable']","['use', 'knn', 'predicting', 'continuous', 'target', 'variable']",use knn predicting continuous target variable,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
1644,data science big data viz tools,Tools,data science big data viz tools,"['data', 'science', 'big', 'data', 'viz', 'tools']",0,"['data', 'science', 'big', 'data', 'viz', 'tool']","['data', 'science', 'big', 'data', 'viz', 'tool']",data science big data viz tool,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
1645,question related to mapping using lag,Techniques,question related to mapping using lag,"['question', 'related', 'to', 'mapping', 'using', 'lag']",0,"['question', 'related', 'to', 'mapping', 'using', 'lag']","['question', 'related', 'mapping', 'using', 'lag']",question related mapping using lag,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
1646,implementation of chisquare test,Techniques,implementation of chisquare test,"['implementation', 'of', 'chisquare', 'test']",0,"['implementation', 'of', 'chisquare', 'test']","['implementation', 'chisquare', 'test']",implementation chisquare test,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
1647,functions and packages for d plots in r,Tools,functions and packages for d plots in r,"['functions', 'and', 'packages', 'for', 'd', 'plots', 'in', 'r']",0,"['function', 'and', 'package', 'for', 'd', 'plot', 'in', 'r']","['function', 'package', 'plot', 'r']",function package plot r,0.0,0.0,8,23,2.5555555555555554,0,0,0,0,0,0,0,0
1648,what are the ways through which we can make a time series stationary,Techniques,what are the ways through which we can make a time series stationary,"['what', 'are', 'the', 'ways', 'through', 'which', 'we', 'can', 'make', 'a', 'time', 'series', 'stationary']",0,"['what', 'are', 'the', 'way', 'through', 'which', 'we', 'can', 'make', 'a', 'time', 'series', 'stationary']","['way', 'make', 'time', 'series', 'stationary']",way make time series stationary,0.0,0.0,13,31,2.2142857142857144,0,0,0,0,0,0,0,0
1649,looking massive dataset for retail analytics,Resources,looking massive dataset for retail analytics,"['looking', 'massive', 'dataset', 'for', 'retail', 'analytics']",0,"['looking', 'massive', 'dataset', 'for', 'retail', 'analytics']","['looking', 'massive', 'dataset', 'retail', 'analytics']",looking massive dataset retail analytics,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
1650,the nlp learning path for  is here,Career,the nlp learning path for  is here,"['the', 'nlp', 'learning', 'path', 'for', 'is', 'here']",1,"['the', 'nlp', 'learning', 'path', 'for', 'is', 'here']","['nlp', 'learning', 'path']",nlp learning path,0.0,0.0,7,17,2.125,0,0,0,0,0,0,0,0
1651,incremental learning algorithms,Techniques,incremental learning algorithms,"['incremental', 'learning', 'algorithms']",0,"['incremental', 'learning', 'algorithm']","['incremental', 'learning', 'algorithm']",incremental learning algorithm,0.0,0.0,3,30,7.5,0,0,0,0,0,0,0,0
1652,how to take a mean of ordinal numbers,Techniques,how to take a mean of ordinal numbers,"['how', 'to', 'take', 'a', 'mean', 'of', 'ordinal', 'numbers']",0,"['how', 'to', 'take', 'a', 'mean', 'of', 'ordinal', 'number']","['take', 'mean', 'ordinal', 'number']",take mean ordinal number,-0.3125,-0.3125,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
1653,how to deal with choose encoding message in r while trying to save code,Tools,how to deal with choose encoding message in r while trying to save code,"['how', 'to', 'deal', 'with', 'choose', 'encoding', 'message', 'in', 'r', 'while', 'trying', 'to', 'save', 'code']",0,"['how', 'to', 'deal', 'with', 'choose', 'encoding', 'message', 'in', 'r', 'while', 'trying', 'to', 'save', 'code']","['deal', 'choose', 'encoding', 'message', 'r', 'trying', 'save', 'code']",deal choose encoding message r trying save code,0.0,0.0,14,47,3.1333333333333333,0,0,0,0,0,0,0,0
1654,harvesting big data tb,Techniques,harvesting big data tb,"['harvesting', 'big', 'data', 'tb']",0,"['harvesting', 'big', 'data', 'tb']","['harvesting', 'big', 'data', 'tb']",harvesting big data tb,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
1655,help me to decide a correct career path to shift my career to analytics,Career,help me to decide a correct career path to shift my career to analytics,"['help', 'me', 'to', 'decide', 'a', 'correct', 'career', 'path', 'to', 'shift', 'my', 'career', 'to', 'analytics']",0,"['help', 'me', 'to', 'decide', 'a', 'correct', 'career', 'path', 'to', 'shift', 'my', 'career', 'to', 'analytics']","['help', 'decide', 'correct', 'career', 'path', 'shift', 'career', 'analytics']",help decide correct career path shift career analytics,0.0,0.0,14,54,3.6,0,0,0,0,0,0,0,0
1656,why are there two rotations in svd,Techniques,why are there two rotations in svd,"['why', 'are', 'there', 'two', 'rotations', 'in', 'svd']",0,"['why', 'are', 'there', 'two', 'rotation', 'in', 'svd']","['two', 'rotation', 'svd']",two rotation svd,0.0,0.0,7,16,2.0,0,0,0,0,0,0,0,0
1657,what path should one follow to become a data scientist,Career,what path should one follow to become a data scientist,"['what', 'path', 'should', 'one', 'follow', 'to', 'become', 'a', 'data', 'scientist']",0,"['what', 'path', 'should', 'one', 'follow', 'to', 'become', 'a', 'data', 'scientist']","['path', 'one', 'follow', 'become', 'data', 'scientist']",path one follow become data scientist,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
1658,is there any ensemble method to fit multiple logistic regression models,Techniques,is there any ensemble method to fit multiple logistic regression models,"['is', 'there', 'any', 'ensemble', 'method', 'to', 'fit', 'multiple', 'logistic', 'regression', 'models']",0,"['is', 'there', 'any', 'ensemble', 'method', 'to', 'fit', 'multiple', 'logistic', 'regression', 'model']","['ensemble', 'method', 'fit', 'multiple', 'logistic', 'regression', 'model']",ensemble method fit multiple logistic regression model,0.2,0.2,11,54,4.5,0,0,0,0,0,0,0,0
1659,how to view the confusion matrix having data counts using caret in r,Tools,how to view the confusion matrix having data counts using caret in r,"['how', 'to', 'view', 'the', 'confusion', 'matrix', 'having', 'data', 'counts', 'using', 'caret', 'in', 'r']",0,"['how', 'to', 'view', 'the', 'confusion', 'matrix', 'having', 'data', 'count', 'using', 'caret', 'in', 'r']","['view', 'confusion', 'matrix', 'data', 'count', 'using', 'caret', 'r']",view confusion matrix data count using caret r,0.0,0.0,13,46,3.2857142857142856,0,0,0,0,0,0,0,0
1660,how to convert a data frame into sparse matrix in r,Tools,how to convert a data frame into sparse matrix in r,"['how', 'to', 'convert', 'a', 'data', 'frame', 'into', 'sparse', 'matrix', 'in', 'r']",0,"['how', 'to', 'convert', 'a', 'data', 'frame', 'into', 'sparse', 'matrix', 'in', 'r']","['convert', 'data', 'frame', 'sparse', 'matrix', 'r']",convert data frame sparse matrix r,0.0,0.0,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
1661,how to train model on high resolution image data,Techniques,how to train model on high resolution image data,"['how', 'to', 'train', 'model', 'on', 'high', 'resolution', 'image', 'data']",0,"['how', 'to', 'train', 'model', 'on', 'high', 'resolution', 'image', 'data']","['train', 'model', 'high', 'resolution', 'image', 'data']",train model high resolution image data,0.16,0.16,9,38,3.8,0,0,0,0,0,0,0,0
1662,print option  for blogs,Other,print option  for blogs,"['print', 'option', 'for', 'blogs']",0,"['print', 'option', 'for', 'blog']","['print', 'option', 'blog']",print option blog,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
1663,sharing a feedback from a current student who likes to stay anon in praxis bangalore,Career,sharing a feedback from a current student who likes to stay anon in praxis bangalore,"['sharing', 'a', 'feedback', 'from', 'a', 'current', 'student', 'who', 'likes', 'to', 'stay', 'anon', 'in', 'praxis', 'bangalore']",0,"['sharing', 'a', 'feedback', 'from', 'a', 'current', 'student', 'who', 'like', 'to', 'stay', 'anon', 'in', 'praxis', 'bangalore']","['sharing', 'feedback', 'current', 'student', 'like', 'stay', 'anon', 'praxis', 'bangalore']",sharing feedback current student like stay anon praxis bangalore,0.0,0.0,15,64,4.0,0,0,0,0,0,0,0,0
1664,can we convert image files from one format into another using r,Tools,can we convert image files from one format into another using r,"['can', 'we', 'convert', 'image', 'files', 'from', 'one', 'format', 'into', 'another', 'using', 'r']",0,"['can', 'we', 'convert', 'image', 'file', 'from', 'one', 'format', 'into', 'another', 'using', 'r']","['convert', 'image', 'file', 'one', 'format', 'another', 'using', 'r']",convert image file one format another using r,0.0,0.0,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
1665,valueerror unknown label type unknown for logisticsregression model,Hackathons,valueerror unknown label type unknown for logisticsregression model,"['valueerror', 'unknown', 'label', 'type', 'unknown', 'for', 'logisticsregression', 'model']",0,"['valueerror', 'unknown', 'label', 'type', 'unknown', 'for', 'logisticsregression', 'model']","['valueerror', 'unknown', 'label', 'type', 'unknown', 'logisticsregression', 'model']",valueerror unknown label type unknown logisticsregression model,-0.1,-0.1,8,63,7.0,0,0,0,0,0,0,0,0
1666,what are some of the uses of the googlevis r package,Tools,what are some of the uses of the googlevis r package,"['what', 'are', 'some', 'of', 'the', 'uses', 'of', 'the', 'googlevis', 'r', 'package']",0,"['what', 'are', 'some', 'of', 'the', 'us', 'of', 'the', 'googlevis', 'r', 'package']","['us', 'googlevis', 'r', 'package']",us googlevis r package,0.0,0.0,11,22,1.8333333333333333,0,0,0,0,0,0,0,0
1667,error could not find function ivmult,Techniques,error could not find function ivmult,"['error', 'could', 'not', 'find', 'function', 'ivmult']",0,"['error', 'could', 'not', 'find', 'function', 'ivmult']","['error', 'could', 'find', 'function', 'ivmult']",error could find function ivmult,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
1668,categorical variables and predictive modelling,Techniques,categorical variables and predictive modelling,"['categorical', 'variables', 'and', 'predictive', 'modelling']",0,"['categorical', 'variable', 'and', 'predictive', 'modelling']","['categorical', 'variable', 'predictive', 'modelling']",categorical variable predictive modelling,0.0,0.0,5,41,6.833333333333333,0,0,0,0,0,0,0,0
1669,unable to download data,Resources,unable to download data,"['unable', 'to', 'download', 'data']",0,"['unable', 'to', 'download', 'data']","['unable', 'download', 'data']",unable download data,-0.5,-0.5,4,20,4.0,0,0,0,0,0,0,0,0
1670,how to merge two csv file by a specific column using r,Tools,how to merge two csv file by a specific column using r,"['how', 'to', 'merge', 'two', 'csv', 'file', 'by', 'a', 'specific', 'column', 'using', 'r']",0,"['how', 'to', 'merge', 'two', 'csv', 'file', 'by', 'a', 'specific', 'column', 'using', 'r']","['merge', 'two', 'csv', 'file', 'specific', 'column', 'using', 'r']",merge two csv file specific column using r,0.0,0.0,12,42,3.230769230769231,0,0,0,0,0,0,0,0
1671,return rank against multiple dimension in qlikview,Tools,return rank against multiple dimension in qlikview,"['return', 'rank', 'against', 'multiple', 'dimension', 'in', 'qlikview']",0,"['return', 'rank', 'against', 'multiple', 'dimension', 'in', 'qlikview']","['return', 'rank', 'multiple', 'dimension', 'qlikview']",return rank multiple dimension qlikview,-0.4,-0.4,7,39,4.875,0,0,0,0,0,0,0,0
1672,shift to analytics domain,Career,shift to analytics domain,"['shift', 'to', 'analytics', 'domain']",0,"['shift', 'to', 'analytics', 'domain']","['shift', 'analytics', 'domain']",shift analytics domain,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
1673,are there any indians who quit their job to study data science through courses and got a job after a few months,Career,are there any indians who quit their job to study data science through courses and got a job after a few months,"['are', 'there', 'any', 'indians', 'who', 'quit', 'their', 'job', 'to', 'study', 'data', 'science', 'through', 'courses', 'and', 'got', 'a', 'job', 'after', 'a', 'few', 'months']",0,"['are', 'there', 'any', 'indian', 'who', 'quit', 'their', 'job', 'to', 'study', 'data', 'science', 'through', 'course', 'and', 'got', 'a', 'job', 'after', 'a', 'few', 'month']","['indian', 'quit', 'job', 'study', 'data', 'science', 'course', 'got', 'job', 'month']",indian quit job study data science course got job month,-0.2,0.0,22,55,2.391304347826087,0,0,0,0,0,0,0,0
1674,what does stat means in ggplot,Techniques,what does stat means in ggplot,"['what', 'does', 'stat', 'means', 'in', 'ggplot']",0,"['what', 'doe', 'stat', 'mean', 'in', 'ggplot']","['doe', 'stat', 'mean', 'ggplot']",doe stat mean ggplot,0.0,-0.3125,6,20,2.857142857142857,0,0,0,0,0,0,0,0
1675,rnn is learning very slow,Techniques,rnn is learning very slow,"['rnn', 'is', 'learning', 'very', 'slow']",0,"['rnn', 'is', 'learning', 'very', 'slow']","['rnn', 'learning', 'slow']",rnn learning slow,-0.39,-0.3,5,17,2.8333333333333335,0,0,0,0,0,0,0,0
1676,text analysis with irregular telecom logs in r,Techniques,text analysis with irregular telecom logs in r,"['text', 'analysis', 'with', 'irregular', 'telecom', 'logs', 'in', 'r']",0,"['text', 'analysis', 'with', 'irregular', 'telecom', 'log', 'in', 'r']","['text', 'analysis', 'irregular', 'telecom', 'log', 'r']",text analysis irregular telecom log r,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
1677,time series in data science,Techniques,time series in data science,"['time', 'series', 'in', 'data', 'science']",0,"['time', 'series', 'in', 'data', 'science']","['time', 'series', 'data', 'science']",time series data science,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
1678,tutorial for ho package in r,Resources,tutorial for ho package in r,"['tutorial', 'for', 'ho', 'package', 'in', 'r']",0,"['tutorial', 'for', 'ho', 'package', 'in', 'r']","['tutorial', 'ho', 'package', 'r']",tutorial ho package r,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
1679,value error in linear regression,Techniques,value error in linear regression,"['value', 'error', 'in', 'linear', 'regression']",0,"['value', 'error', 'in', 'linear', 'regression']","['value', 'error', 'linear', 'regression']",value error linear regression,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
1680,what kind of recommendation system should be used in banking industry where the varietynumber of products is not huge,Techniques,what kind of recommendation system should be used in banking industry where the varietynumber of products is not huge,"['what', 'kind', 'of', 'recommendation', 'system', 'should', 'be', 'used', 'in', 'banking', 'industry', 'where', 'the', 'varietynumber', 'of', 'products', 'is', 'not', 'huge']",0,"['what', 'kind', 'of', 'recommendation', 'system', 'should', 'be', 'used', 'in', 'banking', 'industry', 'where', 'the', 'varietynumber', 'of', 'product', 'is', 'not', 'huge']","['kind', 'recommendation', 'system', 'used', 'banking', 'industry', 'varietynumber', 'product', 'huge']",kind recommendation system used banking industry varietynumber product huge,0.1999999999999999,0.5,19,75,3.75,0,0,0,0,0,0,0,0
1681,python  error in label encoding,Techniques,python  error in label encoding,"['python', 'error', 'in', 'label', 'encoding']",1,"['python', 'error', 'in', 'label', 'encoding']","['python', 'error', 'label', 'encoding']",python error label encoding,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
1682,time series analysis techniques,Techniques,time series analysis techniques,"['time', 'series', 'analysis', 'techniques']",0,"['time', 'series', 'analysis', 'technique']","['time', 'series', 'analysis', 'technique']",time series analysis technique,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
1683,how to plot rpn bounding boxes in mask r cnn code,Techniques,how to plot rpn bounding boxes in mask r cnn code,"['how', 'to', 'plot', 'rpn', 'bounding', 'boxes', 'in', 'mask', 'r', 'cnn', 'code']",0,"['how', 'to', 'plot', 'rpn', 'bounding', 'box', 'in', 'mask', 'r', 'cnn', 'code']","['plot', 'rpn', 'bounding', 'box', 'mask', 'r', 'cnn', 'code']",plot rpn bounding box mask r cnn code,0.0,0.0,11,37,3.0833333333333335,0,0,0,0,0,0,0,0
1684,how to answer case study based analytics interview questions,Misc,how to answer case study based analytics interview questions,"['how', 'to', 'answer', 'case', 'study', 'based', 'analytics', 'interview', 'questions']",0,"['how', 'to', 'answer', 'case', 'study', 'based', 'analytics', 'interview', 'question']","['answer', 'case', 'study', 'based', 'analytics', 'interview', 'question']",answer case study based analytics interview question,0.0,0.0,9,52,5.2,0,0,0,0,0,0,0,0
1685,less topics and case studies on sas,Tools,less topics and case studies on sas,"['less', 'topics', 'and', 'case', 'studies', 'on', 'sas']",0,"['le', 'topic', 'and', 'case', 'study', 'on', 'sa']","['le', 'topic', 'case', 'study', 'sa']",le topic case study sa,-0.1666666666666666,0.0,7,22,2.75,0,0,0,0,0,0,0,0
1686,how to import txt files having continuous variables in python,Hackathons,how to import txt files having continuous variables in python,"['how', 'to', 'import', 'txt', 'files', 'having', 'continuous', 'variables', 'in', 'python']",0,"['how', 'to', 'import', 'txt', 'file', 'having', 'continuous', 'variable', 'in', 'python']","['import', 'txt', 'file', 'continuous', 'variable', 'python']",import txt file continuous variable python,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
1687,about teams in date your data,Hackathons,about teams in date your data,"['about', 'teams', 'in', 'date', 'your', 'data']",0,"['about', 'team', 'in', 'date', 'your', 'data']","['team', 'date', 'data']",team date data,0.0,0.0,6,14,2.0,0,0,0,0,0,0,0,0
1688,what to select  model with statistically insignificant variables but better accuracy or model with statistically significant variables with little bit lower accuracy,Techniques,what to select  model with statistically insignificant variables but better accuracy or model with statistically significant variables with little bit lower accuracy,"['what', 'to', 'select', 'model', 'with', 'statistically', 'insignificant', 'variables', 'but', 'better', 'accuracy', 'or', 'model', 'with', 'statistically', 'significant', 'variables', 'with', 'little', 'bit', 'lower', 'accuracy']",0,"['what', 'to', 'select', 'model', 'with', 'statistically', 'insignificant', 'variable', 'but', 'better', 'accuracy', 'or', 'model', 'with', 'statistically', 'significant', 'variable', 'with', 'little', 'bit', 'lower', 'accuracy']","['select', 'model', 'statistically', 'insignificant', 'variable', 'better', 'accuracy', 'model', 'statistically', 'significant', 'variable', 'little', 'bit', 'lower', 'accuracy']",select model statistically insignificant variable better accuracy model statistically significant variable little bit lower accuracy,0.2291666666666666,0.2291666666666666,22,132,5.739130434782608,0,0,0,0,0,0,0,0
1689,basic requirements for business analytics professional,Career,basic requirements for business analytics professional,"['basic', 'requirements', 'for', 'business', 'analytics', 'professional']",0,"['basic', 'requirement', 'for', 'business', 'analytics', 'professional']","['basic', 'requirement', 'business', 'analytics', 'professional']",basic requirement business analytics professional,0.05,0.05,6,49,7.0,0,0,0,0,0,0,0,0
1690,uses of tdistribution and and normal distribution,Techniques,uses of tdistribution and and normal distribution,"['uses', 'of', 'tdistribution', 'and', 'and', 'normal', 'distribution']",0,"['us', 'of', 'tdistribution', 'and', 'and', 'normal', 'distribution']","['us', 'tdistribution', 'normal', 'distribution']",us tdistribution normal distribution,0.15,0.15,7,36,4.5,0,0,0,0,0,0,0,0
1691,error in xgboost cross and validation prediction output in r,Techniques,error in xgboost cross and validation prediction output in r,"['error', 'in', 'xgboost', 'cross', 'and', 'validation', 'prediction', 'output', 'in', 'r']",0,"['error', 'in', 'xgboost', 'cross', 'and', 'validation', 'prediction', 'output', 'in', 'r']","['error', 'xgboost', 'cross', 'validation', 'prediction', 'output', 'r']",error xgboost cross validation prediction output r,0.0,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
1692,beginner undecided between learning python or r need guidance,Tools,beginner undecided between learning python or r need guidance,"['beginner', 'undecided', 'between', 'learning', 'python', 'or', 'r', 'need', 'guidance']",0,"['beginner', 'undecided', 'between', 'learning', 'python', 'or', 'r', 'need', 'guidance']","['beginner', 'undecided', 'learning', 'python', 'r', 'need', 'guidance']",beginner undecided learning python r need guidance,0.0,0.0,9,50,5.0,0,0,0,0,0,0,0,0
1693,random forest parameters,Techniques,random forest parameters,"['random', 'forest', 'parameters']",0,"['random', 'forest', 'parameter']","['random', 'forest', 'parameter']",random forest parameter,-0.5,-0.5,3,23,5.75,0,0,0,0,0,0,0,0
1694,how to get probabilities from boosting algorithms,Techniques,how to get probabilities from boosting algorithms,"['how', 'to', 'get', 'probabilities', 'from', 'boosting', 'algorithms']",0,"['how', 'to', 'get', 'probability', 'from', 'boosting', 'algorithm']","['get', 'probability', 'boosting', 'algorithm']",get probability boosting algorithm,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
1695,statistics  why squaring is used to calculate error in rmse,Techniques,statistics  why squaring is used to calculate error in rmse,"['statistics', 'why', 'squaring', 'is', 'used', 'to', 'calculate', 'error', 'in', 'rmse']",0,"['statistic', 'why', 'squaring', 'is', 'used', 'to', 'calculate', 'error', 'in', 'rmse']","['statistic', 'squaring', 'used', 'calculate', 'error', 'rmse']",statistic squaring used calculate error rmse,0.0,0.0,10,44,4.0,0,0,0,0,0,0,0,0
1696,techniques and strategies for metadata extraction,Techniques,techniques and strategies for metadata extraction,"['techniques', 'and', 'strategies', 'for', 'metadata', 'extraction']",0,"['technique', 'and', 'strategy', 'for', 'metadata', 'extraction']","['technique', 'strategy', 'metadata', 'extraction']",technique strategy metadata extraction,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
1697,introductions  new members for august ,Misc,introductions  new members for august ,"['introductions', 'new', 'members', 'for', 'august']",1,"['introduction', 'new', 'member', 'for', 'august']","['introduction', 'new', 'member', 'august']",introduction new member august,0.1363636363636363,0.1363636363636363,5,30,5.0,0,0,0,0,0,0,0,0
1698,error in modelframedefault,Techniques,error in modelframedefault,"['error', 'in', 'modelframedefault']",0,"['error', 'in', 'modelframedefault']","['error', 'modelframedefault']",error modelframedefault,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
1699,learning path for numpy scipy scikitlearn deep learning,Tools,learning path for numpy scipy scikitlearn deep learning,"['learning', 'path', 'for', 'numpy', 'scipy', 'scikitlearn', 'deep', 'learning']",0,"['learning', 'path', 'for', 'numpy', 'scipy', 'scikitlearn', 'deep', 'learning']","['learning', 'path', 'numpy', 'scipy', 'scikitlearn', 'deep', 'learning']",learning path numpy scipy scikitlearn deep learning,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
1700,problem implementing an introduction to implementing neural network using tensorflow,Techniques,problem implementing an introduction to implementing neural network using tensorflow,"['problem', 'implementing', 'an', 'introduction', 'to', 'implementing', 'neural', 'network', 'using', 'tensorflow']",0,"['problem', 'implementing', 'an', 'introduction', 'to', 'implementing', 'neural', 'network', 'using', 'tensorflow']","['problem', 'implementing', 'introduction', 'implementing', 'neural', 'network', 'using', 'tensorflow']",problem implementing introduction implementing neural network using tensorflow,0.0,0.0,10,78,7.090909090909091,0,0,0,0,0,0,0,0
1701,business analytics and intelligence from iimb,Career,business analytics and intelligence from iimb,"['business', 'analytics', 'and', 'intelligence', 'from', 'iimb']",0,"['business', 'analytics', 'and', 'intelligence', 'from', 'iimb']","['business', 'analytics', 'intelligence', 'iimb']",business analytics intelligence iimb,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
1702,usg requirements for data,Resources,usg requirements for data,"['usg', 'requirements', 'for', 'data']",0,"['usg', 'requirement', 'for', 'data']","['usg', 'requirement', 'data']",usg requirement data,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
1703,tools for analyzing large data,Tools,tools for analyzing large data,"['tools', 'for', 'analyzing', 'large', 'data']",0,"['tool', 'for', 'analyzing', 'large', 'data']","['tool', 'analyzing', 'large', 'data']",tool analyzing large data,0.2142857142857142,0.2142857142857142,5,25,4.166666666666667,0,0,0,0,0,0,0,0
1704,study materials on keras and theano,Tools,study materials on keras and theano,"['study', 'materials', 'on', 'keras', 'and', 'theano']",0,"['study', 'material', 'on', 'kera', 'and', 'theano']","['study', 'material', 'kera', 'theano']",study material kera theano,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
1705,chatbot using r,Techniques,chatbot using r,"['chatbot', 'using', 'r']",0,"['chatbot', 'using', 'r']","['chatbot', 'using', 'r']",chatbot using r,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
1706,executive program in business analytics  iim lucknow,Career,executive program in business analytics  iim lucknow,"['executive', 'program', 'in', 'business', 'analytics', 'iim', 'lucknow']",0,"['executive', 'program', 'in', 'business', 'analytics', 'iim', 'lucknow']","['executive', 'program', 'business', 'analytics', 'iim', 'lucknow']",executive program business analytics iim lucknow,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
1707,difference between require and library in r,Tools,difference between require and library in r,"['difference', 'between', 'require', 'and', 'library', 'in', 'r']",0,"['difference', 'between', 'require', 'and', 'library', 'in', 'r']","['difference', 'require', 'library', 'r']",difference require library r,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
1708,use of pandascrosstab in python to create stacked histogram,Tools,use of pandascrosstab in python to create stacked histogram,"['use', 'of', 'pandascrosstab', 'in', 'python', 'to', 'create', 'stacked', 'histogram']",0,"['use', 'of', 'pandascrosstab', 'in', 'python', 'to', 'create', 'stacked', 'histogram']","['use', 'pandascrosstab', 'python', 'create', 'stacked', 'histogram']",use pandascrosstab python create stacked histogram,0.0,0.0,9,50,5.0,0,0,0,0,0,0,0,0
1709,how can modeling quality be measured  assessed,Misc,how can modeling quality be measured  assessed,"['how', 'can', 'modeling', 'quality', 'be', 'measured', 'assessed']",0,"['how', 'can', 'modeling', 'quality', 'be', 'measured', 'assessed']","['modeling', 'quality', 'measured', 'assessed']",modeling quality measured assessed,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
1710,zero inflated poisson  negative binomial model  using python statsmodels,Techniques,zero inflated poisson  negative binomial model  using python statsmodels,"['zero', 'inflated', 'poisson', 'negative', 'binomial', 'model', 'using', 'python', 'statsmodels']",0,"['zero', 'inflated', 'poisson', 'negative', 'binomial', 'model', 'using', 'python', 'statsmodels']","['zero', 'inflated', 'poisson', 'negative', 'binomial', 'model', 'using', 'python', 'statsmodels']",zero inflated poisson negative binomial model using python statsmodels,-0.3,-0.3,9,70,7.0,0,0,0,0,0,0,0,0
1711,need help in building x g boost model in r,Tools,need help in building x g boost model in r,"['need', 'help', 'in', 'building', 'x', 'g', 'boost', 'model', 'in', 'r']",0,"['need', 'help', 'in', 'building', 'x', 'g', 'boost', 'model', 'in', 'r']","['need', 'help', 'building', 'x', 'g', 'boost', 'model', 'r']",need help building x g boost model r,0.0,0.0,10,36,3.272727272727273,0,0,0,0,0,0,0,0
1712,visualizing kmeans clustering algorithm,Resources,visualizing kmeans clustering algorithm,"['visualizing', 'kmeans', 'clustering', 'algorithm']",0,"['visualizing', 'kmeans', 'clustering', 'algorithm']","['visualizing', 'kmeans', 'clustering', 'algorithm']",visualizing kmeans clustering algorithm,0.0,0.0,4,39,7.8,0,0,0,0,0,0,0,0
1713,rmongo insert analytic result to db,Tools,rmongo insert analytic result to db,"['rmongo', 'insert', 'analytic', 'result', 'to', 'db']",0,"['rmongo', 'insert', 'analytic', 'result', 'to', 'db']","['rmongo', 'insert', 'analytic', 'result', 'db']",rmongo insert analytic result db,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
1714,where should i now join the analytics course look forward to your guidance,Career,where should i now join the analytics course look forward to your guidance,"['where', 'should', 'i', 'now', 'join', 'the', 'analytics', 'course', 'look', 'forward', 'to', 'your', 'guidance']",0,"['where', 'should', 'i', 'now', 'join', 'the', 'analytics', 'course', 'look', 'forward', 'to', 'your', 'guidance']","['join', 'analytics', 'course', 'look', 'forward', 'guidance']",join analytics course look forward guidance,0.0,0.0,13,43,3.0714285714285716,0,0,0,0,0,0,0,0
1715,feature selection using linear discriminant analysis,Techniques,feature selection using linear discriminant analysis,"['feature', 'selection', 'using', 'linear', 'discriminant', 'analysis']",0,"['feature', 'selection', 'using', 'linear', 'discriminant', 'analysis']","['feature', 'selection', 'using', 'linear', 'discriminant', 'analysis']",feature selection using linear discriminant analysis,0.0,0.0,6,52,7.428571428571429,0,0,0,0,0,0,0,0
1716,unable to submit black friday solution  encountered header do not match error,Hackathons,unable to submit black friday solution  encountered header do not match error,"['unable', 'to', 'submit', 'black', 'friday', 'solution', 'encountered', 'header', 'do', 'not', 'match', 'error']",0,"['unable', 'to', 'submit', 'black', 'friday', 'solution', 'encountered', 'header', 'do', 'not', 'match', 'error']","['unable', 'submit', 'black', 'friday', 'solution', 'encountered', 'header', 'match', 'error']",unable submit black friday solution encountered header match error,-0.3333333333333333,-0.3333333333333333,12,66,5.076923076923077,0,0,0,0,0,0,0,0
1717,error while calculating the information value,Techniques,error while calculating the information value,"['error', 'while', 'calculating', 'the', 'information', 'value']",0,"['error', 'while', 'calculating', 'the', 'information', 'value']","['error', 'calculating', 'information', 'value']",error calculating information value,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
1718,how to use customized stopwords in r,Techniques,how to use customized stopwords in r,"['how', 'to', 'use', 'customized', 'stopwords', 'in', 'r']",0,"['how', 'to', 'use', 'customized', 'stopwords', 'in', 'r']","['use', 'customized', 'stopwords', 'r']",use customized stopwords r,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
1719,difference between regression and time series,Techniques,difference between regression and time series,"['difference', 'between', 'regression', 'and', 'time', 'series']",0,"['difference', 'between', 'regression', 'and', 'time', 'series']","['difference', 'regression', 'time', 'series']",difference regression time series,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
1720,your blog a comprehensive guide to understand and implement text classification in python,Techniques,your blog a comprehensive guide to understand and implement text classification in python,"['your', 'blog', 'a', 'comprehensive', 'guide', 'to', 'understand', 'and', 'implement', 'text', 'classification', 'in', 'python']",0,"['your', 'blog', 'a', 'comprehensive', 'guide', 'to', 'understand', 'and', 'implement', 'text', 'classification', 'in', 'python']","['blog', 'comprehensive', 'guide', 'understand', 'implement', 'text', 'classification', 'python']",blog comprehensive guide understand implement text classification python,0.0,0.0,13,72,5.142857142857143,0,0,0,0,0,0,0,0
1721,how to create a shiny app for logistic regression,Tools,how to create a shiny app for logistic regression,"['how', 'to', 'create', 'a', 'shiny', 'app', 'for', 'logistic', 'regression']",0,"['how', 'to', 'create', 'a', 'shiny', 'app', 'for', 'logistic', 'regression']","['create', 'shiny', 'app', 'logistic', 'regression']",create shiny app logistic regression,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
1722,about getting started with scikitlearn sklearn for machine learning course,Resources,about getting started with scikitlearn sklearn for machine learning course,"['about', 'getting', 'started', 'with', 'scikitlearn', 'sklearn', 'for', 'machine', 'learning', 'course']",0,"['about', 'getting', 'started', 'with', 'scikitlearn', 'sklearn', 'for', 'machine', 'learning', 'course']","['getting', 'started', 'scikitlearn', 'sklearn', 'machine', 'learning', 'course']",getting started scikitlearn sklearn machine learning course,0.0,0.0,10,59,5.363636363636363,0,0,0,0,0,0,0,0
1723,finding all values in a vector that lie within a range in r,Tools,finding all values in a vector that lie within a range in r,"['finding', 'all', 'values', 'in', 'a', 'vector', 'that', 'lie', 'within', 'a', 'range', 'in', 'r']",0,"['finding', 'all', 'value', 'in', 'a', 'vector', 'that', 'lie', 'within', 'a', 'range', 'in', 'r']","['finding', 'value', 'vector', 'lie', 'within', 'range', 'r']",finding value vector lie within range r,0.0,0.0,13,39,2.7857142857142856,0,0,0,0,0,0,0,0
1724,hansa cequity hiring hack   sep  mumbai,Hackathons,hansa cequity hiring hack   sep  mumbai,"['hansa', 'cequity', 'hiring', 'hack', 'sep', 'mumbai']",2,"['hansa', 'cequity', 'hiring', 'hack', 'sep', 'mumbai']","['hansa', 'cequity', 'hiring', 'hack', 'sep', 'mumbai']",hansa cequity hiring hack sep mumbai,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
1725,how to resolve error in algorithms for time dependent data esp market prediction,Tools,how to resolve error in algorithms for time dependent data esp market prediction,"['how', 'to', 'resolve', 'error', 'in', 'algorithms', 'for', 'time', 'dependent', 'data', 'esp', 'market', 'prediction']",0,"['how', 'to', 'resolve', 'error', 'in', 'algorithm', 'for', 'time', 'dependent', 'data', 'esp', 'market', 'prediction']","['resolve', 'error', 'algorithm', 'time', 'dependent', 'data', 'esp', 'market', 'prediction']",resolve error algorithm time dependent data esp market prediction,0.0,0.0,13,65,4.642857142857143,0,0,0,0,0,0,0,0
1726,game recommendation engine  in app purchase,Techniques,game recommendation engine  in app purchase,"['game', 'recommendation', 'engine', 'in', 'app', 'purchase']",0,"['game', 'recommendation', 'engine', 'in', 'app', 'purchase']","['game', 'recommendation', 'engine', 'app', 'purchase']",game recommendation engine app purchase,-0.4,-0.4,6,39,5.571428571428571,0,0,0,0,0,0,0,0
1727,why is npnan used in dataframes in pandas,Tools,why is npnan used in dataframes in pandas,"['why', 'is', 'npnan', 'used', 'in', 'dataframes', 'in', 'pandas']",0,"['why', 'is', 'npnan', 'used', 'in', 'dataframes', 'in', 'panda']","['npnan', 'used', 'dataframes', 'panda']",npnan used dataframes panda,0.0,0.0,8,27,3.0,0,0,0,0,0,0,0,0
1728,computer resource requirement for data science competitions,Tools,computer resource requirement for data science competitions,"['computer', 'resource', 'requirement', 'for', 'data', 'science', 'competitions']",0,"['computer', 'resource', 'requirement', 'for', 'data', 'science', 'competition']","['computer', 'resource', 'requirement', 'data', 'science', 'competition']",computer resource requirement data science competition,0.0,0.0,7,54,6.75,0,0,0,0,0,0,0,0
1729,worthfulness of analytics course offered by internshala,Career,worthfulness of analytics course offered by internshala,"['worthfulness', 'of', 'analytics', 'course', 'offered', 'by', 'internshala']",0,"['worthfulness', 'of', 'analytics', 'course', 'offered', 'by', 'internshala']","['worthfulness', 'analytics', 'course', 'offered', 'internshala']",worthfulness analytics course offered internshala,0.0,0.0,7,49,6.125,0,0,0,0,0,0,0,0
1730,how to find the the correlation between the variables in pca,Techniques,how to find the the correlation between the variables in pca,"['how', 'to', 'find', 'the', 'the', 'correlation', 'between', 'the', 'variables', 'in', 'pca']",0,"['how', 'to', 'find', 'the', 'the', 'correlation', 'between', 'the', 'variable', 'in', 'pca']","['find', 'correlation', 'variable', 'pca']",find correlation variable pca,0.0,0.0,11,29,2.4166666666666665,0,0,0,0,0,0,0,0
1731,when  how  statistical tests  hypothesis testing,Techniques,when  how  statistical tests  hypothesis testing,"['when', 'how', 'statistical', 'tests', 'hypothesis', 'testing']",0,"['when', 'how', 'statistical', 'test', 'hypothesis', 'testing']","['statistical', 'test', 'hypothesis', 'testing']",statistical test hypothesis testing,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
1732,missing data threshold,Techniques,missing data threshold,"['missing', 'data', 'threshold']",0,"['missing', 'data', 'threshold']","['missing', 'data', 'threshold']",missing data threshold,-0.2,-0.2,3,22,5.5,0,0,0,0,0,0,0,0
1733,diagnosis analytics for energy equipments,Techniques,diagnosis analytics for energy equipments,"['diagnosis', 'analytics', 'for', 'energy', 'equipments']",0,"['diagnosis', 'analytics', 'for', 'energy', 'equipment']","['diagnosis', 'analytics', 'energy', 'equipment']",diagnosis analytics energy equipment,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
1734,filling nan values,Hackathons,filling nan values,"['filling', 'nan', 'values']",0,"['filling', 'nan', 'value']","['filling', 'nan', 'value']",filling nan value,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
1735,analysis on resumes using r,Techniques,analysis on resumes using r,"['analysis', 'on', 'resumes', 'using', 'r']",0,"['analysis', 'on', 'resume', 'using', 'r']","['analysis', 'resume', 'using', 'r']",analysis resume using r,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
1736,understanding the results of this ml project,Techniques,understanding the results of this ml project,"['understanding', 'the', 'results', 'of', 'this', 'ml', 'project']",0,"['understanding', 'the', 'result', 'of', 'this', 'ml', 'project']","['understanding', 'result', 'ml', 'project']",understanding result ml project,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
1737,can we send config file as parameter to python,Techniques,can we send config file as parameter to python,"['can', 'we', 'send', 'config', 'file', 'as', 'parameter', 'to', 'python']",0,"['can', 'we', 'send', 'config', 'file', 'a', 'parameter', 'to', 'python']","['send', 'config', 'file', 'parameter', 'python']",send config file parameter python,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
1738,data quality critical data elements identification,Techniques,data quality critical data elements identification,"['data', 'quality', 'critical', 'data', 'elements', 'identification']",0,"['data', 'quality', 'critical', 'data', 'element', 'identification']","['data', 'quality', 'critical', 'data', 'element', 'identification']",data quality critical data element identification,0.0,0.0,6,49,7.0,0,0,0,0,0,0,0,0
1739,what should be the salary for  yrs analytics experienced guy,Career,what should be the salary for  yrs analytics experienced guy,"['what', 'should', 'be', 'the', 'salary', 'for', 'yrs', 'analytics', 'experienced', 'guy']",1,"['what', 'should', 'be', 'the', 'salary', 'for', 'yr', 'analytics', 'experienced', 'guy']","['salary', 'yr', 'analytics', 'experienced', 'guy']",salary yr analytics experienced guy,0.8,0.8,10,35,3.1818181818181817,0,0,0,0,0,0,0,0
1740,python pandasreadexcel error no module named xlrd,Tools,python pandasreadexcel error no module named xlrd,"['python', 'pandasreadexcel', 'error', 'no', 'module', 'named', 'xlrd']",0,"['python', 'pandasreadexcel', 'error', 'no', 'module', 'named', 'xlrd']","['python', 'pandasreadexcel', 'error', 'module', 'named', 'xlrd']",python pandasreadexcel error module named xlrd,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
1741,what is a model and what constitutes a model,Techniques,what is a model and what constitutes a model,"['what', 'is', 'a', 'model', 'and', 'what', 'constitutes', 'a', 'model']",0,"['what', 'is', 'a', 'model', 'and', 'what', 'constitutes', 'a', 'model']","['model', 'constitutes', 'model']",model constitutes model,0.0,0.0,9,23,2.3,0,0,0,0,0,0,0,0
1742,what is the default numestimators in scikitlearns randomforest,Tools,what is the default numestimators in scikitlearns randomforest,"['what', 'is', 'the', 'default', 'numestimators', 'in', 'scikitlearns', 'randomforest']",0,"['what', 'is', 'the', 'default', 'numestimators', 'in', 'scikitlearns', 'randomforest']","['default', 'numestimators', 'scikitlearns', 'randomforest']",default numestimators scikitlearns randomforest,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
1743,need help in understanding a code snippet from titanic passenger survival project,Tools,need help in understanding a code snippet from titanic passenger survival project,"['need', 'help', 'in', 'understanding', 'a', 'code', 'snippet', 'from', 'titanic', 'passenger', 'survival', 'project']",0,"['need', 'help', 'in', 'understanding', 'a', 'code', 'snippet', 'from', 'titanic', 'passenger', 'survival', 'project']","['need', 'help', 'understanding', 'code', 'snippet', 'titanic', 'passenger', 'survival', 'project']",need help understanding code snippet titanic passenger survival project,0.0,0.0,12,71,5.461538461538462,0,0,0,0,0,0,0,0
1744,how to import data from a json file into r,Tools,how to import data from a json file into r,"['how', 'to', 'import', 'data', 'from', 'a', 'json', 'file', 'into', 'r']",0,"['how', 'to', 'import', 'data', 'from', 'a', 'json', 'file', 'into', 'r']","['import', 'data', 'json', 'file', 'r']",import data json file r,0.0,0.0,10,23,2.090909090909091,0,0,0,0,0,0,0,0
1745,gradient descent problem in titanic dataset,Techniques,gradient descent problem in titanic dataset,"['gradient', 'descent', 'problem', 'in', 'titanic', 'dataset']",0,"['gradient', 'descent', 'problem', 'in', 'titanic', 'dataset']","['gradient', 'descent', 'problem', 'titanic', 'dataset']",gradient descent problem titanic dataset,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
1746,explanation on sql vs mysql vs nosql,Tools,explanation on sql vs mysql vs nosql,"['explanation', 'on', 'sql', 'vs', 'mysql', 'vs', 'nosql']",0,"['explanation', 'on', 'sql', 'v', 'mysql', 'v', 'nosql']","['explanation', 'sql', 'v', 'mysql', 'v', 'nosql']",explanation sql v mysql v nosql,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
1747,create multi level drop down validation in excel,Tools,create multi level drop down validation in excel,"['create', 'multi', 'level', 'drop', 'down', 'validation', 'in', 'excel']",0,"['create', 'multi', 'level', 'drop', 'down', 'validation', 'in', 'excel']","['create', 'multi', 'level', 'drop', 'validation', 'excel']",create multi level drop validation excel,-0.1555555555555555,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
1748,techniques for web data mining in r and elsewhere,Other,techniques for web data mining in r and elsewhere,"['techniques', 'for', 'web', 'data', 'mining', 'in', 'r', 'and', 'elsewhere']",0,"['technique', 'for', 'web', 'data', 'mining', 'in', 'r', 'and', 'elsewhere']","['technique', 'web', 'data', 'mining', 'r', 'elsewhere']",technique web data mining r elsewhere,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
1749,how to perform gridsearch in r,Techniques,how to perform gridsearch in r,"['how', 'to', 'perform', 'gridsearch', 'in', 'r']",0,"['how', 'to', 'perform', 'gridsearch', 'in', 'r']","['perform', 'gridsearch', 'r']",perform gridsearch r,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
1750,daskmljoblib google colab modulenotfounderror,Tools,daskmljoblib google colab modulenotfounderror,"['daskmljoblib', 'google', 'colab', 'modulenotfounderror']",0,"['daskmljoblib', 'google', 'colab', 'modulenotfounderror']","['daskmljoblib', 'google', 'colab', 'modulenotfounderror']",daskmljoblib google colab modulenotfounderror,0.0,0.0,4,45,9.0,0,0,0,0,0,0,0,0
1751,sample dashboard  the creative analyst not working,Hackathons,sample dashboard  the creative analyst not working,"['sample', 'dashboard', 'the', 'creative', 'analyst', 'not', 'working']",0,"['sample', 'dashboard', 'the', 'creative', 'analyst', 'not', 'working']","['sample', 'dashboard', 'creative', 'analyst', 'working']",sample dashboard creative analyst working,0.5,0.5,7,41,5.125,0,0,0,0,0,0,0,0
1752,what is the difference between longitudinal study and cross sectional study,Techniques,what is the difference between longitudinal study and cross sectional study,"['what', 'is', 'the', 'difference', 'between', 'longitudinal', 'study', 'and', 'cross', 'sectional', 'study']",0,"['what', 'is', 'the', 'difference', 'between', 'longitudinal', 'study', 'and', 'cross', 'sectional', 'study']","['difference', 'longitudinal', 'study', 'cross', 'sectional', 'study']",difference longitudinal study cross sectional study,0.0,0.0,11,51,4.25,0,0,0,0,0,0,0,0
1753,how can we plot a bar chart with categorical values on xaxis in python,Tools,how can we plot a bar chart with categorical values on xaxis in python,"['how', 'can', 'we', 'plot', 'a', 'bar', 'chart', 'with', 'categorical', 'values', 'on', 'xaxis', 'in', 'python']",0,"['how', 'can', 'we', 'plot', 'a', 'bar', 'chart', 'with', 'categorical', 'value', 'on', 'xaxis', 'in', 'python']","['plot', 'bar', 'chart', 'categorical', 'value', 'xaxis', 'python']",plot bar chart categorical value xaxis python,0.0,0.0,14,45,3.0,0,0,0,0,0,0,0,0
1754,data science thoughts for network challenges,Techniques,data science thoughts for network challenges,"['data', 'science', 'thoughts', 'for', 'network', 'challenges']",0,"['data', 'science', 'thought', 'for', 'network', 'challenge']","['data', 'science', 'thought', 'network', 'challenge']",data science thought network challenge,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
1755,error in code  pythonspyder ,Techniques,error in code  pythonspyder ,"['error', 'in', 'code', 'pythonspyder']",1,"['error', 'in', 'code', 'pythonspyder']","['error', 'code', 'pythonspyder']",error code pythonspyder,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
1756,dealing with missing categorial data,Techniques,dealing with missing categorial data,"['dealing', 'with', 'missing', 'categorial', 'data']",0,"['dealing', 'with', 'missing', 'categorial', 'data']","['dealing', 'missing', 'categorial', 'data']",dealing missing categorial data,-0.2,-0.2,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1757,how to convert data from xml to json,Techniques,how to convert data from xml to json,"['how', 'to', 'convert', 'data', 'from', 'xml', 'to', 'json']",0,"['how', 'to', 'convert', 'data', 'from', 'xml', 'to', 'json']","['convert', 'data', 'xml', 'json']",convert data xml json,0.0,0.0,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
1758,cannibalization effect of one channel over other,Techniques,cannibalization effect of one channel over other,"['cannibalization', 'effect', 'of', 'one', 'channel', 'over', 'other']",0,"['cannibalization', 'effect', 'of', 'one', 'channel', 'over', 'other']","['cannibalization', 'effect', 'one', 'channel']",cannibalization effect one channel,-0.125,0.0,7,34,4.25,0,0,0,0,0,0,0,0
1759,integration of djs bubble chart with shiny,Tools,integration of djs bubble chart with shiny,"['integration', 'of', 'djs', 'bubble', 'chart', 'with', 'shiny']",0,"['integration', 'of', 'dj', 'bubble', 'chart', 'with', 'shiny']","['integration', 'dj', 'bubble', 'chart', 'shiny']",integration dj bubble chart shiny,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
1760,how to create confusion matrix for xgboost in r,Tools,how to create confusion matrix for xgboost in r,"['how', 'to', 'create', 'confusion', 'matrix', 'for', 'xgboost', 'in', 'r']",0,"['how', 'to', 'create', 'confusion', 'matrix', 'for', 'xgboost', 'in', 'r']","['create', 'confusion', 'matrix', 'xgboost', 'r']",create confusion matrix xgboost r,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
1761,ner or training of dataset,Techniques,ner or training of dataset,"['ner', 'or', 'training', 'of', 'dataset']",0,"['ner', 'or', 'training', 'of', 'dataset']","['ner', 'training', 'dataset']",ner training dataset,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
1762,crossvalscore is returning nan list of scores in scikit learn,Techniques,crossvalscore is returning nan list of scores in scikit learn,"['crossvalscore', 'is', 'returning', 'nan', 'list', 'of', 'scores', 'in', 'scikit', 'learn']",0,"['crossvalscore', 'is', 'returning', 'nan', 'list', 'of', 'score', 'in', 'scikit', 'learn']","['crossvalscore', 'returning', 'nan', 'list', 'score', 'scikit', 'learn']",crossvalscore returning nan list score scikit learn,0.0,0.0,10,51,4.636363636363637,0,0,0,0,0,0,0,0
1763,pre post analysis using ab testing,Techniques,pre post analysis using ab testing,"['pre', 'post', 'analysis', 'using', 'ab', 'testing']",0,"['pre', 'post', 'analysis', 'using', 'ab', 'testing']","['pre', 'post', 'analysis', 'using', 'ab', 'testing']",pre post analysis using ab testing,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
1764,ways to find linearity,Techniques,ways to find linearity,"['ways', 'to', 'find', 'linearity']",0,"['way', 'to', 'find', 'linearity']","['way', 'find', 'linearity']",way find linearity,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
1765,need help analysing experiment results,Techniques,need help analysing experiment results,"['need', 'help', 'analysing', 'experiment', 'results']",0,"['need', 'help', 'analysing', 'experiment', 'result']","['need', 'help', 'analysing', 'experiment', 'result']",need help analysing experiment result,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
1766,best structure to start exploring machine learning algorith,Career,best structure to start exploring machine learning algorith,"['best', 'structure', 'to', 'start', 'exploring', 'machine', 'learning', 'algorith']",0,"['best', 'structure', 'to', 'start', 'exploring', 'machine', 'learning', 'algorith']","['best', 'structure', 'start', 'exploring', 'machine', 'learning', 'algorith']",best structure start exploring machine learning algorith,1.0,1.0,8,56,6.222222222222222,0,0,0,0,0,0,0,0
1767,how difficult to get a job as bigdata administrator or developer,Career,how difficult to get a job as bigdata administrator or developer,"['how', 'difficult', 'to', 'get', 'a', 'job', 'as', 'bigdata', 'administrator', 'or', 'developer']",0,"['how', 'difficult', 'to', 'get', 'a', 'job', 'a', 'bigdata', 'administrator', 'or', 'developer']","['difficult', 'get', 'job', 'bigdata', 'administrator', 'developer']",difficult get job bigdata administrator developer,-0.5,-0.5,11,49,4.083333333333333,0,0,0,0,0,0,0,0
1768,how to make a career in business analytics   year it experience,Career,how to make a career in business analytics   year it experience,"['how', 'to', 'make', 'a', 'career', 'in', 'business', 'analytics', 'year', 'it', 'experience']",1,"['how', 'to', 'make', 'a', 'career', 'in', 'business', 'analytics', 'year', 'it', 'experience']","['make', 'career', 'business', 'analytics', 'year', 'experience']",make career business analytics year experience,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
1769,data scientist light,Career,data scientist light,"['data', 'scientist', 'light']",0,"['data', 'scientist', 'light']","['data', 'scientist', 'light']",data scientist light,0.4,0.4,3,20,5.0,0,0,0,0,0,0,0,0
1770,how is edupristines data science program,Career,how is edupristines data science program,"['how', 'is', 'edupristines', 'data', 'science', 'program']",0,"['how', 'is', 'edupristines', 'data', 'science', 'program']","['edupristines', 'data', 'science', 'program']",edupristines data science program,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
1771,discussions for article learning path on r  step by step guide to learn data science on r,Other,discussions for article learning path on r  step by step guide to learn data science on r,"['discussions', 'for', 'article', 'learning', 'path', 'on', 'r', 'step', 'by', 'step', 'guide', 'to', 'learn', 'data', 'science', 'on', 'r']",0,"['discussion', 'for', 'article', 'learning', 'path', 'on', 'r', 'step', 'by', 'step', 'guide', 'to', 'learn', 'data', 'science', 'on', 'r']","['discussion', 'article', 'learning', 'path', 'r', 'step', 'step', 'guide', 'learn', 'data', 'science', 'r']",discussion article learning path r step step guide learn data science r,0.0,0.0,17,71,3.9444444444444446,0,0,0,0,0,0,0,0
1772,why are different base learners used in mboost package in r,Techniques,why are different base learners used in mboost package in r,"['why', 'are', 'different', 'base', 'learners', 'used', 'in', 'mboost', 'package', 'in', 'r']",0,"['why', 'are', 'different', 'base', 'learner', 'used', 'in', 'mboost', 'package', 'in', 'r']","['different', 'base', 'learner', 'used', 'mboost', 'package', 'r']",different base learner used mboost package r,-0.4,-0.4,11,44,3.6666666666666665,0,0,0,0,0,0,0,0
1773,what packages in r can be used to create content based recommender,Tools,what packages in r can be used to create content based recommender,"['what', 'packages', 'in', 'r', 'can', 'be', 'used', 'to', 'create', 'content', 'based', 'recommender']",0,"['what', 'package', 'in', 'r', 'can', 'be', 'used', 'to', 'create', 'content', 'based', 'recommender']","['package', 'r', 'used', 'create', 'content', 'based', 'recommender']",package r used create content based recommender,0.0,0.0,12,47,3.6153846153846154,0,0,0,0,0,0,0,0
1774,analytics career advice for undergrad java professionals to move in analytics,Career,analytics career advice for undergrad java professionals to move in analytics,"['analytics', 'career', 'advice', 'for', 'undergrad', 'java', 'professionals', 'to', 'move', 'in', 'analytics']",0,"['analytics', 'career', 'advice', 'for', 'undergrad', 'java', 'professional', 'to', 'move', 'in', 'analytics']","['analytics', 'career', 'advice', 'undergrad', 'java', 'professional', 'move', 'analytics']",analytics career advice undergrad java professional move analytics,0.0,0.1,11,66,5.5,0,0,0,0,0,0,0,0
1775,deep learning in r,Resources,deep learning in r,"['deep', 'learning', 'in', 'r']",0,"['deep', 'learning', 'in', 'r']","['deep', 'learning', 'r']",deep learning r,0.0,0.0,4,15,3.0,0,0,0,0,0,0,0,0
1776,do these scores make sense,Hackathons,do these scores make sense,"['do', 'these', 'scores', 'make', 'sense']",0,"['do', 'these', 'score', 'make', 'sense']","['score', 'make', 'sense']",score make sense,0.0,0.0,5,16,2.6666666666666665,0,0,0,0,0,0,0,0
1777,feedback required on aegis business analytics program,Career,feedback required on aegis business analytics program,"['feedback', 'required', 'on', 'aegis', 'business', 'analytics', 'program']",0,"['feedback', 'required', 'on', 'aegis', 'business', 'analytics', 'program']","['feedback', 'required', 'aegis', 'business', 'analytics', 'program']",feedback required aegis business analytics program,0.0,0.0,7,50,6.25,0,0,0,0,0,0,0,0
1778,how to calculate the output in convoluted neural networks,Techniques,how to calculate the output in convoluted neural networks,"['how', 'to', 'calculate', 'the', 'output', 'in', 'convoluted', 'neural', 'networks']",0,"['how', 'to', 'calculate', 'the', 'output', 'in', 'convoluted', 'neural', 'network']","['calculate', 'output', 'convoluted', 'neural', 'network']",calculate output convoluted neural network,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
1779,error cannot allocate vector of size  gradient boosting algorithm,Hackathons,error cannot allocate vector of size  gradient boosting algorithm,"['error', 'can', 'not', 'allocate', 'vector', 'of', 'size', 'gradient', 'boosting', 'algorithm']",0,"['error', 'can', 'not', 'allocate', 'vector', 'of', 'size', 'gradient', 'boosting', 'algorithm']","['error', 'allocate', 'vector', 'size', 'gradient', 'boosting', 'algorithm']",error allocate vector size gradient boosting algorithm,0.0,0.0,10,54,4.909090909090909,0,0,0,0,0,0,0,0
1780,missing at random and missing not at random,Techniques,missing at random and missing not at random,"['missing', 'at', 'random', 'and', 'missing', 'not', 'at', 'random']",0,"['missing', 'at', 'random', 'and', 'missing', 'not', 'at', 'random']","['missing', 'random', 'missing', 'random']",missing random missing random,-0.35,-0.35,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
1781,doubt in the article on parameter tunning of xgboost in python,Techniques,doubt in the article on parameter tunning of xgboost in python,"['doubt', 'in', 'the', 'article', 'on', 'parameter', 'tunning', 'of', 'xgboost', 'in', 'python']",0,"['doubt', 'in', 'the', 'article', 'on', 'parameter', 'tunning', 'of', 'xgboost', 'in', 'python']","['doubt', 'article', 'parameter', 'tunning', 'xgboost', 'python']",doubt article parameter tunning xgboost python,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
1782,stack overflow xml data parsing,Techniques,stack overflow xml data parsing,"['stack', 'overflow', 'xml', 'data', 'parsing']",0,"['stack', 'overflow', 'xml', 'data', 'parsing']","['stack', 'overflow', 'xml', 'data', 'parsing']",stack overflow xml data parsing,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1783,how to interpret the output from factor analysis in r,Tools,how to interpret the output from factor analysis in r,"['how', 'to', 'interpret', 'the', 'output', 'from', 'factor', 'analysis', 'in', 'r']",0,"['how', 'to', 'interpret', 'the', 'output', 'from', 'factor', 'analysis', 'in', 'r']","['interpret', 'output', 'factor', 'analysis', 'r']",interpret output factor analysis r,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
1784,barriers to data analytics in automobile industry,Misc,barriers to data analytics in automobile industry,"['barriers', 'to', 'data', 'analytics', 'in', 'automobile', 'industry']",0,"['barrier', 'to', 'data', 'analytics', 'in', 'automobile', 'industry']","['barrier', 'data', 'analytics', 'automobile', 'industry']",barrier data analytics automobile industry,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
1785,problem while creating a csv file in r for kaggle,Tools,problem while creating a csv file in r for kaggle,"['problem', 'while', 'creating', 'a', 'csv', 'file', 'in', 'r', 'for', 'kaggle']",0,"['problem', 'while', 'creating', 'a', 'csv', 'file', 'in', 'r', 'for', 'kaggle']","['problem', 'creating', 'csv', 'file', 'r', 'kaggle']",problem creating csv file r kaggle,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
1786,unable to plot histogram with density curve using ggplot,Techniques,unable to plot histogram with density curve using ggplot,"['unable', 'to', 'plot', 'histogram', 'with', 'density', 'curve', 'using', 'ggplot']",0,"['unable', 'to', 'plot', 'histogram', 'with', 'density', 'curve', 'using', 'ggplot']","['unable', 'plot', 'histogram', 'density', 'curve', 'using', 'ggplot']",unable plot histogram density curve using ggplot,-0.5,-0.5,9,48,4.8,0,0,0,0,0,0,0,0
1787,how to find the percentage of missing value in a column,Techniques,how to find the percentage of missing value in a column,"['how', 'to', 'find', 'the', 'percentage', 'of', 'missing', 'value', 'in', 'a', 'column']",0,"['how', 'to', 'find', 'the', 'percentage', 'of', 'missing', 'value', 'in', 'a', 'column']","['find', 'percentage', 'missing', 'value', 'column']",find percentage missing value column,-0.2,-0.2,11,36,3.0,0,0,0,0,0,0,0,0
1788,dataset related to consumer retail  marketing data in india,Resources,dataset related to consumer retail  marketing data in india,"['dataset', 'related', 'to', 'consumer', 'retail', 'marketing', 'data', 'in', 'india']",0,"['dataset', 'related', 'to', 'consumer', 'retail', 'marketing', 'data', 'in', 'india']","['dataset', 'related', 'consumer', 'retail', 'marketing', 'data', 'india']",dataset related consumer retail marketing data india,0.0,0.0,9,52,5.2,0,0,0,0,0,0,0,0
1789,label encoding vs one hot encoding in machine learning model,Techniques,label encoding vs one hot encoding in machine learning model,"['label', 'encoding', 'vs', 'one', 'hot', 'encoding', 'in', 'machine', 'learning', 'model']",0,"['label', 'encoding', 'v', 'one', 'hot', 'encoding', 'in', 'machine', 'learning', 'model']","['label', 'encoding', 'v', 'one', 'hot', 'encoding', 'machine', 'learning', 'model']",label encoding v one hot encoding machine learning model,0.25,0.25,10,56,5.090909090909091,0,0,0,0,0,0,0,0
1790,how do i use results from a random forest algo for prediction,Tools,how do i use results from a random forest algo for prediction,"['how', 'do', 'i', 'use', 'results', 'from', 'a', 'random', 'forest', 'algo', 'for', 'prediction']",0,"['how', 'do', 'i', 'use', 'result', 'from', 'a', 'random', 'forest', 'algo', 'for', 'prediction']","['use', 'result', 'random', 'forest', 'algo', 'prediction']",use result random forest algo prediction,-0.5,-0.5,12,40,3.076923076923077,0,0,0,0,0,0,0,0
1791,filling missing values,Hackathons,filling missing values,"['filling', 'missing', 'values']",0,"['filling', 'missing', 'value']","['filling', 'missing', 'value']",filling missing value,-0.2,-0.2,3,21,5.25,0,0,0,0,0,0,0,0
1792,why is sql a prerequisite to get started in data science,Career,why is sql a prerequisite to get started in data science,"['why', 'is', 'sql', 'a', 'prerequisite', 'to', 'get', 'started', 'in', 'data', 'science']",0,"['why', 'is', 'sql', 'a', 'prerequisite', 'to', 'get', 'started', 'in', 'data', 'science']","['sql', 'prerequisite', 'get', 'started', 'data', 'science']",sql prerequisite get started data science,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
1793,complete guide to parameter tuning in gradient boosting gbm in python,Techniques,complete guide to parameter tuning in gradient boosting gbm in python,"['complete', 'guide', 'to', 'parameter', 'tuning', 'in', 'gradient', 'boosting', 'gbm', 'in', 'python']",0,"['complete', 'guide', 'to', 'parameter', 'tuning', 'in', 'gradient', 'boosting', 'gbm', 'in', 'python']","['complete', 'guide', 'parameter', 'tuning', 'gradient', 'boosting', 'gbm', 'python']",complete guide parameter tuning gradient boosting gbm python,0.1,0.1,11,60,5.0,0,0,0,0,0,0,0,0
1794,pick only first  females from the dataset,Tools,pick only first  females from the dataset,"['pick', 'only', 'first', 'females', 'from', 'the', 'dataset']",1,"['pick', 'only', 'first', 'female', 'from', 'the', 'dataset']","['pick', 'first', 'female', 'dataset']",pick first female dataset,0.125,0.125,7,25,3.125,0,0,0,0,0,0,0,0
1795,dataset processing,Tools,dataset processing,"['dataset', 'processing']",0,"['dataset', 'processing']","['dataset', 'processing']",dataset processing,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
1796,implement incremental load in qlikview,Tools,implement incremental load in qlikview,"['implement', 'incremental', 'load', 'in', 'qlikview']",0,"['implement', 'incremental', 'load', 'in', 'qlikview']","['implement', 'incremental', 'load', 'qlikview']",implement incremental load qlikview,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
1797,cannot find tutorial data,Hackathons,cannot find tutorial data,"['can', 'not', 'find', 'tutorial', 'data']",0,"['can', 'not', 'find', 'tutorial', 'data']","['find', 'tutorial', 'data']",find tutorial data,0.0,0.0,5,18,3.0,0,0,0,0,0,0,0,0
1798,best feature selection method,Techniques,best feature selection method,"['best', 'feature', 'selection', 'method']",0,"['best', 'feature', 'selection', 'method']","['best', 'feature', 'selection', 'method']",best feature selection method,1.0,1.0,4,29,5.8,0,0,0,0,0,0,0,0
1799,how to generate vector of integer in r,Tools,how to generate vector of integer in r,"['how', 'to', 'generate', 'vector', 'of', 'integer', 'in', 'r']",0,"['how', 'to', 'generate', 'vector', 'of', 'integer', 'in', 'r']","['generate', 'vector', 'integer', 'r']",generate vector integer r,0.0,0.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
1800,scrubbing of unstructured text data,Techniques,scrubbing of unstructured text data,"['scrubbing', 'of', 'unstructured', 'text', 'data']",0,"['scrubbing', 'of', 'unstructured', 'text', 'data']","['scrubbing', 'unstructured', 'text', 'data']",scrubbing unstructured text data,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
1801,clustering using mixed variables  with categorical variables having about  categories,Techniques,clustering using mixed variables  with categorical variables having about  categories,"['clustering', 'using', 'mixed', 'variables', 'with', 'categorical', 'variables', 'having', 'about', 'categories']",1,"['clustering', 'using', 'mixed', 'variable', 'with', 'categorical', 'variable', 'having', 'about', 'category']","['clustering', 'using', 'mixed', 'variable', 'categorical', 'variable', 'category']",clustering using mixed variable categorical variable category,0.0,0.0,10,61,5.545454545454546,0,0,0,0,0,0,0,0
1802,linear and logistic regression r functions,Techniques,linear and logistic regression r functions,"['linear', 'and', 'logistic', 'regression', 'r', 'functions']",0,"['linear', 'and', 'logistic', 'regression', 'r', 'function']","['linear', 'logistic', 'regression', 'r', 'function']",linear logistic regression r function,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
1803,how does machine learning model works on raw data,Techniques,how does machine learning model works on raw data,"['how', 'does', 'machine', 'learning', 'model', 'works', 'on', 'raw', 'data']",0,"['how', 'doe', 'machine', 'learning', 'model', 'work', 'on', 'raw', 'data']","['doe', 'machine', 'learning', 'model', 'work', 'raw', 'data']",doe machine learning model work raw data,-0.2307692307692307,-0.2307692307692307,9,40,4.0,0,0,0,0,0,0,0,0
1804,rfm analysis using r,Techniques,rfm analysis using r,"['rfm', 'analysis', 'using', 'r']",0,"['rfm', 'analysis', 'using', 'r']","['rfm', 'analysis', 'using', 'r']",rfm analysis using r,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
1805,what is private leaderboard in hackathon and how to submit the submission file there,Techniques,what is private leaderboard in hackathon and how to submit the submission file there,"['what', 'is', 'private', 'leaderboard', 'in', 'hackathon', 'and', 'how', 'to', 'submit', 'the', 'submission', 'file', 'there']",0,"['what', 'is', 'private', 'leaderboard', 'in', 'hackathon', 'and', 'how', 'to', 'submit', 'the', 'submission', 'file', 'there']","['private', 'leaderboard', 'hackathon', 'submit', 'submission', 'file']",private leaderboard hackathon submit submission file,0.0,0.0,14,52,3.466666666666667,0,0,0,0,0,0,0,0
1806,loan prediction  reveal your approach,Hackathons,loan prediction  reveal your approach,"['loan', 'prediction', 'reveal', 'your', 'approach']",1,"['loan', 'prediction', 'reveal', 'your', 'approach']","['loan', 'prediction', 'reveal', 'approach']",loan prediction reveal approach,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1807,roc and auc curve,Techniques,roc and auc curve,"['roc', 'and', 'auc', 'curve']",0,"['roc', 'and', 'auc', 'curve']","['roc', 'auc', 'curve']",roc auc curve,0.0,0.0,4,13,2.6,0,0,0,0,0,0,0,0
1808,data normality question,Techniques,data normality question,"['data', 'normality', 'question']",0,"['data', 'normality', 'question']","['data', 'normality', 'question']",data normality question,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
1809,bigmart baseline solution  score  python codes,Hackathons,bigmart baseline solution  score  python codes,"['bigmart', 'baseline', 'solution', 'score', 'python', 'codes']",1,"['bigmart', 'baseline', 'solution', 'score', 'python', 'code']","['bigmart', 'baseline', 'solution', 'score', 'python', 'code']",bigmart baseline solution score python code,0.0,0.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
1810,what are top  best data mining tools that can replace sasspss,Tools,what are top  best data mining tools that can replace sasspss,"['what', 'are', 'top', 'best', 'data', 'mining', 'tools', 'that', 'can', 'replace', 'sasspss']",1,"['what', 'are', 'top', 'best', 'data', 'mining', 'tool', 'that', 'can', 'replace', 'sasspss']","['top', 'best', 'data', 'mining', 'tool', 'replace', 'sasspss']",top best data mining tool replace sasspss,0.75,0.75,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
1811,packages in r for image analytics,Techniques,packages in r for image analytics,"['packages', 'in', 'r', 'for', 'image', 'analytics']",0,"['package', 'in', 'r', 'for', 'image', 'analytics']","['package', 'r', 'image', 'analytics']",package r image analytics,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
1812,errorall arguments must have same length,Techniques,errorall arguments must have same length,"['errorall', 'arguments', 'must', 'have', 'same', 'length']",0,"['errorall', 'argument', 'must', 'have', 'same', 'length']","['errorall', 'argument', 'must', 'length']",errorall argument must length,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
1813,survival random forest with time dependent covariates in r,Techniques,survival random forest with time dependent covariates in r,"['survival', 'random', 'forest', 'with', 'time', 'dependent', 'covariates', 'in', 'r']",0,"['survival', 'random', 'forest', 'with', 'time', 'dependent', 'covariates', 'in', 'r']","['survival', 'random', 'forest', 'time', 'dependent', 'covariates', 'r']",survival random forest time dependent covariates r,-0.5,-0.5,9,50,5.0,0,0,0,0,0,0,0,0
1814,model testing  validation,Techniques,model testing  validation,"['model', 'testing', 'validation']",0,"['model', 'testing', 'validation']","['model', 'testing', 'validation']",model testing validation,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
1815,elmo for feature extraction,Techniques,elmo for feature extraction,"['elmo', 'for', 'feature', 'extraction']",0,"['elmo', 'for', 'feature', 'extraction']","['elmo', 'feature', 'extraction']",elmo feature extraction,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
1816,why we need to calculate the zscore of each variable while calculating pearsons r,Techniques,why we need to calculate the zscore of each variable while calculating pearsons r,"['why', 'we', 'need', 'to', 'calculate', 'the', 'zscore', 'of', 'each', 'variable', 'while', 'calculating', 'pearsons', 'r']",0,"['why', 'we', 'need', 'to', 'calculate', 'the', 'zscore', 'of', 'each', 'variable', 'while', 'calculating', 'pearsons', 'r']","['need', 'calculate', 'zscore', 'variable', 'calculating', 'pearsons', 'r']",need calculate zscore variable calculating pearsons r,0.0,0.0,14,53,3.533333333333333,0,0,0,0,0,0,0,0
1817,error in importing a csv file using pandas,Tools,error in importing a csv file using pandas,"['error', 'in', 'importing', 'a', 'csv', 'file', 'using', 'pandas']",0,"['error', 'in', 'importing', 'a', 'csv', 'file', 'using', 'panda']","['error', 'importing', 'csv', 'file', 'using', 'panda']",error importing csv file using panda,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
1818,improve holtwinter forecast model accuracy,Techniques,improve holtwinter forecast model accuracy,"['improve', 'holtwinter', 'forecast', 'model', 'accuracy']",0,"['improve', 'holtwinter', 'forecast', 'model', 'accuracy']","['improve', 'holtwinter', 'forecast', 'model', 'accuracy']",improve holtwinter forecast model accuracy,0.0,0.0,5,42,7.0,0,0,0,0,0,0,0,0
1819,visualization of decision boundaries,Resources,visualization of decision boundaries,"['visualization', 'of', 'decision', 'boundaries']",0,"['visualization', 'of', 'decision', 'boundary']","['visualization', 'decision', 'boundary']",visualization decision boundary,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
1820,pytesseract giving errors,Techniques,pytesseract giving errors,"['pytesseract', 'giving', 'errors']",0,"['pytesseract', 'giving', 'error']","['pytesseract', 'giving', 'error']",pytesseract giving error,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
1821,arranging multiple dates and times,Tools,arranging multiple dates and times,"['arranging', 'multiple', 'dates', 'and', 'times']",0,"['arranging', 'multiple', 'date', 'and', 'time']","['arranging', 'multiple', 'date', 'time']",arranging multiple date time,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
1822,creating networks using tfagents for reinforcement learning,Techniques,creating networks using tfagents for reinforcement learning,"['creating', 'networks', 'using', 'tfagents', 'for', 'reinforcement', 'learning']",0,"['creating', 'network', 'using', 'tfagents', 'for', 'reinforcement', 'learning']","['creating', 'network', 'using', 'tfagents', 'reinforcement', 'learning']",creating network using tfagents reinforcement learning,0.0,0.0,7,54,6.75,0,0,0,0,0,0,0,0
1823,data anonymization,Misc,data anonymization,"['data', 'anonymization']",0,"['data', 'anonymization']","['data', 'anonymization']",data anonymization,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
1824,probabilistic graphical model doubt,Techniques,probabilistic graphical model doubt,"['probabilistic', 'graphical', 'model', 'doubt']",0,"['probabilistic', 'graphical', 'model', 'doubt']","['probabilistic', 'graphical', 'model', 'doubt']",probabilistic graphical model doubt,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
1825,what is the fundamental difference between randomforest and gradient boosting algorithms,Techniques,what is the fundamental difference between randomforest and gradient boosting algorithms,"['what', 'is', 'the', 'fundamental', 'difference', 'between', 'randomforest', 'and', 'gradient', 'boosting', 'algorithms']",0,"['what', 'is', 'the', 'fundamental', 'difference', 'between', 'randomforest', 'and', 'gradient', 'boosting', 'algorithm']","['fundamental', 'difference', 'randomforest', 'gradient', 'boosting', 'algorithm']",fundamental difference randomforest gradient boosting algorithm,0.0,0.0,11,63,5.25,0,0,0,0,0,0,0,0
1826,calculate price elasticity of demand with limited data,Techniques,calculate price elasticity of demand with limited data,"['calculate', 'price', 'elasticity', 'of', 'demand', 'with', 'limited', 'data']",0,"['calculate', 'price', 'elasticity', 'of', 'demand', 'with', 'limited', 'data']","['calculate', 'price', 'elasticity', 'demand', 'limited', 'data']",calculate price elasticity demand limited data,-0.0714285714285714,-0.0714285714285714,8,46,5.111111111111111,0,0,0,0,0,0,0,0
1827,i did not understand credithistory variable can any one help me with the explanation please,Hackathons,i did not understand credithistory variable can any one help me with the explanation please,"['i', 'did', 'not', 'understand', 'credithistory', 'variable', 'can', 'any', 'one', 'help', 'me', 'with', 'the', 'explanation', 'please']",0,"['i', 'did', 'not', 'understand', 'credithistory', 'variable', 'can', 'any', 'one', 'help', 'me', 'with', 'the', 'explanation', 'please']","['understand', 'credithistory', 'variable', 'one', 'help', 'explanation', 'please']",understand credithistory variable one help explanation please,0.0,0.0,15,61,3.8125,0,0,0,0,0,0,0,0
1828,labelencoder  how to reverse it,Other,labelencoder  how to reverse it,"['labelencoder', 'how', 'to', 'reverse', 'it']",0,"['labelencoder', 'how', 'to', 'reverse', 'it']","['labelencoder', 'reverse']",labelencoder reverse,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
1829,hackathon   share your approach  learning,Hackathons,hackathon   share your approach  learning,"['hackathon', 'share', 'your', 'approach', 'learning']",1,"['hackathon', 'share', 'your', 'approach', 'learning']","['hackathon', 'share', 'approach', 'learning']",hackathon share approach learning,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
1830,ensemble technique,Techniques,ensemble technique,"['ensemble', 'technique']",0,"['ensemble', 'technique']","['ensemble', 'technique']",ensemble technique,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
1831,need help in fetching data from hbase to r studio server,Tools,need help in fetching data from hbase to r studio server,"['need', 'help', 'in', 'fetching', 'data', 'from', 'hbase', 'to', 'r', 'studio', 'server']",0,"['need', 'help', 'in', 'fetching', 'data', 'from', 'hbase', 'to', 'r', 'studio', 'server']","['need', 'help', 'fetching', 'data', 'hbase', 'r', 'studio', 'server']",need help fetching data hbase r studio server,0.0,0.0,11,45,3.75,0,0,0,0,0,0,0,0
1832,finding length of unstructered data,Techniques,finding length of unstructered data,"['finding', 'length', 'of', 'unstructered', 'data']",0,"['finding', 'length', 'of', 'unstructered', 'data']","['finding', 'length', 'unstructered', 'data']",finding length unstructered data,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
1833,a complete tutorial to learn data science with python from scratch,Hackathons,a complete tutorial to learn data science with python from scratch,"['a', 'complete', 'tutorial', 'to', 'learn', 'data', 'science', 'with', 'python', 'from', 'scratch']",0,"['a', 'complete', 'tutorial', 'to', 'learn', 'data', 'science', 'with', 'python', 'from', 'scratch']","['complete', 'tutorial', 'learn', 'data', 'science', 'python', 'scratch']",complete tutorial learn data science python scratch,0.1,0.1,11,51,4.25,0,0,0,0,0,0,0,0
1834,emerging bi  data analytics trends for  and beyond,Resources,emerging bi  data analytics trends for  and beyond,"['emerging', 'bi', 'data', 'analytics', 'trends', 'for', 'and', 'beyond']",1,"['emerging', 'bi', 'data', 'analytics', 'trend', 'for', 'and', 'beyond']","['emerging', 'bi', 'data', 'analytics', 'trend', 'beyond']",emerging bi data analytics trend beyond,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
1835,what protocol should i use for loadrunner when recording oracles primavera p ppm,Tools,what protocol should i use for loadrunner when recording oracles primavera p ppm,"['what', 'protocol', 'should', 'i', 'use', 'for', 'loadrunner', 'when', 'recording', 'oracles', 'primavera', 'p', 'ppm']",0,"['what', 'protocol', 'should', 'i', 'use', 'for', 'loadrunner', 'when', 'recording', 'oracle', 'primavera', 'p', 'ppm']","['protocol', 'use', 'loadrunner', 'recording', 'oracle', 'primavera', 'p', 'ppm']",protocol use loadrunner recording oracle primavera p ppm,0.0,0.0,13,56,4.0,0,0,0,0,0,0,0,0
1836,strategic monk competition,Hackathons,strategic monk competition,"['strategic', 'monk', 'competition']",0,"['strategic', 'monk', 'competition']","['strategic', 'monk', 'competition']",strategic monk competition,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
1837,is data analytics will be good option to opt,Career,is data analytics will be good option to opt,"['is', 'data', 'analytics', 'will', 'be', 'good', 'option', 'to', 'opt']",0,"['is', 'data', 'analytics', 'will', 'be', 'good', 'option', 'to', 'opt']","['data', 'analytics', 'good', 'option', 'opt']",data analytics good option opt,0.7,0.7,9,30,3.0,0,0,0,0,0,0,0,0
1838,saving and reusing model,Techniques,saving and reusing model,"['saving', 'and', 'reusing', 'model']",0,"['saving', 'and', 'reusing', 'model']","['saving', 'reusing', 'model']",saving reusing model,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
1839,identify emerging trends,Techniques,identify emerging trends,"['identify', 'emerging', 'trends']",0,"['identify', 'emerging', 'trend']","['identify', 'emerging', 'trend']",identify emerging trend,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
1840,is bias term in machine learning different from deep learning,Techniques,is bias term in machine learning different from deep learning,"['is', 'bias', 'term', 'in', 'machine', 'learning', 'different', 'from', 'deep', 'learning']",0,"['is', 'bias', 'term', 'in', 'machine', 'learning', 'different', 'from', 'deep', 'learning']","['bias', 'term', 'machine', 'learning', 'different', 'deep', 'learning']",bias term machine learning different deep learning,0.0,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
1841,how to calculate vif in python  with scipy ,Tools,how to calculate vif in python  with scipy ,"['how', 'to', 'calculate', 'vif', 'in', 'python', 'with', 'scipy']",2,"['how', 'to', 'calculate', 'vif', 'in', 'python', 'with', 'scipy']","['calculate', 'vif', 'python', 'scipy']",calculate vif python scipy,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
1842,correlation doubt,Techniques,correlation doubt,"['correlation', 'doubt']",0,"['correlation', 'doubt']","['correlation', 'doubt']",correlation doubt,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
1843,what does robustness means in svm algorithm,Techniques,what does robustness means in svm algorithm,"['what', 'does', 'robustness', 'means', 'in', 'svm', 'algorithm']",0,"['what', 'doe', 'robustness', 'mean', 'in', 'svm', 'algorithm']","['doe', 'robustness', 'mean', 'svm', 'algorithm']",doe robustness mean svm algorithm,0.0,-0.3125,7,33,4.125,0,0,0,0,0,0,0,0
1844,career change   years of experience,Career,career change   years of experience,"['career', 'change', 'years', 'of', 'experience']",1,"['career', 'change', 'year', 'of', 'experience']","['career', 'change', 'year', 'experience']",career change year experience,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
1845,python variable data type understanding,Techniques,python variable data type understanding,"['python', 'variable', 'data', 'type', 'understanding']",0,"['python', 'variable', 'data', 'type', 'understanding']","['python', 'variable', 'data', 'type', 'understanding']",python variable data type understanding,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
1846,why datasets are categorized into train and test data,Tools,why datasets are categorized into train and test data,"['why', 'datasets', 'are', 'categorized', 'into', 'train', 'and', 'test', 'data']",0,"['why', 'datasets', 'are', 'categorized', 'into', 'train', 'and', 'test', 'data']","['datasets', 'categorized', 'train', 'test', 'data']",datasets categorized train test data,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
1847,job opportunities in india after big data certification,Career,job opportunities in india after big data certification,"['job', 'opportunities', 'in', 'india', 'after', 'big', 'data', 'certification']",0,"['job', 'opportunity', 'in', 'india', 'after', 'big', 'data', 'certification']","['job', 'opportunity', 'india', 'big', 'data', 'certification']",job opportunity india big data certification,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
1848,pretrained models,Resources,pretrained models,"['pretrained', 'models']",0,"['pretrained', 'model']","['pretrained', 'model']",pretrained model,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
1849,calling stored procedure for the automated report in qliksense,Techniques,calling stored procedure for the automated report in qliksense,"['calling', 'stored', 'procedure', 'for', 'the', 'automated', 'report', 'in', 'qliksense']",0,"['calling', 'stored', 'procedure', 'for', 'the', 'automated', 'report', 'in', 'qliksense']","['calling', 'stored', 'procedure', 'automated', 'report', 'qliksense']",calling stored procedure automated report qliksense,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
1850,how are eigen values and eigen vectors calculated from a covariance matrix,Techniques,how are eigen values and eigen vectors calculated from a covariance matrix,"['how', 'are', 'eigen', 'values', 'and', 'eigen', 'vectors', 'calculated', 'from', 'a', 'covariance', 'matrix']",0,"['how', 'are', 'eigen', 'value', 'and', 'eigen', 'vector', 'calculated', 'from', 'a', 'covariance', 'matrix']","['eigen', 'value', 'eigen', 'vector', 'calculated', 'covariance', 'matrix']",eigen value eigen vector calculated covariance matrix,0.0,0.0,12,53,4.076923076923077,0,0,0,0,0,0,0,0
1851,multiple linear regression  transformation on percentage regressors,Techniques,multiple linear regression  transformation on percentage regressors,"['multiple', 'linear', 'regression', 'transformation', 'on', 'percentage', 'regressors']",0,"['multiple', 'linear', 'regression', 'transformation', 'on', 'percentage', 'regressors']","['multiple', 'linear', 'regression', 'transformation', 'percentage', 'regressors']",multiple linear regression transformation percentage regressors,0.0,0.0,7,63,7.875,0,0,0,0,0,0,0,0
1852,in which situations should we decide to use regularization in our model building,Techniques,in which situations should we decide to use regularization in our model building,"['in', 'which', 'situations', 'should', 'we', 'decide', 'to', 'use', 'regularization', 'in', 'our', 'model', 'building']",0,"['in', 'which', 'situation', 'should', 'we', 'decide', 'to', 'use', 'regularization', 'in', 'our', 'model', 'building']","['situation', 'decide', 'use', 'regularization', 'model', 'building']",situation decide use regularization model building,0.0,0.0,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
1853,what are the difference between cortest and with function in r,Tools,what are the difference between cortest and with function in r,"['what', 'are', 'the', 'difference', 'between', 'cortest', 'and', 'with', 'function', 'in', 'r']",0,"['what', 'are', 'the', 'difference', 'between', 'cortest', 'and', 'with', 'function', 'in', 'r']","['difference', 'cortest', 'function', 'r']",difference cortest function r,0.0,0.0,11,29,2.4166666666666665,0,0,0,0,0,0,0,0
1854,missed the webinar use of analytics in telecom industry,Resources,missed the webinar use of analytics in telecom industry,"['missed', 'the', 'webinar', 'use', 'of', 'analytics', 'in', 'telecom', 'industry']",0,"['missed', 'the', 'webinar', 'use', 'of', 'analytics', 'in', 'telecom', 'industry']","['missed', 'webinar', 'use', 'analytics', 'telecom', 'industry']",missed webinar use analytics telecom industry,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
1855,deep learning on wsn  network nodes,Techniques,deep learning on wsn  network nodes,"['deep', 'learning', 'on', 'wsn', 'network', 'nodes']",0,"['deep', 'learning', 'on', 'wsn', 'network', 'node']","['deep', 'learning', 'wsn', 'network', 'node']",deep learning wsn network node,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
1856,guide to newbies of r programming language,Tools,guide to newbies of r programming language,"['guide', 'to', 'newbies', 'of', 'r', 'programming', 'language']",0,"['guide', 'to', 'newbie', 'of', 'r', 'programming', 'language']","['guide', 'newbie', 'r', 'programming', 'language']",guide newbie r programming language,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
1857,how to set up hadoop on aws,Tools,how to set up hadoop on aws,"['how', 'to', 'set', 'up', 'hadoop', 'on', 'aws']",0,"['how', 'to', 'set', 'up', 'hadoop', 'on', 'aws']","['set', 'hadoop', 'aws']",set hadoop aws,0.0,0.0,7,14,1.75,0,0,0,0,0,0,0,0
1858,error while building a decision tree in r,Tools,error while building a decision tree in r,"['error', 'while', 'building', 'a', 'decision', 'tree', 'in', 'r']",0,"['error', 'while', 'building', 'a', 'decision', 'tree', 'in', 'r']","['error', 'building', 'decision', 'tree', 'r']",error building decision tree r,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
1859,machine learning algorithm selection,Techniques,machine learning algorithm selection,"['machine', 'learning', 'algorithm', 'selection']",0,"['machine', 'learning', 'algorithm', 'selection']","['machine', 'learning', 'algorithm', 'selection']",machine learning algorithm selection,0.0,0.0,4,36,7.2,0,0,0,0,0,0,0,0
1860,prediction of which loan emi is going to default,Techniques,prediction of which loan emi is going to default,"['prediction', 'of', 'which', 'loan', 'emi', 'is', 'going', 'to', 'default']",0,"['prediction', 'of', 'which', 'loan', 'emi', 'is', 'going', 'to', 'default']","['prediction', 'loan', 'emi', 'going', 'default']",prediction loan emi going default,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
1861,outlier treatment of negative value in r,Techniques,outlier treatment of negative value in r,"['outlier', 'treatment', 'of', 'negative', 'value', 'in', 'r']",0,"['outlier', 'treatment', 'of', 'negative', 'value', 'in', 'r']","['outlier', 'treatment', 'negative', 'value', 'r']",outlier treatment negative value r,-0.3,-0.3,7,34,4.25,0,0,0,0,0,0,0,0
1862,should target be missing in the test file,Hackathons,should target be missing in the test file,"['should', 'target', 'be', 'missing', 'in', 'the', 'test', 'file']",0,"['should', 'target', 'be', 'missing', 'in', 'the', 'test', 'file']","['target', 'missing', 'test', 'file']",target missing test file,-0.2,-0.2,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
1863,r interface with web tools,Tools,r interface with web tools,"['r', 'interface', 'with', 'web', 'tools']",0,"['r', 'interface', 'with', 'web', 'tool']","['r', 'interface', 'web', 'tool']",r interface web tool,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
1864,use of rank  order functions in r dplyr package with example,Misc,use of rank  order functions in r dplyr package with example,"['use', 'of', 'rank', 'order', 'functions', 'in', 'r', 'dplyr', 'package', 'with', 'example']",0,"['use', 'of', 'rank', 'order', 'function', 'in', 'r', 'dplyr', 'package', 'with', 'example']","['use', 'rank', 'order', 'function', 'r', 'dplyr', 'package', 'example']",use rank order function r dplyr package example,-0.8,-0.8,11,47,3.9166666666666665,0,0,0,0,0,0,0,0
1865,career advice for mtech grad,Career,career advice for mtech grad,"['career', 'advice', 'for', 'mtech', 'grad']",0,"['career', 'advice', 'for', 'mtech', 'grad']","['career', 'advice', 'mtech', 'grad']",career advice mtech grad,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
1866,effect of increasedecrease of aic and sc values in logistic regression,Techniques,effect of increasedecrease of aic and sc values in logistic regression,"['effect', 'of', 'increasedecrease', 'of', 'aic', 'and', 'sc', 'values', 'in', 'logistic', 'regression']",0,"['effect', 'of', 'increasedecrease', 'of', 'aic', 'and', 'sc', 'value', 'in', 'logistic', 'regression']","['effect', 'increasedecrease', 'aic', 'sc', 'value', 'logistic', 'regression']",effect increasedecrease aic sc value logistic regression,0.0,0.0,11,56,4.666666666666667,0,0,0,0,0,0,0,0
1867,how to find  or  conf interval  and a suitable length l,Other,how to find  or  conf interval  and a suitable length l,"['how', 'to', 'find', 'or', 'conf', 'interval', 'and', 'a', 'suitable', 'length', 'l']",2,"['how', 'to', 'find', 'or', 'conf', 'interval', 'and', 'a', 'suitable', 'length', 'l']","['find', 'conf', 'interval', 'suitable', 'length', 'l']",find conf interval suitable length l,0.55,0.55,11,36,3.0,0,0,0,0,0,0,0,0
1868,how to calculate coefficients for variable in multiple regression what is the concept behind it,Techniques,how to calculate coefficients for variable in multiple regression what is the concept behind it,"['how', 'to', 'calculate', 'coefficients', 'for', 'variable', 'in', 'multiple', 'regression', 'what', 'is', 'the', 'concept', 'behind', 'it']",0,"['how', 'to', 'calculate', 'coefficient', 'for', 'variable', 'in', 'multiple', 'regression', 'what', 'is', 'the', 'concept', 'behind', 'it']","['calculate', 'coefficient', 'variable', 'multiple', 'regression', 'concept', 'behind']",calculate coefficient variable multiple regression concept behind,-0.2,-0.2,15,65,4.0625,0,0,0,0,0,0,0,0
1869,unable to read xls file in r,Tools,unable to read xls file in r,"['unable', 'to', 'read', 'xls', 'file', 'in', 'r']",0,"['unable', 'to', 'read', 'xl', 'file', 'in', 'r']","['unable', 'read', 'xl', 'file', 'r']",unable read xl file r,-0.5,-0.5,7,21,2.625,0,0,0,0,0,0,0,0
1870,how to do feature selection in r using random forest for classification and regression,Techniques,how to do feature selection in r using random forest for classification and regression,"['how', 'to', 'do', 'feature', 'selection', 'in', 'r', 'using', 'random', 'forest', 'for', 'classification', 'and', 'regression']",0,"['how', 'to', 'do', 'feature', 'selection', 'in', 'r', 'using', 'random', 'forest', 'for', 'classification', 'and', 'regression']","['feature', 'selection', 'r', 'using', 'random', 'forest', 'classification', 'regression']",feature selection r using random forest classification regression,-0.5,-0.5,14,65,4.333333333333333,0,0,0,0,0,0,0,0
1871,how to resolve groupby error in aggregate function in r,Tools,how to resolve groupby error in aggregate function in r,"['how', 'to', 'resolve', 'groupby', 'error', 'in', 'aggregate', 'function', 'in', 'r']",0,"['how', 'to', 'resolve', 'groupby', 'error', 'in', 'aggregate', 'function', 'in', 'r']","['resolve', 'groupby', 'error', 'aggregate', 'function', 'r']",resolve groupby error aggregate function r,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
1872,tweeter analysis submission file issue,Hackathons,tweeter analysis submission file issue,"['tweeter', 'analysis', 'submission', 'file', 'issue']",0,"['tweeter', 'analysis', 'submission', 'file', 'issue']","['tweeter', 'analysis', 'submission', 'file', 'issue']",tweeter analysis submission file issue,0.0,0.0,5,38,6.333333333333333,0,0,0,0,0,0,0,0
1873,is there a good book to practice sas sqlmacroarrays concepts with examples having sas problems and solutions can anyone please suggest,Tools,is there a good book to practice sas sqlmacroarrays concepts with examples having sas problems and solutions can anyone please suggest,"['is', 'there', 'a', 'good', 'book', 'to', 'practice', 'sas', 'sqlmacroarrays', 'concepts', 'with', 'examples', 'having', 'sas', 'problems', 'and', 'solutions', 'can', 'anyone', 'please', 'suggest']",0,"['is', 'there', 'a', 'good', 'book', 'to', 'practice', 'sa', 'sqlmacroarrays', 'concept', 'with', 'example', 'having', 'sa', 'problem', 'and', 'solution', 'can', 'anyone', 'please', 'suggest']","['good', 'book', 'practice', 'sa', 'sqlmacroarrays', 'concept', 'example', 'sa', 'problem', 'solution', 'anyone', 'please', 'suggest']",good book practice sa sqlmacroarrays concept example sa problem solution anyone please suggest,0.7,0.7,21,94,4.2727272727272725,0,0,0,0,0,0,0,0
1874,certification in r,Career,certification in r,"['certification', 'in', 'r']",0,"['certification', 'in', 'r']","['certification', 'r']",certification r,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
1875,combining two targets variable together to find out the optimal range between two,Techniques,combining two targets variable together to find out the optimal range between two,"['combining', 'two', 'targets', 'variable', 'together', 'to', 'find', 'out', 'the', 'optimal', 'range', 'between', 'two']",0,"['combining', 'two', 'target', 'variable', 'together', 'to', 'find', 'out', 'the', 'optimal', 'range', 'between', 'two']","['combining', 'two', 'target', 'variable', 'together', 'find', 'optimal', 'range', 'two']",combining two target variable together find optimal range two,0.0,0.0,13,61,4.357142857142857,0,0,0,0,0,0,0,0
1876,need help with stratifiedshufflesplit,Techniques,need help with stratifiedshufflesplit,"['need', 'help', 'with', 'stratifiedshufflesplit']",0,"['need', 'help', 'with', 'stratifiedshufflesplit']","['need', 'help', 'stratifiedshufflesplit']",need help stratifiedshufflesplit,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
1877,calculating conditional probabilities among all columns in a data frame,Techniques,calculating conditional probabilities among all columns in a data frame,"['calculating', 'conditional', 'probabilities', 'among', 'all', 'columns', 'in', 'a', 'data', 'frame']",0,"['calculating', 'conditional', 'probability', 'among', 'all', 'column', 'in', 'a', 'data', 'frame']","['calculating', 'conditional', 'probability', 'among', 'column', 'data', 'frame']",calculating conditional probability among column data frame,0.0,0.0,10,59,5.363636363636363,0,0,0,0,0,0,0,0
1878,knoctober related question  comprehending healthcampdetailcsv file,Hackathons,knoctober related question  comprehending healthcampdetailcsv file,"['knoctober', 'related', 'question', 'comprehending', 'healthcampdetailcsv', 'file']",0,"['knoctober', 'related', 'question', 'comprehending', 'healthcampdetailcsv', 'file']","['knoctober', 'related', 'question', 'comprehending', 'healthcampdetailcsv', 'file']",knoctober related question comprehending healthcampdetailcsv file,0.0,0.0,6,65,9.285714285714286,0,0,0,0,0,0,0,0
1879,why does the matrix have to be symmetric while applying svd,Techniques,why does the matrix have to be symmetric while applying svd,"['why', 'does', 'the', 'matrix', 'have', 'to', 'be', 'symmetric', 'while', 'applying', 'svd']",0,"['why', 'doe', 'the', 'matrix', 'have', 'to', 'be', 'symmetric', 'while', 'applying', 'svd']","['doe', 'matrix', 'symmetric', 'applying', 'svd']",doe matrix symmetric applying svd,0.0,0.0,11,33,2.75,0,0,0,0,0,0,0,0
1880,regression analysis wrong predictions help appreciated full analysis included  very useful for beginners,Techniques,regression analysis wrong predictions help appreciated full analysis included  very useful for beginners,"['regression', 'analysis', 'wrong', 'predictions', 'help', 'appreciated', 'full', 'analysis', 'included', 'very', 'useful', 'for', 'beginners']",0,"['regression', 'analysis', 'wrong', 'prediction', 'help', 'appreciated', 'full', 'analysis', 'included', 'very', 'useful', 'for', 'beginner']","['regression', 'analysis', 'wrong', 'prediction', 'help', 'appreciated', 'full', 'analysis', 'included', 'useful', 'beginner']",regression analysis wrong prediction help appreciated full analysis included useful beginner,0.11,0.0875,13,92,6.571428571428571,0,0,0,0,0,0,0,0
1881,how to run r on jupyter ipython notebooks,Tools,how to run r on jupyter ipython notebooks,"['how', 'to', 'run', 'r', 'on', 'jupyter', 'ipython', 'notebooks']",0,"['how', 'to', 'run', 'r', 'on', 'jupyter', 'ipython', 'notebook']","['run', 'r', 'jupyter', 'ipython', 'notebook']",run r jupyter ipython notebook,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
1882,how to predict buyers propensity for different product at user lable,Techniques,how to predict buyers propensity for different product at user lable,"['how', 'to', 'predict', 'buyers', 'propensity', 'for', 'different', 'product', 'at', 'user', 'lable']",0,"['how', 'to', 'predict', 'buyer', 'propensity', 'for', 'different', 'product', 'at', 'user', 'lable']","['predict', 'buyer', 'propensity', 'different', 'product', 'user', 'lable']",predict buyer propensity different product user lable,0.0,0.0,11,53,4.416666666666667,0,0,0,0,0,0,0,0
1883,python error incompatible indexer with series,Tools,python error incompatible indexer with series,"['python', 'error', 'incompatible', 'indexer', 'with', 'series']",0,"['python', 'error', 'incompatible', 'indexer', 'with', 'series']","['python', 'error', 'incompatible', 'indexer', 'series']",python error incompatible indexer series,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
1884,video explanation of svd,Resources,video explanation of svd,"['video', 'explanation', 'of', 'svd']",0,"['video', 'explanation', 'of', 'svd']","['video', 'explanation', 'svd']",video explanation svd,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
1885,what kind of answers can we find in the analysis of google analytics and facebook ads data,Techniques,what kind of answers can we find in the analysis of google analytics and facebook ads data,"['what', 'kind', 'of', 'answers', 'can', 'we', 'find', 'in', 'the', 'analysis', 'of', 'google', 'analytics', 'and', 'facebook', 'ads', 'data']",0,"['what', 'kind', 'of', 'answer', 'can', 'we', 'find', 'in', 'the', 'analysis', 'of', 'google', 'analytics', 'and', 'facebook', 'ad', 'data']","['kind', 'answer', 'find', 'analysis', 'google', 'analytics', 'facebook', 'ad', 'data']",kind answer find analysis google analytics facebook ad data,0.6,0.6,17,59,3.2777777777777777,0,0,0,0,0,0,0,0
1886,explain the argv function in python,Tools,explain the argv function in python,"['explain', 'the', 'argv', 'function', 'in', 'python']",0,"['explain', 'the', 'argv', 'function', 'in', 'python']","['explain', 'argv', 'function', 'python']",explain argv function python,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
1887,what are supply chain problems,Techniques,what are supply chain problems,"['what', 'are', 'supply', 'chain', 'problems']",0,"['what', 'are', 'supply', 'chain', 'problem']","['supply', 'chain', 'problem']",supply chain problem,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
1888,r doubt and sentiment analysis,Tools,r doubt and sentiment analysis,"['r', 'doubt', 'and', 'sentiment', 'analysis']",0,"['r', 'doubt', 'and', 'sentiment', 'analysis']","['r', 'doubt', 'sentiment', 'analysis']",r doubt sentiment analysis,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
1889,handling categorical variables in regression models,Techniques,handling categorical variables in regression models,"['handling', 'categorical', 'variables', 'in', 'regression', 'models']",0,"['handling', 'categorical', 'variable', 'in', 'regression', 'model']","['handling', 'categorical', 'variable', 'regression', 'model']",handling categorical variable regression model,0.0,0.0,6,46,6.571428571428571,0,0,0,0,0,0,0,0
1890,can some one help in python  mins code test  coding questions,Resources,can some one help in python  mins code test  coding questions,"['can', 'some', 'one', 'help', 'in', 'python', 'mins', 'code', 'test', 'coding', 'questions']",2,"['can', 'some', 'one', 'help', 'in', 'python', 'min', 'code', 'test', 'coding', 'question']","['one', 'help', 'python', 'min', 'code', 'test', 'coding', 'question']",one help python min code test coding question,0.0,0.0,11,45,3.75,0,0,0,0,0,0,0,0
1891,which business analytics program is better  sp jains business analytics program or misb bocconis,Career,which business analytics program is better  sp jains business analytics program or misb bocconis,"['which', 'business', 'analytics', 'program', 'is', 'better', 'sp', 'jains', 'business', 'analytics', 'program', 'or', 'misb', 'bocconis']",0,"['which', 'business', 'analytics', 'program', 'is', 'better', 'sp', 'jains', 'business', 'analytics', 'program', 'or', 'misb', 'bocconis']","['business', 'analytics', 'program', 'better', 'sp', 'jains', 'business', 'analytics', 'program', 'misb', 'bocconis']",business analytics program better sp jains business analytics program misb bocconis,0.5,0.5,14,83,5.533333333333333,0,0,0,0,0,0,0,0
1892,which classification algorithm should be selected for boosting,Techniques,which classification algorithm should be selected for boosting,"['which', 'classification', 'algorithm', 'should', 'be', 'selected', 'for', 'boosting']",0,"['which', 'classification', 'algorithm', 'should', 'be', 'selected', 'for', 'boosting']","['classification', 'algorithm', 'selected', 'boosting']",classification algorithm selected boosting,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
1893,beginner in python,Tools,beginner in python,"['beginner', 'in', 'python']",0,"['beginner', 'in', 'python']","['beginner', 'python']",beginner python,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
1894,multi class text classification,Techniques,multi class text classification,"['multi', 'class', 'text', 'classification']",0,"['multi', 'class', 'text', 'classification']","['multi', 'class', 'text', 'classification']",multi class text classification,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
1895,the strategic monk solution,Hackathons,the strategic monk solution,"['the', 'strategic', 'monk', 'solution']",0,"['the', 'strategic', 'monk', 'solution']","['strategic', 'monk', 'solution']",strategic monk solution,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
1896,error in rose package r,Techniques,error in rose package r,"['error', 'in', 'rose', 'package', 'r']",0,"['error', 'in', 'rose', 'package', 'r']","['error', 'rose', 'package', 'r']",error rose package r,0.6,0.6,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
1897,varrank package r,Techniques,varrank package r,"['varrank', 'package', 'r']",0,"['varrank', 'package', 'r']","['varrank', 'package', 'r']",varrank package r,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
1898,error in calculating mean using sqldf package in r,Tools,error in calculating mean using sqldf package in r,"['error', 'in', 'calculating', 'mean', 'using', 'sqldf', 'package', 'in', 'r']",0,"['error', 'in', 'calculating', 'mean', 'using', 'sqldf', 'package', 'in', 'r']","['error', 'calculating', 'mean', 'using', 'sqldf', 'package', 'r']",error calculating mean using sqldf package r,-0.3125,-0.3125,9,44,4.4,0,0,0,0,0,0,0,0
1899,help with the must read books for qlikview for beginner,Tools,help with the must read books for qlikview for beginner,"['help', 'with', 'the', 'must', 'read', 'books', 'for', 'qlikview', 'for', 'beginner']",0,"['help', 'with', 'the', 'must', 'read', 'book', 'for', 'qlikview', 'for', 'beginner']","['help', 'must', 'read', 'book', 'qlikview', 'beginner']",help must read book qlikview beginner,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
1900,minimum sample size for multinomial classifier,Techniques,minimum sample size for multinomial classifier,"['minimum', 'sample', 'size', 'for', 'multinomial', 'classifier']",0,"['minimum', 'sample', 'size', 'for', 'multinomial', 'classifier']","['minimum', 'sample', 'size', 'multinomial', 'classifier']",minimum sample size multinomial classifier,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
1901,error while importing xlsx file from url using the xlsx package in r,Tools,error while importing xlsx file from url using the xlsx package in r,"['error', 'while', 'importing', 'xlsx', 'file', 'from', 'url', 'using', 'the', 'xlsx', 'package', 'in', 'r']",0,"['error', 'while', 'importing', 'xlsx', 'file', 'from', 'url', 'using', 'the', 'xlsx', 'package', 'in', 'r']","['error', 'importing', 'xlsx', 'file', 'url', 'using', 'xlsx', 'package', 'r']",error importing xlsx file url using xlsx package r,0.0,0.0,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
1902,shiny app scrolling list in fvizcontrib,Other,shiny app scrolling list in fvizcontrib,"['shiny', 'app', 'scrolling', 'list', 'in', 'fvizcontrib']",0,"['shiny', 'app', 'scrolling', 'list', 'in', 'fvizcontrib']","['shiny', 'app', 'scrolling', 'list', 'fvizcontrib']",shiny app scrolling list fvizcontrib,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
1903,is ms in data science a really good option for a cs student in aspect of job opportunities in tech firms,Career,is ms in data science a really good option for a cs student in aspect of job opportunities in tech firms,"['is', 'ms', 'in', 'data', 'science', 'a', 'really', 'good', 'option', 'for', 'a', 'cs', 'student', 'in', 'aspect', 'of', 'job', 'opportunities', 'in', 'tech', 'firms']",0,"['is', 'm', 'in', 'data', 'science', 'a', 'really', 'good', 'option', 'for', 'a', 'c', 'student', 'in', 'aspect', 'of', 'job', 'opportunity', 'in', 'tech', 'firm']","['data', 'science', 'really', 'good', 'option', 'c', 'student', 'aspect', 'job', 'opportunity', 'tech', 'firm']",data science really good option c student aspect job opportunity tech firm,0.7,0.2499999999999999,21,74,3.3636363636363638,0,0,0,0,0,0,0,0
1904,getting an error error in dist  humidity  comparison  is possible only for atomic and list types while creating a shiny web app in r,Tools,getting an error error in dist  humidity  comparison  is possible only for atomic and list types while creating a shiny web app in r,"['getting', 'an', 'error', 'error', 'in', 'dist', 'humidity', 'comparison', 'is', 'possible', 'only', 'for', 'atomic', 'and', 'list', 'types', 'while', 'creating', 'a', 'shiny', 'web', 'app', 'in', 'r']",1,"['getting', 'an', 'error', 'error', 'in', 'dist', 'humidity', 'comparison', 'is', 'possible', 'only', 'for', 'atomic', 'and', 'list', 'type', 'while', 'creating', 'a', 'shiny', 'web', 'app', 'in', 'r']","['getting', 'error', 'error', 'dist', 'humidity', 'comparison', 'possible', 'atomic', 'list', 'type', 'creating', 'shiny', 'web', 'app', 'r']",getting error error dist humidity comparison possible atomic list type creating shiny web app r,0.0,0.0,24,95,3.8,0,0,0,0,0,0,0,0
1905,how to map values using  columns,Hackathons,how to map values using  columns,"['how', 'to', 'map', 'values', 'using', 'columns']",1,"['how', 'to', 'map', 'value', 'using', 'column']","['map', 'value', 'using', 'column']",map value using column,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
1906,resources for data preparation requested,Techniques,resources for data preparation requested,"['resources', 'for', 'data', 'preparation', 'requested']",0,"['resource', 'for', 'data', 'preparation', 'requested']","['resource', 'data', 'preparation', 'requested']",resource data preparation requested,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
1907,how to leverage linkedin data for companyposition analysis,Career,how to leverage linkedin data for companyposition analysis,"['how', 'to', 'leverage', 'linkedin', 'data', 'for', 'companyposition', 'analysis']",0,"['how', 'to', 'leverage', 'linkedin', 'data', 'for', 'companyposition', 'analysis']","['leverage', 'linkedin', 'data', 'companyposition', 'analysis']",leverage linkedin data companyposition analysis,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
1908,hyperparameter tuning,Techniques,hyperparameter tuning,"['hyperparameter', 'tuning']",0,"['hyperparameter', 'tuning']","['hyperparameter', 'tuning']",hyperparameter tuning,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
1909,how to cluster big data in r with mixed variables,Tools,how to cluster big data in r with mixed variables,"['how', 'to', 'cluster', 'big', 'data', 'in', 'r', 'with', 'mixed', 'variables']",0,"['how', 'to', 'cluster', 'big', 'data', 'in', 'r', 'with', 'mixed', 'variable']","['cluster', 'big', 'data', 'r', 'mixed', 'variable']",cluster big data r mixed variable,0.0,0.0,10,33,3.0,0,0,0,0,0,0,0,0
1910,scoring param does not available in linear regression,Hackathons,scoring param does not available in linear regression,"['scoring', 'param', 'does', 'not', 'available', 'in', 'linear', 'regression']",0,"['scoring', 'param', 'doe', 'not', 'available', 'in', 'linear', 'regression']","['scoring', 'param', 'doe', 'available', 'linear', 'regression']",scoring param doe available linear regression,-0.2,0.4,8,45,5.0,0,0,0,0,0,0,0,0
1911,dataframe rearrangement in r,Tools,dataframe rearrangement in r,"['dataframe', 'rearrangement', 'in', 'r']",0,"['dataframe', 'rearrangement', 'in', 'r']","['dataframe', 'rearrangement', 'r']",dataframe rearrangement r,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
1912,first and second transaction dates using r from transaction table,Tools,first and second transaction dates using r from transaction table,"['first', 'and', 'second', 'transaction', 'dates', 'using', 'r', 'from', 'transaction', 'table']",0,"['first', 'and', 'second', 'transaction', 'date', 'using', 'r', 'from', 'transaction', 'table']","['first', 'second', 'transaction', 'date', 'using', 'r', 'transaction', 'table']",first second transaction date using r transaction table,0.125,0.125,10,55,5.0,0,0,0,0,0,0,0,0
1913,what is more valuable  pg in business analytics or execmba,Career,what is more valuable  pg in business analytics or execmba,"['what', 'is', 'more', 'valuable', 'pg', 'in', 'business', 'analytics', 'or', 'execmba']",0,"['what', 'is', 'more', 'valuable', 'pg', 'in', 'business', 'analytics', 'or', 'execmba']","['valuable', 'pg', 'business', 'analytics', 'execmba']",valuable pg business analytics execmba,0.5,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
1914,any suggestions on how to measure the success of email campaigns,Techniques,any suggestions on how to measure the success of email campaigns,"['any', 'suggestions', 'on', 'how', 'to', 'measure', 'the', 'success', 'of', 'email', 'campaigns']",0,"['any', 'suggestion', 'on', 'how', 'to', 'measure', 'the', 'success', 'of', 'email', 'campaign']","['suggestion', 'measure', 'success', 'email', 'campaign']",suggestion measure success email campaign,0.3,0.3,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
1915,downsizing images in object detection,Techniques,downsizing images in object detection,"['downsizing', 'images', 'in', 'object', 'detection']",0,"['downsizing', 'image', 'in', 'object', 'detection']","['downsizing', 'image', 'object', 'detection']",downsizing image object detection,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
1916,dataset for beginners guide on logistic regression in r,Resources,dataset for beginners guide on logistic regression in r,"['dataset', 'for', 'beginners', 'guide', 'on', 'logistic', 'regression', 'in', 'r']",0,"['dataset', 'for', 'beginner', 'guide', 'on', 'logistic', 'regression', 'in', 'r']","['dataset', 'beginner', 'guide', 'logistic', 'regression', 'r']",dataset beginner guide logistic regression r,0.0,0.0,9,44,4.4,0,0,0,0,0,0,0,0
1917,r shiny developer demand in india,Tools,r shiny developer demand in india,"['r', 'shiny', 'developer', 'demand', 'in', 'india']",0,"['r', 'shiny', 'developer', 'demand', 'in', 'india']","['r', 'shiny', 'developer', 'demand', 'india']",r shiny developer demand india,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
1918,data visualization for investment decision,Other,data visualization for investment decision,"['data', 'visualization', 'for', 'investment', 'decision']",0,"['data', 'visualization', 'for', 'investment', 'decision']","['data', 'visualization', 'investment', 'decision']",data visualization investment decision,0.0,0.0,5,38,6.333333333333333,0,0,0,0,0,0,0,0
1919,adaptive batch normalization,Techniques,adaptive batch normalization,"['adaptive', 'batch', 'normalization']",0,"['adaptive', 'batch', 'normalization']","['adaptive', 'batch', 'normalization']",adaptive batch normalization,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
1920,difference between various sas certifications and their uses,Tools,difference between various sas certifications and their uses,"['difference', 'between', 'various', 'sas', 'certifications', 'and', 'their', 'uses']",0,"['difference', 'between', 'various', 'sa', 'certification', 'and', 'their', 'us']","['difference', 'various', 'sa', 'certification', 'us']",difference various sa certification us,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
1921,data science interviewapplication question help,Career,data science interviewapplication question help,"['data', 'science', 'interviewapplication', 'question', 'help']",0,"['data', 'science', 'interviewapplication', 'question', 'help']","['data', 'science', 'interviewapplication', 'question', 'help']",data science interviewapplication question help,0.0,0.0,5,47,7.833333333333333,0,0,0,0,0,0,0,0
1922,what should i consider while adding or deleting features,Techniques,what should i consider while adding or deleting features,"['what', 'should', 'i', 'consider', 'while', 'adding', 'or', 'deleting', 'features']",0,"['what', 'should', 'i', 'consider', 'while', 'adding', 'or', 'deleting', 'feature']","['consider', 'adding', 'deleting', 'feature']",consider adding deleting feature,0.0,0.0,9,32,3.2,0,0,0,0,0,0,0,0
1923,error in sortlisty  x must be atomic for sortlist,Techniques,error in sortlisty  x must be atomic for sortlist,"['error', 'in', 'sortlisty', 'x', 'must', 'be', 'atomic', 'for', 'sortlist']",0,"['error', 'in', 'sortlisty', 'x', 'must', 'be', 'atomic', 'for', 'sortlist']","['error', 'sortlisty', 'x', 'must', 'atomic', 'sortlist']",error sortlisty x must atomic sortlist,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
1924,what is z value and prz in logistic regression,Techniques,what is z value and prz in logistic regression,"['what', 'is', 'z', 'value', 'and', 'prz', 'in', 'logistic', 'regression']",0,"['what', 'is', 'z', 'value', 'and', 'prz', 'in', 'logistic', 'regression']","['z', 'value', 'prz', 'logistic', 'regression']",z value prz logistic regression,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
1925,discussions for article a complete tutorial on tree based modeling from scratch in r  python,Other,discussions for article a complete tutorial on tree based modeling from scratch in r  python,"['discussions', 'for', 'article', 'a', 'complete', 'tutorial', 'on', 'tree', 'based', 'modeling', 'from', 'scratch', 'in', 'r', 'python']",0,"['discussion', 'for', 'article', 'a', 'complete', 'tutorial', 'on', 'tree', 'based', 'modeling', 'from', 'scratch', 'in', 'r', 'python']","['discussion', 'article', 'complete', 'tutorial', 'tree', 'based', 'modeling', 'scratch', 'r', 'python']",discussion article complete tutorial tree based modeling scratch r python,0.1,0.1,15,73,4.5625,0,0,0,0,0,0,0,0
1926,need r c c code to build a dataset like table   r would be prefered ,Techniques,need r c c code to build a dataset like table   r would be prefered ,"['need', 'r', 'c', 'c', 'code', 'to', 'build', 'a', 'dataset', 'like', 'table', 'r', 'would', 'be', 'prefered']",1,"['need', 'r', 'c', 'c', 'code', 'to', 'build', 'a', 'dataset', 'like', 'table', 'r', 'would', 'be', 'prefered']","['need', 'r', 'c', 'c', 'code', 'build', 'dataset', 'like', 'table', 'r', 'would', 'prefered']",need r c c code build dataset like table r would prefered,0.0,0.0,15,57,3.5625,0,0,0,0,0,0,0,0
1927,big data and analytics full time course in india,Career,big data and analytics full time course in india,"['big', 'data', 'and', 'analytics', 'full', 'time', 'course', 'in', 'india']",0,"['big', 'data', 'and', 'analytics', 'full', 'time', 'course', 'in', 'india']","['big', 'data', 'analytics', 'full', 'time', 'course', 'india']",big data analytics full time course india,0.175,0.175,9,41,4.1,0,0,0,0,0,0,0,0
1928,how to extract total content from a blog and across the whole website using importio,Tools,how to extract total content from a blog and across the whole website using importio,"['how', 'to', 'extract', 'total', 'content', 'from', 'a', 'blog', 'and', 'across', 'the', 'whole', 'website', 'using', 'importio']",0,"['how', 'to', 'extract', 'total', 'content', 'from', 'a', 'blog', 'and', 'across', 'the', 'whole', 'website', 'using', 'importio']","['extract', 'total', 'content', 'blog', 'across', 'whole', 'website', 'using', 'importio']",extract total content blog across whole website using importio,0.1,0.1,15,62,3.875,0,0,0,0,0,0,0,0
1929,why different classifier behaves differently for different data,Techniques,why different classifier behaves differently for different data,"['why', 'different', 'classifier', 'behaves', 'differently', 'for', 'different', 'data']",0,"['why', 'different', 'classifier', 'behaves', 'differently', 'for', 'different', 'data']","['different', 'classifier', 'behaves', 'differently', 'different', 'data']",different classifier behaves differently different data,0.0,0.0,8,55,6.111111111111111,0,0,0,0,0,0,0,0
1930,how to make a plot with axes at the centre in r,Tools,how to make a plot with axes at the centre in r,"['how', 'to', 'make', 'a', 'plot', 'with', 'axes', 'at', 'the', 'centre', 'in', 'r']",0,"['how', 'to', 'make', 'a', 'plot', 'with', 'ax', 'at', 'the', 'centre', 'in', 'r']","['make', 'plot', 'ax', 'centre', 'r']",make plot ax centre r,0.0,0.0,12,21,1.6153846153846154,0,0,0,0,0,0,0,0
1931,linear regression in r  coefficients having na in summarymodel,Tools,linear regression in r  coefficients having na in summarymodel,"['linear', 'regression', 'in', 'r', 'coefficients', 'having', 'na', 'in', 'summarymodel']",0,"['linear', 'regression', 'in', 'r', 'coefficient', 'having', 'na', 'in', 'summarymodel']","['linear', 'regression', 'r', 'coefficient', 'na', 'summarymodel']",linear regression r coefficient na summarymodel,0.0,0.0,9,47,4.7,0,0,0,0,0,0,0,0
1932,best tool for text mining image processingvideo analysis,Techniques,best tool for text mining image processingvideo analysis,"['best', 'tool', 'for', 'text', 'mining', 'image', 'processingvideo', 'analysis']",0,"['best', 'tool', 'for', 'text', 'mining', 'image', 'processingvideo', 'analysis']","['best', 'tool', 'text', 'mining', 'image', 'processingvideo', 'analysis']",best tool text mining image processingvideo analysis,1.0,1.0,8,52,5.777777777777778,0,0,0,0,0,0,0,0
1933,why ordinal variable can not be converted into a quantitative variable,Techniques,why ordinal variable can not be converted into a quantitative variable,"['why', 'ordinal', 'variable', 'can', 'not', 'be', 'converted', 'into', 'a', 'quantitative', 'variable']",0,"['why', 'ordinal', 'variable', 'can', 'not', 'be', 'converted', 'into', 'a', 'quantitative', 'variable']","['ordinal', 'variable', 'converted', 'quantitative', 'variable']",ordinal variable converted quantitative variable,0.0,0.0,11,48,4.0,0,0,0,0,0,0,0,0
1934,career in analytics for experienced professionals,Career,career in analytics for experienced professionals,"['career', 'in', 'analytics', 'for', 'experienced', 'professionals']",0,"['career', 'in', 'analytics', 'for', 'experienced', 'professional']","['career', 'analytics', 'experienced', 'professional']",career analytics experienced professional,0.8,0.45,6,41,5.857142857142857,0,0,0,0,0,0,0,0
1935,how the right dashboard software will benefit your business in ,Resources,how the right dashboard software will benefit your business in ,"['how', 'the', 'right', 'dashboard', 'software', 'will', 'benefit', 'your', 'business', 'in']",1,"['how', 'the', 'right', 'dashboard', 'software', 'will', 'benefit', 'your', 'business', 'in']","['right', 'dashboard', 'software', 'benefit', 'business']",right dashboard software benefit business,0.2857142857142857,0.2857142857142857,10,41,3.727272727272727,0,0,0,0,0,0,0,0
1936,black friday hackathon  not able to run even lm algorithm due to memory constraint,Hackathons,black friday hackathon  not able to run even lm algorithm due to memory constraint,"['black', 'friday', 'hackathon', 'not', 'able', 'to', 'run', 'even', 'lm', 'algorithm', 'due', 'to', 'memory', 'constraint']",0,"['black', 'friday', 'hackathon', 'not', 'able', 'to', 'run', 'even', 'lm', 'algorithm', 'due', 'to', 'memory', 'constraint']","['black', 'friday', 'hackathon', 'able', 'run', 'even', 'lm', 'algorithm', 'due', 'memory', 'constraint']",black friday hackathon able run even lm algorithm due memory constraint,-0.1805555555555555,0.0694444444444444,14,71,4.733333333333333,0,0,0,0,0,0,0,0
1937,increase submission time,Hackathons,increase submission time,"['increase', 'submission', 'time']",0,"['increase', 'submission', 'time']","['increase', 'submission', 'time']",increase submission time,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
1938,which measure gives the appropriate answer,Tools,which measure gives the appropriate answer,"['which', 'measure', 'gives', 'the', 'appropriate', 'answer']",0,"['which', 'measure', 'give', 'the', 'appropriate', 'answer']","['measure', 'give', 'appropriate', 'answer']",measure give appropriate answer,0.5,0.5,6,31,4.428571428571429,0,0,0,0,0,0,0,0
1939,how to add regression line to the given scatter plot in r,Techniques,how to add regression line to the given scatter plot in r,"['how', 'to', 'add', 'regression', 'line', 'to', 'the', 'given', 'scatter', 'plot', 'in', 'r']",0,"['how', 'to', 'add', 'regression', 'line', 'to', 'the', 'given', 'scatter', 'plot', 'in', 'r']","['add', 'regression', 'line', 'given', 'scatter', 'plot', 'r']",add regression line given scatter plot r,0.0,0.0,12,40,3.076923076923077,0,0,0,0,0,0,0,0
1940,how to become a data scienceanalytics blogger,Career,how to become a data scienceanalytics blogger,"['how', 'to', 'become', 'a', 'data', 'scienceanalytics', 'blogger']",0,"['how', 'to', 'become', 'a', 'data', 'scienceanalytics', 'blogger']","['become', 'data', 'scienceanalytics', 'blogger']",become data scienceanalytics blogger,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
1941, practice problem loan prediction,Hackathons, practice problem loan prediction,"['practice', 'problem', 'loan', 'prediction']",0,"['practice', 'problem', 'loan', 'prediction']","['practice', 'problem', 'loan', 'prediction']",practice problem loan prediction,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
1942,need help in increasing accuracy no class,Other,need help in increasing accuracy no class,"['need', 'help', 'in', 'increasing', 'accuracy', 'no', 'class']",0,"['need', 'help', 'in', 'increasing', 'accuracy', 'no', 'class']","['need', 'help', 'increasing', 'accuracy', 'class']",need help increasing accuracy class,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
1943,opinions required on iim c  executive program in business analytics,Career,opinions required on iim c  executive program in business analytics,"['opinions', 'required', 'on', 'iim', 'c', 'executive', 'program', 'in', 'business', 'analytics']",0,"['opinion', 'required', 'on', 'iim', 'c', 'executive', 'program', 'in', 'business', 'analytics']","['opinion', 'required', 'iim', 'c', 'executive', 'program', 'business', 'analytics']",opinion required iim c executive program business analytics,0.0,0.0,10,59,5.363636363636363,0,0,0,0,0,0,0,0
1944,knowledge of data structures,Career,knowledge of data structures,"['knowledge', 'of', 'data', 'structures']",0,"['knowledge', 'of', 'data', 'structure']","['knowledge', 'data', 'structure']",knowledge data structure,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
1945,implement neural network using tensorflow unboundlocalerror,Techniques,implement neural network using tensorflow unboundlocalerror,"['implement', 'neural', 'network', 'using', 'tensorflow', 'unboundlocalerror']",0,"['implement', 'neural', 'network', 'using', 'tensorflow', 'unboundlocalerror']","['implement', 'neural', 'network', 'using', 'tensorflow', 'unboundlocalerror']",implement neural network using tensorflow unboundlocalerror,0.0,0.0,6,59,8.428571428571429,0,0,0,0,0,0,0,0
1946,big mart sales datasets,Resources,big mart sales datasets,"['big', 'mart', 'sales', 'datasets']",0,"['big', 'mart', 'sale', 'datasets']","['big', 'mart', 'sale', 'datasets']",big mart sale datasets,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
1947,when i submit answer my score didnt show,Hackathons,when i submit answer my score didnt show,"['when', 'i', 'submit', 'answer', 'my', 'score', 'didnt', 'show']",0,"['when', 'i', 'submit', 'answer', 'my', 'score', 'didnt', 'show']","['submit', 'answer', 'score', 'didnt', 'show']",submit answer score didnt show,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
1948,relative importance of independent variables,Techniques,relative importance of independent variables,"['relative', 'importance', 'of', 'independent', 'variables']",0,"['relative', 'importance', 'of', 'independent', 'variable']","['relative', 'importance', 'independent', 'variable']",relative importance independent variable,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
1949,a general info about jupyter notebook,Tools,a general info about jupyter notebook,"['a', 'general', 'info', 'about', 'jupyter', 'notebook']",0,"['a', 'general', 'info', 'about', 'jupyter', 'notebook']","['general', 'info', 'jupyter', 'notebook']",general info jupyter notebook,0.05,0.05,6,29,4.142857142857143,0,0,0,0,0,0,0,0
1950,why it is necessary to standardize the data in pca,Techniques,why it is necessary to standardize the data in pca,"['why', 'it', 'is', 'necessary', 'to', 'standardize', 'the', 'data', 'in', 'pca']",0,"['why', 'it', 'is', 'necessary', 'to', 'standardize', 'the', 'data', 'in', 'pca']","['necessary', 'standardize', 'data', 'pca']",necessary standardize data pca,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
1951,object detection and not using transfer learning,Techniques,object detection and not using transfer learning,"['object', 'detection', 'and', 'not', 'using', 'transfer', 'learning']",0,"['object', 'detection', 'and', 'not', 'using', 'transfer', 'learning']","['object', 'detection', 'using', 'transfer', 'learning']",object detection using transfer learning,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
1952,how to interpret the scatterplot matrix in r,Tools,how to interpret the scatterplot matrix in r,"['how', 'to', 'interpret', 'the', 'scatterplot', 'matrix', 'in', 'r']",0,"['how', 'to', 'interpret', 'the', 'scatterplot', 'matrix', 'in', 'r']","['interpret', 'scatterplot', 'matrix', 'r']",interpret scatterplot matrix r,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
1953,big data analytics in ecommerce industry,Techniques,big data analytics in ecommerce industry,"['big', 'data', 'analytics', 'in', 'ecommerce', 'industry']",0,"['big', 'data', 'analytics', 'in', 'ecommerce', 'industry']","['big', 'data', 'analytics', 'ecommerce', 'industry']",big data analytics ecommerce industry,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
1954,can you recommend some good communities for big data,Techniques,can you recommend some good communities for big data,"['can', 'you', 'recommend', 'some', 'good', 'communities', 'for', 'big', 'data']",0,"['can', 'you', 'recommend', 'some', 'good', 'community', 'for', 'big', 'data']","['recommend', 'good', 'community', 'big', 'data']",recommend good community big data,0.35,0.35,9,33,3.3,0,0,0,0,0,0,0,0
1955,unable to download train dataintel scene classification challenge,Hackathons,unable to download train dataintel scene classification challenge,"['unable', 'to', 'download', 'train', 'dataintel', 'scene', 'classification', 'challenge']",0,"['unable', 'to', 'download', 'train', 'dataintel', 'scene', 'classification', 'challenge']","['unable', 'download', 'train', 'dataintel', 'scene', 'classification', 'challenge']",unable download train dataintel scene classification challenge,-0.5,-0.5,8,62,6.888888888888889,0,0,0,0,0,0,0,0
1956,how to replace values of all variables in a sas data set,Tools,how to replace values of all variables in a sas data set,"['how', 'to', 'replace', 'values', 'of', 'all', 'variables', 'in', 'a', 'sas', 'data', 'set']",0,"['how', 'to', 'replace', 'value', 'of', 'all', 'variable', 'in', 'a', 'sa', 'data', 'set']","['replace', 'value', 'variable', 'sa', 'data', 'set']",replace value variable sa data set,0.0,0.0,12,34,2.6153846153846154,0,0,0,0,0,0,0,0
1957,what does the shrinkage option in gbm do,Techniques,what does the shrinkage option in gbm do,"['what', 'does', 'the', 'shrinkage', 'option', 'in', 'gbm', 'do']",0,"['what', 'doe', 'the', 'shrinkage', 'option', 'in', 'gbm', 'do']","['doe', 'shrinkage', 'option', 'gbm']",doe shrinkage option gbm,0.0,0.0,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
1958,how is the data divided into splits in decision tree algorithm,Techniques,how is the data divided into splits in decision tree algorithm,"['how', 'is', 'the', 'data', 'divided', 'into', 'splits', 'in', 'decision', 'tree', 'algorithm']",0,"['how', 'is', 'the', 'data', 'divided', 'into', 'split', 'in', 'decision', 'tree', 'algorithm']","['data', 'divided', 'split', 'decision', 'tree', 'algorithm']",data divided split decision tree algorithm,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
1959,pca on binary dataset,Techniques,pca on binary dataset,"['pca', 'on', 'binary', 'dataset']",0,"['pca', 'on', 'binary', 'dataset']","['pca', 'binary', 'dataset']",pca binary dataset,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
1960,how to get a data scientist job outside chennai,Career,how to get a data scientist job outside chennai,"['how', 'to', 'get', 'a', 'data', 'scientist', 'job', 'outside', 'chennai']",0,"['how', 'to', 'get', 'a', 'data', 'scientist', 'job', 'outside', 'chennai']","['get', 'data', 'scientist', 'job', 'outside', 'chennai']",get data scientist job outside chennai,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
1961,what is a bzip file and how do i open a bzip file in r,Tools,what is a bzip file and how do i open a bzip file in r,"['what', 'is', 'a', 'bzip', 'file', 'and', 'how', 'do', 'i', 'open', 'a', 'bzip', 'file', 'in', 'r']",0,"['what', 'is', 'a', 'bzip', 'file', 'and', 'how', 'do', 'i', 'open', 'a', 'bzip', 'file', 'in', 'r']","['bzip', 'file', 'open', 'bzip', 'file', 'r']",bzip file open bzip file r,0.0,0.0,15,26,1.625,0,0,0,0,0,0,0,0
1962,analytics job for freshers,Career,analytics job for freshers,"['analytics', 'job', 'for', 'freshers']",0,"['analytics', 'job', 'for', 'fresher']","['analytics', 'job', 'fresher']",analytics job fresher,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
1963,find number of unique words in a string text file using python,Tools,find number of unique words in a string text file using python,"['find', 'number', 'of', 'unique', 'words', 'in', 'a', 'string', 'text', 'file', 'using', 'python']",0,"['find', 'number', 'of', 'unique', 'word', 'in', 'a', 'string', 'text', 'file', 'using', 'python']","['find', 'number', 'unique', 'word', 'string', 'text', 'file', 'using', 'python']",find number unique word string text file using python,0.375,0.375,12,53,4.076923076923077,0,0,0,0,0,0,0,0
1964,how to become a data visualization expert,Career,how to become a data visualization expert,"['how', 'to', 'become', 'a', 'data', 'visualization', 'expert']",0,"['how', 'to', 'become', 'a', 'data', 'visualization', 'expert']","['become', 'data', 'visualization', 'expert']",become data visualization expert,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
1965,classification course in  work plan,Resources,classification course in  work plan,"['classification', 'course', 'in', 'work', 'plan']",1,"['classification', 'course', 'in', 'work', 'plan']","['classification', 'course', 'work', 'plan']",classification course work plan,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
1966,cv vs repeatedcv,Techniques,cv vs repeatedcv,"['cv', 'vs', 'repeatedcv']",0,"['cv', 'v', 'repeatedcv']","['cv', 'v', 'repeatedcv']",cv v repeatedcv,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
1967,praxis in bangalore,Career,praxis in bangalore,"['praxis', 'in', 'bangalore']",0,"['praxis', 'in', 'bangalore']","['praxis', 'bangalore']",praxis bangalore,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
1968,how do we interpret hidden states in a latent markov model,Tools,how do we interpret hidden states in a latent markov model,"['how', 'do', 'we', 'interpret', 'hidden', 'states', 'in', 'a', 'latent', 'markov', 'model']",0,"['how', 'do', 'we', 'interpret', 'hidden', 'state', 'in', 'a', 'latent', 'markov', 'model']","['interpret', 'hidden', 'state', 'latent', 'markov', 'model']",interpret hidden state latent markov model,-0.1666666666666666,-0.1666666666666666,11,42,3.5,0,0,0,0,0,0,0,0
1969,unable to find the dataset,Resources,unable to find the dataset,"['unable', 'to', 'find', 'the', 'dataset']",0,"['unable', 'to', 'find', 'the', 'dataset']","['unable', 'find', 'dataset']",unable find dataset,-0.5,-0.5,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
1970, useful pandas techniques in python for data manipulation  – imputing missing files,Resources, useful pandas techniques in python for data manipulation  – imputing missing files,"['useful', 'pandas', 'techniques', 'in', 'python', 'for', 'data', 'manipulation', '–', 'imputing', 'missing', 'files']",2,"['useful', 'panda', 'technique', 'in', 'python', 'for', 'data', 'manipulation', '–', 'imputing', 'missing', 'file']","['useful', 'panda', 'technique', 'python', 'data', 'manipulation', '–', 'imputing', 'missing', 'file']",useful panda technique python data manipulation – imputing missing file,0.0499999999999999,0.0499999999999999,12,71,5.461538461538462,0,0,0,0,0,0,0,0
1971,machine performance prediction,Other,machine performance prediction,"['machine', 'performance', 'prediction']",0,"['machine', 'performance', 'prediction']","['machine', 'performance', 'prediction']",machine performance prediction,0.0,0.0,3,30,7.5,0,0,0,0,0,0,0,0
1972,how to impute missing values for a variable like gender,Hackathons,how to impute missing values for a variable like gender,"['how', 'to', 'impute', 'missing', 'values', 'for', 'a', 'variable', 'like', 'gender']",0,"['how', 'to', 'impute', 'missing', 'value', 'for', 'a', 'variable', 'like', 'gender']","['impute', 'missing', 'value', 'variable', 'like', 'gender']",impute missing value variable like gender,-0.2,-0.2,10,41,3.727272727272727,0,0,0,0,0,0,0,0
1973,analyzing the outcomes of cart random forest,Techniques,analyzing the outcomes of cart random forest,"['analyzing', 'the', 'outcomes', 'of', 'cart', 'random', 'forest']",0,"['analyzing', 'the', 'outcome', 'of', 'cart', 'random', 'forest']","['analyzing', 'outcome', 'cart', 'random', 'forest']",analyzing outcome cart random forest,-0.5,-0.5,7,36,4.5,0,0,0,0,0,0,0,0
1974,what is singularity and how to remove it,Techniques,what is singularity and how to remove it,"['what', 'is', 'singularity', 'and', 'how', 'to', 'remove', 'it']",0,"['what', 'is', 'singularity', 'and', 'how', 'to', 'remove', 'it']","['singularity', 'remove']",singularity remove,0.0,0.0,8,18,2.0,0,0,0,0,0,0,0,0
1975,should i join robosoft technologies as a data analyst with  years bond,Career,should i join robosoft technologies as a data analyst with  years bond,"['should', 'i', 'join', 'robosoft', 'technologies', 'as', 'a', 'data', 'analyst', 'with', 'years', 'bond']",1,"['should', 'i', 'join', 'robosoft', 'technology', 'a', 'a', 'data', 'analyst', 'with', 'year', 'bond']","['join', 'robosoft', 'technology', 'data', 'analyst', 'year', 'bond']",join robosoft technology data analyst year bond,0.0,0.0,12,47,3.6153846153846154,0,0,0,0,0,0,0,0
1976,applying stateoftheart nlp to earning transcripts,Resources,applying stateoftheart nlp to earning transcripts,"['applying', 'stateoftheart', 'nlp', 'to', 'earning', 'transcripts']",0,"['applying', 'stateoftheart', 'nlp', 'to', 'earning', 'transcript']","['applying', 'stateoftheart', 'nlp', 'earning', 'transcript']",applying stateoftheart nlp earning transcript,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
1977,career switch from programming in it to non technical role in analytics  data science,Career,career switch from programming in it to non technical role in analytics  data science,"['career', 'switch', 'from', 'programming', 'in', 'it', 'to', 'non', 'technical', 'role', 'in', 'analytics', 'data', 'science']",0,"['career', 'switch', 'from', 'programming', 'in', 'it', 'to', 'non', 'technical', 'role', 'in', 'analytics', 'data', 'science']","['career', 'switch', 'programming', 'non', 'technical', 'role', 'analytics', 'data', 'science']",career switch programming non technical role analytics data science,0.0,0.0,14,67,4.466666666666667,0,0,0,0,0,0,0,0
1978,crime classification problem,Misc,crime classification problem,"['crime', 'classification', 'problem']",0,"['crime', 'classification', 'problem']","['crime', 'classification', 'problem']",crime classification problem,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
1979,best online course in statistics and analytics,Career,best online course in statistics and analytics,"['best', 'online', 'course', 'in', 'statistics', 'and', 'analytics']",0,"['best', 'online', 'course', 'in', 'statistic', 'and', 'analytics']","['best', 'online', 'course', 'statistic', 'analytics']",best online course statistic analytics,1.0,1.0,7,38,4.75,0,0,0,0,0,0,0,0
1980,cooccurence matrix based on context window,Techniques,cooccurence matrix based on context window,"['cooccurence', 'matrix', 'based', 'on', 'context', 'window']",0,"['cooccurence', 'matrix', 'based', 'on', 'context', 'window']","['cooccurence', 'matrix', 'based', 'context', 'window']",cooccurence matrix based context window,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
1981,can cnn be used for nond problems,Techniques,can cnn be used for nond problems,"['can', 'cnn', 'be', 'used', 'for', 'nond', 'problems']",0,"['can', 'cnn', 'be', 'used', 'for', 'nond', 'problem']","['cnn', 'used', 'nond', 'problem']",cnn used nond problem,0.0,0.0,7,21,2.625,0,0,0,0,0,0,0,0
1982,svm  whats the criteria for tranforming data to a higher dimension,Techniques,svm  whats the criteria for tranforming data to a higher dimension,"['svm', 'whats', 'the', 'criteria', 'for', 'tranforming', 'data', 'to', 'a', 'higher', 'dimension']",0,"['svm', 'whats', 'the', 'criterion', 'for', 'tranforming', 'data', 'to', 'a', 'higher', 'dimension']","['svm', 'whats', 'criterion', 'tranforming', 'data', 'higher', 'dimension']",svm whats criterion tranforming data higher dimension,0.25,0.25,11,53,4.416666666666667,0,0,0,0,0,0,0,0
1983,machine learning repositories,Misc,machine learning repositories,"['machine', 'learning', 'repositories']",0,"['machine', 'learning', 'repository']","['machine', 'learning', 'repository']",machine learning repository,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
1984,predicting continuous variable using machine learning algorithms,Techniques,predicting continuous variable using machine learning algorithms,"['predicting', 'continuous', 'variable', 'using', 'machine', 'learning', 'algorithms']",0,"['predicting', 'continuous', 'variable', 'using', 'machine', 'learning', 'algorithm']","['predicting', 'continuous', 'variable', 'using', 'machine', 'learning', 'algorithm']",predicting continuous variable using machine learning algorithm,0.0,0.0,7,63,7.875,0,0,0,0,0,0,0,0
1985,data manipulation,Techniques,data manipulation,"['data', 'manipulation']",0,"['data', 'manipulation']","['data', 'manipulation']",data manipulation,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
1986,experiments with data  analytics workshop for beginners,Other,experiments with data  analytics workshop for beginners,"['experiments', 'with', 'data', 'analytics', 'workshop', 'for', 'beginners']",0,"['experiment', 'with', 'data', 'analytics', 'workshop', 'for', 'beginner']","['experiment', 'data', 'analytics', 'workshop', 'beginner']",experiment data analytics workshop beginner,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
1987,drawback of removing intercept from regression equation,Techniques,drawback of removing intercept from regression equation,"['drawback', 'of', 'removing', 'intercept', 'from', 'regression', 'equation']",0,"['drawback', 'of', 'removing', 'intercept', 'from', 'regression', 'equation']","['drawback', 'removing', 'intercept', 'regression', 'equation']",drawback removing intercept regression equation,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
1988,there is no discussion board for the time series jetrail hackathon,Other,there is no discussion board for the time series jetrail hackathon,"['there', 'is', 'no', 'discussion', 'board', 'for', 'the', 'time', 'series', 'jetrail', 'hackathon']",0,"['there', 'is', 'no', 'discussion', 'board', 'for', 'the', 'time', 'series', 'jetrail', 'hackathon']","['discussion', 'board', 'time', 'series', 'jetrail', 'hackathon']",discussion board time series jetrail hackathon,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
1989,big change in accuracy xgboost classification,Techniques,big change in accuracy xgboost classification,"['big', 'change', 'in', 'accuracy', 'xgboost', 'classification']",0,"['big', 'change', 'in', 'accuracy', 'xgboost', 'classification']","['big', 'change', 'accuracy', 'xgboost', 'classification']",big change accuracy xgboost classification,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
1990,career shift to data analytics without actual handson experience,Career,career shift to data analytics without actual handson experience,"['career', 'shift', 'to', 'data', 'analytics', 'without', 'actual', 'handson', 'experience']",0,"['career', 'shift', 'to', 'data', 'analytics', 'without', 'actual', 'handson', 'experience']","['career', 'shift', 'data', 'analytics', 'without', 'actual', 'handson', 'experience']",career shift data analytics without actual handson experience,0.0,0.0,9,61,6.1,0,0,0,0,0,0,0,0
1991,predictive analyticsout of stock,Techniques,predictive analyticsout of stock,"['predictive', 'analyticsout', 'of', 'stock']",0,"['predictive', 'analyticsout', 'of', 'stock']","['predictive', 'analyticsout', 'stock']",predictive analyticsout stock,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
1992,why big data hadoop is becoming popular among data scientists,Techniques,why big data hadoop is becoming popular among data scientists,"['why', 'big', 'data', 'hadoop', 'is', 'becoming', 'popular', 'among', 'data', 'scientists']",0,"['why', 'big', 'data', 'hadoop', 'is', 'becoming', 'popular', 'among', 'data', 'scientist']","['big', 'data', 'hadoop', 'becoming', 'popular', 'among', 'data', 'scientist']",big data hadoop becoming popular among data scientist,0.35,0.35,10,53,4.818181818181818,0,0,0,0,0,0,0,0
1993,is any certificate provided for this workshop,Other,is any certificate provided for this workshop,"['is', 'any', 'certificate', 'provided', 'for', 'this', 'workshop']",0,"['is', 'any', 'certificate', 'provided', 'for', 'this', 'workshop']","['certificate', 'provided', 'workshop']",certificate provided workshop,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
1994,what to do for missing values in important variables,Techniques,what to do for missing values in important variables,"['what', 'to', 'do', 'for', 'missing', 'values', 'in', 'important', 'variables']",0,"['what', 'to', 'do', 'for', 'missing', 'value', 'in', 'important', 'variable']","['missing', 'value', 'important', 'variable']",missing value important variable,0.1,0.1,9,32,3.2,0,0,0,0,0,0,0,0
1995,softmax vs softprob in xgboost,Techniques,softmax vs softprob in xgboost,"['softmax', 'vs', 'softprob', 'in', 'xgboost']",0,"['softmax', 'v', 'softprob', 'in', 'xgboost']","['softmax', 'v', 'softprob', 'xgboost']",softmax v softprob xgboost,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
1996,how to handle missingundefined values in our data,Techniques,how to handle missingundefined values in our data,"['how', 'to', 'handle', 'missingundefined', 'values', 'in', 'our', 'data']",0,"['how', 'to', 'handle', 'missingundefined', 'value', 'in', 'our', 'data']","['handle', 'missingundefined', 'value', 'data']",handle missingundefined value data,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
1997,intention analysis of text,Techniques,intention analysis of text,"['intention', 'analysis', 'of', 'text']",0,"['intention', 'analysis', 'of', 'text']","['intention', 'analysis', 'text']",intention analysis text,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
1998,ideas to improve score,Hackathons,ideas to improve score,"['ideas', 'to', 'improve', 'score']",0,"['idea', 'to', 'improve', 'score']","['idea', 'improve', 'score']",idea improve score,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
1999,data classification for beginners,Tools,data classification for beginners,"['data', 'classification', 'for', 'beginners']",0,"['data', 'classification', 'for', 'beginner']","['data', 'classification', 'beginner']",data classification beginner,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
2000,statistical modelling,Techniques,statistical modelling,"['statistical', 'modelling']",0,"['statistical', 'modelling']","['statistical', 'modelling']",statistical modelling,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
2001,printabtrue returning b why,Tools,printabtrue returning b why,"['printabtrue', 'returning', 'b', 'why']",0,"['printabtrue', 'returning', 'b', 'why']","['printabtrue', 'returning', 'b']",printabtrue returning b,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
2002,ridge regression using glmnet in r,Techniques,ridge regression using glmnet in r,"['ridge', 'regression', 'using', 'glmnet', 'in', 'r']",0,"['ridge', 'regression', 'using', 'glmnet', 'in', 'r']","['ridge', 'regression', 'using', 'glmnet', 'r']",ridge regression using glmnet r,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
2003,test data not found in complete guide to parameter tuning in xgboost with codes in python,Techniques,test data not found in complete guide to parameter tuning in xgboost with codes in python,"['test', 'data', 'not', 'found', 'in', 'complete', 'guide', 'to', 'parameter', 'tuning', 'in', 'xgboost', 'with', 'codes', 'in', 'python']",0,"['test', 'data', 'not', 'found', 'in', 'complete', 'guide', 'to', 'parameter', 'tuning', 'in', 'xgboost', 'with', 'code', 'in', 'python']","['test', 'data', 'found', 'complete', 'guide', 'parameter', 'tuning', 'xgboost', 'code', 'python']",test data found complete guide parameter tuning xgboost code python,0.1,0.1,16,67,3.9411764705882355,0,0,0,0,0,0,0,0
2004,data mining  clustering algorithm,Techniques,data mining  clustering algorithm,"['data', 'mining', 'clustering', 'algorithm']",0,"['data', 'mining', 'clustering', 'algorithm']","['data', 'mining', 'clustering', 'algorithm']",data mining clustering algorithm,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
2005,what is the difference between chi square goodness of fit and independence test,Techniques,what is the difference between chi square goodness of fit and independence test,"['what', 'is', 'the', 'difference', 'between', 'chi', 'square', 'goodness', 'of', 'fit', 'and', 'independence', 'test']",0,"['what', 'is', 'the', 'difference', 'between', 'chi', 'square', 'goodness', 'of', 'fit', 'and', 'independence', 'test']","['difference', 'chi', 'square', 'goodness', 'fit', 'independence', 'test']",difference chi square goodness fit independence test,0.4,0.4,13,52,3.7142857142857144,0,0,0,0,0,0,0,0
2006,importance of error term in linear equation,Techniques,importance of error term in linear equation,"['importance', 'of', 'error', 'term', 'in', 'linear', 'equation']",0,"['importance', 'of', 'error', 'term', 'in', 'linear', 'equation']","['importance', 'error', 'term', 'linear', 'equation']",importance error term linear equation,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
2007,joining two data tables in r,Tools,joining two data tables in r,"['joining', 'two', 'data', 'tables', 'in', 'r']",0,"['joining', 'two', 'data', 'table', 'in', 'r']","['joining', 'two', 'data', 'table', 'r']",joining two data table r,0.0,0.0,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
2008,set a single value in a datatable equal to null in r,Techniques,set a single value in a datatable equal to null in r,"['set', 'a', 'single', 'value', 'in', 'a', 'datatable', 'equal', 'to', 'null', 'in', 'r']",0,"['set', 'a', 'single', 'value', 'in', 'a', 'datatable', 'equal', 'to', 'null', 'in', 'r']","['set', 'single', 'value', 'datatable', 'equal', 'null', 'r']",set single value datatable equal null r,-0.0357142857142857,-0.0357142857142857,12,39,3.0,0,0,0,0,0,0,0,0
2009,question on poem text generator,Hackathons,question on poem text generator,"['question', 'on', 'poem', 'text', 'generator']",0,"['question', 'on', 'poem', 'text', 'generator']","['question', 'poem', 'text', 'generator']",question poem text generator,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
2010,find optimal independent variable values in a classification problem,Techniques,find optimal independent variable values in a classification problem,"['find', 'optimal', 'independent', 'variable', 'values', 'in', 'a', 'classification', 'problem']",0,"['find', 'optimal', 'independent', 'variable', 'value', 'in', 'a', 'classification', 'problem']","['find', 'optimal', 'independent', 'variable', 'value', 'classification', 'problem']",find optimal independent variable value classification problem,0.0,0.0,9,62,6.2,0,0,0,0,0,0,0,0
2011,advantages and disadvantages of arima model,Techniques,advantages and disadvantages of arima model,"['advantages', 'and', 'disadvantages', 'of', 'arima', 'model']",0,"['advantage', 'and', 'disadvantage', 'of', 'arima', 'model']","['advantage', 'disadvantage', 'arima', 'model']",advantage disadvantage arima model,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
2012,correlation coefficient,Techniques,correlation coefficient,"['correlation', 'coefficient']",0,"['correlation', 'coefficient']","['correlation', 'coefficient']",correlation coefficient,0.0,0.0,2,23,7.666666666666667,0,0,0,0,0,0,0,0
2013,error while using predict function on extratrees r,Tools,error while using predict function on extratrees r,"['error', 'while', 'using', 'predict', 'function', 'on', 'extratrees', 'r']",0,"['error', 'while', 'using', 'predict', 'function', 'on', 'extratrees', 'r']","['error', 'using', 'predict', 'function', 'extratrees', 'r']",error using predict function extratrees r,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2014,type of analysis,Techniques,type of analysis,"['type', 'of', 'analysis']",0,"['type', 'of', 'analysis']","['type', 'analysis']",type analysis,0.0,0.0,3,13,3.25,0,0,0,0,0,0,0,0
2015,career transition,Career,career transition,"['career', 'transition']",0,"['career', 'transition']","['career', 'transition']",career transition,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
2016,accuracy as a measure for imbalanced class for datahack hour,Hackathons,accuracy as a measure for imbalanced class for datahack hour,"['accuracy', 'as', 'a', 'measure', 'for', 'imbalanced', 'class', 'for', 'datahack', 'hour']",0,"['accuracy', 'a', 'a', 'measure', 'for', 'imbalanced', 'class', 'for', 'datahack', 'hour']","['accuracy', 'measure', 'imbalanced', 'class', 'datahack', 'hour']",accuracy measure imbalanced class datahack hour,0.0,0.0,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
2017,hr analytics and data science for beginner,Techniques,hr analytics and data science for beginner,"['hr', 'analytics', 'and', 'data', 'science', 'for', 'beginner']",0,"['hr', 'analytics', 'and', 'data', 'science', 'for', 'beginner']","['hr', 'analytics', 'data', 'science', 'beginner']",hr analytics data science beginner,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
2018,multilabel text classification in python  r,Techniques,multilabel text classification in python  r,"['multilabel', 'text', 'classification', 'in', 'python', 'r']",0,"['multilabel', 'text', 'classification', 'in', 'python', 'r']","['multilabel', 'text', 'classification', 'python', 'r']",multilabel text classification python r,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
2019,r code help removing duplicates based on one column  condition in other column,Tools,r code help removing duplicates based on one column  condition in other column,"['r', 'code', 'help', 'removing', 'duplicates', 'based', 'on', 'one', 'column', 'condition', 'in', 'other', 'column']",0,"['r', 'code', 'help', 'removing', 'duplicate', 'based', 'on', 'one', 'column', 'condition', 'in', 'other', 'column']","['r', 'code', 'help', 'removing', 'duplicate', 'based', 'one', 'column', 'condition', 'column']",r code help removing duplicate based one column condition column,-0.125,0.0,13,64,4.571428571428571,0,0,0,0,0,0,0,0
2020,data analysis for it department,Other,data analysis for it department,"['data', 'analysis', 'for', 'it', 'department']",0,"['data', 'analysis', 'for', 'it', 'department']","['data', 'analysis', 'department']",data analysis department,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
2021,libreoffice and linux,Tools,libreoffice and linux,"['libreoffice', 'and', 'linux']",0,"['libreoffice', 'and', 'linux']","['libreoffice', 'linux']",libreoffice linux,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
2022,job opportunities in clinical sas programming after  years of experience,Career,job opportunities in clinical sas programming after  years of experience,"['job', 'opportunities', 'in', 'clinical', 'sas', 'programming', 'after', 'years', 'of', 'experience']",1,"['job', 'opportunity', 'in', 'clinical', 'sa', 'programming', 'after', 'year', 'of', 'experience']","['job', 'opportunity', 'clinical', 'sa', 'programming', 'year', 'experience']",job opportunity clinical sa programming year experience,0.0,0.0,10,55,5.0,0,0,0,0,0,0,0,0
2023,forecasting  predicting internet usage over time,Techniques,forecasting  predicting internet usage over time,"['forecasting', 'predicting', 'internet', 'usage', 'over', 'time']",0,"['forecasting', 'predicting', 'internet', 'usage', 'over', 'time']","['forecasting', 'predicting', 'internet', 'usage', 'time']",forecasting predicting internet usage time,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
2024,how to process natural language question in order to find target variable,Techniques,how to process natural language question in order to find target variable,"['how', 'to', 'process', 'natural', 'language', 'question', 'in', 'order', 'to', 'find', 'target', 'variable']",0,"['how', 'to', 'process', 'natural', 'language', 'question', 'in', 'order', 'to', 'find', 'target', 'variable']","['process', 'natural', 'language', 'question', 'order', 'find', 'target', 'variable']",process natural language question order find target variable,0.1,0.1,12,60,4.615384615384615,0,0,0,0,0,0,0,0
2025,instantiating a neural network design,Techniques,instantiating a neural network design,"['instantiating', 'a', 'neural', 'network', 'design']",0,"['instantiating', 'a', 'neural', 'network', 'design']","['instantiating', 'neural', 'network', 'design']",instantiating neural network design,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
2026,download guide to crack difficult analytics interviews,Career,download guide to crack difficult analytics interviews,"['download', 'guide', 'to', 'crack', 'difficult', 'analytics', 'interviews']",0,"['download', 'guide', 'to', 'crack', 'difficult', 'analytics', 'interview']","['download', 'guide', 'crack', 'difficult', 'analytics', 'interview']",download guide crack difficult analytics interview,-0.5,-0.5,7,50,6.25,0,0,0,0,0,0,0,0
2027,recommender system error,Techniques,recommender system error,"['recommender', 'system', 'error']",0,"['recommender', 'system', 'error']","['recommender', 'system', 'error']",recommender system error,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
2028,how to check and interpret the result of kfold cross validation in r,Tools,how to check and interpret the result of kfold cross validation in r,"['how', 'to', 'check', 'and', 'interpret', 'the', 'result', 'of', 'kfold', 'cross', 'validation', 'in', 'r']",0,"['how', 'to', 'check', 'and', 'interpret', 'the', 'result', 'of', 'kfold', 'cross', 'validation', 'in', 'r']","['check', 'interpret', 'result', 'kfold', 'cross', 'validation', 'r']",check interpret result kfold cross validation r,0.0,0.0,13,47,3.357142857142857,0,0,0,0,0,0,0,0
2029,running randomforest on subset data,Techniques,running randomforest on subset data,"['running', 'randomforest', 'on', 'subset', 'data']",0,"['running', 'randomforest', 'on', 'subset', 'data']","['running', 'randomforest', 'subset', 'data']",running randomforest subset data,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2030,how can we remove top and bottom  records to load in qlikview,Tools,how can we remove top and bottom  records to load in qlikview,"['how', 'can', 'we', 'remove', 'top', 'and', 'bottom', 'records', 'to', 'load', 'in', 'qlikview']",1,"['how', 'can', 'we', 'remove', 'top', 'and', 'bottom', 'record', 'to', 'load', 'in', 'qlikview']","['remove', 'top', 'bottom', 'record', 'load', 'qlikview']",remove top bottom record load qlikview,0.5,0.5,12,38,2.923076923076923,0,0,0,0,0,0,0,0
2031,should i switch to python  or continue with ,Tools,should i switch to python  or continue with ,"['should', 'i', 'switch', 'to', 'python', 'or', 'continue', 'with']",2,"['should', 'i', 'switch', 'to', 'python', 'or', 'continue', 'with']","['switch', 'python', 'continue']",switch python continue,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
2032,data scaling in knn algorithm,Techniques,data scaling in knn algorithm,"['data', 'scaling', 'in', 'knn', 'algorithm']",0,"['data', 'scaling', 'in', 'knn', 'algorithm']","['data', 'scaling', 'knn', 'algorithm']",data scaling knn algorithm,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
2033,why gradient descent for optimization,Techniques,why gradient descent for optimization,"['why', 'gradient', 'descent', 'for', 'optimization']",0,"['why', 'gradient', 'descent', 'for', 'optimization']","['gradient', 'descent', 'optimization']",gradient descent optimization,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
2034,how to generate predicted probabilities using gbm,Techniques,how to generate predicted probabilities using gbm,"['how', 'to', 'generate', 'predicted', 'probabilities', 'using', 'gbm']",0,"['how', 'to', 'generate', 'predicted', 'probability', 'using', 'gbm']","['generate', 'predicted', 'probability', 'using', 'gbm']",generate predicted probability using gbm,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
2035,visualising missing values in a dataset,Techniques,visualising missing values in a dataset,"['visualising', 'missing', 'values', 'in', 'a', 'dataset']",0,"['visualising', 'missing', 'value', 'in', 'a', 'dataset']","['visualising', 'missing', 'value', 'dataset']",visualising missing value dataset,-0.2,-0.2,6,33,4.714285714285714,0,0,0,0,0,0,0,0
2036,how to identify potential customers who are ready to convert in to paid,Techniques,how to identify potential customers who are ready to convert in to paid,"['how', 'to', 'identify', 'potential', 'customers', 'who', 'are', 'ready', 'to', 'convert', 'in', 'to', 'paid']",0,"['how', 'to', 'identify', 'potential', 'customer', 'who', 'are', 'ready', 'to', 'convert', 'in', 'to', 'paid']","['identify', 'potential', 'customer', 'ready', 'convert', 'paid']",identify potential customer ready convert paid,0.1,0.1,13,46,3.2857142857142856,0,0,0,0,0,0,0,0
2037,parametric vs non parametric models with examples,Techniques,parametric vs non parametric models with examples,"['parametric', 'vs', 'non', 'parametric', 'models', 'with', 'examples']",0,"['parametric', 'v', 'non', 'parametric', 'model', 'with', 'example']","['parametric', 'v', 'non', 'parametric', 'model', 'example']",parametric v non parametric model example,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
2038,how to detect a worker presence in different working sites,Hackathons,how to detect a worker presence in different working sites,"['how', 'to', 'detect', 'a', 'worker', 'presence', 'in', 'different', 'working', 'sites']",0,"['how', 'to', 'detect', 'a', 'worker', 'presence', 'in', 'different', 'working', 'site']","['detect', 'worker', 'presence', 'different', 'working', 'site']",detect worker presence different working site,0.0,0.0,10,45,4.090909090909091,0,0,0,0,0,0,0,0
2039,how decision tree performs nonlinear classification,Techniques,how decision tree performs nonlinear classification,"['how', 'decision', 'tree', 'performs', 'nonlinear', 'classification']",0,"['how', 'decision', 'tree', 'performs', 'nonlinear', 'classification']","['decision', 'tree', 'performs', 'nonlinear', 'classification']",decision tree performs nonlinear classification,0.0,0.0,6,47,6.714285714285714,0,0,0,0,0,0,0,0
2040,mba after analytics,Career,mba after analytics,"['mba', 'after', 'analytics']",0,"['mba', 'after', 'analytics']","['mba', 'analytics']",mba analytics,0.0,0.0,3,13,3.25,0,0,0,0,0,0,0,0
2041,how to plot the cluster of documents and words after lsa in r,Tools,how to plot the cluster of documents and words after lsa in r,"['how', 'to', 'plot', 'the', 'cluster', 'of', 'documents', 'and', 'words', 'after', 'lsa', 'in', 'r']",0,"['how', 'to', 'plot', 'the', 'cluster', 'of', 'document', 'and', 'word', 'after', 'lsa', 'in', 'r']","['plot', 'cluster', 'document', 'word', 'lsa', 'r']",plot cluster document word lsa r,0.0,0.0,13,32,2.2857142857142856,0,0,0,0,0,0,0,0
2042,continuous variable selection  splitting in regression tree,Techniques,continuous variable selection  splitting in regression tree,"['continuous', 'variable', 'selection', 'splitting', 'in', 'regression', 'tree']",0,"['continuous', 'variable', 'selection', 'splitting', 'in', 'regression', 'tree']","['continuous', 'variable', 'selection', 'splitting', 'regression', 'tree']",continuous variable selection splitting regression tree,0.0,0.0,7,55,6.875,0,0,0,0,0,0,0,0
2043,how to estimate the out of bag error,Techniques,how to estimate the out of bag error,"['how', 'to', 'estimate', 'the', 'out', 'of', 'bag', 'error']",0,"['how', 'to', 'estimate', 'the', 'out', 'of', 'bag', 'error']","['estimate', 'bag', 'error']",estimate bag error,0.0,0.0,8,18,2.0,0,0,0,0,0,0,0,0
2044,time series data groupinf,Techniques,time series data groupinf,"['time', 'series', 'data', 'groupinf']",0,"['time', 'series', 'data', 'groupinf']","['time', 'series', 'data', 'groupinf']",time series data groupinf,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
2045,best approachgeneral advice for predicting anomaly in timeseries,Techniques,best approachgeneral advice for predicting anomaly in timeseries,"['best', 'approachgeneral', 'advice', 'for', 'predicting', 'anomaly', 'in', 'timeseries']",0,"['best', 'approachgeneral', 'advice', 'for', 'predicting', 'anomaly', 'in', 'timeseries']","['best', 'approachgeneral', 'advice', 'predicting', 'anomaly', 'timeseries']",best approachgeneral advice predicting anomaly timeseries,1.0,1.0,8,57,6.333333333333333,0,0,0,0,0,0,0,0
2046,which is the best regression for the data whose response is binary,Techniques,which is the best regression for the data whose response is binary,"['which', 'is', 'the', 'best', 'regression', 'for', 'the', 'data', 'whose', 'response', 'is', 'binary']",0,"['which', 'is', 'the', 'best', 'regression', 'for', 'the', 'data', 'whose', 'response', 'is', 'binary']","['best', 'regression', 'data', 'whose', 'response', 'binary']",best regression data whose response binary,1.0,1.0,12,42,3.230769230769231,0,0,0,0,0,0,0,0
2047,how to do validation steps in logistic model,Techniques,how to do validation steps in logistic model,"['how', 'to', 'do', 'validation', 'steps', 'in', 'logistic', 'model']",0,"['how', 'to', 'do', 'validation', 'step', 'in', 'logistic', 'model']","['validation', 'step', 'logistic', 'model']",validation step logistic model,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
2048,explain why regression analysis is not efficient in classifying categorical data,Techniques,explain why regression analysis is not efficient in classifying categorical data,"['explain', 'why', 'regression', 'analysis', 'is', 'not', 'efficient', 'in', 'classifying', 'categorical', 'data']",0,"['explain', 'why', 'regression', 'analysis', 'is', 'not', 'efficient', 'in', 'classifying', 'categorical', 'data']","['explain', 'regression', 'analysis', 'efficient', 'classifying', 'categorical', 'data']",explain regression analysis efficient classifying categorical data,0.0,0.0,11,66,5.5,0,0,0,0,0,0,0,0
2049,image augmentation for multiple images,Techniques,image augmentation for multiple images,"['image', 'augmentation', 'for', 'multiple', 'images']",0,"['image', 'augmentation', 'for', 'multiple', 'image']","['image', 'augmentation', 'multiple', 'image']",image augmentation multiple image,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
2050,stringsasfactor  false is a good practice or not,Tools,stringsasfactor  false is a good practice or not,"['stringsasfactor', 'false', 'is', 'a', 'good', 'practice', 'or', 'not']",0,"['stringsasfactor', 'false', 'is', 'a', 'good', 'practice', 'or', 'not']","['stringsasfactor', 'false', 'good', 'practice']",stringsasfactor false good practice,0.1499999999999999,0.1499999999999999,8,35,3.888888888888889,0,0,0,0,0,0,0,0
2051,data engineering tasks for building a modern data science platform,Tools,data engineering tasks for building a modern data science platform,"['data', 'engineering', 'tasks', 'for', 'building', 'a', 'modern', 'data', 'science', 'platform']",0,"['data', 'engineering', 'task', 'for', 'building', 'a', 'modern', 'data', 'science', 'platform']","['data', 'engineering', 'task', 'building', 'modern', 'data', 'science', 'platform']",data engineering task building modern data science platform,0.2,0.2,10,59,5.363636363636363,0,0,0,0,0,0,0,0
2052,model accuracy without over fitting data,Misc,model accuracy without over fitting data,"['model', 'accuracy', 'without', 'over', 'fitting', 'data']",0,"['model', 'accuracy', 'without', 'over', 'fitting', 'data']","['model', 'accuracy', 'without', 'fitting', 'data']",model accuracy without fitting data,0.5,0.5,6,35,5.0,0,0,0,0,0,0,0,0
2053,how to extract social media data without using r packages,Tools,how to extract social media data without using r packages,"['how', 'to', 'extract', 'social', 'media', 'data', 'without', 'using', 'r', 'packages']",0,"['how', 'to', 'extract', 'social', 'medium', 'data', 'without', 'using', 'r', 'package']","['extract', 'social', 'medium', 'data', 'without', 'using', 'r', 'package']",extract social medium data without using r package,0.0333333333333333,0.0333333333333333,10,50,4.545454545454546,0,0,0,0,0,0,0,0
2054,how do i go about performing unsupervised topic and opinion extraction from freetext,Techniques,how do i go about performing unsupervised topic and opinion extraction from freetext,"['how', 'do', 'i', 'go', 'about', 'performing', 'unsupervised', 'topic', 'and', 'opinion', 'extraction', 'from', 'freetext']",0,"['how', 'do', 'i', 'go', 'about', 'performing', 'unsupervised', 'topic', 'and', 'opinion', 'extraction', 'from', 'freetext']","['go', 'performing', 'unsupervised', 'topic', 'opinion', 'extraction', 'freetext']",go performing unsupervised topic opinion extraction freetext,0.0,0.0,13,60,4.285714285714286,0,0,0,0,0,0,0,0
2055,rjava performance,Techniques,rjava performance,"['rjava', 'performance']",0,"['rjava', 'performance']","['rjava', 'performance']",rjava performance,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
2056,can we do incremental machine learning model training for python sklearn algos,Techniques,can we do incremental machine learning model training for python sklearn algos,"['can', 'we', 'do', 'incremental', 'machine', 'learning', 'model', 'training', 'for', 'python', 'sklearn', 'algos']",0,"['can', 'we', 'do', 'incremental', 'machine', 'learning', 'model', 'training', 'for', 'python', 'sklearn', 'algos']","['incremental', 'machine', 'learning', 'model', 'training', 'python', 'sklearn', 'algos']",incremental machine learning model training python sklearn algos,0.0,0.0,12,64,4.923076923076923,0,0,0,0,0,0,0,0
2057,identifying dictionary words in email addresses using sas,Tools,identifying dictionary words in email addresses using sas,"['identifying', 'dictionary', 'words', 'in', 'email', 'addresses', 'using', 'sas']",0,"['identifying', 'dictionary', 'word', 'in', 'email', 'address', 'using', 'sa']","['identifying', 'dictionary', 'word', 'email', 'address', 'using', 'sa']",identifying dictionary word email address using sa,0.0,0.0,8,50,5.555555555555555,0,0,0,0,0,0,0,0
2058,how to identify whether a data is time series data,Techniques,how to identify whether a data is time series data,"['how', 'to', 'identify', 'whether', 'a', 'data', 'is', 'time', 'series', 'data']",0,"['how', 'to', 'identify', 'whether', 'a', 'data', 'is', 'time', 'series', 'data']","['identify', 'whether', 'data', 'time', 'series', 'data']",identify whether data time series data,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
2059,need help in an interview question,Career,need help in an interview question,"['need', 'help', 'in', 'an', 'interview', 'question']",0,"['need', 'help', 'in', 'an', 'interview', 'question']","['need', 'help', 'interview', 'question']",need help interview question,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
2060,convert html page source to txt format,Techniques,convert html page source to txt format,"['convert', 'html', 'page', 'source', 'to', 'txt', 'format']",0,"['convert', 'html', 'page', 'source', 'to', 'txt', 'format']","['convert', 'html', 'page', 'source', 'txt', 'format']",convert html page source txt format,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
2061,how to improve qlikview data model,Tools,how to improve qlikview data model,"['how', 'to', 'improve', 'qlikview', 'data', 'model']",0,"['how', 'to', 'improve', 'qlikview', 'data', 'model']","['improve', 'qlikview', 'data', 'model']",improve qlikview data model,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
2062,after installing anaconda while trying to create new environment its throwing below error please help,Tools,after installing anaconda while trying to create new environment its throwing below error please help,"['after', 'installing', 'anaconda', 'while', 'trying', 'to', 'create', 'new', 'environment', 'its', 'throwing', 'below', 'error', 'please', 'help']",0,"['after', 'installing', 'anaconda', 'while', 'trying', 'to', 'create', 'new', 'environment', 'it', 'throwing', 'below', 'error', 'please', 'help']","['installing', 'anaconda', 'trying', 'create', 'new', 'environment', 'throwing', 'error', 'please', 'help']",installing anaconda trying create new environment throwing error please help,0.1363636363636363,0.1363636363636363,15,76,4.75,0,0,0,0,0,0,0,0
2063,how to display the count during reducebykey,Techniques,how to display the count during reducebykey,"['how', 'to', 'display', 'the', 'count', 'during', 'reducebykey']",0,"['how', 'to', 'display', 'the', 'count', 'during', 'reducebykey']","['display', 'count', 'reducebykey']",display count reducebykey,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
2064,data visualization in python,Techniques,data visualization in python,"['data', 'visualization', 'in', 'python']",0,"['data', 'visualization', 'in', 'python']","['data', 'visualization', 'python']",data visualization python,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
2065,working with flashtext with non ascii text,Tools,working with flashtext with non ascii text,"['working', 'with', 'flashtext', 'with', 'non', 'ascii', 'text']",0,"['working', 'with', 'flashtext', 'with', 'non', 'ascii', 'text']","['working', 'flashtext', 'non', 'ascii', 'text']",working flashtext non ascii text,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
2066,batch generation using keras imagedatagenerator,Techniques,batch generation using keras imagedatagenerator,"['batch', 'generation', 'using', 'keras', 'imagedatagenerator']",0,"['batch', 'generation', 'using', 'kera', 'imagedatagenerator']","['batch', 'generation', 'using', 'kera', 'imagedatagenerator']",batch generation using kera imagedatagenerator,0.0,0.0,5,46,7.666666666666667,0,0,0,0,0,0,0,0
2067,where to download minihack quicksolver dataset,Hackathons,where to download minihack quicksolver dataset,"['where', 'to', 'download', 'minihack', 'quicksolver', 'dataset']",0,"['where', 'to', 'download', 'minihack', 'quicksolver', 'dataset']","['download', 'minihack', 'quicksolver', 'dataset']",download minihack quicksolver dataset,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
2068,why does the normal approximation to the binomial distribution break for small intervals,Techniques,why does the normal approximation to the binomial distribution break for small intervals,"['why', 'does', 'the', 'normal', 'approximation', 'to', 'the', 'binomial', 'distribution', 'break', 'for', 'small', 'intervals']",0,"['why', 'doe', 'the', 'normal', 'approximation', 'to', 'the', 'binomial', 'distribution', 'break', 'for', 'small', 'interval']","['doe', 'normal', 'approximation', 'binomial', 'distribution', 'break', 'small', 'interval']",doe normal approximation binomial distribution break small interval,-0.05,-0.05,13,67,4.785714285714286,0,0,0,0,0,0,0,0
2069,where can i find an ecommerce dataset for building recommendation engine,Resources,where can i find an ecommerce dataset for building recommendation engine,"['where', 'can', 'i', 'find', 'an', 'ecommerce', 'dataset', 'for', 'building', 'recommendation', 'engine']",0,"['where', 'can', 'i', 'find', 'an', 'ecommerce', 'dataset', 'for', 'building', 'recommendation', 'engine']","['find', 'ecommerce', 'dataset', 'building', 'recommendation', 'engine']",find ecommerce dataset building recommendation engine,0.0,0.0,11,53,4.416666666666667,0,0,0,0,0,0,0,0
2070,how to bring multiple cvs file in to r console box,Techniques,how to bring multiple cvs file in to r console box,"['how', 'to', 'bring', 'multiple', 'cvs', 'file', 'in', 'to', 'r', 'console', 'box']",0,"['how', 'to', 'bring', 'multiple', 'cv', 'file', 'in', 'to', 'r', 'console', 'box']","['bring', 'multiple', 'cv', 'file', 'r', 'console', 'box']",bring multiple cv file r console box,0.0,0.0,11,36,3.0,0,0,0,0,0,0,0,0
2071,reinforcement multi armed bandit,Techniques,reinforcement multi armed bandit,"['reinforcement', 'multi', 'armed', 'bandit']",0,"['reinforcement', 'multi', 'armed', 'bandit']","['reinforcement', 'multi', 'armed', 'bandit']",reinforcement multi armed bandit,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
2072,how can i analize a large data set,Techniques,how can i analize a large data set,"['how', 'can', 'i', 'analize', 'a', 'large', 'data', 'set']",0,"['how', 'can', 'i', 'analize', 'a', 'large', 'data', 'set']","['analize', 'large', 'data', 'set']",analize large data set,0.2142857142857142,0.2142857142857142,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
2073,suggestions for the problem statement of data science in r,Tools,suggestions for the problem statement of data science in r,"['suggestions', 'for', 'the', 'problem', 'statement', 'of', 'data', 'science', 'in', 'r']",0,"['suggestion', 'for', 'the', 'problem', 'statement', 'of', 'data', 'science', 'in', 'r']","['suggestion', 'problem', 'statement', 'data', 'science', 'r']",suggestion problem statement data science r,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
2074,error while performing classification using gradient boosting in r,Techniques,error while performing classification using gradient boosting in r,"['error', 'while', 'performing', 'classification', 'using', 'gradient', 'boosting', 'in', 'r']",0,"['error', 'while', 'performing', 'classification', 'using', 'gradient', 'boosting', 'in', 'r']","['error', 'performing', 'classification', 'using', 'gradient', 'boosting', 'r']",error performing classification using gradient boosting r,0.0,0.0,9,57,5.7,0,0,0,0,0,0,0,0
2075,cross validation  leave one out vs kfold,Techniques,cross validation  leave one out vs kfold,"['cross', 'validation', 'leave', 'one', 'out', 'vs', 'kfold']",0,"['cross', 'validation', 'leave', 'one', 'out', 'v', 'kfold']","['cross', 'validation', 'leave', 'one', 'v', 'kfold']",cross validation leave one v kfold,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
2076,can i start career in data science after  yrs of experience as clinical sas programmer,Career,can i start career in data science after  yrs of experience as clinical sas programmer,"['can', 'i', 'start', 'career', 'in', 'data', 'science', 'after', 'yrs', 'of', 'experience', 'as', 'clinical', 'sas', 'programmer']",1,"['can', 'i', 'start', 'career', 'in', 'data', 'science', 'after', 'yr', 'of', 'experience', 'a', 'clinical', 'sa', 'programmer']","['start', 'career', 'data', 'science', 'yr', 'experience', 'clinical', 'sa', 'programmer']",start career data science yr experience clinical sa programmer,0.0,0.0,15,62,3.875,0,0,0,0,0,0,0,0
2077,when to use if and do compare to if and do in sas,Tools,when to use if and do compare to if and do in sas,"['when', 'to', 'use', 'if', 'and', 'do', 'compare', 'to', 'if', 'and', 'do', 'in', 'sas']",0,"['when', 'to', 'use', 'if', 'and', 'do', 'compare', 'to', 'if', 'and', 'do', 'in', 'sa']","['use', 'compare', 'sa']",use compare sa,0.0,0.0,13,14,1.0,0,0,0,0,0,0,0,0
2078,can support vector machine algorithm be used for classification into more than two categories,Techniques,can support vector machine algorithm be used for classification into more than two categories,"['can', 'support', 'vector', 'machine', 'algorithm', 'be', 'used', 'for', 'classification', 'into', 'more', 'than', 'two', 'categories']",0,"['can', 'support', 'vector', 'machine', 'algorithm', 'be', 'used', 'for', 'classification', 'into', 'more', 'than', 'two', 'category']","['support', 'vector', 'machine', 'algorithm', 'used', 'classification', 'two', 'category']",support vector machine algorithm used classification two category,0.5,0.0,14,65,4.333333333333333,0,0,0,0,0,0,0,0
2079,which are the big data startups in india,Resources,which are the big data startups in india,"['which', 'are', 'the', 'big', 'data', 'startups', 'in', 'india']",0,"['which', 'are', 'the', 'big', 'data', 'startup', 'in', 'india']","['big', 'data', 'startup', 'india']",big data startup india,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
2080,data analytics use cases in networking domain,Other,data analytics use cases in networking domain,"['data', 'analytics', 'use', 'cases', 'in', 'networking', 'domain']",0,"['data', 'analytics', 'use', 'case', 'in', 'networking', 'domain']","['data', 'analytics', 'use', 'case', 'networking', 'domain']",data analytics use case networking domain,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
2081,outlier treatment in r,Techniques,outlier treatment in r,"['outlier', 'treatment', 'in', 'r']",0,"['outlier', 'treatment', 'in', 'r']","['outlier', 'treatment', 'r']",outlier treatment r,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
2082,difference between cforest and random forest in r,Tools,difference between cforest and random forest in r,"['difference', 'between', 'cforest', 'and', 'random', 'forest', 'in', 'r']",0,"['difference', 'between', 'cforest', 'and', 'random', 'forest', 'in', 'r']","['difference', 'cforest', 'random', 'forest', 'r']",difference cforest random forest r,-0.5,-0.5,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
2083,how to select top  records while using the aggregate function in r,Tools,how to select top  records while using the aggregate function in r,"['how', 'to', 'select', 'top', 'records', 'while', 'using', 'the', 'aggregate', 'function', 'in', 'r']",1,"['how', 'to', 'select', 'top', 'record', 'while', 'using', 'the', 'aggregate', 'function', 'in', 'r']","['select', 'top', 'record', 'using', 'aggregate', 'function', 'r']",select top record using aggregate function r,0.5,0.5,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
2084,predictive analytics for k education,Other,predictive analytics for k education,"['predictive', 'analytics', 'for', 'k', 'education']",0,"['predictive', 'analytics', 'for', 'k', 'education']","['predictive', 'analytics', 'k', 'education']",predictive analytics k education,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2085,solution to loan prediction problem,Hackathons,solution to loan prediction problem,"['solution', 'to', 'loan', 'prediction', 'problem']",0,"['solution', 'to', 'loan', 'prediction', 'problem']","['solution', 'loan', 'prediction', 'problem']",solution loan prediction problem,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2086,putting labels to a table in r,Tools,putting labels to a table in r,"['putting', 'labels', 'to', 'a', 'table', 'in', 'r']",0,"['putting', 'label', 'to', 'a', 'table', 'in', 'r']","['putting', 'label', 'table', 'r']",putting label table r,0.0,0.0,7,21,2.625,0,0,0,0,0,0,0,0
2087,how can we replace null values with na in qlikview straight table,Tools,how can we replace null values with na in qlikview straight table,"['how', 'can', 'we', 'replace', 'null', 'values', 'with', 'na', 'in', 'qlikview', 'straight', 'table']",0,"['how', 'can', 'we', 'replace', 'null', 'value', 'with', 'na', 'in', 'qlikview', 'straight', 'table']","['replace', 'null', 'value', 'na', 'qlikview', 'straight', 'table']",replace null value na qlikview straight table,0.2,0.2,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
2088,sales forecasting based on historical order data,Techniques,sales forecasting based on historical order data,"['sales', 'forecasting', 'based', 'on', 'historical', 'order', 'data']",0,"['sale', 'forecasting', 'based', 'on', 'historical', 'order', 'data']","['sale', 'forecasting', 'based', 'historical', 'order', 'data']",sale forecasting based historical order data,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
2089,sampling of san francisco crime data on the basis of category,Techniques,sampling of san francisco crime data on the basis of category,"['sampling', 'of', 'san', 'francisco', 'crime', 'data', 'on', 'the', 'basis', 'of', 'category']",0,"['sampling', 'of', 'san', 'francisco', 'crime', 'data', 'on', 'the', 'basis', 'of', 'category']","['sampling', 'san', 'francisco', 'crime', 'data', 'basis', 'category']",sampling san francisco crime data basis category,0.0,0.0,11,48,4.0,0,0,0,0,0,0,0,0
2090,converting data frame into time series using r,Techniques,converting data frame into time series using r,"['converting', 'data', 'frame', 'into', 'time', 'series', 'using', 'r']",0,"['converting', 'data', 'frame', 'into', 'time', 'series', 'using', 'r']","['converting', 'data', 'frame', 'time', 'series', 'using', 'r']",converting data frame time series using r,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2091,how to plot scatter plot matrix of all the variable in the data set,Techniques,how to plot scatter plot matrix of all the variable in the data set,"['how', 'to', 'plot', 'scatter', 'plot', 'matrix', 'of', 'all', 'the', 'variable', 'in', 'the', 'data', 'set']",0,"['how', 'to', 'plot', 'scatter', 'plot', 'matrix', 'of', 'all', 'the', 'variable', 'in', 'the', 'data', 'set']","['plot', 'scatter', 'plot', 'matrix', 'variable', 'data', 'set']",plot scatter plot matrix variable data set,0.0,0.0,14,42,2.8,0,0,0,0,0,0,0,0
2092,discussion for article essentials of deep learning  trudging into unsupervised deep learning,Other,discussion for article essentials of deep learning  trudging into unsupervised deep learning,"['discussion', 'for', 'article', 'essentials', 'of', 'deep', 'learning', 'trudging', 'into', 'unsupervised', 'deep', 'learning']",0,"['discussion', 'for', 'article', 'essential', 'of', 'deep', 'learning', 'trudging', 'into', 'unsupervised', 'deep', 'learning']","['discussion', 'article', 'essential', 'deep', 'learning', 'trudging', 'unsupervised', 'deep', 'learning']",discussion article essential deep learning trudging unsupervised deep learning,0.0,0.0,12,78,6.0,0,0,0,0,0,0,0,0
2093,forecast daily data  working day using arima in r,Techniques,forecast daily data  working day using arima in r,"['forecast', 'daily', 'data', 'working', 'day', 'using', 'arima', 'in', 'r']",1,"['forecast', 'daily', 'data', 'working', 'day', 'using', 'arima', 'in', 'r']","['forecast', 'daily', 'data', 'working', 'day', 'using', 'arima', 'r']",forecast daily data working day using arima r,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
2094,should i use same feature engineering  feature selection method for both supervised  unsupervised ml,Techniques,should i use same feature engineering  feature selection method for both supervised  unsupervised ml,"['should', 'i', 'use', 'same', 'feature', 'engineering', 'feature', 'selection', 'method', 'for', 'both', 'supervised', 'unsupervised', 'ml']",0,"['should', 'i', 'use', 'same', 'feature', 'engineering', 'feature', 'selection', 'method', 'for', 'both', 'supervised', 'unsupervised', 'ml']","['use', 'feature', 'engineering', 'feature', 'selection', 'method', 'supervised', 'unsupervised', 'ml']",use feature engineering feature selection method supervised unsupervised ml,0.0,0.0,14,75,5.0,0,0,0,0,0,0,0,0
2095,alternative way to read data everytime we open a new r session,Techniques,alternative way to read data everytime we open a new r session,"['alternative', 'way', 'to', 'read', 'data', 'everytime', 'we', 'open', 'a', 'new', 'r', 'session']",0,"['alternative', 'way', 'to', 'read', 'data', 'everytime', 'we', 'open', 'a', 'new', 'r', 'session']","['alternative', 'way', 'read', 'data', 'everytime', 'open', 'new', 'r', 'session']",alternative way read data everytime open new r session,0.0681818181818181,0.0681818181818181,12,54,4.153846153846154,0,0,0,0,0,0,0,0
2096,zeppelin installation error,Tools,zeppelin installation error,"['zeppelin', 'installation', 'error']",0,"['zeppelin', 'installation', 'error']","['zeppelin', 'installation', 'error']",zeppelin installation error,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
2097,machine learning with imbalanced classification,Techniques,machine learning with imbalanced classification,"['machine', 'learning', 'with', 'imbalanced', 'classification']",0,"['machine', 'learning', 'with', 'imbalanced', 'classification']","['machine', 'learning', 'imbalanced', 'classification']",machine learning imbalanced classification,0.0,0.0,5,42,7.0,0,0,0,0,0,0,0,0
2098,boxing fight analytics in r,Techniques,boxing fight analytics in r,"['boxing', 'fight', 'analytics', 'in', 'r']",0,"['boxing', 'fight', 'analytics', 'in', 'r']","['boxing', 'fight', 'analytics', 'r']",boxing fight analytics r,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
2099,is it worth doing predictive business analytics courese from bridge school of management,Career,is it worth doing predictive business analytics courese from bridge school of management,"['is', 'it', 'worth', 'doing', 'predictive', 'business', 'analytics', 'courese', 'from', 'bridge', 'school', 'of', 'management']",0,"['is', 'it', 'worth', 'doing', 'predictive', 'business', 'analytics', 'courese', 'from', 'bridge', 'school', 'of', 'management']","['worth', 'predictive', 'business', 'analytics', 'courese', 'bridge', 'school', 'management']",worth predictive business analytics courese bridge school management,0.3,0.3,13,68,4.857142857142857,0,0,0,0,0,0,0,0
2100,diagnostic plots for logistic regression,Techniques,diagnostic plots for logistic regression,"['diagnostic', 'plots', 'for', 'logistic', 'regression']",0,"['diagnostic', 'plot', 'for', 'logistic', 'regression']","['diagnostic', 'plot', 'logistic', 'regression']",diagnostic plot logistic regression,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
2101,open datasets used in datahack premier league,Hackathons,open datasets used in datahack premier league,"['open', 'datasets', 'used', 'in', 'datahack', 'premier', 'league']",0,"['open', 'datasets', 'used', 'in', 'datahack', 'premier', 'league']","['open', 'datasets', 'used', 'datahack', 'premier', 'league']",open datasets used datahack premier league,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
2102,what is the difference between logistic function and log likelihood,Techniques,what is the difference between logistic function and log likelihood,"['what', 'is', 'the', 'difference', 'between', 'logistic', 'function', 'and', 'log', 'likelihood']",0,"['what', 'is', 'the', 'difference', 'between', 'logistic', 'function', 'and', 'log', 'likelihood']","['difference', 'logistic', 'function', 'log', 'likelihood']",difference logistic function log likelihood,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
2103,is it necessary to convert categorical variable into numeric variable in a model fitting,Techniques,is it necessary to convert categorical variable into numeric variable in a model fitting,"['is', 'it', 'necessary', 'to', 'convert', 'categorical', 'variable', 'into', 'numeric', 'variable', 'in', 'a', 'model', 'fitting']",0,"['is', 'it', 'necessary', 'to', 'convert', 'categorical', 'variable', 'into', 'numeric', 'variable', 'in', 'a', 'model', 'fitting']","['necessary', 'convert', 'categorical', 'variable', 'numeric', 'variable', 'model', 'fitting']",necessary convert categorical variable numeric variable model fitting,0.25,0.25,14,69,4.6,0,0,0,0,0,0,0,0
2104,laptop specs for analytics,Resources,laptop specs for analytics,"['laptop', 'specs', 'for', 'analytics']",0,"['laptop', 'spec', 'for', 'analytics']","['laptop', 'spec', 'analytics']",laptop spec analytics,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
2105,what are the d u v returned by svd in r,Tools,what are the d u v returned by svd in r,"['what', 'are', 'the', 'd', 'u', 'v', 'returned', 'by', 'svd', 'in', 'r']",0,"['what', 'are', 'the', 'd', 'u', 'v', 'returned', 'by', 'svd', 'in', 'r']","['u', 'v', 'returned', 'svd', 'r']",u v returned svd r,0.0,0.0,11,18,1.5,0,0,0,0,0,0,0,0
2106,defaulters prediction on next cycle,Techniques,defaulters prediction on next cycle,"['defaulters', 'prediction', 'on', 'next', 'cycle']",0,"['defaulter', 'prediction', 'on', 'next', 'cycle']","['defaulter', 'prediction', 'next', 'cycle']",defaulter prediction next cycle,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
2107,xgbimportance unable to plot sparsemodelmatrix,Misc,xgbimportance unable to plot sparsemodelmatrix,"['xgbimportance', 'unable', 'to', 'plot', 'sparsemodelmatrix']",0,"['xgbimportance', 'unable', 'to', 'plot', 'sparsemodelmatrix']","['xgbimportance', 'unable', 'plot', 'sparsemodelmatrix']",xgbimportance unable plot sparsemodelmatrix,-0.5,-0.5,5,43,7.166666666666667,0,0,0,0,0,0,0,0
2108,performing joins in sas,Techniques,performing joins in sas,"['performing', 'joins', 'in', 'sas']",0,"['performing', 'join', 'in', 'sa']","['performing', 'join', 'sa']",performing join sa,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
2109,can we retrieve information from facebook account based on mail id,Tools,can we retrieve information from facebook account based on mail id,"['can', 'we', 'retrieve', 'information', 'from', 'facebook', 'account', 'based', 'on', 'mail', 'id']",0,"['can', 'we', 'retrieve', 'information', 'from', 'facebook', 'account', 'based', 'on', 'mail', 'id']","['retrieve', 'information', 'facebook', 'account', 'based', 'mail', 'id']",retrieve information facebook account based mail id,0.0,0.0,11,51,4.25,0,0,0,0,0,0,0,0
2110,matchbox implementation in r,Tools,matchbox implementation in r,"['matchbox', 'implementation', 'in', 'r']",0,"['matchbox', 'implementation', 'in', 'r']","['matchbox', 'implementation', 'r']",matchbox implementation r,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
2111,how to get standardized coefficients from lm in r,Tools,how to get standardized coefficients from lm in r,"['how', 'to', 'get', 'standardized', 'coefficients', 'from', 'lm', 'in', 'r']",0,"['how', 'to', 'get', 'standardized', 'coefficient', 'from', 'lm', 'in', 'r']","['get', 'standardized', 'coefficient', 'lm', 'r']",get standardized coefficient lm r,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
2112,variable importance in inputs that caused a shift in the output variable,Techniques,variable importance in inputs that caused a shift in the output variable,"['variable', 'importance', 'in', 'inputs', 'that', 'caused', 'a', 'shift', 'in', 'the', 'output', 'variable']",0,"['variable', 'importance', 'in', 'input', 'that', 'caused', 'a', 'shift', 'in', 'the', 'output', 'variable']","['variable', 'importance', 'input', 'caused', 'shift', 'output', 'variable']",variable importance input caused shift output variable,0.0,0.0,12,54,4.153846153846154,0,0,0,0,0,0,0,0
2113,loan prediction   questions on applying the model,Hackathons,loan prediction   questions on applying the model,"['loan', 'prediction', 'questions', 'on', 'applying', 'the', 'model']",1,"['loan', 'prediction', 'question', 'on', 'applying', 'the', 'model']","['loan', 'prediction', 'question', 'applying', 'model']",loan prediction question applying model,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
2114,heres your learning path to master computer vision in ,Career,heres your learning path to master computer vision in ,"['heres', 'your', 'learning', 'path', 'to', 'master', 'computer', 'vision', 'in']",1,"['here', 'your', 'learning', 'path', 'to', 'master', 'computer', 'vision', 'in']","['learning', 'path', 'master', 'computer', 'vision']",learning path master computer vision,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
2115,change email of scubscription,Misc,change email of scubscription,"['change', 'email', 'of', 'scubscription']",0,"['change', 'email', 'of', 'scubscription']","['change', 'email', 'scubscription']",change email scubscription,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
2116,how to start learning machine learning,Techniques,how to start learning machine learning,"['how', 'to', 'start', 'learning', 'machine', 'learning']",0,"['how', 'to', 'start', 'learning', 'machine', 'learning']","['start', 'learning', 'machine', 'learning']",start learning machine learning,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
2117,evaluation score  date your data contest,Hackathons,evaluation score  date your data contest,"['evaluation', 'score', 'date', 'your', 'data', 'contest']",0,"['evaluation', 'score', 'date', 'your', 'data', 'contest']","['evaluation', 'score', 'date', 'data', 'contest']",evaluation score date data contest,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
2118,how to check accuracy of logistic regression model,Hackathons,how to check accuracy of logistic regression model,"['how', 'to', 'check', 'accuracy', 'of', 'logistic', 'regression', 'model']",0,"['how', 'to', 'check', 'accuracy', 'of', 'logistic', 'regression', 'model']","['check', 'accuracy', 'logistic', 'regression', 'model']",check accuracy logistic regression model,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
2119,minor error in beginner’s guide to build data visualisations on the web with djs,Misc,minor error in beginner’s guide to build data visualisations on the web with djs,"['minor', 'error', 'in', 'beginner', '’', 's', 'guide', 'to', 'build', 'data', 'visualisations', 'on', 'the', 'web', 'with', 'djs']",0,"['minor', 'error', 'in', 'beginner', '’', 's', 'guide', 'to', 'build', 'data', 'visualisation', 'on', 'the', 'web', 'with', 'dj']","['minor', 'error', 'beginner', '’', 'guide', 'build', 'data', 'visualisation', 'web', 'dj']",minor error beginner ’ guide build data visualisation web dj,-0.05,-0.05,16,60,3.5294117647058822,0,0,0,0,0,0,0,0
2120,is the output value of different statistic model logistic regression and xgboost carry the same meaning and measurement,Techniques,is the output value of different statistic model logistic regression and xgboost carry the same meaning and measurement,"['is', 'the', 'output', 'value', 'of', 'different', 'statistic', 'model', 'logistic', 'regression', 'and', 'xgboost', 'carry', 'the', 'same', 'meaning', 'and', 'measurement']",0,"['is', 'the', 'output', 'value', 'of', 'different', 'statistic', 'model', 'logistic', 'regression', 'and', 'xgboost', 'carry', 'the', 'same', 'meaning', 'and', 'measurement']","['output', 'value', 'different', 'statistic', 'model', 'logistic', 'regression', 'xgboost', 'carry', 'meaning', 'measurement']",output value different statistic model logistic regression xgboost carry meaning measurement,0.0,0.0,18,92,4.842105263157895,0,0,0,0,0,0,0,0
2121,how to interpret the plot of factors in r,Techniques,how to interpret the plot of factors in r,"['how', 'to', 'interpret', 'the', 'plot', 'of', 'factors', 'in', 'r']",0,"['how', 'to', 'interpret', 'the', 'plot', 'of', 'factor', 'in', 'r']","['interpret', 'plot', 'factor', 'r']",interpret plot factor r,0.0,0.0,9,23,2.3,0,0,0,0,0,0,0,0
2122,anyone read introduction to machine learning with python a guide for data scientists st edition,Resources,anyone read introduction to machine learning with python a guide for data scientists st edition,"['anyone', 'read', 'introduction', 'to', 'machine', 'learning', 'with', 'python', 'a', 'guide', 'for', 'data', 'scientists', 'st', 'edition']",0,"['anyone', 'read', 'introduction', 'to', 'machine', 'learning', 'with', 'python', 'a', 'guide', 'for', 'data', 'scientist', 'st', 'edition']","['anyone', 'read', 'introduction', 'machine', 'learning', 'python', 'guide', 'data', 'scientist', 'st', 'edition']",anyone read introduction machine learning python guide data scientist st edition,0.0,0.0,15,80,5.0,0,0,0,0,0,0,0,0
2123,difference between proc univariate and proc sgplot when producing a graph,Tools,difference between proc univariate and proc sgplot when producing a graph,"['difference', 'between', 'proc', 'univariate', 'and', 'proc', 'sgplot', 'when', 'producing', 'a', 'graph']",0,"['difference', 'between', 'proc', 'univariate', 'and', 'proc', 'sgplot', 'when', 'producing', 'a', 'graph']","['difference', 'proc', 'univariate', 'proc', 'sgplot', 'producing', 'graph']",difference proc univariate proc sgplot producing graph,0.0,0.0,11,54,4.5,0,0,0,0,0,0,0,0
2124,time series learning resources,Resources,time series learning resources,"['time', 'series', 'learning', 'resources']",0,"['time', 'series', 'learning', 'resource']","['time', 'series', 'learning', 'resource']",time series learning resource,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
2125,naive byes text classification gives different result from hand computed,Techniques,naive byes text classification gives different result from hand computed,"['naive', 'byes', 'text', 'classification', 'gives', 'different', 'result', 'from', 'hand', 'computed']",0,"['naive', 'bye', 'text', 'classification', 'give', 'different', 'result', 'from', 'hand', 'computed']","['naive', 'bye', 'text', 'classification', 'give', 'different', 'result', 'hand', 'computed']",naive bye text classification give different result hand computed,-0.15,-0.15,10,65,5.909090909090909,0,0,0,0,0,0,0,0
2126,download cheatsheet for data exploration using pandas in python,Resources,download cheatsheet for data exploration using pandas in python,"['download', 'cheatsheet', 'for', 'data', 'exploration', 'using', 'pandas', 'in', 'python']",0,"['download', 'cheatsheet', 'for', 'data', 'exploration', 'using', 'panda', 'in', 'python']","['download', 'cheatsheet', 'data', 'exploration', 'using', 'panda', 'python']",download cheatsheet data exploration using panda python,0.0,0.0,9,55,5.5,0,0,0,0,0,0,0,0
2127,analytics in startup vs a big company,Career,analytics in startup vs a big company,"['analytics', 'in', 'startup', 'vs', 'a', 'big', 'company']",0,"['analytics', 'in', 'startup', 'v', 'a', 'big', 'company']","['analytics', 'startup', 'v', 'big', 'company']",analytics startup v big company,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
2128,unable to load csv in r studion in macbook,Techniques,unable to load csv in r studion in macbook,"['unable', 'to', 'load', 'csv', 'in', 'r', 'studion', 'in', 'macbook']",0,"['unable', 'to', 'load', 'csv', 'in', 'r', 'studion', 'in', 'macbook']","['unable', 'load', 'csv', 'r', 'studion', 'macbook']",unable load csv r studion macbook,-0.5,-0.5,9,33,3.3,0,0,0,0,0,0,0,0
2129,convert the unknown file format to dataframe in r,Tools,convert the unknown file format to dataframe in r,"['convert', 'the', 'unknown', 'file', 'format', 'to', 'dataframe', 'in', 'r']",0,"['convert', 'the', 'unknown', 'file', 'format', 'to', 'dataframe', 'in', 'r']","['convert', 'unknown', 'file', 'format', 'dataframe', 'r']",convert unknown file format dataframe r,-0.1,-0.1,9,39,3.9,0,0,0,0,0,0,0,0
2130,how to find correlation among more than two categorical variables,Techniques,how to find correlation among more than two categorical variables,"['how', 'to', 'find', 'correlation', 'among', 'more', 'than', 'two', 'categorical', 'variables']",0,"['how', 'to', 'find', 'correlation', 'among', 'more', 'than', 'two', 'categorical', 'variable']","['find', 'correlation', 'among', 'two', 'categorical', 'variable']",find correlation among two categorical variable,0.5,0.0,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
2131,importing xgboost package in python,Tools,importing xgboost package in python,"['importing', 'xgboost', 'package', 'in', 'python']",0,"['importing', 'xgboost', 'package', 'in', 'python']","['importing', 'xgboost', 'package', 'python']",importing xgboost package python,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2132,reveal your approach  mlware recommendation engine problem,Hackathons,reveal your approach  mlware recommendation engine problem,"['reveal', 'your', 'approach', 'mlware', 'recommendation', 'engine', 'problem']",0,"['reveal', 'your', 'approach', 'mlware', 'recommendation', 'engine', 'problem']","['reveal', 'approach', 'mlware', 'recommendation', 'engine', 'problem']",reveal approach mlware recommendation engine problem,0.0,0.0,7,52,6.5,0,0,0,0,0,0,0,0
2133,extract date from text in pythontext mining,Techniques,extract date from text in pythontext mining,"['extract', 'date', 'from', 'text', 'in', 'pythontext', 'mining']",0,"['extract', 'date', 'from', 'text', 'in', 'pythontext', 'mining']","['extract', 'date', 'text', 'pythontext', 'mining']",extract date text pythontext mining,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
2134,starting career in data science,Career,starting career in data science,"['starting', 'career', 'in', 'data', 'science']",0,"['starting', 'career', 'in', 'data', 'science']","['starting', 'career', 'data', 'science']",starting career data science,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
2135,need help in solving data analysis problem,Techniques,need help in solving data analysis problem,"['need', 'help', 'in', 'solving', 'data', 'analysis', 'problem']",0,"['need', 'help', 'in', 'solving', 'data', 'analysis', 'problem']","['need', 'help', 'solving', 'data', 'analysis', 'problem']",need help solving data analysis problem,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
2136,what is word embedding and character embedding,Techniques,what is word embedding and character embedding,"['what', 'is', 'word', 'embedding', 'and', 'character', 'embedding']",0,"['what', 'is', 'word', 'embedding', 'and', 'character', 'embedding']","['word', 'embedding', 'character', 'embedding']",word embedding character embedding,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
2137,image segmentation for breaking image for individual object,Techniques,image segmentation for breaking image for individual object,"['image', 'segmentation', 'for', 'breaking', 'image', 'for', 'individual', 'object']",0,"['image', 'segmentation', 'for', 'breaking', 'image', 'for', 'individual', 'object']","['image', 'segmentation', 'breaking', 'image', 'individual', 'object']",image segmentation breaking image individual object,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
2138,how to calculate number of days between  dates in r,Tools,how to calculate number of days between  dates in r,"['how', 'to', 'calculate', 'number', 'of', 'days', 'between', 'dates', 'in', 'r']",1,"['how', 'to', 'calculate', 'number', 'of', 'day', 'between', 'date', 'in', 'r']","['calculate', 'number', 'day', 'date', 'r']",calculate number day date r,0.0,0.0,10,27,2.4545454545454546,0,0,0,0,0,0,0,0
2139,catboost parameter tuning,Techniques,catboost parameter tuning,"['catboost', 'parameter', 'tuning']",0,"['catboost', 'parameter', 'tuning']","['catboost', 'parameter', 'tuning']",catboost parameter tuning,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
2140,time series analysis python,Techniques,time series analysis python,"['time', 'series', 'analysis', 'python']",0,"['time', 'series', 'analysis', 'python']","['time', 'series', 'analysis', 'python']",time series analysis python,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
2141,how block bootstrap is different from normal bootstrap,Techniques,how block bootstrap is different from normal bootstrap,"['how', 'block', 'bootstrap', 'is', 'different', 'from', 'normal', 'bootstrap']",0,"['how', 'block', 'bootstrap', 'is', 'different', 'from', 'normal', 'bootstrap']","['block', 'bootstrap', 'different', 'normal', 'bootstrap']",block bootstrap different normal bootstrap,0.075,0.075,8,42,4.666666666666667,0,0,0,0,0,0,0,0
2142,difference between ai  ml and ds,Career,difference between ai  ml and ds,"['difference', 'between', 'ai', 'ml', 'and', 'ds']",0,"['difference', 'between', 'ai', 'ml', 'and', 'd']","['difference', 'ai', 'ml']",difference ai ml,0.0,0.0,6,16,2.2857142857142856,0,0,0,0,0,0,0,0
2143,tranforming the test set,Techniques,tranforming the test set,"['tranforming', 'the', 'test', 'set']",0,"['tranforming', 'the', 'test', 'set']","['tranforming', 'test', 'set']",tranforming test set,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
2144,getting started with reinforcement learning,Techniques,getting started with reinforcement learning,"['getting', 'started', 'with', 'reinforcement', 'learning']",0,"['getting', 'started', 'with', 'reinforcement', 'learning']","['getting', 'started', 'reinforcement', 'learning']",getting started reinforcement learning,0.0,0.0,5,38,6.333333333333333,0,0,0,0,0,0,0,0
2145,anyone experience with rapidminer,Tools,anyone experience with rapidminer,"['anyone', 'experience', 'with', 'rapidminer']",0,"['anyone', 'experience', 'with', 'rapidminer']","['anyone', 'experience', 'rapidminer']",anyone experience rapidminer,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
2146,should i use virtual machines for data science projects,Tools,should i use virtual machines for data science projects,"['should', 'i', 'use', 'virtual', 'machines', 'for', 'data', 'science', 'projects']",0,"['should', 'i', 'use', 'virtual', 'machine', 'for', 'data', 'science', 'project']","['use', 'virtual', 'machine', 'data', 'science', 'project']",use virtual machine data science project,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
2147,which analytics certificate program  isb or online course from university of california irvine extension,Career,which analytics certificate program  isb or online course from university of california irvine extension,"['which', 'analytics', 'certificate', 'program', 'isb', 'or', 'online', 'course', 'from', 'university', 'of', 'california', 'irvine', 'extension']",0,"['which', 'analytics', 'certificate', 'program', 'isb', 'or', 'online', 'course', 'from', 'university', 'of', 'california', 'irvine', 'extension']","['analytics', 'certificate', 'program', 'isb', 'online', 'course', 'university', 'california', 'irvine', 'extension']",analytics certificate program isb online course university california irvine extension,0.0,0.0,14,86,5.733333333333333,0,0,0,0,0,0,0,0
2148,what is the point of univariate and bivariate analysis,Techniques,what is the point of univariate and bivariate analysis,"['what', 'is', 'the', 'point', 'of', 'univariate', 'and', 'bivariate', 'analysis']",0,"['what', 'is', 'the', 'point', 'of', 'univariate', 'and', 'bivariate', 'analysis']","['point', 'univariate', 'bivariate', 'analysis']",point univariate bivariate analysis,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
2149,how to optimize prediction using keras package,Techniques,how to optimize prediction using keras package,"['how', 'to', 'optimize', 'prediction', 'using', 'keras', 'package']",0,"['how', 'to', 'optimize', 'prediction', 'using', 'kera', 'package']","['optimize', 'prediction', 'using', 'kera', 'package']",optimize prediction using kera package,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
2150,multilogloss metric in naivebayes,Techniques,multilogloss metric in naivebayes,"['multilogloss', 'metric', 'in', 'naivebayes']",0,"['multilogloss', 'metric', 'in', 'naivebayes']","['multilogloss', 'metric', 'naivebayes']",multilogloss metric naivebayes,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
2151,xgboost： hyperparameter tuning makes auc worse ,Techniques,xgboost： hyperparameter tuning makes auc worse ,"['xgboost：', 'hyperparameter', 'tuning', 'makes', 'auc', 'worse']",0,"['xgboost：', 'hyperparameter', 'tuning', 'make', 'auc', 'worse']","['xgboost：', 'hyperparameter', 'tuning', 'make', 'auc', 'worse']",xgboost： hyperparameter tuning make auc worse,-0.4,-0.4,6,45,6.428571428571429,0,0,0,0,0,0,0,0
2152,to determine probabilites for a given classification problem,Techniques,to determine probabilites for a given classification problem,"['to', 'determine', 'probabilites', 'for', 'a', 'given', 'classification', 'problem']",0,"['to', 'determine', 'probabilites', 'for', 'a', 'given', 'classification', 'problem']","['determine', 'probabilites', 'given', 'classification', 'problem']",determine probabilites given classification problem,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
2153,how to fine tune the regression model if it has high dimensional multi variate data,Techniques,how to fine tune the regression model if it has high dimensional multi variate data,"['how', 'to', 'fine', 'tune', 'the', 'regression', 'model', 'if', 'it', 'has', 'high', 'dimensional', 'multi', 'variate', 'data']",0,"['how', 'to', 'fine', 'tune', 'the', 'regression', 'model', 'if', 'it', 'ha', 'high', 'dimensional', 'multi', 'variate', 'data']","['fine', 'tune', 'regression', 'model', 'ha', 'high', 'dimensional', 'multi', 'variate', 'data']",fine tune regression model ha high dimensional multi variate data,0.2883333333333333,0.2883333333333333,15,65,4.0625,0,0,0,0,0,0,0,0
2154,what scores value signifies in factor analysis,Techniques,what scores value signifies in factor analysis,"['what', 'scores', 'value', 'signifies', 'in', 'factor', 'analysis']",0,"['what', 'score', 'value', 'signifies', 'in', 'factor', 'analysis']","['score', 'value', 'signifies', 'factor', 'analysis']",score value signifies factor analysis,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
2155,error in intablinea  a b  b h  h v  v untf  untf   plotnew has not been called yet,Techniques,error in intablinea  a b  b h  h v  v untf  untf   plotnew has not been called yet,"['error', 'in', 'intablinea', 'a', 'b', 'b', 'h', 'h', 'v', 'v', 'untf', 'untf', 'plotnew', 'has', 'not', 'been', 'called', 'yet']",0,"['error', 'in', 'intablinea', 'a', 'b', 'b', 'h', 'h', 'v', 'v', 'untf', 'untf', 'plotnew', 'ha', 'not', 'been', 'called', 'yet']","['error', 'intablinea', 'b', 'b', 'h', 'h', 'v', 'v', 'untf', 'untf', 'plotnew', 'ha', 'called', 'yet']",error intablinea b b h h v v untf untf plotnew ha called yet,0.0,0.0,18,60,3.1578947368421053,0,0,0,0,0,0,0,0
2156,how can we create word cloud in qlikview,Tools,how can we create word cloud in qlikview,"['how', 'can', 'we', 'create', 'word', 'cloud', 'in', 'qlikview']",0,"['how', 'can', 'we', 'create', 'word', 'cloud', 'in', 'qlikview']","['create', 'word', 'cloud', 'qlikview']",create word cloud qlikview,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
2157,using smote function to handle imbalanced data set,Techniques,using smote function to handle imbalanced data set,"['using', 'smote', 'function', 'to', 'handle', 'imbalanced', 'data', 'set']",0,"['using', 'smote', 'function', 'to', 'handle', 'imbalanced', 'data', 'set']","['using', 'smote', 'function', 'handle', 'imbalanced', 'data', 'set']",using smote function handle imbalanced data set,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
2158,ncessary skills for ms in data science,Career,ncessary skills for ms in data science,"['ncessary', 'skills', 'for', 'ms', 'in', 'data', 'science']",0,"['ncessary', 'skill', 'for', 'm', 'in', 'data', 'science']","['ncessary', 'skill', 'data', 'science']",ncessary skill data science,0.0,0.0,7,27,3.375,0,0,0,0,0,0,0,0
2159,kindly guide me,Career,kindly guide me,"['kindly', 'guide', 'me']",0,"['kindly', 'guide', 'me']","['kindly', 'guide']",kindly guide,0.6,0.6,3,12,3.0,0,0,0,0,0,0,0,0
2160,problem to get the  of participation for the accumulated data,Techniques,problem to get the  of participation for the accumulated data,"['problem', 'to', 'get', 'the', 'of', 'participation', 'for', 'the', 'accumulated', 'data']",0,"['problem', 'to', 'get', 'the', 'of', 'participation', 'for', 'the', 'accumulated', 'data']","['problem', 'get', 'participation', 'accumulated', 'data']",problem get participation accumulated data,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
2161,career shift from model validation to model development,Career,career shift from model validation to model development,"['career', 'shift', 'from', 'model', 'validation', 'to', 'model', 'development']",0,"['career', 'shift', 'from', 'model', 'validation', 'to', 'model', 'development']","['career', 'shift', 'model', 'validation', 'model', 'development']",career shift model validation model development,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
2162,data engineer to become a data scientist,Career,data engineer to become a data scientist,"['data', 'engineer', 'to', 'become', 'a', 'data', 'scientist']",0,"['data', 'engineer', 'to', 'become', 'a', 'data', 'scientist']","['data', 'engineer', 'become', 'data', 'scientist']",data engineer become data scientist,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
2163,ridge regression,Techniques,ridge regression,"['ridge', 'regression']",0,"['ridge', 'regression']","['ridge', 'regression']",ridge regression,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
2164,predicted class of the datapoint,Tools,predicted class of the datapoint,"['predicted', 'class', 'of', 'the', 'datapoint']",0,"['predicted', 'class', 'of', 'the', 'datapoint']","['predicted', 'class', 'datapoint']",predicted class datapoint,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
2165,data cleaning before using arima,Techniques,data cleaning before using arima,"['data', 'cleaning', 'before', 'using', 'arima']",0,"['data', 'cleaning', 'before', 'using', 'arima']","['data', 'cleaning', 'using', 'arima']",data cleaning using arima,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
2166,how to apply different aggregations for different columns,Techniques,how to apply different aggregations for different columns,"['how', 'to', 'apply', 'different', 'aggregations', 'for', 'different', 'columns']",0,"['how', 'to', 'apply', 'different', 'aggregation', 'for', 'different', 'column']","['apply', 'different', 'aggregation', 'different', 'column']",apply different aggregation different column,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
2167,what does the weight option do in glmboost in r,Tools,what does the weight option do in glmboost in r,"['what', 'does', 'the', 'weight', 'option', 'do', 'in', 'glmboost', 'in', 'r']",0,"['what', 'doe', 'the', 'weight', 'option', 'do', 'in', 'glmboost', 'in', 'r']","['doe', 'weight', 'option', 'glmboost', 'r']",doe weight option glmboost r,0.0,0.0,10,28,2.5454545454545454,0,0,0,0,0,0,0,0
2168,how to identify which variables are important in a large dataset,Hackathons,how to identify which variables are important in a large dataset,"['how', 'to', 'identify', 'which', 'variables', 'are', 'important', 'in', 'a', 'large', 'dataset']",0,"['how', 'to', 'identify', 'which', 'variable', 'are', 'important', 'in', 'a', 'large', 'dataset']","['identify', 'variable', 'important', 'large', 'dataset']",identify variable important large dataset,0.3071428571428571,0.3071428571428571,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
2169,issue with rcurlsoap request with attachment,Tools,issue with rcurlsoap request with attachment,"['issue', 'with', 'rcurlsoap', 'request', 'with', 'attachment']",0,"['issue', 'with', 'rcurlsoap', 'request', 'with', 'attachment']","['issue', 'rcurlsoap', 'request', 'attachment']",issue rcurlsoap request attachment,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
2170,why i am not getting a job even after r  sas knowledge,Career,why i am not getting a job even after r  sas knowledge,"['why', 'i', 'am', 'not', 'getting', 'a', 'job', 'even', 'after', 'r', 'sas', 'knowledge']",0,"['why', 'i', 'am', 'not', 'getting', 'a', 'job', 'even', 'after', 'r', 'sa', 'knowledge']","['getting', 'job', 'even', 'r', 'sa', 'knowledge']",getting job even r sa knowledge,0.0,0.0,12,31,2.3846153846153846,0,0,0,0,0,0,0,0
2171,will analytics be automated five years down the line,Misc,will analytics be automated five years down the line,"['will', 'analytics', 'be', 'automated', 'five', 'years', 'down', 'the', 'line']",0,"['will', 'analytics', 'be', 'automated', 'five', 'year', 'down', 'the', 'line']","['analytics', 'automated', 'five', 'year', 'line']",analytics automated five year line,-0.1555555555555555,0.0,9,34,3.4,0,0,0,0,0,0,0,0
2172,need help to develop an recommendation engine in python,Techniques,need help to develop an recommendation engine in python,"['need', 'help', 'to', 'develop', 'an', 'recommendation', 'engine', 'in', 'python']",0,"['need', 'help', 'to', 'develop', 'an', 'recommendation', 'engine', 'in', 'python']","['need', 'help', 'develop', 'recommendation', 'engine', 'python']",need help develop recommendation engine python,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
2173,wns hackathon solutions by top finishers,Hackathons,wns hackathon solutions by top finishers,"['wns', 'hackathon', 'solutions', 'by', 'top', 'finishers']",0,"['wns', 'hackathon', 'solution', 'by', 'top', 'finisher']","['wns', 'hackathon', 'solution', 'top', 'finisher']",wns hackathon solution top finisher,0.5,0.5,6,35,5.0,0,0,0,0,0,0,0,0
2174,the metric accuracy was not in the result set roc will be used instead  parameter tuning caret,Techniques,the metric accuracy was not in the result set roc will be used instead  parameter tuning caret,"['the', 'metric', 'accuracy', 'was', 'not', 'in', 'the', 'result', 'set', 'roc', 'will', 'be', 'used', 'instead', 'parameter', 'tuning', 'caret']",0,"['the', 'metric', 'accuracy', 'wa', 'not', 'in', 'the', 'result', 'set', 'roc', 'will', 'be', 'used', 'instead', 'parameter', 'tuning', 'caret']","['metric', 'accuracy', 'wa', 'result', 'set', 'roc', 'used', 'instead', 'parameter', 'tuning', 'caret']",metric accuracy wa result set roc used instead parameter tuning caret,0.0,0.0,17,69,3.8333333333333335,0,0,0,0,0,0,0,0
2175,sas or power bi or power bi with r,Tools,sas or power bi or power bi with r,"['sas', 'or', 'power', 'bi', 'or', 'power', 'bi', 'with', 'r']",0,"['sa', 'or', 'power', 'bi', 'or', 'power', 'bi', 'with', 'r']","['sa', 'power', 'bi', 'power', 'bi', 'r']",sa power bi power bi r,0.0,0.0,9,22,2.2,0,0,0,0,0,0,0,0
2176,textmining with english  hindi words,Techniques,textmining with english  hindi words,"['textmining', 'with', 'english', 'hindi', 'words']",0,"['textmining', 'with', 'english', 'hindi', 'word']","['textmining', 'english', 'hindi', 'word']",textmining english hindi word,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
2177,how to separate values of multiple class in r,Tools,how to separate values of multiple class in r,"['how', 'to', 'separate', 'values', 'of', 'multiple', 'class', 'in', 'r']",0,"['how', 'to', 'separate', 'value', 'of', 'multiple', 'class', 'in', 'r']","['separate', 'value', 'multiple', 'class', 'r']",separate value multiple class r,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
2178,copy of files from one hdfs to another,Techniques,copy of files from one hdfs to another,"['copy', 'of', 'files', 'from', 'one', 'hdfs', 'to', 'another']",0,"['copy', 'of', 'file', 'from', 'one', 'hdfs', 'to', 'another']","['copy', 'file', 'one', 'hdfs', 'another']",copy file one hdfs another,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
2179,what are the differences between sumproduct and sumifs functions in excel,Tools,what are the differences between sumproduct and sumifs functions in excel,"['what', 'are', 'the', 'differences', 'between', 'sumproduct', 'and', 'sumifs', 'functions', 'in', 'excel']",0,"['what', 'are', 'the', 'difference', 'between', 'sumproduct', 'and', 'sumifs', 'function', 'in', 'excel']","['difference', 'sumproduct', 'sumifs', 'function', 'excel']",difference sumproduct sumifs function excel,0.0,0.0,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
2180,please help to debug python code,Tools,please help to debug python code,"['please', 'help', 'to', 'debug', 'python', 'code']",0,"['please', 'help', 'to', 'debug', 'python', 'code']","['please', 'help', 'debug', 'python', 'code']",please help debug python code,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
2181,data structure of machine learning model,Techniques,data structure of machine learning model,"['data', 'structure', 'of', 'machine', 'learning', 'model']",0,"['data', 'structure', 'of', 'machine', 'learning', 'model']","['data', 'structure', 'machine', 'learning', 'model']",data structure machine learning model,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
2182,data visualisation in r,Tools,data visualisation in r,"['data', 'visualisation', 'in', 'r']",0,"['data', 'visualisation', 'in', 'r']","['data', 'visualisation', 'r']",data visualisation r,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
2183,mnist csv dataset,Resources,mnist csv dataset,"['mnist', 'csv', 'dataset']",0,"['mnist', 'csv', 'dataset']","['mnist', 'csv', 'dataset']",mnist csv dataset,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
2184,interpreting residual plot of lm model for bigmart problem,Techniques,interpreting residual plot of lm model for bigmart problem,"['interpreting', 'residual', 'plot', 'of', 'lm', 'model', 'for', 'bigmart', 'problem']",0,"['interpreting', 'residual', 'plot', 'of', 'lm', 'model', 'for', 'bigmart', 'problem']","['interpreting', 'residual', 'plot', 'lm', 'model', 'bigmart', 'problem']",interpreting residual plot lm model bigmart problem,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
2185,how r performs element wise comparison,Tools,how r performs element wise comparison,"['how', 'r', 'performs', 'element', 'wise', 'comparison']",0,"['how', 'r', 'performs', 'element', 'wise', 'comparison']","['r', 'performs', 'element', 'wise', 'comparison']",r performs element wise comparison,0.7,0.7,6,34,4.857142857142857,0,0,0,0,0,0,0,0
2186,iris submission,Hackathons,iris submission,"['iris', 'submission']",0,"['iris', 'submission']","['iris', 'submission']",iris submission,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
2187,icc cricket world cup  prediction game  github,Techniques,icc cricket world cup  prediction game  github,"['icc', 'cricket', 'world', 'cup', 'prediction', 'game', 'github']",1,"['icc', 'cricket', 'world', 'cup', 'prediction', 'game', 'github']","['icc', 'cricket', 'world', 'cup', 'prediction', 'game', 'github']",icc cricket world cup prediction game github,-0.4,-0.4,7,44,5.5,0,0,0,0,0,0,0,0
2188,artificial intelligence machine learning and big data  a report,Career,artificial intelligence machine learning and big data  a report,"['artificial', 'intelligence', 'machine', 'learning', 'and', 'big', 'data', 'a', 'report']",0,"['artificial', 'intelligence', 'machine', 'learning', 'and', 'big', 'data', 'a', 'report']","['artificial', 'intelligence', 'machine', 'learning', 'big', 'data', 'report']",artificial intelligence machine learning big data report,-0.3,-0.3,9,56,5.6,0,0,0,0,0,0,0,0
2189,treatment of outliers,Techniques,treatment of outliers,"['treatment', 'of', 'outliers']",0,"['treatment', 'of', 'outlier']","['treatment', 'outlier']",treatment outlier,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
2190,how can i automate the classification of feedback or complaint,Techniques,how can i automate the classification of feedback or complaint,"['how', 'can', 'i', 'automate', 'the', 'classification', 'of', 'feedback', 'or', 'complaint']",0,"['how', 'can', 'i', 'automate', 'the', 'classification', 'of', 'feedback', 'or', 'complaint']","['automate', 'classification', 'feedback', 'complaint']",automate classification feedback complaint,-0.3,-0.3,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
2191,data mining with rattle,Tools,data mining with rattle,"['data', 'mining', 'with', 'rattle']",0,"['data', 'mining', 'with', 'rattle']","['data', 'mining', 'rattle']",data mining rattle,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
2192,how to delete a column from a data frame in r,Tools,how to delete a column from a data frame in r,"['how', 'to', 'delete', 'a', 'column', 'from', 'a', 'data', 'frame', 'in', 'r']",0,"['how', 'to', 'delete', 'a', 'column', 'from', 'a', 'data', 'frame', 'in', 'r']","['delete', 'column', 'data', 'frame', 'r']",delete column data frame r,0.0,0.0,11,26,2.1666666666666665,0,0,0,0,0,0,0,0
2193,difference between map apply and applymap in pandas,Tools,difference between map apply and applymap in pandas,"['difference', 'between', 'map', 'apply', 'and', 'applymap', 'in', 'pandas']",0,"['difference', 'between', 'map', 'apply', 'and', 'applymap', 'in', 'panda']","['difference', 'map', 'apply', 'applymap', 'panda']",difference map apply applymap panda,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
2194,how can i remove duplicate values from data set in sas,Tools,how can i remove duplicate values from data set in sas,"['how', 'can', 'i', 'remove', 'duplicate', 'values', 'from', 'data', 'set', 'in', 'sas']",0,"['how', 'can', 'i', 'remove', 'duplicate', 'value', 'from', 'data', 'set', 'in', 'sa']","['remove', 'duplicate', 'value', 'data', 'set', 'sa']",remove duplicate value data set sa,0.0,0.0,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
2195,data cleaning decision trees,Techniques,data cleaning decision trees,"['data', 'cleaning', 'decision', 'trees']",0,"['data', 'cleaning', 'decision', 'tree']","['data', 'cleaning', 'decision', 'tree']",data cleaning decision tree,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
2196,restricted boltzmenn machine,Techniques,restricted boltzmenn machine,"['restricted', 'boltzmenn', 'machine']",0,"['restricted', 'boltzmenn', 'machine']","['restricted', 'boltzmenn', 'machine']",restricted boltzmenn machine,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
2197,how to update probabilities,Techniques,how to update probabilities,"['how', 'to', 'update', 'probabilities']",0,"['how', 'to', 'update', 'probability']","['update', 'probability']",update probability,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
2198,feature selection and dimensionality reduction,Techniques,feature selection and dimensionality reduction,"['feature', 'selection', 'and', 'dimensionality', 'reduction']",0,"['feature', 'selection', 'and', 'dimensionality', 'reduction']","['feature', 'selection', 'dimensionality', 'reduction']",feature selection dimensionality reduction,0.0,0.0,5,42,7.0,0,0,0,0,0,0,0,0
2199,plotting two plots in a single row using ggplot in r,Tools,plotting two plots in a single row using ggplot in r,"['plotting', 'two', 'plots', 'in', 'a', 'single', 'row', 'using', 'ggplot', 'in', 'r']",0,"['plotting', 'two', 'plot', 'in', 'a', 'single', 'row', 'using', 'ggplot', 'in', 'r']","['plotting', 'two', 'plot', 'single', 'row', 'using', 'ggplot', 'r']",plotting two plot single row using ggplot r,-0.0714285714285714,-0.0714285714285714,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
2201,whether to go for r or python or sas first as beginner,Career,whether to go for r or python or sas first as beginner,"['whether', 'to', 'go', 'for', 'r', 'or', 'python', 'or', 'sas', 'first', 'as', 'beginner']",0,"['whether', 'to', 'go', 'for', 'r', 'or', 'python', 'or', 'sa', 'first', 'a', 'beginner']","['whether', 'go', 'r', 'python', 'sa', 'first', 'beginner']",whether go r python sa first beginner,0.25,0.25,12,37,2.8461538461538463,0,0,0,0,0,0,0,0
2202,find a algorithm to apply my prevention system to predict the incidents,Techniques,find a algorithm to apply my prevention system to predict the incidents,"['find', 'a', 'algorithm', 'to', 'apply', 'my', 'prevention', 'system', 'to', 'predict', 'the', 'incidents']",0,"['find', 'a', 'algorithm', 'to', 'apply', 'my', 'prevention', 'system', 'to', 'predict', 'the', 'incident']","['find', 'algorithm', 'apply', 'prevention', 'system', 'predict', 'incident']",find algorithm apply prevention system predict incident,0.0,0.0,12,55,4.230769230769231,0,0,0,0,0,0,0,0
2203,mckinsey analytics online hackathon,Hackathons,mckinsey analytics online hackathon,"['mckinsey', 'analytics', 'online', 'hackathon']",0,"['mckinsey', 'analytics', 'online', 'hackathon']","['mckinsey', 'analytics', 'online', 'hackathon']",mckinsey analytics online hackathon,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
2204,treatment for missing values,Techniques,treatment for missing values,"['treatment', 'for', 'missing', 'values']",0,"['treatment', 'for', 'missing', 'value']","['treatment', 'missing', 'value']",treatment missing value,-0.2,-0.2,4,23,4.6,0,0,0,0,0,0,0,0
2205,ensemble model doubt from article how to build ensemble models in machine learning with code in r,Techniques,ensemble model doubt from article how to build ensemble models in machine learning with code in r,"['ensemble', 'model', 'doubt', 'from', 'article', 'how', 'to', 'build', 'ensemble', 'models', 'in', 'machine', 'learning', 'with', 'code', 'in', 'r']",0,"['ensemble', 'model', 'doubt', 'from', 'article', 'how', 'to', 'build', 'ensemble', 'model', 'in', 'machine', 'learning', 'with', 'code', 'in', 'r']","['ensemble', 'model', 'doubt', 'article', 'build', 'ensemble', 'model', 'machine', 'learning', 'code', 'r']",ensemble model doubt article build ensemble model machine learning code r,0.0,0.0,17,73,4.055555555555555,0,0,0,0,0,0,0,0
2206,how wordvec work,Techniques,how wordvec work,"['how', 'wordvec', 'work']",0,"['how', 'wordvec', 'work']","['wordvec', 'work']",wordvec work,0.0,0.0,3,12,3.0,0,0,0,0,0,0,0,0
2207,meet ups for data science,Resources,meet ups for data science,"['meet', 'ups', 'for', 'data', 'science']",0,"['meet', 'ups', 'for', 'data', 'science']","['meet', 'ups', 'data', 'science']",meet ups data science,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
2208,should i go for sas certification,Tools,should i go for sas certification,"['should', 'i', 'go', 'for', 'sas', 'certification']",0,"['should', 'i', 'go', 'for', 'sa', 'certification']","['go', 'sa', 'certification']",go sa certification,0.0,0.0,6,19,2.7142857142857144,0,0,0,0,0,0,0,0
2209,analytics in energy sector  hvac building optimization,Resources,analytics in energy sector  hvac building optimization,"['analytics', 'in', 'energy', 'sector', 'hvac', 'building', 'optimization']",0,"['analytics', 'in', 'energy', 'sector', 'hvac', 'building', 'optimization']","['analytics', 'energy', 'sector', 'hvac', 'building', 'optimization']",analytics energy sector hvac building optimization,0.0,0.0,7,50,6.25,0,0,0,0,0,0,0,0
2210,most frequent factor in r,Tools,most frequent factor in r,"['most', 'frequent', 'factor', 'in', 'r']",0,"['most', 'frequent', 'factor', 'in', 'r']","['frequent', 'factor', 'r']",frequent factor r,0.3,0.1,5,17,2.8333333333333335,0,0,0,0,0,0,0,0
2211,how to move to the next sheet in r while exporting,Tools,how to move to the next sheet in r while exporting,"['how', 'to', 'move', 'to', 'the', 'next', 'sheet', 'in', 'r', 'while', 'exporting']",0,"['how', 'to', 'move', 'to', 'the', 'next', 'sheet', 'in', 'r', 'while', 'exporting']","['move', 'next', 'sheet', 'r', 'exporting']",move next sheet r exporting,0.0,0.0,11,27,2.25,0,0,0,0,0,0,0,0
2212,lift gain calculation,Techniques,lift gain calculation,"['lift', 'gain', 'calculation']",0,"['lift', 'gain', 'calculation']","['lift', 'gain', 'calculation']",lift gain calculation,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
2213,which model we use for multilabel class prediction,Techniques,which model we use for multilabel class prediction,"['which', 'model', 'we', 'use', 'for', 'multilabel', 'class', 'prediction']",0,"['which', 'model', 'we', 'use', 'for', 'multilabel', 'class', 'prediction']","['model', 'use', 'multilabel', 'class', 'prediction']",model use multilabel class prediction,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
2214,why should we use lstm for handwritten recognition,Techniques,why should we use lstm for handwritten recognition,"['why', 'should', 'we', 'use', 'lstm', 'for', 'handwritten', 'recognition']",0,"['why', 'should', 'we', 'use', 'lstm', 'for', 'handwritten', 'recognition']","['use', 'lstm', 'handwritten', 'recognition']",use lstm handwritten recognition,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
2215,iris dataset eda for beginners,Techniques,iris dataset eda for beginners,"['iris', 'dataset', 'eda', 'for', 'beginners']",0,"['iris', 'dataset', 'eda', 'for', 'beginner']","['iris', 'dataset', 'eda', 'beginner']",iris dataset eda beginner,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
2216,looking for your guidance for prepartion of base sas certification,Tools,looking for your guidance for prepartion of base sas certification,"['looking', 'for', 'your', 'guidance', 'for', 'prepartion', 'of', 'base', 'sas', 'certification']",0,"['looking', 'for', 'your', 'guidance', 'for', 'prepartion', 'of', 'base', 'sa', 'certification']","['looking', 'guidance', 'prepartion', 'base', 'sa', 'certification']",looking guidance prepartion base sa certification,-0.8,-0.8,10,49,4.454545454545454,0,0,0,0,0,0,0,0
2217,getting error while downloading a csv file with google colab,Misc,getting error while downloading a csv file with google colab,"['getting', 'error', 'while', 'downloading', 'a', 'csv', 'file', 'with', 'google', 'colab']",0,"['getting', 'error', 'while', 'downloading', 'a', 'csv', 'file', 'with', 'google', 'colab']","['getting', 'error', 'downloading', 'csv', 'file', 'google', 'colab']",getting error downloading csv file google colab,0.0,0.0,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
2218,r data manipulation to find out driver staticmoving status from lat long from other table,Tools,r data manipulation to find out driver staticmoving status from lat long from other table,"['r', 'data', 'manipulation', 'to', 'find', 'out', 'driver', 'staticmoving', 'status', 'from', 'lat', 'long', 'from', 'other', 'table']",0,"['r', 'data', 'manipulation', 'to', 'find', 'out', 'driver', 'staticmoving', 'status', 'from', 'lat', 'long', 'from', 'other', 'table']","['r', 'data', 'manipulation', 'find', 'driver', 'staticmoving', 'status', 'lat', 'long', 'table']",r data manipulation find driver staticmoving status lat long table,-0.0875,-0.05,15,66,4.125,0,0,0,0,0,0,0,0
2219,what is difference between e and klar package for naive bayes in r,Tools,what is difference between e and klar package for naive bayes in r,"['what', 'is', 'difference', 'between', 'e', 'and', 'klar', 'package', 'for', 'naive', 'bayes', 'in', 'r']",0,"['what', 'is', 'difference', 'between', 'e', 'and', 'klar', 'package', 'for', 'naive', 'bayes', 'in', 'r']","['difference', 'e', 'klar', 'package', 'naive', 'bayes', 'r']",difference e klar package naive bayes r,-0.3,-0.3,13,39,2.7857142857142856,0,0,0,0,0,0,0,0
2220,plotting percentages in pandas,Techniques,plotting percentages in pandas,"['plotting', 'percentages', 'in', 'pandas']",0,"['plotting', 'percentage', 'in', 'panda']","['plotting', 'percentage', 'panda']",plotting percentage panda,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
2221,switching from r to python,Tools,switching from r to python,"['switching', 'from', 'r', 'to', 'python']",0,"['switching', 'from', 'r', 'to', 'python']","['switching', 'r', 'python']",switching r python,0.0,0.0,5,18,3.0,0,0,0,0,0,0,0,0
2222,how to scrape all the data from dl table in manner waylikedt dd,Tools,how to scrape all the data from dl table in manner waylikedt dd,"['how', 'to', 'scrape', 'all', 'the', 'data', 'from', 'dl', 'table', 'in', 'manner', 'waylikedt', 'dd']",0,"['how', 'to', 'scrape', 'all', 'the', 'data', 'from', 'dl', 'table', 'in', 'manner', 'waylikedt', 'dd']","['scrape', 'data', 'dl', 'table', 'manner', 'waylikedt', 'dd']",scrape data dl table manner waylikedt dd,0.0,0.0,13,40,2.857142857142857,0,0,0,0,0,0,0,0
2223,how to interpret clusters after doing latent semantic analysis on review data,Techniques,how to interpret clusters after doing latent semantic analysis on review data,"['how', 'to', 'interpret', 'clusters', 'after', 'doing', 'latent', 'semantic', 'analysis', 'on', 'review', 'data']",0,"['how', 'to', 'interpret', 'cluster', 'after', 'doing', 'latent', 'semantic', 'analysis', 'on', 'review', 'data']","['interpret', 'cluster', 'latent', 'semantic', 'analysis', 'review', 'data']",interpret cluster latent semantic analysis review data,0.0,0.0,12,54,4.153846153846154,0,0,0,0,0,0,0,0
2224,how do you split a list into evenly sized chunks in python,Tools,how do you split a list into evenly sized chunks in python,"['how', 'do', 'you', 'split', 'a', 'list', 'into', 'evenly', 'sized', 'chunks', 'in', 'python']",0,"['how', 'do', 'you', 'split', 'a', 'list', 'into', 'evenly', 'sized', 'chunk', 'in', 'python']","['split', 'list', 'evenly', 'sized', 'chunk', 'python']",split list evenly sized chunk python,0.0,0.0,12,36,2.769230769230769,0,0,0,0,0,0,0,0
2225,apache spark course,Resources,apache spark course,"['apache', 'spark', 'course']",0,"['apache', 'spark', 'course']","['apache', 'spark', 'course']",apache spark course,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
2226,cannot allocate vector size,Tools,cannot allocate vector size,"['can', 'not', 'allocate', 'vector', 'size']",0,"['can', 'not', 'allocate', 'vector', 'size']","['allocate', 'vector', 'size']",allocate vector size,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
2227,regarding automated feature engineering article,Other,regarding automated feature engineering article,"['regarding', 'automated', 'feature', 'engineering', 'article']",0,"['regarding', 'automated', 'feature', 'engineering', 'article']","['regarding', 'automated', 'feature', 'engineering', 'article']",regarding automated feature engineering article,0.0,0.0,5,47,7.833333333333333,0,0,0,0,0,0,0,0
2228,supervised label data preparation,Techniques,supervised label data preparation,"['supervised', 'label', 'data', 'preparation']",0,"['supervised', 'label', 'data', 'preparation']","['supervised', 'label', 'data', 'preparation']",supervised label data preparation,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
2229,conversion of data class from factor to ts,Techniques,conversion of data class from factor to ts,"['conversion', 'of', 'data', 'class', 'from', 'factor', 'to', 'ts']",0,"['conversion', 'of', 'data', 'class', 'from', 'factor', 'to', 't']","['conversion', 'data', 'class', 'factor']",conversion data class factor,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
2230,building a real time geo location mapping of surge price of uber cabs,Techniques,building a real time geo location mapping of surge price of uber cabs,"['building', 'a', 'real', 'time', 'geo', 'location', 'mapping', 'of', 'surge', 'price', 'of', 'uber', 'cabs']",0,"['building', 'a', 'real', 'time', 'geo', 'location', 'mapping', 'of', 'surge', 'price', 'of', 'uber', 'cab']","['building', 'real', 'time', 'geo', 'location', 'mapping', 'surge', 'price', 'uber', 'cab']",building real time geo location mapping surge price uber cab,0.2,0.2,13,60,4.285714285714286,0,0,0,0,0,0,0,0
2231,what are the reason when test error is less than train error,Techniques,what are the reason when test error is less than train error,"['what', 'are', 'the', 'reason', 'when', 'test', 'error', 'is', 'less', 'than', 'train', 'error']",0,"['what', 'are', 'the', 'reason', 'when', 'test', 'error', 'is', 'le', 'than', 'train', 'error']","['reason', 'test', 'error', 'le', 'train', 'error']",reason test error le train error,-0.1666666666666666,0.0,12,32,2.4615384615384617,0,0,0,0,0,0,0,0
2232,discussion for quizzes in article hands on with deep learning – solution for age detection practice problem,Hackathons,discussion for quizzes in article hands on with deep learning – solution for age detection practice problem,"['discussion', 'for', 'quizzes', 'in', 'article', 'hands', 'on', 'with', 'deep', 'learning', '–', 'solution', 'for', 'age', 'detection', 'practice', 'problem']",0,"['discussion', 'for', 'quiz', 'in', 'article', 'hand', 'on', 'with', 'deep', 'learning', '–', 'solution', 'for', 'age', 'detection', 'practice', 'problem']","['discussion', 'quiz', 'article', 'hand', 'deep', 'learning', '–', 'solution', 'age', 'detection', 'practice', 'problem']",discussion quiz article hand deep learning – solution age detection practice problem,0.0,0.0,17,84,4.666666666666667,0,0,0,0,0,0,0,0
2233,make a cluster of id holding null values using dbscan,Tools,make a cluster of id holding null values using dbscan,"['make', 'a', 'cluster', 'of', 'id', 'holding', 'null', 'values', 'using', 'dbscan']",0,"['make', 'a', 'cluster', 'of', 'id', 'holding', 'null', 'value', 'using', 'dbscan']","['make', 'cluster', 'id', 'holding', 'null', 'value', 'using', 'dbscan']",make cluster id holding null value using dbscan,0.0,0.0,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
2234,how do i use the parameters after i have found them using multiple linear regression,Techniques,how do i use the parameters after i have found them using multiple linear regression,"['how', 'do', 'i', 'use', 'the', 'parameters', 'after', 'i', 'have', 'found', 'them', 'using', 'multiple', 'linear', 'regression']",0,"['how', 'do', 'i', 'use', 'the', 'parameter', 'after', 'i', 'have', 'found', 'them', 'using', 'multiple', 'linear', 'regression']","['use', 'parameter', 'found', 'using', 'multiple', 'linear', 'regression']",use parameter found using multiple linear regression,0.0,0.0,15,52,3.25,0,0,0,0,0,0,0,0
2235,open sdk for tensorflow,Tools,open sdk for tensorflow,"['open', 'sdk', 'for', 'tensorflow']",0,"['open', 'sdk', 'for', 'tensorflow']","['open', 'sdk', 'tensorflow']",open sdk tensorflow,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
2236,is data feature scaling needed for input features in logistic regression,Techniques,is data feature scaling needed for input features in logistic regression,"['is', 'data', 'feature', 'scaling', 'needed', 'for', 'input', 'features', 'in', 'logistic', 'regression']",0,"['is', 'data', 'feature', 'scaling', 'needed', 'for', 'input', 'feature', 'in', 'logistic', 'regression']","['data', 'feature', 'scaling', 'needed', 'input', 'feature', 'logistic', 'regression']",data feature scaling needed input feature logistic regression,0.0,0.0,11,61,5.083333333333333,0,0,0,0,0,0,0,0
2237,how to extract data between two whitespaces in r using gsub,Hackathons,how to extract data between two whitespaces in r using gsub,"['how', 'to', 'extract', 'data', 'between', 'two', 'whitespaces', 'in', 'r', 'using', 'gsub']",0,"['how', 'to', 'extract', 'data', 'between', 'two', 'whitespaces', 'in', 'r', 'using', 'gsub']","['extract', 'data', 'two', 'whitespaces', 'r', 'using', 'gsub']",extract data two whitespaces r using gsub,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
2238,plotting data on y axis,Tools,plotting data on y axis,"['plotting', 'data', 'on', 'y', 'axis']",0,"['plotting', 'data', 'on', 'y', 'axis']","['plotting', 'data', 'axis']",plotting data axis,0.0,0.0,5,18,3.0,0,0,0,0,0,0,0,0
2239,how to paste two character vector in r,Tools,how to paste two character vector in r,"['how', 'to', 'paste', 'two', 'character', 'vector', 'in', 'r']",0,"['how', 'to', 'paste', 'two', 'character', 'vector', 'in', 'r']","['paste', 'two', 'character', 'vector', 'r']",paste two character vector r,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
2240,how do i receive avro messages through kafka in a spark streaming scala application,Tools,how do i receive avro messages through kafka in a spark streaming scala application,"['how', 'do', 'i', 'receive', 'avro', 'messages', 'through', 'kafka', 'in', 'a', 'spark', 'streaming', 'scala', 'application']",0,"['how', 'do', 'i', 'receive', 'avro', 'message', 'through', 'kafka', 'in', 'a', 'spark', 'streaming', 'scala', 'application']","['receive', 'avro', 'message', 'kafka', 'spark', 'streaming', 'scala', 'application']",receive avro message kafka spark streaming scala application,0.0,0.0,14,60,4.0,0,0,0,0,0,0,0,0
2241,autogenerate relative xpaths,Techniques,autogenerate relative xpaths,"['autogenerate', 'relative', 'xpaths']",0,"['autogenerate', 'relative', 'xpaths']","['autogenerate', 'relative', 'xpaths']",autogenerate relative xpaths,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
2242,how to deal with more than  levels in a factor variable in r,Tools,how to deal with more than  levels in a factor variable in r,"['how', 'to', 'deal', 'with', 'more', 'than', 'levels', 'in', 'a', 'factor', 'variable', 'in', 'r']",1,"['how', 'to', 'deal', 'with', 'more', 'than', 'level', 'in', 'a', 'factor', 'variable', 'in', 'r']","['deal', 'level', 'factor', 'variable', 'r']",deal level factor variable r,0.5,0.0,13,28,2.0,0,0,0,0,0,0,0,0
2243,lubridate vs date time functions in r,Tools,lubridate vs date time functions in r,"['lubridate', 'vs', 'date', 'time', 'functions', 'in', 'r']",0,"['lubridate', 'v', 'date', 'time', 'function', 'in', 'r']","['lubridate', 'v', 'date', 'time', 'function', 'r']",lubridate v date time function r,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
2244,performing decile analysis on the dataset where i have to figure out the defaulter,Techniques,performing decile analysis on the dataset where i have to figure out the defaulter,"['performing', 'decile', 'analysis', 'on', 'the', 'dataset', 'where', 'i', 'have', 'to', 'figure', 'out', 'the', 'defaulter']",0,"['performing', 'decile', 'analysis', 'on', 'the', 'dataset', 'where', 'i', 'have', 'to', 'figure', 'out', 'the', 'defaulter']","['performing', 'decile', 'analysis', 'dataset', 'figure', 'defaulter']",performing decile analysis dataset figure defaulter,0.0,0.0,14,51,3.4,0,0,0,0,0,0,0,0
2245,classification problem,Techniques,classification problem,"['classification', 'problem']",0,"['classification', 'problem']","['classification', 'problem']",classification problem,0.0,0.0,2,22,7.333333333333333,0,0,0,0,0,0,0,0
2246,time series in python using multiple input features,Techniques,time series in python using multiple input features,"['time', 'series', 'in', 'python', 'using', 'multiple', 'input', 'features']",0,"['time', 'series', 'in', 'python', 'using', 'multiple', 'input', 'feature']","['time', 'series', 'python', 'using', 'multiple', 'input', 'feature']",time series python using multiple input feature,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
2247,how to use r packages in tableau,Tools,how to use r packages in tableau,"['how', 'to', 'use', 'r', 'packages', 'in', 'tableau']",0,"['how', 'to', 'use', 'r', 'package', 'in', 'tableau']","['use', 'r', 'package', 'tableau']",use r package tableau,0.0,0.0,7,21,2.625,0,0,0,0,0,0,0,0
2248,how to decide what treatment to apply to missing values in our data,Techniques,how to decide what treatment to apply to missing values in our data,"['how', 'to', 'decide', 'what', 'treatment', 'to', 'apply', 'to', 'missing', 'values', 'in', 'our', 'data']",0,"['how', 'to', 'decide', 'what', 'treatment', 'to', 'apply', 'to', 'missing', 'value', 'in', 'our', 'data']","['decide', 'treatment', 'apply', 'missing', 'value', 'data']",decide treatment apply missing value data,-0.2,-0.2,13,41,2.9285714285714284,0,0,0,0,0,0,0,0
2249,overfitting concept,Techniques,overfitting concept,"['overfitting', 'concept']",0,"['overfitting', 'concept']","['overfitting', 'concept']",overfitting concept,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
2250,question on ffnetuning bert for text classification,Techniques,question on ffnetuning bert for text classification,"['question', 'on', 'ffnetuning', 'bert', 'for', 'text', 'classification']",0,"['question', 'on', 'ffnetuning', 'bert', 'for', 'text', 'classification']","['question', 'ffnetuning', 'bert', 'text', 'classification']",question ffnetuning bert text classification,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
2251,how to parse keyword which is in sentence using nltk,Techniques,how to parse keyword which is in sentence using nltk,"['how', 'to', 'parse', 'keyword', 'which', 'is', 'in', 'sentence', 'using', 'nltk']",0,"['how', 'to', 'parse', 'keyword', 'which', 'is', 'in', 'sentence', 'using', 'nltk']","['parse', 'keyword', 'sentence', 'using', 'nltk']",parse keyword sentence using nltk,0.0,0.0,10,33,3.0,0,0,0,0,0,0,0,0
2252,how to create a column or should i say categorical variable,Misc,how to create a column or should i say categorical variable,"['how', 'to', 'create', 'a', 'column', 'or', 'should', 'i', 'say', 'categorical', 'variable']",0,"['how', 'to', 'create', 'a', 'column', 'or', 'should', 'i', 'say', 'categorical', 'variable']","['create', 'column', 'say', 'categorical', 'variable']",create column say categorical variable,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
2253,ts forecasting code,Techniques,ts forecasting code,"['ts', 'forecasting', 'code']",0,"['t', 'forecasting', 'code']","['forecasting', 'code']",forecasting code,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
2254,analytics domain for engineering background candidates,Career,analytics domain for engineering background candidates,"['analytics', 'domain', 'for', 'engineering', 'background', 'candidates']",0,"['analytics', 'domain', 'for', 'engineering', 'background', 'candidate']","['analytics', 'domain', 'engineering', 'background', 'candidate']",analytics domain engineering background candidate,0.0,0.0,6,49,7.0,0,0,0,0,0,0,0,0
2255,propensity scoring in r,Techniques,propensity scoring in r,"['propensity', 'scoring', 'in', 'r']",0,"['propensity', 'scoring', 'in', 'r']","['propensity', 'scoring', 'r']",propensity scoring r,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
2256,how to compare rows of data,Tools,how to compare rows of data,"['how', 'to', 'compare', 'rows', 'of', 'data']",0,"['how', 'to', 'compare', 'row', 'of', 'data']","['compare', 'row', 'data']",compare row data,0.0,0.0,6,16,2.2857142857142856,0,0,0,0,0,0,0,0
2257,understand which factors influence customer buying behavior in category,Techniques,understand which factors influence customer buying behavior in category,"['understand', 'which', 'factors', 'influence', 'customer', 'buying', 'behavior', 'in', 'category']",0,"['understand', 'which', 'factor', 'influence', 'customer', 'buying', 'behavior', 'in', 'category']","['understand', 'factor', 'influence', 'customer', 'buying', 'behavior', 'category']",understand factor influence customer buying behavior category,0.0,0.0,9,61,6.1,0,0,0,0,0,0,0,0
2258,how to sample a fixed vector in r,Techniques,how to sample a fixed vector in r,"['how', 'to', 'sample', 'a', 'fixed', 'vector', 'in', 'r']",0,"['how', 'to', 'sample', 'a', 'fixed', 'vector', 'in', 'r']","['sample', 'fixed', 'vector', 'r']",sample fixed vector r,0.1,0.1,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
2259,how can i convert list of lists to list in python,Tools,how can i convert list of lists to list in python,"['how', 'can', 'i', 'convert', 'list', 'of', 'lists', 'to', 'list', 'in', 'python']",0,"['how', 'can', 'i', 'convert', 'list', 'of', 'list', 'to', 'list', 'in', 'python']","['convert', 'list', 'list', 'list', 'python']",convert list list list python,0.0,0.0,11,29,2.4166666666666665,0,0,0,0,0,0,0,0
2260,in the input file userdata what is difference between the field maxrating and rating,Hackathons,in the input file userdata what is difference between the field maxrating and rating,"['in', 'the', 'input', 'file', 'userdata', 'what', 'is', 'difference', 'between', 'the', 'field', 'maxrating', 'and', 'rating']",0,"['in', 'the', 'input', 'file', 'userdata', 'what', 'is', 'difference', 'between', 'the', 'field', 'maxrating', 'and', 'rating']","['input', 'file', 'userdata', 'difference', 'field', 'maxrating', 'rating']",input file userdata difference field maxrating rating,0.0,0.0,14,53,3.533333333333333,0,0,0,0,0,0,0,0
2261,how to import images folder,Techniques,how to import images folder,"['how', 'to', 'import', 'images', 'folder']",0,"['how', 'to', 'import', 'image', 'folder']","['import', 'image', 'folder']",import image folder,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
2262,sas function substrhow to use it as pseudo variable,Tools,sas function substrhow to use it as pseudo variable,"['sas', 'function', 'substrhow', 'to', 'use', 'it', 'as', 'pseudo', 'variable']",0,"['sa', 'function', 'substrhow', 'to', 'use', 'it', 'a', 'pseudo', 'variable']","['sa', 'function', 'substrhow', 'use', 'pseudo', 'variable']",sa function substrhow use pseudo variable,0.0,0.0,9,41,4.1,0,0,0,0,0,0,0,0
2263,free nocode data analysis,Resources,free nocode data analysis,"['free', 'nocode', 'data', 'analysis']",0,"['free', 'nocode', 'data', 'analysis']","['free', 'nocode', 'data', 'analysis']",free nocode data analysis,0.4,0.4,4,25,5.0,0,0,0,0,0,0,0,0
2264,quick response needed which is better aegis pgp babd vs praxis pgp ba course,Career,quick response needed which is better aegis pgp babd vs praxis pgp ba course,"['quick', 'response', 'needed', 'which', 'is', 'better', 'aegis', 'pgp', 'babd', 'vs', 'praxis', 'pgp', 'ba', 'course']",0,"['quick', 'response', 'needed', 'which', 'is', 'better', 'aegis', 'pgp', 'babd', 'v', 'praxis', 'pgp', 'ba', 'course']","['quick', 'response', 'needed', 'better', 'aegis', 'pgp', 'babd', 'v', 'praxis', 'pgp', 'ba', 'course']",quick response needed better aegis pgp babd v praxis pgp ba course,0.4166666666666666,0.4166666666666666,14,66,4.4,0,0,0,0,0,0,0,0
2265,how to shorten the length of long sequence of text in r,Techniques,how to shorten the length of long sequence of text in r,"['how', 'to', 'shorten', 'the', 'length', 'of', 'long', 'sequence', 'of', 'text', 'in', 'r']",0,"['how', 'to', 'shorten', 'the', 'length', 'of', 'long', 'sequence', 'of', 'text', 'in', 'r']","['shorten', 'length', 'long', 'sequence', 'text', 'r']",shorten length long sequence text r,-0.05,-0.05,12,35,2.6923076923076925,0,0,0,0,0,0,0,0
2266,does data science include working knowledge of big data,Career,does data science include working knowledge of big data,"['does', 'data', 'science', 'include', 'working', 'knowledge', 'of', 'big', 'data']",0,"['doe', 'data', 'science', 'include', 'working', 'knowledge', 'of', 'big', 'data']","['doe', 'data', 'science', 'include', 'working', 'knowledge', 'big', 'data']",doe data science include working knowledge big data,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
2267,text mining tools which has control operators,Tools,text mining tools which has control operators,"['text', 'mining', 'tools', 'which', 'has', 'control', 'operators']",0,"['text', 'mining', 'tool', 'which', 'ha', 'control', 'operator']","['text', 'mining', 'tool', 'ha', 'control', 'operator']",text mining tool ha control operator,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
2268,explaining null values vs missing values to a predictive model,Techniques,explaining null values vs missing values to a predictive model,"['explaining', 'null', 'values', 'vs', 'missing', 'values', 'to', 'a', 'predictive', 'model']",0,"['explaining', 'null', 'value', 'v', 'missing', 'value', 'to', 'a', 'predictive', 'model']","['explaining', 'null', 'value', 'v', 'missing', 'value', 'predictive', 'model']",explaining null value v missing value predictive model,-0.2,-0.2,10,54,4.909090909090909,0,0,0,0,0,0,0,0
2269,intermediate completed now want to make a career in data science need guidance,Career,intermediate completed now want to make a career in data science need guidance,"['intermediate', 'completed', 'now', 'want', 'to', 'make', 'a', 'career', 'in', 'data', 'science', 'need', 'guidance']",0,"['intermediate', 'completed', 'now', 'want', 'to', 'make', 'a', 'career', 'in', 'data', 'science', 'need', 'guidance']","['intermediate', 'completed', 'want', 'make', 'career', 'data', 'science', 'need', 'guidance']",intermediate completed want make career data science need guidance,0.0,0.0,13,66,4.714285714285714,0,0,0,0,0,0,0,0
2270,splitting between traintest for customer churn survival models,Techniques,splitting between traintest for customer churn survival models,"['splitting', 'between', 'traintest', 'for', 'customer', 'churn', 'survival', 'models']",0,"['splitting', 'between', 'traintest', 'for', 'customer', 'churn', 'survival', 'model']","['splitting', 'traintest', 'customer', 'churn', 'survival', 'model']",splitting traintest customer churn survival model,0.0,0.0,8,49,5.444444444444445,0,0,0,0,0,0,0,0
2271,question on logistic regression,Techniques,question on logistic regression,"['question', 'on', 'logistic', 'regression']",0,"['question', 'on', 'logistic', 'regression']","['question', 'logistic', 'regression']",question logistic regression,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
2272,production environment choice  r  python  sas,Tools,production environment choice  r  python  sas,"['production', 'environment', 'choice', 'r', 'python', 'sas']",0,"['production', 'environment', 'choice', 'r', 'python', 'sa']","['production', 'environment', 'choice', 'r', 'python', 'sa']",production environment choice r python sa,0.0,0.0,6,41,5.857142857142857,0,0,0,0,0,0,0,0
2273,how embedding weights are created in wordvec,Techniques,how embedding weights are created in wordvec,"['how', 'embedding', 'weights', 'are', 'created', 'in', 'wordvec']",0,"['how', 'embedding', 'weight', 'are', 'created', 'in', 'wordvec']","['embedding', 'weight', 'created', 'wordvec']",embedding weight created wordvec,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
2274,how to choose the model for forecasting and how to know that model is fit or not,Techniques,how to choose the model for forecasting and how to know that model is fit or not,"['how', 'to', 'choose', 'the', 'model', 'for', 'forecasting', 'and', 'how', 'to', 'know', 'that', 'model', 'is', 'fit', 'or', 'not']",0,"['how', 'to', 'choose', 'the', 'model', 'for', 'forecasting', 'and', 'how', 'to', 'know', 'that', 'model', 'is', 'fit', 'or', 'not']","['choose', 'model', 'forecasting', 'know', 'model', 'fit']",choose model forecasting know model fit,0.4,0.4,17,39,2.1666666666666665,0,0,0,0,0,0,0,0
2275,how to make color of different plot same,Tools,how to make color of different plot same,"['how', 'to', 'make', 'color', 'of', 'different', 'plot', 'same']",0,"['how', 'to', 'make', 'color', 'of', 'different', 'plot', 'same']","['make', 'color', 'different', 'plot']",make color different plot,0.0,0.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
2276,how can i create venn diagram in qlikview,Tools,how can i create venn diagram in qlikview,"['how', 'can', 'i', 'create', 'venn', 'diagram', 'in', 'qlikview']",0,"['how', 'can', 'i', 'create', 'venn', 'diagram', 'in', 'qlikview']","['create', 'venn', 'diagram', 'qlikview']",create venn diagram qlikview,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
2277,intellimindz certification  training,Career,intellimindz certification  training,"['intellimindz', 'certification', 'training']",0,"['intellimindz', 'certification', 'training']","['intellimindz', 'certification', 'training']",intellimindz certification training,0.0,0.0,3,35,8.75,0,0,0,0,0,0,0,0
2278,web scraping in r with top  movies on imdb post,Techniques,web scraping in r with top  movies on imdb post,"['web', 'scraping', 'in', 'r', 'with', 'top', 'movies', 'on', 'imdb', 'post']",1,"['web', 'scraping', 'in', 'r', 'with', 'top', 'movie', 'on', 'imdb', 'post']","['web', 'scraping', 'r', 'top', 'movie', 'imdb', 'post']",web scraping r top movie imdb post,0.5,0.5,10,34,3.090909090909091,0,0,0,0,0,0,0,0
2279,knocktober questions,Hackathons,knocktober questions,"['knocktober', 'questions']",0,"['knocktober', 'question']","['knocktober', 'question']",knocktober question,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
2280,please provide me an idea of what can i mine from the database described below,Resources,please provide me an idea of what can i mine from the database described below,"['please', 'provide', 'me', 'an', 'idea', 'of', 'what', 'can', 'i', 'mine', 'from', 'the', 'database', 'described', 'below']",0,"['please', 'provide', 'me', 'an', 'idea', 'of', 'what', 'can', 'i', 'mine', 'from', 'the', 'database', 'described', 'below']","['please', 'provide', 'idea', 'mine', 'database', 'described']",please provide idea mine database described,0.0,0.0,15,43,2.6875,0,0,0,0,0,0,0,0
2281,error while creating a connection in rpostgresql package,Techniques,error while creating a connection in rpostgresql package,"['error', 'while', 'creating', 'a', 'connection', 'in', 'rpostgresql', 'package']",0,"['error', 'while', 'creating', 'a', 'connection', 'in', 'rpostgresql', 'package']","['error', 'creating', 'connection', 'rpostgresql', 'package']",error creating connection rpostgresql package,0.0,0.0,8,45,5.0,0,0,0,0,0,0,0,0
2282,use of  assignment operator in r,Tools,use of  assignment operator in r,"['use', 'of', 'assignment', 'operator', 'in', 'r']",0,"['use', 'of', 'assignment', 'operator', 'in', 'r']","['use', 'assignment', 'operator', 'r']",use assignment operator r,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
2283,concatenating arrays in python using numpy,Tools,concatenating arrays in python using numpy,"['concatenating', 'arrays', 'in', 'python', 'using', 'numpy']",0,"['concatenating', 'array', 'in', 'python', 'using', 'numpy']","['concatenating', 'array', 'python', 'using', 'numpy']",concatenating array python using numpy,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
2284,how to deal with test data having less feature than train data,Hackathons,how to deal with test data having less feature than train data,"['how', 'to', 'deal', 'with', 'test', 'data', 'having', 'less', 'feature', 'than', 'train', 'data']",0,"['how', 'to', 'deal', 'with', 'test', 'data', 'having', 'le', 'feature', 'than', 'train', 'data']","['deal', 'test', 'data', 'le', 'feature', 'train', 'data']",deal test data le feature train data,-0.1666666666666666,0.0,12,36,2.769230769230769,0,0,0,0,0,0,0,0
2285,arima acf residuals error in r,Tools,arima acf residuals error in r,"['arima', 'acf', 'residuals', 'error', 'in', 'r']",0,"['arima', 'acf', 'residual', 'error', 'in', 'r']","['arima', 'acf', 'residual', 'error', 'r']",arima acf residual error r,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
2286,which model to select for ml,Techniques,which model to select for ml,"['which', 'model', 'to', 'select', 'for', 'ml']",0,"['which', 'model', 'to', 'select', 'for', 'ml']","['model', 'select', 'ml']",model select ml,0.0,0.0,6,15,2.142857142857143,0,0,0,0,0,0,0,0
2287,capillary hackathon dataset,Hackathons,capillary hackathon dataset,"['capillary', 'hackathon', 'dataset']",0,"['capillary', 'hackathon', 'dataset']","['capillary', 'hackathon', 'dataset']",capillary hackathon dataset,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
2288,clustering using kohonen self organising maps,Techniques,clustering using kohonen self organising maps,"['clustering', 'using', 'kohonen', 'self', 'organising', 'maps']",0,"['clustering', 'using', 'kohonen', 'self', 'organising', 'map']","['clustering', 'using', 'kohonen', 'self', 'organising', 'map']",clustering using kohonen self organising map,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
2289,how is the test error rate affected by kfold cross validation,Techniques,how is the test error rate affected by kfold cross validation,"['how', 'is', 'the', 'test', 'error', 'rate', 'affected', 'by', 'kfold', 'cross', 'validation']",0,"['how', 'is', 'the', 'test', 'error', 'rate', 'affected', 'by', 'kfold', 'cross', 'validation']","['test', 'error', 'rate', 'affected', 'kfold', 'cross', 'validation']",test error rate affected kfold cross validation,0.0,0.0,11,47,3.9166666666666665,0,0,0,0,0,0,0,0
2290,how to choose predictors and interaction to add to the model,Techniques,how to choose predictors and interaction to add to the model,"['how', 'to', 'choose', 'predictors', 'and', 'interaction', 'to', 'add', 'to', 'the', 'model']",0,"['how', 'to', 'choose', 'predictor', 'and', 'interaction', 'to', 'add', 'to', 'the', 'model']","['choose', 'predictor', 'interaction', 'add', 'model']",choose predictor interaction add model,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
2291,share your approach  lord of machines,Hackathons,share your approach  lord of machines,"['share', 'your', 'approach', 'lord', 'of', 'machines']",0,"['share', 'your', 'approach', 'lord', 'of', 'machine']","['share', 'approach', 'lord', 'machine']",share approach lord machine,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
2292,sequence of preprocessing and feature creation,Techniques,sequence of preprocessing and feature creation,"['sequence', 'of', 'preprocessing', 'and', 'feature', 'creation']",0,"['sequence', 'of', 'preprocessing', 'and', 'feature', 'creation']","['sequence', 'preprocessing', 'feature', 'creation']",sequence preprocessing feature creation,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
2293,similarity scores in strings in python,Tools,similarity scores in strings in python,"['similarity', 'scores', 'in', 'strings', 'in', 'python']",0,"['similarity', 'score', 'in', 'string', 'in', 'python']","['similarity', 'score', 'string', 'python']",similarity score string python,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
2294,r package for interactive data exploration,Tools,r package for interactive data exploration,"['r', 'package', 'for', 'interactive', 'data', 'exploration']",0,"['r', 'package', 'for', 'interactive', 'data', 'exploration']","['r', 'package', 'interactive', 'data', 'exploration']",r package interactive data exploration,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
2295,data set for practice  build model with datatable and ho,Tools,data set for practice  build model with datatable and ho,"['data', 'set', 'for', 'practice', 'build', 'model', 'with', 'datatable', 'and', 'ho']",0,"['data', 'set', 'for', 'practice', 'build', 'model', 'with', 'datatable', 'and', 'ho']","['data', 'set', 'practice', 'build', 'model', 'datatable', 'ho']",data set practice build model datatable ho,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
2296,how to resolve error while ensembling randomforest and logistic regression using caretensemble package,Tools,how to resolve error while ensembling randomforest and logistic regression using caretensemble package,"['how', 'to', 'resolve', 'error', 'while', 'ensembling', 'randomforest', 'and', 'logistic', 'regression', 'using', 'caretensemble', 'package']",0,"['how', 'to', 'resolve', 'error', 'while', 'ensembling', 'randomforest', 'and', 'logistic', 'regression', 'using', 'caretensemble', 'package']","['resolve', 'error', 'ensembling', 'randomforest', 'logistic', 'regression', 'using', 'caretensemble', 'package']",resolve error ensembling randomforest logistic regression using caretensemble package,0.0,0.0,13,85,6.071428571428571,0,0,0,0,0,0,0,0
2297,how to resolve argument of length  error while using boosting in r,Tools,how to resolve argument of length  error while using boosting in r,"['how', 'to', 'resolve', 'argument', 'of', 'length', 'error', 'while', 'using', 'boosting', 'in', 'r']",1,"['how', 'to', 'resolve', 'argument', 'of', 'length', 'error', 'while', 'using', 'boosting', 'in', 'r']","['resolve', 'argument', 'length', 'error', 'using', 'boosting', 'r']",resolve argument length error using boosting r,0.0,0.0,12,46,3.5384615384615383,0,0,0,0,0,0,0,0
2298,what is the system is computationally singular error while using the factanal function in r,Tools,what is the system is computationally singular error while using the factanal function in r,"['what', 'is', 'the', 'system', 'is', 'computationally', 'singular', 'error', 'while', 'using', 'the', 'factanal', 'function', 'in', 'r']",0,"['what', 'is', 'the', 'system', 'is', 'computationally', 'singular', 'error', 'while', 'using', 'the', 'factanal', 'function', 'in', 'r']","['system', 'computationally', 'singular', 'error', 'using', 'factanal', 'function', 'r']",system computationally singular error using factanal function r,0.0,0.0,15,63,3.9375,0,0,0,0,0,0,0,0
2299,deploying pmml models in cc,Tools,deploying pmml models in cc,"['deploying', 'pmml', 'models', 'in', 'cc']",0,"['deploying', 'pmml', 'model', 'in', 'cc']","['deploying', 'pmml', 'model', 'cc']",deploying pmml model cc,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
2300,how to use chisquare test to find multicollinearity,Techniques,how to use chisquare test to find multicollinearity,"['how', 'to', 'use', 'chisquare', 'test', 'to', 'find', 'multicollinearity']",0,"['how', 'to', 'use', 'chisquare', 'test', 'to', 'find', 'multicollinearity']","['use', 'chisquare', 'test', 'find', 'multicollinearity']",use chisquare test find multicollinearity,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2301,what is difference between c and rpart package,Tools,what is difference between c and rpart package,"['what', 'is', 'difference', 'between', 'c', 'and', 'rpart', 'package']",0,"['what', 'is', 'difference', 'between', 'c', 'and', 'rpart', 'package']","['difference', 'c', 'rpart', 'package']",difference c rpart package,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
2302,technical sales analytics products,Career,technical sales analytics products,"['technical', 'sales', 'analytics', 'products']",0,"['technical', 'sale', 'analytics', 'product']","['technical', 'sale', 'analytics', 'product']",technical sale analytics product,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
2303,hi everyone  wanted to say hi and ask a question  class imbalance,Techniques,hi everyone  wanted to say hi and ask a question  class imbalance,"['hi', 'everyone', 'wanted', 'to', 'say', 'hi', 'and', 'ask', 'a', 'question', 'class', 'imbalance']",0,"['hi', 'everyone', 'wanted', 'to', 'say', 'hi', 'and', 'ask', 'a', 'question', 'class', 'imbalance']","['hi', 'everyone', 'wanted', 'say', 'hi', 'ask', 'question', 'class', 'imbalance']",hi everyone wanted say hi ask question class imbalance,0.0,0.0,12,54,4.153846153846154,0,0,0,0,0,0,0,0
2304,dashboards using python,Tools,dashboards using python,"['dashboards', 'using', 'python']",0,"['dashboard', 'using', 'python']","['dashboard', 'using', 'python']",dashboard using python,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
2305,why skewed data increases error after few iterations,Techniques,why skewed data increases error after few iterations,"['why', 'skewed', 'data', 'increases', 'error', 'after', 'few', 'iterations']",0,"['why', 'skewed', 'data', 'increase', 'error', 'after', 'few', 'iteration']","['skewed', 'data', 'increase', 'error', 'iteration']",skewed data increase error iteration,-0.2,0.0,8,36,4.0,0,0,0,0,0,0,0,0
2306,question on general probability,Techniques,question on general probability,"['question', 'on', 'general', 'probability']",0,"['question', 'on', 'general', 'probability']","['question', 'general', 'probability']",question general probability,0.05,0.05,4,28,5.6,0,0,0,0,0,0,0,0
2307,resources about business case  analytical case structure thinking,Other,resources about business case  analytical case structure thinking,"['resources', 'about', 'business', 'case', 'analytical', 'case', 'structure', 'thinking']",0,"['resource', 'about', 'business', 'case', 'analytical', 'case', 'structure', 'thinking']","['resource', 'business', 'case', 'analytical', 'case', 'structure', 'thinking']",resource business case analytical case structure thinking,0.0,0.0,8,57,6.333333333333333,0,0,0,0,0,0,0,0
2308,combing two legends into one using r,Tools,combing two legends into one using r,"['combing', 'two', 'legends', 'into', 'one', 'using', 'r']",0,"['combing', 'two', 'legend', 'into', 'one', 'using', 'r']","['combing', 'two', 'legend', 'one', 'using', 'r']",combing two legend one using r,0.0,0.0,7,30,3.75,0,0,0,0,0,0,0,0
2309,how to remove value from a vector in r,Tools,how to remove value from a vector in r,"['how', 'to', 'remove', 'value', 'from', 'a', 'vector', 'in', 'r']",0,"['how', 'to', 'remove', 'value', 'from', 'a', 'vector', 'in', 'r']","['remove', 'value', 'vector', 'r']",remove value vector r,0.0,0.0,9,21,2.1,0,0,0,0,0,0,0,0
2310,iris data set analysis looking for detailed instructions and code,Techniques,iris data set analysis looking for detailed instructions and code,"['iris', 'data', 'set', 'analysis', 'looking', 'for', 'detailed', 'instructions', 'and', 'code']",0,"['iris', 'data', 'set', 'analysis', 'looking', 'for', 'detailed', 'instruction', 'and', 'code']","['iris', 'data', 'set', 'analysis', 'looking', 'detailed', 'instruction', 'code']",iris data set analysis looking detailed instruction code,0.4,0.4,10,56,5.090909090909091,0,0,0,0,0,0,0,0
2311,the dataset about imbalanced data,Resources,the dataset about imbalanced data,"['the', 'dataset', 'about', 'imbalanced', 'data']",0,"['the', 'dataset', 'about', 'imbalanced', 'data']","['dataset', 'imbalanced', 'data']",dataset imbalanced data,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
2312,topic modelling in r,Techniques,topic modelling in r,"['topic', 'modelling', 'in', 'r']",0,"['topic', 'modelling', 'in', 'r']","['topic', 'modelling', 'r']",topic modelling r,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
2313,what is the best way to implement the r code that uses packages from r on your website,Tools,what is the best way to implement the r code that uses packages from r on your website,"['what', 'is', 'the', 'best', 'way', 'to', 'implement', 'the', 'r', 'code', 'that', 'uses', 'packages', 'from', 'r', 'on', 'your', 'website']",0,"['what', 'is', 'the', 'best', 'way', 'to', 'implement', 'the', 'r', 'code', 'that', 'us', 'package', 'from', 'r', 'on', 'your', 'website']","['best', 'way', 'implement', 'r', 'code', 'us', 'package', 'r', 'website']",best way implement r code us package r website,1.0,1.0,18,46,2.4210526315789473,0,0,0,0,0,0,0,0
2314,point systems ,Misc,point systems ,"['point', 'systems']",0,"['point', 'system']","['point', 'system']",point system,0.0,0.0,2,12,4.0,0,0,0,0,0,0,0,0
2315,omit sentences that arent related to neither class binary text classification,Techniques,omit sentences that arent related to neither class binary text classification,"['omit', 'sentences', 'that', 'arent', 'related', 'to', 'neither', 'class', 'binary', 'text', 'classification']",0,"['omit', 'sentence', 'that', 'arent', 'related', 'to', 'neither', 'class', 'binary', 'text', 'classification']","['omit', 'sentence', 'arent', 'related', 'neither', 'class', 'binary', 'text', 'classification']",omit sentence arent related neither class binary text classification,0.0,0.0,11,68,5.666666666666667,0,0,0,0,0,0,0,0
2316,valueerror given a pandas object and the index does not contain dates,Techniques,valueerror given a pandas object and the index does not contain dates,"['valueerror', 'given', 'a', 'pandas', 'object', 'and', 'the', 'index', 'does', 'not', 'contain', 'dates']",0,"['valueerror', 'given', 'a', 'panda', 'object', 'and', 'the', 'index', 'doe', 'not', 'contain', 'date']","['valueerror', 'given', 'panda', 'object', 'index', 'doe', 'contain', 'date']",valueerror given panda object index doe contain date,0.0,0.0,12,52,4.0,0,0,0,0,0,0,0,0
2317,use of asfactor in r,Techniques,use of asfactor in r,"['use', 'of', 'asfactor', 'in', 'r']",0,"['use', 'of', 'asfactor', 'in', 'r']","['use', 'asfactor', 'r']",use asfactor r,0.0,0.0,5,14,2.3333333333333335,0,0,0,0,0,0,0,0
2318,is this a content or course,Hackathons,is this a content or course,"['is', 'this', 'a', 'content', 'or', 'course']",0,"['is', 'this', 'a', 'content', 'or', 'course']","['content', 'course']",content course,0.0,0.0,6,14,2.0,0,0,0,0,0,0,0,0
2319,which regression algorithm could be applied for correcting sensor values,Techniques,which regression algorithm could be applied for correcting sensor values,"['which', 'regression', 'algorithm', 'could', 'be', 'applied', 'for', 'correcting', 'sensor', 'values']",0,"['which', 'regression', 'algorithm', 'could', 'be', 'applied', 'for', 'correcting', 'sensor', 'value']","['regression', 'algorithm', 'could', 'applied', 'correcting', 'sensor', 'value']",regression algorithm could applied correcting sensor value,0.0,0.0,10,58,5.2727272727272725,0,0,0,0,0,0,0,0
2320,need your guidance regarding career in data science,Career,need your guidance regarding career in data science,"['need', 'your', 'guidance', 'regarding', 'career', 'in', 'data', 'science']",0,"['need', 'your', 'guidance', 'regarding', 'career', 'in', 'data', 'science']","['need', 'guidance', 'regarding', 'career', 'data', 'science']",need guidance regarding career data science,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
2321,calculating distance between coordinates,Techniques,calculating distance between coordinates,"['calculating', 'distance', 'between', 'coordinates']",0,"['calculating', 'distance', 'between', 'coordinate']","['calculating', 'distance', 'coordinate']",calculating distance coordinate,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
2322,data analysis clustering,Techniques,data analysis clustering,"['data', 'analysis', 'clustering']",0,"['data', 'analysis', 'clustering']","['data', 'analysis', 'clustering']",data analysis clustering,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
2323,data issue for forecast daily sales,Techniques,data issue for forecast daily sales,"['data', 'issue', 'for', 'forecast', 'daily', 'sales']",0,"['data', 'issue', 'for', 'forecast', 'daily', 'sale']","['data', 'issue', 'forecast', 'daily', 'sale']",data issue forecast daily sale,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
2324,models for spreading sales target across months,Techniques,models for spreading sales target across months,"['models', 'for', 'spreading', 'sales', 'target', 'across', 'months']",0,"['model', 'for', 'spreading', 'sale', 'target', 'across', 'month']","['model', 'spreading', 'sale', 'target', 'across', 'month']",model spreading sale target across month,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
2325, years of experience in telecom,Career, years of experience in telecom,"['years', 'of', 'experience', 'in', 'telecom']",1,"['year', 'of', 'experience', 'in', 'telecom']","['year', 'experience', 'telecom']",year experience telecom,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
2326,how to plot the decision boundary of knn in r,Tools,how to plot the decision boundary of knn in r,"['how', 'to', 'plot', 'the', 'decision', 'boundary', 'of', 'knn', 'in', 'r']",0,"['how', 'to', 'plot', 'the', 'decision', 'boundary', 'of', 'knn', 'in', 'r']","['plot', 'decision', 'boundary', 'knn', 'r']",plot decision boundary knn r,0.0,0.0,10,28,2.5454545454545454,0,0,0,0,0,0,0,0
2327,how to access sas data set in qlikview,Tools,how to access sas data set in qlikview,"['how', 'to', 'access', 'sas', 'data', 'set', 'in', 'qlikview']",0,"['how', 'to', 'access', 'sa', 'data', 'set', 'in', 'qlikview']","['access', 'sa', 'data', 'set', 'qlikview']",access sa data set qlikview,0.0,0.0,8,27,3.0,0,0,0,0,0,0,0,0
2328,how to calculate the entropy of distribution with or without a given plot,Techniques,how to calculate the entropy of distribution with or without a given plot,"['how', 'to', 'calculate', 'the', 'entropy', 'of', 'distribution', 'with', 'or', 'without', 'a', 'given', 'plot']",0,"['how', 'to', 'calculate', 'the', 'entropy', 'of', 'distribution', 'with', 'or', 'without', 'a', 'given', 'plot']","['calculate', 'entropy', 'distribution', 'without', 'given', 'plot']",calculate entropy distribution without given plot,0.0,0.0,13,49,3.5,0,0,0,0,0,0,0,0
2329,few queries regarding cart and logistic algorithms and missing data,Techniques,few queries regarding cart and logistic algorithms and missing data,"['few', 'queries', 'regarding', 'cart', 'and', 'logistic', 'algorithms', 'and', 'missing', 'data']",0,"['few', 'query', 'regarding', 'cart', 'and', 'logistic', 'algorithm', 'and', 'missing', 'data']","['query', 'regarding', 'cart', 'logistic', 'algorithm', 'missing', 'data']",query regarding cart logistic algorithm missing data,-0.2,-0.2,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
2330,chartered accountancy  data science,Career,chartered accountancy  data science,"['chartered', 'accountancy', 'data', 'science']",0,"['chartered', 'accountancy', 'data', 'science']","['chartered', 'accountancy', 'data', 'science']",chartered accountancy data science,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
2331,linear regression on categorial and continuous data,Techniques,linear regression on categorial and continuous data,"['linear', 'regression', 'on', 'categorial', 'and', 'continuous', 'data']",0,"['linear', 'regression', 'on', 'categorial', 'and', 'continuous', 'data']","['linear', 'regression', 'categorial', 'continuous', 'data']",linear regression categorial continuous data,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
2332,how adjusted rsquared value is different from multiple rsquared value,Techniques,how adjusted rsquared value is different from multiple rsquared value,"['how', 'adjusted', 'rsquared', 'value', 'is', 'different', 'from', 'multiple', 'rsquared', 'value']",0,"['how', 'adjusted', 'rsquared', 'value', 'is', 'different', 'from', 'multiple', 'rsquared', 'value']","['adjusted', 'rsquared', 'value', 'different', 'multiple', 'rsquared', 'value']",adjusted rsquared value different multiple rsquared value,0.0,0.0,10,57,5.181818181818182,0,0,0,0,0,0,0,0
2333,can median be used for ordinal variable,Techniques,can median be used for ordinal variable,"['can', 'median', 'be', 'used', 'for', 'ordinal', 'variable']",0,"['can', 'median', 'be', 'used', 'for', 'ordinal', 'variable']","['median', 'used', 'ordinal', 'variable']",median used ordinal variable,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
2334,how can i check whether my data frame contains nainf values in some column or not in r,Tools,how can i check whether my data frame contains nainf values in some column or not in r,"['how', 'can', 'i', 'check', 'whether', 'my', 'data', 'frame', 'contains', 'nainf', 'values', 'in', 'some', 'column', 'or', 'not', 'in', 'r']",0,"['how', 'can', 'i', 'check', 'whether', 'my', 'data', 'frame', 'contains', 'nainf', 'value', 'in', 'some', 'column', 'or', 'not', 'in', 'r']","['check', 'whether', 'data', 'frame', 'contains', 'nainf', 'value', 'column', 'r']",check whether data frame contains nainf value column r,0.0,0.0,18,54,2.8421052631578947,0,0,0,0,0,0,0,0
2335,shape and type of xtrain and yvalid for googlenet,Techniques,shape and type of xtrain and yvalid for googlenet,"['shape', 'and', 'type', 'of', 'xtrain', 'and', 'yvalid', 'for', 'googlenet']",0,"['shape', 'and', 'type', 'of', 'xtrain', 'and', 'yvalid', 'for', 'googlenet']","['shape', 'type', 'xtrain', 'yvalid', 'googlenet']",shape type xtrain yvalid googlenet,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
2336,r studio  read a file in unix from r,Tools,r studio  read a file in unix from r,"['r', 'studio', 'read', 'a', 'file', 'in', 'unix', 'from', 'r']",0,"['r', 'studio', 'read', 'a', 'file', 'in', 'unix', 'from', 'r']","['r', 'studio', 'read', 'file', 'unix', 'r']",r studio read file unix r,0.0,0.0,9,25,2.5,0,0,0,0,0,0,0,0
2337,gradient class activation mapping for regression tasks,Techniques,gradient class activation mapping for regression tasks,"['gradient', 'class', 'activation', 'mapping', 'for', 'regression', 'tasks']",0,"['gradient', 'class', 'activation', 'mapping', 'for', 'regression', 'task']","['gradient', 'class', 'activation', 'mapping', 'regression', 'task']",gradient class activation mapping regression task,0.0,0.0,7,49,6.125,0,0,0,0,0,0,0,0
2338,is there any good reading material for facial keypoints detection in rkaggle competition,Resources,is there any good reading material for facial keypoints detection in rkaggle competition,"['is', 'there', 'any', 'good', 'reading', 'material', 'for', 'facial', 'keypoints', 'detection', 'in', 'rkaggle', 'competition']",0,"['is', 'there', 'any', 'good', 'reading', 'material', 'for', 'facial', 'keypoints', 'detection', 'in', 'rkaggle', 'competition']","['good', 'reading', 'material', 'facial', 'keypoints', 'detection', 'rkaggle', 'competition']",good reading material facial keypoints detection rkaggle competition,0.35,0.35,13,68,4.857142857142857,0,0,0,0,0,0,0,0
2339,how to prepare for sas certification on your own  self study,Tools,how to prepare for sas certification on your own  self study,"['how', 'to', 'prepare', 'for', 'sas', 'certification', 'on', 'your', 'own', 'self', 'study']",0,"['how', 'to', 'prepare', 'for', 'sa', 'certification', 'on', 'your', 'own', 'self', 'study']","['prepare', 'sa', 'certification', 'self', 'study']",prepare sa certification self study,0.6,0.0,11,35,2.9166666666666665,0,0,0,0,0,0,0,0
2340,how to pick only diagonal observations from a sas dataset,Tools,how to pick only diagonal observations from a sas dataset,"['how', 'to', 'pick', 'only', 'diagonal', 'observations', 'from', 'a', 'sas', 'dataset']",0,"['how', 'to', 'pick', 'only', 'diagonal', 'observation', 'from', 'a', 'sa', 'dataset']","['pick', 'diagonal', 'observation', 'sa', 'dataset']",pick diagonal observation sa dataset,0.0,0.0,10,36,3.272727272727273,0,0,0,0,0,0,0,0
2341,data scienceanalytics use case advice,Techniques,data scienceanalytics use case advice,"['data', 'scienceanalytics', 'use', 'case', 'advice']",0,"['data', 'scienceanalytics', 'use', 'case', 'advice']","['data', 'scienceanalytics', 'use', 'case', 'advice']",data scienceanalytics use case advice,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
2342,list of analytics startups in india,Resources,list of analytics startups in india,"['list', 'of', 'analytics', 'startups', 'in', 'india']",0,"['list', 'of', 'analytics', 'startup', 'in', 'india']","['list', 'analytics', 'startup', 'india']",list analytics startup india,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
2343,take home data challenge  samples,Career,take home data challenge  samples,"['take', 'home', 'data', 'challenge', 'samples']",0,"['take', 'home', 'data', 'challenge', 'sample']","['take', 'home', 'data', 'challenge', 'sample']",take home data challenge sample,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
2344,why create dummy variables,Techniques,why create dummy variables,"['why', 'create', 'dummy', 'variables']",0,"['why', 'create', 'dummy', 'variable']","['create', 'dummy', 'variable']",create dummy variable,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
2345,should we perform factorization on binarycatagorical variables while doing regression,Techniques,should we perform factorization on binarycatagorical variables while doing regression,"['should', 'we', 'perform', 'factorization', 'on', 'binarycatagorical', 'variables', 'while', 'doing', 'regression']",0,"['should', 'we', 'perform', 'factorization', 'on', 'binarycatagorical', 'variable', 'while', 'doing', 'regression']","['perform', 'factorization', 'binarycatagorical', 'variable', 'regression']",perform factorization binarycatagorical variable regression,0.0,0.0,10,59,5.363636363636363,0,0,0,0,0,0,0,0
2346,masters degree selection,Career,masters degree selection,"['masters', 'degree', 'selection']",0,"['master', 'degree', 'selection']","['master', 'degree', 'selection']",master degree selection,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
2347,certification in business analytics  ssn chennai,Career,certification in business analytics  ssn chennai,"['certification', 'in', 'business', 'analytics', 'ssn', 'chennai']",0,"['certification', 'in', 'business', 'analytics', 'ssn', 'chennai']","['certification', 'business', 'analytics', 'ssn', 'chennai']",certification business analytics ssn chennai,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
2348,svm vs random forest,Techniques,svm vs random forest,"['svm', 'vs', 'random', 'forest']",0,"['svm', 'v', 'random', 'forest']","['svm', 'v', 'random', 'forest']",svm v random forest,-0.5,-0.5,4,19,3.8,0,0,0,0,0,0,0,0
2349,application of ledger data in ml,Other,application of ledger data in ml,"['application', 'of', 'ledger', 'data', 'in', 'ml']",0,"['application', 'of', 'ledger', 'data', 'in', 'ml']","['application', 'ledger', 'data', 'ml']",application ledger data ml,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
2350,how to calculate inner matrix product in ipython,Tools,how to calculate inner matrix product in ipython,"['how', 'to', 'calculate', 'inner', 'matrix', 'product', 'in', 'ipython']",0,"['how', 'to', 'calculate', 'inner', 'matrix', 'product', 'in', 'ipython']","['calculate', 'inner', 'matrix', 'product', 'ipython']",calculate inner matrix product ipython,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
2351,how to interpret cvfolds   warning message while running gbm in r,Techniques,how to interpret cvfolds   warning message while running gbm in r,"['how', 'to', 'interpret', 'cvfolds', 'warning', 'message', 'while', 'running', 'gbm', 'in', 'r']",1,"['how', 'to', 'interpret', 'cvfolds', 'warning', 'message', 'while', 'running', 'gbm', 'in', 'r']","['interpret', 'cvfolds', 'warning', 'message', 'running', 'gbm', 'r']",interpret cvfolds warning message running gbm r,0.0,0.0,11,47,3.9166666666666665,0,0,0,0,0,0,0,0
2352,solution checker for past hackathons,Other,solution checker for past hackathons,"['solution', 'checker', 'for', 'past', 'hackathons']",0,"['solution', 'checker', 'for', 'past', 'hackathons']","['solution', 'checker', 'past', 'hackathons']",solution checker past hackathons,-0.25,-0.25,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2353,start a business based on data science,Career,start a business based on data science,"['start', 'a', 'business', 'based', 'on', 'data', 'science']",0,"['start', 'a', 'business', 'based', 'on', 'data', 'science']","['start', 'business', 'based', 'data', 'science']",start business based data science,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
2354,what does the warning the response has five or fewer unique values while building random forest mean,Techniques,what does the warning the response has five or fewer unique values while building random forest mean,"['what', 'does', 'the', 'warning', 'the', 'response', 'has', 'five', 'or', 'fewer', 'unique', 'values', 'while', 'building', 'random', 'forest', 'mean']",0,"['what', 'doe', 'the', 'warning', 'the', 'response', 'ha', 'five', 'or', 'fewer', 'unique', 'value', 'while', 'building', 'random', 'forest', 'mean']","['doe', 'warning', 'response', 'ha', 'five', 'fewer', 'unique', 'value', 'building', 'random', 'forest', 'mean']",doe warning response ha five fewer unique value building random forest mean,-0.1458333333333333,-0.1458333333333333,17,75,4.166666666666667,0,0,0,0,0,0,0,0
2355,how to select which regression techiques will be implimented,Techniques,how to select which regression techiques will be implimented,"['how', 'to', 'select', 'which', 'regression', 'techiques', 'will', 'be', 'implimented']",0,"['how', 'to', 'select', 'which', 'regression', 'techiques', 'will', 'be', 'implimented']","['select', 'regression', 'techiques', 'implimented']",select regression techiques implimented,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
2356,applications of ml algorithms in businness,Techniques,applications of ml algorithms in businness,"['applications', 'of', 'ml', 'algorithms', 'in', 'businness']",0,"['application', 'of', 'ml', 'algorithm', 'in', 'businness']","['application', 'ml', 'algorithm', 'businness']",application ml algorithm businness,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
2357,doubt in algorithm tunning,Techniques,doubt in algorithm tunning,"['doubt', 'in', 'algorithm', 'tunning']",0,"['doubt', 'in', 'algorithm', 'tunning']","['doubt', 'algorithm', 'tunning']",doubt algorithm tunning,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
2358,how to count number of distinct values in a column of a data table in r,Tools,how to count number of distinct values in a column of a data table in r,"['how', 'to', 'count', 'number', 'of', 'distinct', 'values', 'in', 'a', 'column', 'of', 'a', 'data', 'table', 'in', 'r']",0,"['how', 'to', 'count', 'number', 'of', 'distinct', 'value', 'in', 'a', 'column', 'of', 'a', 'data', 'table', 'in', 'r']","['count', 'number', 'distinct', 'value', 'column', 'data', 'table', 'r']",count number distinct value column data table r,0.3,0.3,16,47,2.764705882352941,0,0,0,0,0,0,0,0
2359,which sas course shall i pursue and why,Career,which sas course shall i pursue and why,"['which', 'sas', 'course', 'shall', 'i', 'pursue', 'and', 'why']",0,"['which', 'sa', 'course', 'shall', 'i', 'pursue', 'and', 'why']","['sa', 'course', 'shall', 'pursue']",sa course shall pursue,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
2360,can i attend the statistics skilltest now,Hackathons,can i attend the statistics skilltest now,"['can', 'i', 'attend', 'the', 'statistics', 'skilltest', 'now']",0,"['can', 'i', 'attend', 'the', 'statistic', 'skilltest', 'now']","['attend', 'statistic', 'skilltest']",attend statistic skilltest,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
2361,frequent pattern growth algorithm in r,Techniques,frequent pattern growth algorithm in r,"['frequent', 'pattern', 'growth', 'algorithm', 'in', 'r']",0,"['frequent', 'pattern', 'growth', 'algorithm', 'in', 'r']","['frequent', 'pattern', 'growth', 'algorithm', 'r']",frequent pattern growth algorithm r,0.1,0.1,6,35,5.0,0,0,0,0,0,0,0,0
2362,use of dfappend in pandas with python,Tools,use of dfappend in pandas with python,"['use', 'of', 'dfappend', 'in', 'pandas', 'with', 'python']",0,"['use', 'of', 'dfappend', 'in', 'panda', 'with', 'python']","['use', 'dfappend', 'panda', 'python']",use dfappend panda python,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
2363,data transformation while predicting for new dataone hot encoding issue,Techniques,data transformation while predicting for new dataone hot encoding issue,"['data', 'transformation', 'while', 'predicting', 'for', 'new', 'dataone', 'hot', 'encoding', 'issue']",0,"['data', 'transformation', 'while', 'predicting', 'for', 'new', 'dataone', 'hot', 'encoding', 'issue']","['data', 'transformation', 'predicting', 'new', 'dataone', 'hot', 'encoding', 'issue']",data transformation predicting new dataone hot encoding issue,0.1931818181818181,0.1931818181818181,10,61,5.545454545454546,0,0,0,0,0,0,0,0
2364,which algorithm is best suited for recommendation system problem,Hackathons,which algorithm is best suited for recommendation system problem,"['which', 'algorithm', 'is', 'best', 'suited', 'for', 'recommendation', 'system', 'problem']",0,"['which', 'algorithm', 'is', 'best', 'suited', 'for', 'recommendation', 'system', 'problem']","['algorithm', 'best', 'suited', 'recommendation', 'system', 'problem']",algorithm best suited recommendation system problem,1.0,1.0,9,51,5.1,0,0,0,0,0,0,0,0
2366,how to plot the difference between sample mean and population mean in r,Tools,how to plot the difference between sample mean and population mean in r,"['how', 'to', 'plot', 'the', 'difference', 'between', 'sample', 'mean', 'and', 'population', 'mean', 'in', 'r']",0,"['how', 'to', 'plot', 'the', 'difference', 'between', 'sample', 'mean', 'and', 'population', 'mean', 'in', 'r']","['plot', 'difference', 'sample', 'mean', 'population', 'mean', 'r']",plot difference sample mean population mean r,-0.3125,-0.3125,13,45,3.2142857142857144,0,0,0,0,0,0,0,0
2367,apply function in r,Tools,apply function in r,"['apply', 'function', 'in', 'r']",0,"['apply', 'function', 'in', 'r']","['apply', 'function', 'r']",apply function r,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
2368,is analytics making an impact in todays world,Other,is analytics making an impact in todays world,"['is', 'analytics', 'making', 'an', 'impact', 'in', 'todays', 'world']",0,"['is', 'analytics', 'making', 'an', 'impact', 'in', 'today', 'world']","['analytics', 'making', 'impact', 'today', 'world']",analytics making impact today world,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
2369,how can i extract all mail ids from a text file in python,Tools,how can i extract all mail ids from a text file in python,"['how', 'can', 'i', 'extract', 'all', 'mail', 'ids', 'from', 'a', 'text', 'file', 'in', 'python']",0,"['how', 'can', 'i', 'extract', 'all', 'mail', 'id', 'from', 'a', 'text', 'file', 'in', 'python']","['extract', 'mail', 'id', 'text', 'file', 'python']",extract mail id text file python,0.0,0.0,13,32,2.2857142857142856,0,0,0,0,0,0,0,0
2370,bangalore hackathon  th june ,Hackathons,bangalore hackathon  th june ,"['bangalore', 'hackathon', 'th', 'june']",1,"['bangalore', 'hackathon', 'th', 'june']","['bangalore', 'hackathon', 'th', 'june']",bangalore hackathon th june,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
2371,trivial question related to kfold,Techniques,trivial question related to kfold,"['trivial', 'question', 'related', 'to', 'kfold']",0,"['trivial', 'question', 'related', 'to', 'kfold']","['trivial', 'question', 'related', 'kfold']",trivial question related kfold,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
2372,how to code the response variable into a scatter plot in r,Tools,how to code the response variable into a scatter plot in r,"['how', 'to', 'code', 'the', 'response', 'variable', 'into', 'a', 'scatter', 'plot', 'in', 'r']",0,"['how', 'to', 'code', 'the', 'response', 'variable', 'into', 'a', 'scatter', 'plot', 'in', 'r']","['code', 'response', 'variable', 'scatter', 'plot', 'r']",code response variable scatter plot r,0.0,0.0,12,37,2.8461538461538463,0,0,0,0,0,0,0,0
2373,what machine learning techniques could be used to derive benchmarks for a time series data,Techniques,what machine learning techniques could be used to derive benchmarks for a time series data,"['what', 'machine', 'learning', 'techniques', 'could', 'be', 'used', 'to', 'derive', 'benchmarks', 'for', 'a', 'time', 'series', 'data']",0,"['what', 'machine', 'learning', 'technique', 'could', 'be', 'used', 'to', 'derive', 'benchmark', 'for', 'a', 'time', 'series', 'data']","['machine', 'learning', 'technique', 'could', 'used', 'derive', 'benchmark', 'time', 'series', 'data']",machine learning technique could used derive benchmark time series data,0.0,0.0,15,71,4.4375,0,0,0,0,0,0,0,0
2374,need help on test data,Hackathons,need help on test data,"['need', 'help', 'on', 'test', 'data']",0,"['need', 'help', 'on', 'test', 'data']","['need', 'help', 'test', 'data']",need help test data,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
2375,how to access output of groupby as a dataframe in python,Tools,how to access output of groupby as a dataframe in python,"['how', 'to', 'access', 'output', 'of', 'groupby', 'as', 'a', 'dataframe', 'in', 'python']",0,"['how', 'to', 'access', 'output', 'of', 'groupby', 'a', 'a', 'dataframe', 'in', 'python']","['access', 'output', 'groupby', 'dataframe', 'python']",access output groupby dataframe python,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
2376,switching career from teleco to data analytics after a break,Career,switching career from teleco to data analytics after a break,"['switching', 'career', 'from', 'teleco', 'to', 'data', 'analytics', 'after', 'a', 'break']",0,"['switching', 'career', 'from', 'teleco', 'to', 'data', 'analytics', 'after', 'a', 'break']","['switching', 'career', 'teleco', 'data', 'analytics', 'break']",switching career teleco data analytics break,0.0,0.0,10,44,4.0,0,0,0,0,0,0,0,0
2377,how can we lookup values from left in excel,Tools,how can we lookup values from left in excel,"['how', 'can', 'we', 'lookup', 'values', 'from', 'left', 'in', 'excel']",0,"['how', 'can', 'we', 'lookup', 'value', 'from', 'left', 'in', 'excel']","['lookup', 'value', 'left', 'excel']",lookup value left excel,0.0,0.0,9,23,2.3,0,0,0,0,0,0,0,0
2378,deep learning  use cases,Techniques,deep learning  use cases,"['deep', 'learning', 'use', 'cases']",0,"['deep', 'learning', 'use', 'case']","['deep', 'learning', 'use', 'case']",deep learning use case,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
2379,approaches promo code analysis for dataset,Techniques,approaches promo code analysis for dataset,"['approaches', 'promo', 'code', 'analysis', 'for', 'dataset']",0,"['approach', 'promo', 'code', 'analysis', 'for', 'dataset']","['approach', 'promo', 'code', 'analysis', 'dataset']",approach promo code analysis dataset,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
2380,how to decide which tool or technology to be selected for a machine learning problem,Techniques,how to decide which tool or technology to be selected for a machine learning problem,"['how', 'to', 'decide', 'which', 'tool', 'or', 'technology', 'to', 'be', 'selected', 'for', 'a', 'machine', 'learning', 'problem']",0,"['how', 'to', 'decide', 'which', 'tool', 'or', 'technology', 'to', 'be', 'selected', 'for', 'a', 'machine', 'learning', 'problem']","['decide', 'tool', 'technology', 'selected', 'machine', 'learning', 'problem']",decide tool technology selected machine learning problem,0.0,0.0,15,56,3.5,0,0,0,0,0,0,0,0
2381,case studies solved,Misc,case studies solved,"['case', 'studies', 'solved']",0,"['case', 'study', 'solved']","['case', 'study', 'solved']",case study solved,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
2382,predective maintenance modeling,Techniques,predective maintenance modeling,"['predective', 'maintenance', 'modeling']",0,"['predective', 'maintenance', 'modeling']","['predective', 'maintenance', 'modeling']",predective maintenance modeling,0.0,0.0,3,31,7.75,0,0,0,0,0,0,0,0
2383,useful ness of factor in data set in r,Tools,useful ness of factor in data set in r,"['useful', 'ness', 'of', 'factor', 'in', 'data', 'set', 'in', 'r']",0,"['useful', 'ness', 'of', 'factor', 'in', 'data', 'set', 'in', 'r']","['useful', 'ness', 'factor', 'data', 'set', 'r']",useful ness factor data set r,0.3,0.3,9,29,2.9,0,0,0,0,0,0,0,0
2384,arpredict for forecasting arima model,Techniques,arpredict for forecasting arima model,"['arpredict', 'for', 'forecasting', 'arima', 'model']",0,"['arpredict', 'for', 'forecasting', 'arima', 'model']","['arpredict', 'forecasting', 'arima', 'model']",arpredict forecasting arima model,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
2385,extract sentence embedding from gpt,Techniques,extract sentence embedding from gpt,"['extract', 'sentence', 'embedding', 'from', 'gpt']",0,"['extract', 'sentence', 'embedding', 'from', 'gpt']","['extract', 'sentence', 'embedding', 'gpt']",extract sentence embedding gpt,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
2386,visualize the color of points in a scatter plot based on maximum value in tableau,Tools,visualize the color of points in a scatter plot based on maximum value in tableau,"['visualize', 'the', 'color', 'of', 'points', 'in', 'a', 'scatter', 'plot', 'based', 'on', 'maximum', 'value', 'in', 'tableau']",0,"['visualize', 'the', 'color', 'of', 'point', 'in', 'a', 'scatter', 'plot', 'based', 'on', 'maximum', 'value', 'in', 'tableau']","['visualize', 'color', 'point', 'scatter', 'plot', 'based', 'maximum', 'value', 'tableau']",visualize color point scatter plot based maximum value tableau,0.0,0.0,15,62,3.875,0,0,0,0,0,0,0,0
2387,is multicollinearity always a problem in regression,Techniques,is multicollinearity always a problem in regression,"['is', 'multicollinearity', 'always', 'a', 'problem', 'in', 'regression']",0,"['is', 'multicollinearity', 'always', 'a', 'problem', 'in', 'regression']","['multicollinearity', 'always', 'problem', 'regression']",multicollinearity always problem regression,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
2388,what are the ways we can convert an image to a matrix in r,Tools,what are the ways we can convert an image to a matrix in r,"['what', 'are', 'the', 'ways', 'we', 'can', 'convert', 'an', 'image', 'to', 'a', 'matrix', 'in', 'r']",0,"['what', 'are', 'the', 'way', 'we', 'can', 'convert', 'an', 'image', 'to', 'a', 'matrix', 'in', 'r']","['way', 'convert', 'image', 'matrix', 'r']",way convert image matrix r,0.0,0.0,14,26,1.7333333333333334,0,0,0,0,0,0,0,0
2389,are there any ms data science or related programs for msphd health science or biology,Career,are there any ms data science or related programs for msphd health science or biology,"['are', 'there', 'any', 'ms', 'data', 'science', 'or', 'related', 'programs', 'for', 'msphd', 'health', 'science', 'or', 'biology']",0,"['are', 'there', 'any', 'm', 'data', 'science', 'or', 'related', 'program', 'for', 'msphd', 'health', 'science', 'or', 'biology']","['data', 'science', 'related', 'program', 'msphd', 'health', 'science', 'biology']",data science related program msphd health science biology,0.0,0.0,15,57,3.5625,0,0,0,0,0,0,0,0
2390,how can i create dual axis chart in qlikview,Tools,how can i create dual axis chart in qlikview,"['how', 'can', 'i', 'create', 'dual', 'axis', 'chart', 'in', 'qlikview']",0,"['how', 'can', 'i', 'create', 'dual', 'axis', 'chart', 'in', 'qlikview']","['create', 'dual', 'axis', 'chart', 'qlikview']",create dual axis chart qlikview,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
2391,method for linear regression,Techniques,method for linear regression,"['method', 'for', 'linear', 'regression']",0,"['method', 'for', 'linear', 'regression']","['method', 'linear', 'regression']",method linear regression,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
2392,tfidf features on non nlp problems,Hackathons,tfidf features on non nlp problems,"['tfidf', 'features', 'on', 'non', 'nlp', 'problems']",0,"['tfidf', 'feature', 'on', 'non', 'nlp', 'problem']","['tfidf', 'feature', 'non', 'nlp', 'problem']",tfidf feature non nlp problem,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
2393,why cases control sampling is most effective when the prior probabilities of class are unequal,Techniques,why cases control sampling is most effective when the prior probabilities of class are unequal,"['why', 'cases', 'control', 'sampling', 'is', 'most', 'effective', 'when', 'the', 'prior', 'probabilities', 'of', 'class', 'are', 'unequal']",0,"['why', 'case', 'control', 'sampling', 'is', 'most', 'effective', 'when', 'the', 'prior', 'probability', 'of', 'class', 'are', 'unequal']","['case', 'control', 'sampling', 'effective', 'prior', 'probability', 'class', 'unequal']",case control sampling effective prior probability class unequal,0.3666666666666667,0.3,15,63,3.9375,0,0,0,0,0,0,0,0
2394,ensembling technique in r,Techniques,ensembling technique in r,"['ensembling', 'technique', 'in', 'r']",0,"['ensembling', 'technique', 'in', 'r']","['ensembling', 'technique', 'r']",ensembling technique r,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
2395,comparing actual vs predicted values,Techniques,comparing actual vs predicted values,"['comparing', 'actual', 'vs', 'predicted', 'values']",0,"['comparing', 'actual', 'v', 'predicted', 'value']","['comparing', 'actual', 'v', 'predicted', 'value']",comparing actual v predicted value,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
2396,missing values imputation by prediction,Techniques,missing values imputation by prediction,"['missing', 'values', 'imputation', 'by', 'prediction']",0,"['missing', 'value', 'imputation', 'by', 'prediction']","['missing', 'value', 'imputation', 'prediction']",missing value imputation prediction,-0.2,-0.2,5,35,5.833333333333333,0,0,0,0,0,0,0,0
2397,using  in swirl r programming is showing error,Tools,using  in swirl r programming is showing error,"['using', 'in', 'swirl', 'r', 'programming', 'is', 'showing', 'error']",0,"['using', 'in', 'swirl', 'r', 'programming', 'is', 'showing', 'error']","['using', 'swirl', 'r', 'programming', 'showing', 'error']",using swirl r programming showing error,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
2398,best approach for text classification in unbalanced dataset,Techniques,best approach for text classification in unbalanced dataset,"['best', 'approach', 'for', 'text', 'classification', 'in', 'unbalanced', 'dataset']",0,"['best', 'approach', 'for', 'text', 'classification', 'in', 'unbalanced', 'dataset']","['best', 'approach', 'text', 'classification', 'unbalanced', 'dataset']",best approach text classification unbalanced dataset,1.0,1.0,8,52,5.777777777777778,0,0,0,0,0,0,0,0
2399,can the oob estimate of error in randomforest model be realiably used to estimate the accuracy of the model,Techniques,can the oob estimate of error in randomforest model be realiably used to estimate the accuracy of the model,"['can', 'the', 'oob', 'estimate', 'of', 'error', 'in', 'randomforest', 'model', 'be', 'realiably', 'used', 'to', 'estimate', 'the', 'accuracy', 'of', 'the', 'model']",0,"['can', 'the', 'oob', 'estimate', 'of', 'error', 'in', 'randomforest', 'model', 'be', 'realiably', 'used', 'to', 'estimate', 'the', 'accuracy', 'of', 'the', 'model']","['oob', 'estimate', 'error', 'randomforest', 'model', 'realiably', 'used', 'estimate', 'accuracy', 'model']",oob estimate error randomforest model realiably used estimate accuracy model,0.0,0.0,19,76,3.8,0,0,0,0,0,0,0,0
2400,low r value in prediction of discrete value,Techniques,low r value in prediction of discrete value,"['low', 'r', 'value', 'in', 'prediction', 'of', 'discrete', 'value']",0,"['low', 'r', 'value', 'in', 'prediction', 'of', 'discrete', 'value']","['low', 'r', 'value', 'prediction', 'discrete', 'value']",low r value prediction discrete value,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
2401,how does yolo behave with rotated images,Techniques,how does yolo behave with rotated images,"['how', 'does', 'yolo', 'behave', 'with', 'rotated', 'images']",0,"['how', 'doe', 'yolo', 'behave', 'with', 'rotated', 'image']","['doe', 'yolo', 'behave', 'rotated', 'image']",doe yolo behave rotated image,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
2402,how to cleanse place of work in dataset of k records,Techniques,how to cleanse place of work in dataset of k records,"['how', 'to', 'cleanse', 'place', 'of', 'work', 'in', 'dataset', 'of', 'k', 'records']",0,"['how', 'to', 'cleanse', 'place', 'of', 'work', 'in', 'dataset', 'of', 'k', 'record']","['cleanse', 'place', 'work', 'dataset', 'k', 'record']",cleanse place work dataset k record,0.0,0.0,11,35,2.9166666666666665,0,0,0,0,0,0,0,0
2403,how to deal with na while doing factor analysis in r,Tools,how to deal with na while doing factor analysis in r,"['how', 'to', 'deal', 'with', 'na', 'while', 'doing', 'factor', 'analysis', 'in', 'r']",0,"['how', 'to', 'deal', 'with', 'na', 'while', 'doing', 'factor', 'analysis', 'in', 'r']","['deal', 'na', 'factor', 'analysis', 'r']",deal na factor analysis r,0.0,0.0,11,25,2.0833333333333335,0,0,0,0,0,0,0,0
2404,how to decode encoded xml in wso developer studio proxy service,Techniques,how to decode encoded xml in wso developer studio proxy service,"['how', 'to', 'decode', 'encoded', 'xml', 'in', 'wso', 'developer', 'studio', 'proxy', 'service']",0,"['how', 'to', 'decode', 'encoded', 'xml', 'in', 'wso', 'developer', 'studio', 'proxy', 'service']","['decode', 'encoded', 'xml', 'wso', 'developer', 'studio', 'proxy', 'service']",decode encoded xml wso developer studio proxy service,0.0,0.0,11,53,4.416666666666667,0,0,0,0,0,0,0,0
2405,recommendation engine algos,Techniques,recommendation engine algos,"['recommendation', 'engine', 'algos']",0,"['recommendation', 'engine', 'algos']","['recommendation', 'engine', 'algos']",recommendation engine algos,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
2406,r capability for advance charts and reports,Tools,r capability for advance charts and reports,"['r', 'capability', 'for', 'advance', 'charts', 'and', 'reports']",0,"['r', 'capability', 'for', 'advance', 'chart', 'and', 'report']","['r', 'capability', 'advance', 'chart', 'report']",r capability advance chart report,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
2407,how to stack a graph on geomcrossbar based on one column in r,Tools,how to stack a graph on geomcrossbar based on one column in r,"['how', 'to', 'stack', 'a', 'graph', 'on', 'geomcrossbar', 'based', 'on', 'one', 'column', 'in', 'r']",0,"['how', 'to', 'stack', 'a', 'graph', 'on', 'geomcrossbar', 'based', 'on', 'one', 'column', 'in', 'r']","['stack', 'graph', 'geomcrossbar', 'based', 'one', 'column', 'r']",stack graph geomcrossbar based one column r,0.0,0.0,13,43,3.0714285714285716,0,0,0,0,0,0,0,0
2408,how to replace all nan with a value in r,Tools,how to replace all nan with a value in r,"['how', 'to', 'replace', 'all', 'nan', 'with', 'a', 'value', 'in', 'r']",0,"['how', 'to', 'replace', 'all', 'nan', 'with', 'a', 'value', 'in', 'r']","['replace', 'nan', 'value', 'r']",replace nan value r,0.0,0.0,10,19,1.7272727272727273,0,0,0,0,0,0,0,0
2409,hands on training in data science,Resources,hands on training in data science,"['hands', 'on', 'training', 'in', 'data', 'science']",0,"['hand', 'on', 'training', 'in', 'data', 'science']","['hand', 'training', 'data', 'science']",hand training data science,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
2410,change the order of individual plots in the boxplot graph in r,Tools,change the order of individual plots in the boxplot graph in r,"['change', 'the', 'order', 'of', 'individual', 'plots', 'in', 'the', 'boxplot', 'graph', 'in', 'r']",0,"['change', 'the', 'order', 'of', 'individual', 'plot', 'in', 'the', 'boxplot', 'graph', 'in', 'r']","['change', 'order', 'individual', 'plot', 'boxplot', 'graph', 'r']",change order individual plot boxplot graph r,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
2411,how to import all files containing a specific string in sas,Tools,how to import all files containing a specific string in sas,"['how', 'to', 'import', 'all', 'files', 'containing', 'a', 'specific', 'string', 'in', 'sas']",0,"['how', 'to', 'import', 'all', 'file', 'containing', 'a', 'specific', 'string', 'in', 'sa']","['import', 'file', 'containing', 'specific', 'string', 'sa']",import file containing specific string sa,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
2412,gini impurity in decision tress,Techniques,gini impurity in decision tress,"['gini', 'impurity', 'in', 'decision', 'tress']",0,"['gini', 'impurity', 'in', 'decision', 'tress']","['gini', 'impurity', 'decision', 'tress']",gini impurity decision tress,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
2413,good read learning path for deep learning,Resources,good read learning path for deep learning,"['good', 'read', 'learning', 'path', 'for', 'deep', 'learning']",0,"['good', 'read', 'learning', 'path', 'for', 'deep', 'learning']","['good', 'read', 'learning', 'path', 'deep', 'learning']",good read learning path deep learning,0.35,0.35,7,37,4.625,0,0,0,0,0,0,0,0
2414,how to work with predicting continuous output,Techniques,how to work with predicting continuous output,"['how', 'to', 'work', 'with', 'predicting', 'continuous', 'output']",0,"['how', 'to', 'work', 'with', 'predicting', 'continuous', 'output']","['work', 'predicting', 'continuous', 'output']",work predicting continuous output,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
2415,how can we remove synthetic keys and table during data modelling in qlikview,Tools,how can we remove synthetic keys and table during data modelling in qlikview,"['how', 'can', 'we', 'remove', 'synthetic', 'keys', 'and', 'table', 'during', 'data', 'modelling', 'in', 'qlikview']",0,"['how', 'can', 'we', 'remove', 'synthetic', 'key', 'and', 'table', 'during', 'data', 'modelling', 'in', 'qlikview']","['remove', 'synthetic', 'key', 'table', 'data', 'modelling', 'qlikview']",remove synthetic key table data modelling qlikview,0.0,0.0,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
2416,create a report by using macros,Techniques,create a report by using macros,"['create', 'a', 'report', 'by', 'using', 'macros']",0,"['create', 'a', 'report', 'by', 'using', 'macro']","['create', 'report', 'using', 'macro']",create report using macro,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
2417,algorithms for time series forecasting,Techniques,algorithms for time series forecasting,"['algorithms', 'for', 'time', 'series', 'forecasting']",0,"['algorithm', 'for', 'time', 'series', 'forecasting']","['algorithm', 'time', 'series', 'forecasting']",algorithm time series forecasting,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
2418,analytics interview question,Career,analytics interview question,"['analytics', 'interview', 'question']",0,"['analytics', 'interview', 'question']","['analytics', 'interview', 'question']",analytics interview question,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
2419,determining how cute a puppy or cat is using deep learning,Techniques,determining how cute a puppy or cat is using deep learning,"['determining', 'how', 'cute', 'a', 'puppy', 'or', 'cat', 'is', 'using', 'deep', 'learning']",0,"['determining', 'how', 'cute', 'a', 'puppy', 'or', 'cat', 'is', 'using', 'deep', 'learning']","['determining', 'cute', 'puppy', 'cat', 'using', 'deep', 'learning']",determining cute puppy cat using deep learning,0.25,0.25,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
2420,interactive maps,Tools,interactive maps,"['interactive', 'maps']",0,"['interactive', 'map']","['interactive', 'map']",interactive map,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
2421,sigma cab train file  multiclass classification,Resources,sigma cab train file  multiclass classification,"['sigma', 'cab', 'train', 'file', 'multiclass', 'classification']",0,"['sigma', 'cab', 'train', 'file', 'multiclass', 'classification']","['sigma', 'cab', 'train', 'file', 'multiclass', 'classification']",sigma cab train file multiclass classification,0.0,0.0,6,46,6.571428571428571,0,0,0,0,0,0,0,0
2422,time series database,Tools,time series database,"['time', 'series', 'database']",0,"['time', 'series', 'database']","['time', 'series', 'database']",time series database,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
2423,researchproject ideas during time abroad   months,Misc,researchproject ideas during time abroad   months,"['researchproject', 'ideas', 'during', 'time', 'abroad', 'months']",1,"['researchproject', 'idea', 'during', 'time', 'abroad', 'month']","['researchproject', 'idea', 'time', 'abroad', 'month']",researchproject idea time abroad month,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
2424,descriptive statistics of time series data,Techniques,descriptive statistics of time series data,"['descriptive', 'statistics', 'of', 'time', 'series', 'data']",0,"['descriptive', 'statistic', 'of', 'time', 'series', 'data']","['descriptive', 'statistic', 'time', 'series', 'data']",descriptive statistic time series data,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
2425,how to calculate the model building and predicting time of a classifier in python,Tools,how to calculate the model building and predicting time of a classifier in python,"['how', 'to', 'calculate', 'the', 'model', 'building', 'and', 'predicting', 'time', 'of', 'a', 'classifier', 'in', 'python']",0,"['how', 'to', 'calculate', 'the', 'model', 'building', 'and', 'predicting', 'time', 'of', 'a', 'classifier', 'in', 'python']","['calculate', 'model', 'building', 'predicting', 'time', 'classifier', 'python']",calculate model building predicting time classifier python,0.0,0.0,14,58,3.8666666666666667,0,0,0,0,0,0,0,0
2426,data science interview questions,Techniques,data science interview questions,"['data', 'science', 'interview', 'questions']",0,"['data', 'science', 'interview', 'question']","['data', 'science', 'interview', 'question']",data science interview question,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
2427,load csv file data to databasemysql in r,Other,load csv file data to databasemysql in r,"['load', 'csv', 'file', 'data', 'to', 'databasemysql', 'in', 'r']",0,"['load', 'csv', 'file', 'data', 'to', 'databasemysql', 'in', 'r']","['load', 'csv', 'file', 'data', 'databasemysql', 'r']",load csv file data databasemysql r,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
2428,how to use rename in sas while merging datasets,Tools,how to use rename in sas while merging datasets,"['how', 'to', 'use', 'rename', 'in', 'sas', 'while', 'merging', 'datasets']",0,"['how', 'to', 'use', 'rename', 'in', 'sa', 'while', 'merging', 'datasets']","['use', 'rename', 'sa', 'merging', 'datasets']",use rename sa merging datasets,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
2429,calculating mean for circular quantities,Techniques,calculating mean for circular quantities,"['calculating', 'mean', 'for', 'circular', 'quantities']",0,"['calculating', 'mean', 'for', 'circular', 'quantity']","['calculating', 'mean', 'circular', 'quantity']",calculating mean circular quantity,-0.3125,-0.3125,5,34,5.666666666666667,0,0,0,0,0,0,0,0
2430,top consultancies in analytics for freshers in bangalore,Career,top consultancies in analytics for freshers in bangalore,"['top', 'consultancies', 'in', 'analytics', 'for', 'freshers', 'in', 'bangalore']",0,"['top', 'consultancy', 'in', 'analytics', 'for', 'fresher', 'in', 'bangalore']","['top', 'consultancy', 'analytics', 'fresher', 'bangalore']",top consultancy analytics fresher bangalore,0.5,0.5,8,43,4.777777777777778,0,0,0,0,0,0,0,0
2431,speech recognition using python,Techniques,speech recognition using python,"['speech', 'recognition', 'using', 'python']",0,"['speech', 'recognition', 'using', 'python']","['speech', 'recognition', 'using', 'python']",speech recognition using python,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
2432,if conditions in sas,Tools,if conditions in sas,"['if', 'conditions', 'in', 'sas']",0,"['if', 'condition', 'in', 'sa']","['condition', 'sa']",condition sa,0.0,0.0,4,12,2.4,0,0,0,0,0,0,0,0
2433,rbcdsai post bac fellowship test,Hackathons,rbcdsai post bac fellowship test,"['rbcdsai', 'post', 'bac', 'fellowship', 'test']",0,"['rbcdsai', 'post', 'bac', 'fellowship', 'test']","['rbcdsai', 'post', 'bac', 'fellowship', 'test']",rbcdsai post bac fellowship test,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2434,is there opportunities for freshers in data analyticsscience,Career,is there opportunities for freshers in data analyticsscience,"['is', 'there', 'opportunities', 'for', 'freshers', 'in', 'data', 'analyticsscience']",0,"['is', 'there', 'opportunity', 'for', 'fresher', 'in', 'data', 'analyticsscience']","['opportunity', 'fresher', 'data', 'analyticsscience']",opportunity fresher data analyticsscience,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2435,difference in coordcartesian and scaleycontinuous,Tools,difference in coordcartesian and scaleycontinuous,"['difference', 'in', 'coordcartesian', 'and', 'scaleycontinuous']",0,"['difference', 'in', 'coordcartesian', 'and', 'scaleycontinuous']","['difference', 'coordcartesian', 'scaleycontinuous']",difference coordcartesian scaleycontinuous,0.0,0.0,5,42,7.0,0,0,0,0,0,0,0,0
2436,overundersampling for fraud analytics,Techniques,overundersampling for fraud analytics,"['overundersampling', 'for', 'fraud', 'analytics']",0,"['overundersampling', 'for', 'fraud', 'analytics']","['overundersampling', 'fraud', 'analytics']",overundersampling fraud analytics,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
2437,what is the meaning of interaction depth in gbm using caret in r,Techniques,what is the meaning of interaction depth in gbm using caret in r,"['what', 'is', 'the', 'meaning', 'of', 'interaction', 'depth', 'in', 'gbm', 'using', 'caret', 'in', 'r']",0,"['what', 'is', 'the', 'meaning', 'of', 'interaction', 'depth', 'in', 'gbm', 'using', 'caret', 'in', 'r']","['meaning', 'interaction', 'depth', 'gbm', 'using', 'caret', 'r']",meaning interaction depth gbm using caret r,0.0,0.0,13,43,3.0714285714285716,0,0,0,0,0,0,0,0
2438,what are the common methods to deal with circular reference in qlikview,Tools,what are the common methods to deal with circular reference in qlikview,"['what', 'are', 'the', 'common', 'methods', 'to', 'deal', 'with', 'circular', 'reference', 'in', 'qlikview']",0,"['what', 'are', 'the', 'common', 'method', 'to', 'deal', 'with', 'circular', 'reference', 'in', 'qlikview']","['common', 'method', 'deal', 'circular', 'reference', 'qlikview']",common method deal circular reference qlikview,-0.3,-0.3,12,46,3.5384615384615383,0,0,0,0,0,0,0,0
2439,how to decide number of bins for continuous variable to calculate iv and woe value,Techniques,how to decide number of bins for continuous variable to calculate iv and woe value,"['how', 'to', 'decide', 'number', 'of', 'bins', 'for', 'continuous', 'variable', 'to', 'calculate', 'iv', 'and', 'woe', 'value']",0,"['how', 'to', 'decide', 'number', 'of', 'bin', 'for', 'continuous', 'variable', 'to', 'calculate', 'iv', 'and', 'woe', 'value']","['decide', 'number', 'bin', 'continuous', 'variable', 'calculate', 'iv', 'woe', 'value']",decide number bin continuous variable calculate iv woe value,0.0,0.0,15,60,3.75,0,0,0,0,0,0,0,0
2440,lean six sigma to big data and data science,Career,lean six sigma to big data and data science,"['lean', 'six', 'sigma', 'to', 'big', 'data', 'and', 'data', 'science']",0,"['lean', 'six', 'sigma', 'to', 'big', 'data', 'and', 'data', 'science']","['lean', 'six', 'sigma', 'big', 'data', 'data', 'science']",lean six sigma big data data science,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
2441,how to classify output variable in different levels of output variable,Techniques,how to classify output variable in different levels of output variable,"['how', 'to', 'classify', 'output', 'variable', 'in', 'different', 'levels', 'of', 'output', 'variable']",0,"['how', 'to', 'classify', 'output', 'variable', 'in', 'different', 'level', 'of', 'output', 'variable']","['classify', 'output', 'variable', 'different', 'level', 'output', 'variable']",classify output variable different level output variable,0.0,0.0,11,56,4.666666666666667,0,0,0,0,0,0,0,0
2442,please help me about my decision of career shift from healthcare sales to analytics,Career,please help me about my decision of career shift from healthcare sales to analytics,"['please', 'help', 'me', 'about', 'my', 'decision', 'of', 'career', 'shift', 'from', 'healthcare', 'sales', 'to', 'analytics']",0,"['please', 'help', 'me', 'about', 'my', 'decision', 'of', 'career', 'shift', 'from', 'healthcare', 'sale', 'to', 'analytics']","['please', 'help', 'decision', 'career', 'shift', 'healthcare', 'sale', 'analytics']",please help decision career shift healthcare sale analytics,0.0,0.0,14,59,3.933333333333333,0,0,0,0,0,0,0,0
2443,variable clustering in r,Techniques,variable clustering in r,"['variable', 'clustering', 'in', 'r']",0,"['variable', 'clustering', 'in', 'r']","['variable', 'clustering', 'r']",variable clustering r,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
2444,which machine learning algorithm to use when variance is more than bias,Techniques,which machine learning algorithm to use when variance is more than bias,"['which', 'machine', 'learning', 'algorithm', 'to', 'use', 'when', 'variance', 'is', 'more', 'than', 'bias']",0,"['which', 'machine', 'learning', 'algorithm', 'to', 'use', 'when', 'variance', 'is', 'more', 'than', 'bias']","['machine', 'learning', 'algorithm', 'use', 'variance', 'bias']",machine learning algorithm use variance bias,0.5,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
2445,dataquest or datacamp,Resources,dataquest or datacamp,"['dataquest', 'or', 'datacamp']",0,"['dataquest', 'or', 'datacamp']","['dataquest', 'datacamp']",dataquest datacamp,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
2446,comparing data science platform capabilities,Tools,comparing data science platform capabilities,"['comparing', 'data', 'science', 'platform', 'capabilities']",0,"['comparing', 'data', 'science', 'platform', 'capability']","['comparing', 'data', 'science', 'platform', 'capability']",comparing data science platform capability,0.0,0.0,5,42,7.0,0,0,0,0,0,0,0,0
2447,resume parser  sentence matcher,Techniques,resume parser  sentence matcher,"['resume', 'parser', 'sentence', 'matcher']",0,"['resume', 'parser', 'sentence', 'matcher']","['resume', 'parser', 'sentence', 'matcher']",resume parser sentence matcher,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
2448,offsetting oversampling in sas for rare events in logistic regression,Techniques,offsetting oversampling in sas for rare events in logistic regression,"['offsetting', 'oversampling', 'in', 'sas', 'for', 'rare', 'events', 'in', 'logistic', 'regression']",0,"['offsetting', 'oversampling', 'in', 'sa', 'for', 'rare', 'event', 'in', 'logistic', 'regression']","['offsetting', 'oversampling', 'sa', 'rare', 'event', 'logistic', 'regression']",offsetting oversampling sa rare event logistic regression,0.3,0.3,10,57,5.181818181818182,0,0,0,0,0,0,0,0
2449,ann and arima hybrid model for time series forecasting in python,Tools,ann and arima hybrid model for time series forecasting in python,"['ann', 'and', 'arima', 'hybrid', 'model', 'for', 'time', 'series', 'forecasting', 'in', 'python']",0,"['ann', 'and', 'arima', 'hybrid', 'model', 'for', 'time', 'series', 'forecasting', 'in', 'python']","['ann', 'arima', 'hybrid', 'model', 'time', 'series', 'forecasting', 'python']",ann arima hybrid model time series forecasting python,0.0,0.0,11,53,4.416666666666667,0,0,0,0,0,0,0,0
2450,high dimensional data with large number of rows in regression,Techniques,high dimensional data with large number of rows in regression,"['high', 'dimensional', 'data', 'with', 'large', 'number', 'of', 'rows', 'in', 'regression']",0,"['high', 'dimensional', 'data', 'with', 'large', 'number', 'of', 'row', 'in', 'regression']","['high', 'dimensional', 'data', 'large', 'number', 'row', 'regression']",high dimensional data large number row regression,0.1871428571428571,0.1871428571428571,10,49,4.454545454545454,0,0,0,0,0,0,0,0
2451,feature selection through caret,Tools,feature selection through caret,"['feature', 'selection', 'through', 'caret']",0,"['feature', 'selection', 'through', 'caret']","['feature', 'selection', 'caret']",feature selection caret,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
2452,chi square goodness of fit,Techniques,chi square goodness of fit,"['chi', 'square', 'goodness', 'of', 'fit']",0,"['chi', 'square', 'goodness', 'of', 'fit']","['chi', 'square', 'goodness', 'fit']",chi square goodness fit,0.4,0.4,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
2453,random forestsvmpca,Techniques,random forestsvmpca,"['random', 'forestsvmpca']",0,"['random', 'forestsvmpca']","['random', 'forestsvmpca']",random forestsvmpca,-0.5,-0.5,2,19,6.333333333333333,0,0,0,0,0,0,0,0
2454,macbook  vs macbook  for machine learning,Tools,macbook  vs macbook  for machine learning,"['macbook', 'vs', 'macbook', 'for', 'machine', 'learning']",2,"['macbook', 'v', 'macbook', 'for', 'machine', 'learning']","['macbook', 'v', 'macbook', 'machine', 'learning']",macbook v macbook machine learning,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
2455,which is the best online training institute,Career,which is the best online training institute,"['which', 'is', 'the', 'best', 'online', 'training', 'institute']",0,"['which', 'is', 'the', 'best', 'online', 'training', 'institute']","['best', 'online', 'training', 'institute']",best online training institute,1.0,1.0,7,30,3.75,0,0,0,0,0,0,0,0
2456,movies auto data fetcher,Techniques,movies auto data fetcher,"['movies', 'auto', 'data', 'fetcher']",0,"['movie', 'auto', 'data', 'fetcher']","['movie', 'auto', 'data', 'fetcher']",movie auto data fetcher,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
2457,data scientist and big data developer,Career,data scientist and big data developer,"['data', 'scientist', 'and', 'big', 'data', 'developer']",0,"['data', 'scientist', 'and', 'big', 'data', 'developer']","['data', 'scientist', 'big', 'data', 'developer']",data scientist big data developer,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
2458,i analyzed more than  youtube trending videos here are the results what do you think,Other,i analyzed more than  youtube trending videos here are the results what do you think,"['i', 'analyzed', 'more', 'than', 'youtube', 'trending', 'videos', 'here', 'are', 'the', 'results', 'what', 'do', 'you', 'think']",1,"['i', 'analyzed', 'more', 'than', 'youtube', 'trending', 'video', 'here', 'are', 'the', 'result', 'what', 'do', 'you', 'think']","['analyzed', 'youtube', 'trending', 'video', 'result', 'think']",analyzed youtube trending video result think,0.5,0.0,15,44,2.75,0,0,0,0,0,0,0,0
2459,response variable column missing from test file,Hackathons,response variable column missing from test file,"['response', 'variable', 'column', 'missing', 'from', 'test', 'file']",0,"['response', 'variable', 'column', 'missing', 'from', 'test', 'file']","['response', 'variable', 'column', 'missing', 'test', 'file']",response variable column missing test file,-0.2,-0.2,7,42,5.25,0,0,0,0,0,0,0,0
2460,how to fix number of bins in histogram using r,Techniques,how to fix number of bins in histogram using r,"['how', 'to', 'fix', 'number', 'of', 'bins', 'in', 'histogram', 'using', 'r']",0,"['how', 'to', 'fix', 'number', 'of', 'bin', 'in', 'histogram', 'using', 'r']","['fix', 'number', 'bin', 'histogram', 'using', 'r']",fix number bin histogram using r,0.0,0.0,10,32,2.909090909090909,0,0,0,0,0,0,0,0
2461,commonly used methods on real time data in companies for the following,Techniques,commonly used methods on real time data in companies for the following,"['commonly', 'used', 'methods', 'on', 'real', 'time', 'data', 'in', 'companies', 'for', 'the', 'following']",0,"['commonly', 'used', 'method', 'on', 'real', 'time', 'data', 'in', 'company', 'for', 'the', 'following']","['commonly', 'used', 'method', 'real', 'time', 'data', 'company', 'following']",commonly used method real time data company following,-0.0333333333333333,-0.0333333333333333,12,53,4.076923076923077,0,0,0,0,0,0,0,0
2462,how to show predictions for models fitted using caret in r,Tools,how to show predictions for models fitted using caret in r,"['how', 'to', 'show', 'predictions', 'for', 'models', 'fitted', 'using', 'caret', 'in', 'r']",0,"['how', 'to', 'show', 'prediction', 'for', 'model', 'fitted', 'using', 'caret', 'in', 'r']","['show', 'prediction', 'model', 'fitted', 'using', 'caret', 'r']",show prediction model fitted using caret r,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
2463,sentiment analysis  is there a dictionary of “hate” words and similarly for “compassionateneutral” words,Techniques,sentiment analysis  is there a dictionary of “hate” words and similarly for “compassionateneutral” words,"['sentiment', 'analysis', 'is', 'there', 'a', 'dictionary', 'of', '“', 'hate', '”', 'words', 'and', 'similarly', 'for', '“', 'compassionateneutral', '”', 'words']",0,"['sentiment', 'analysis', 'is', 'there', 'a', 'dictionary', 'of', '“', 'hate', '”', 'word', 'and', 'similarly', 'for', '“', 'compassionateneutral', '”', 'word']","['sentiment', 'analysis', 'dictionary', '“', 'hate', '”', 'word', 'similarly', '“', 'compassionateneutral', '”', 'word']",sentiment analysis dictionary “ hate ” word similarly “ compassionateneutral ” word,-0.4,-0.4,18,83,4.368421052631579,0,0,0,0,0,0,0,0
2464,how to group the groups,Techniques,how to group the groups,"['how', 'to', 'group', 'the', 'groups']",0,"['how', 'to', 'group', 'the', 'group']","['group', 'group']",group group,0.0,0.0,5,11,1.8333333333333333,0,0,0,0,0,0,0,0
2465,assumption of same variance in linear discriminant analysis,Techniques,assumption of same variance in linear discriminant analysis,"['assumption', 'of', 'same', 'variance', 'in', 'linear', 'discriminant', 'analysis']",0,"['assumption', 'of', 'same', 'variance', 'in', 'linear', 'discriminant', 'analysis']","['assumption', 'variance', 'linear', 'discriminant', 'analysis']",assumption variance linear discriminant analysis,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
2466,logistic regression doubt,Other,logistic regression doubt,"['logistic', 'regression', 'doubt']",0,"['logistic', 'regression', 'doubt']","['logistic', 'regression', 'doubt']",logistic regression doubt,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
2467,graphical user interface gui to learn r for beginners,Tools,graphical user interface gui to learn r for beginners,"['graphical', 'user', 'interface', 'gui', 'to', 'learn', 'r', 'for', 'beginners']",0,"['graphical', 'user', 'interface', 'gui', 'to', 'learn', 'r', 'for', 'beginner']","['graphical', 'user', 'interface', 'gui', 'learn', 'r', 'beginner']",graphical user interface gui learn r beginner,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
2468,seeking advice to switch my career to analytics,Career,seeking advice to switch my career to analytics,"['seeking', 'advice', 'to', 'switch', 'my', 'career', 'to', 'analytics']",0,"['seeking', 'advice', 'to', 'switch', 'my', 'career', 'to', 'analytics']","['seeking', 'advice', 'switch', 'career', 'analytics']",seeking advice switch career analytics,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
2469,how can i make graphs like the one shown below in r,Tools,how can i make graphs like the one shown below in r,"['how', 'can', 'i', 'make', 'graphs', 'like', 'the', 'one', 'shown', 'below', 'in', 'r']",0,"['how', 'can', 'i', 'make', 'graph', 'like', 'the', 'one', 'shown', 'below', 'in', 'r']","['make', 'graph', 'like', 'one', 'shown', 'r']",make graph like one shown r,0.0,0.0,12,27,2.076923076923077,0,0,0,0,0,0,0,0
2470,best book on practical data miningdata science,Techniques,best book on practical data miningdata science,"['best', 'book', 'on', 'practical', 'data', 'miningdata', 'science']",0,"['best', 'book', 'on', 'practical', 'data', 'miningdata', 'science']","['best', 'book', 'practical', 'data', 'miningdata', 'science']",best book practical data miningdata science,1.0,1.0,7,43,5.375,0,0,0,0,0,0,0,0
2471,entry into an analytics career,Career,entry into an analytics career,"['entry', 'into', 'an', 'analytics', 'career']",0,"['entry', 'into', 'an', 'analytics', 'career']","['entry', 'analytics', 'career']",entry analytics career,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
2472,how to find correlation between variable,Techniques,how to find correlation between variable,"['how', 'to', 'find', 'correlation', 'between', 'variable']",0,"['how', 'to', 'find', 'correlation', 'between', 'variable']","['find', 'correlation', 'variable']",find correlation variable,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
2473,cpee certification from insofe  pgpba from great lakes which should i go with,Career,cpee certification from insofe  pgpba from great lakes which should i go with,"['cpee', 'certification', 'from', 'insofe', 'pgpba', 'from', 'great', 'lakes', 'which', 'should', 'i', 'go', 'with']",1,"['cpee', 'certification', 'from', 'insofe', 'pgpba', 'from', 'great', 'lake', 'which', 'should', 'i', 'go', 'with']","['cpee', 'certification', 'insofe', 'pgpba', 'great', 'lake', 'go']",cpee certification insofe pgpba great lake go,0.8,0.8,13,45,3.2142857142857144,0,0,0,0,0,0,0,0
2474,help me to understand python code related to numpy library,Tools,help me to understand python code related to numpy library,"['help', 'me', 'to', 'understand', 'python', 'code', 'related', 'to', 'numpy', 'library']",0,"['help', 'me', 'to', 'understand', 'python', 'code', 'related', 'to', 'numpy', 'library']","['help', 'understand', 'python', 'code', 'related', 'numpy', 'library']",help understand python code related numpy library,0.0,0.0,10,49,4.454545454545454,0,0,0,0,0,0,0,0
2475,time forecast  predict a persons chances of login tomorrow with a predicted time,Techniques,time forecast  predict a persons chances of login tomorrow with a predicted time,"['time', 'forecast', 'predict', 'a', 'persons', 'chances', 'of', 'login', 'tomorrow', 'with', 'a', 'predicted', 'time']",0,"['time', 'forecast', 'predict', 'a', 'person', 'chance', 'of', 'login', 'tomorrow', 'with', 'a', 'predicted', 'time']","['time', 'forecast', 'predict', 'person', 'chance', 'login', 'tomorrow', 'predicted', 'time']",time forecast predict person chance login tomorrow predicted time,0.0,0.0,13,65,4.642857142857143,0,0,0,0,0,0,0,0
2476,ms  mtech application in data science  data analytics  business analytics for non tech background,Career,ms  mtech application in data science  data analytics  business analytics for non tech background,"['ms', 'mtech', 'application', 'in', 'data', 'science', 'data', 'analytics', 'business', 'analytics', 'for', 'non', 'tech', 'background']",0,"['m', 'mtech', 'application', 'in', 'data', 'science', 'data', 'analytics', 'business', 'analytics', 'for', 'non', 'tech', 'background']","['mtech', 'application', 'data', 'science', 'data', 'analytics', 'business', 'analytics', 'non', 'tech', 'background']",mtech application data science data analytics business analytics non tech background,0.0,0.0,14,84,5.6,0,0,0,0,0,0,0,0
2477,how to remove all the variable from workspace in r,Tools,how to remove all the variable from workspace in r,"['how', 'to', 'remove', 'all', 'the', 'variable', 'from', 'workspace', 'in', 'r']",0,"['how', 'to', 'remove', 'all', 'the', 'variable', 'from', 'workspace', 'in', 'r']","['remove', 'variable', 'workspace', 'r']",remove variable workspace r,0.0,0.0,10,27,2.4545454545454546,0,0,0,0,0,0,0,0
2478,good intro mooc for statistics in r,Resources,good intro mooc for statistics in r,"['good', 'intro', 'mooc', 'for', 'statistics', 'in', 'r']",0,"['good', 'intro', 'mooc', 'for', 'statistic', 'in', 'r']","['good', 'intro', 'mooc', 'statistic', 'r']",good intro mooc statistic r,0.7,0.7,7,27,3.375,0,0,0,0,0,0,0,0
2479,how do i decide on the optimal value of cost in svm in r,Tools,how do i decide on the optimal value of cost in svm in r,"['how', 'do', 'i', 'decide', 'on', 'the', 'optimal', 'value', 'of', 'cost', 'in', 'svm', 'in', 'r']",0,"['how', 'do', 'i', 'decide', 'on', 'the', 'optimal', 'value', 'of', 'cost', 'in', 'svm', 'in', 'r']","['decide', 'optimal', 'value', 'cost', 'svm', 'r']",decide optimal value cost svm r,0.0,0.0,14,31,2.066666666666667,0,0,0,0,0,0,0,0
2480,can you please describe each term of the crosstab function tables,Other,can you please describe each term of the crosstab function tables,"['can', 'you', 'please', 'describe', 'each', 'term', 'of', 'the', 'crosstab', 'function', 'tables']",0,"['can', 'you', 'please', 'describe', 'each', 'term', 'of', 'the', 'crosstab', 'function', 'table']","['please', 'describe', 'term', 'crosstab', 'function', 'table']",please describe term crosstab function table,0.0,0.0,11,44,3.6666666666666665,0,0,0,0,0,0,0,0
2481,upcoming ml competitions,Hackathons,upcoming ml competitions,"['upcoming', 'ml', 'competitions']",0,"['upcoming', 'ml', 'competition']","['upcoming', 'ml', 'competition']",upcoming ml competition,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
2482,predict customer behavior,Techniques,predict customer behavior,"['predict', 'customer', 'behavior']",0,"['predict', 'customer', 'behavior']","['predict', 'customer', 'behavior']",predict customer behavior,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
2483,difference between cross sell vs market basket and churn vs survival analysis,Techniques,difference between cross sell vs market basket and churn vs survival analysis,"['difference', 'between', 'cross', 'sell', 'vs', 'market', 'basket', 'and', 'churn', 'vs', 'survival', 'analysis']",0,"['difference', 'between', 'cross', 'sell', 'v', 'market', 'basket', 'and', 'churn', 'v', 'survival', 'analysis']","['difference', 'cross', 'sell', 'v', 'market', 'basket', 'churn', 'v', 'survival', 'analysis']",difference cross sell v market basket churn v survival analysis,0.0,0.0,12,63,4.846153846153846,0,0,0,0,0,0,0,0
2484,data mining in python for excel mid function,Techniques,data mining in python for excel mid function,"['data', 'mining', 'in', 'python', 'for', 'excel', 'mid', 'function']",0,"['data', 'mining', 'in', 'python', 'for', 'excel', 'mid', 'function']","['data', 'mining', 'python', 'excel', 'mid', 'function']",data mining python excel mid function,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
2485,tutorial on making neural networks smaller,Resources,tutorial on making neural networks smaller,"['tutorial', 'on', 'making', 'neural', 'networks', 'smaller']",0,"['tutorial', 'on', 'making', 'neural', 'network', 'smaller']","['tutorial', 'making', 'neural', 'network', 'smaller']",tutorial making neural network smaller,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
2486,using text mining to evaluate and score interview candidates,Techniques,using text mining to evaluate and score interview candidates,"['using', 'text', 'mining', 'to', 'evaluate', 'and', 'score', 'interview', 'candidates']",0,"['using', 'text', 'mining', 'to', 'evaluate', 'and', 'score', 'interview', 'candidate']","['using', 'text', 'mining', 'evaluate', 'score', 'interview', 'candidate']",using text mining evaluate score interview candidate,0.0,0.0,9,52,5.2,0,0,0,0,0,0,0,0
2487,career switch from net to big data  data science,Career,career switch from net to big data  data science,"['career', 'switch', 'from', 'net', 'to', 'big', 'data', 'data', 'science']",0,"['career', 'switch', 'from', 'net', 'to', 'big', 'data', 'data', 'science']","['career', 'switch', 'net', 'big', 'data', 'data', 'science']",career switch net big data data science,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
2488,what is the difference between rose and syn function in handling unbalanced data in r,Techniques,what is the difference between rose and syn function in handling unbalanced data in r,"['what', 'is', 'the', 'difference', 'between', 'rose', 'and', 'syn', 'function', 'in', 'handling', 'unbalanced', 'data', 'in', 'r']",0,"['what', 'is', 'the', 'difference', 'between', 'rose', 'and', 'syn', 'function', 'in', 'handling', 'unbalanced', 'data', 'in', 'r']","['difference', 'rose', 'syn', 'function', 'handling', 'unbalanced', 'data', 'r']",difference rose syn function handling unbalanced data r,0.6,0.6,15,55,3.4375,0,0,0,0,0,0,0,0
2489,multi collinearity,Techniques,multi collinearity,"['multi', 'collinearity']",0,"['multi', 'collinearity']","['multi', 'collinearity']",multi collinearity,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
2490,text mining problem urgent,Other,text mining problem urgent,"['text', 'mining', 'problem', 'urgent']",0,"['text', 'mining', 'problem', 'urgent']","['text', 'mining', 'problem', 'urgent']",text mining problem urgent,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
2491,how are data cubes used in analytics,Techniques,how are data cubes used in analytics,"['how', 'are', 'data', 'cubes', 'used', 'in', 'analytics']",0,"['how', 'are', 'data', 'cube', 'used', 'in', 'analytics']","['data', 'cube', 'used', 'analytics']",data cube used analytics,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
2492,need your valuable advice on the career shift to ba,Career,need your valuable advice on the career shift to ba,"['need', 'your', 'valuable', 'advice', 'on', 'the', 'career', 'shift', 'to', 'ba']",0,"['need', 'your', 'valuable', 'advice', 'on', 'the', 'career', 'shift', 'to', 'ba']","['need', 'valuable', 'advice', 'career', 'shift', 'ba']",need valuable advice career shift ba,0.0,0.0,10,36,3.272727272727273,0,0,0,0,0,0,0,0
2493,performance measurement with sparkr,Tools,performance measurement with sparkr,"['performance', 'measurement', 'with', 'sparkr']",0,"['performance', 'measurement', 'with', 'sparkr']","['performance', 'measurement', 'sparkr']",performance measurement sparkr,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
2494,probability mass function,Techniques,probability mass function,"['probability', 'mass', 'function']",0,"['probability', 'mass', 'function']","['probability', 'mass', 'function']",probability mass function,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
2495,should we group a large number of categories into broader groups while predicting into them,Tools,should we group a large number of categories into broader groups while predicting into them,"['should', 'we', 'group', 'a', 'large', 'number', 'of', 'categories', 'into', 'broader', 'groups', 'while', 'predicting', 'into', 'them']",0,"['should', 'we', 'group', 'a', 'large', 'number', 'of', 'category', 'into', 'broader', 'group', 'while', 'predicting', 'into', 'them']","['group', 'large', 'number', 'category', 'broader', 'group', 'predicting']",group large number category broader group predicting,0.2142857142857142,0.2142857142857142,15,52,3.25,0,0,0,0,0,0,0,0
2496,error in reading csv file in pandas,Tools,error in reading csv file in pandas,"['error', 'in', 'reading', 'csv', 'file', 'in', 'pandas']",0,"['error', 'in', 'reading', 'csv', 'file', 'in', 'panda']","['error', 'reading', 'csv', 'file', 'panda']",error reading csv file panda,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
2497,image classification reading and loading images in r,Techniques,image classification reading and loading images in r,"['image', 'classification', 'reading', 'and', 'loading', 'images', 'in', 'r']",0,"['image', 'classification', 'reading', 'and', 'loading', 'image', 'in', 'r']","['image', 'classification', 'reading', 'loading', 'image', 'r']",image classification reading loading image r,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
2498,postagger techniques,Techniques,postagger techniques,"['postagger', 'techniques']",0,"['postagger', 'technique']","['postagger', 'technique']",postagger technique,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
2499,suitable methods for numerical prediction can baysian probability be used,Techniques,suitable methods for numerical prediction can baysian probability be used,"['suitable', 'methods', 'for', 'numerical', 'prediction', 'can', 'baysian', 'probability', 'be', 'used']",0,"['suitable', 'method', 'for', 'numerical', 'prediction', 'can', 'baysian', 'probability', 'be', 'used']","['suitable', 'method', 'numerical', 'prediction', 'baysian', 'probability', 'used']",suitable method numerical prediction baysian probability used,0.55,0.55,10,61,5.545454545454546,0,0,0,0,0,0,0,0
2500,r package  size note  lazydatacompression  testhat failobject not found,Tools,r package  size note  lazydatacompression  testhat failobject not found,"['r', 'package', 'size', 'note', 'lazydatacompression', 'testhat', 'failobject', 'not', 'found']",0,"['r', 'package', 'size', 'note', 'lazydatacompression', 'testhat', 'failobject', 'not', 'found']","['r', 'package', 'size', 'note', 'lazydatacompression', 'testhat', 'failobject', 'found']",r package size note lazydatacompression testhat failobject found,0.0,0.0,9,64,6.4,0,0,0,0,0,0,0,0
2501,please provide hierarchy of analytics,Techniques,please provide hierarchy of analytics,"['please', 'provide', 'hierarchy', 'of', 'analytics']",0,"['please', 'provide', 'hierarchy', 'of', 'analytics']","['please', 'provide', 'hierarchy', 'analytics']",please provide hierarchy analytics,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
2502,what are the techniques of seo,Techniques,what are the techniques of seo,"['what', 'are', 'the', 'techniques', 'of', 'seo']",0,"['what', 'are', 'the', 'technique', 'of', 'seo']","['technique', 'seo']",technique seo,0.0,0.0,6,13,1.8571428571428572,0,0,0,0,0,0,0,0
2503,good analyst and bad analyst,Misc,good analyst and bad analyst,"['good', 'analyst', 'and', 'bad', 'analyst']",0,"['good', 'analyst', 'and', 'bad', 'analyst']","['good', 'analyst', 'bad', 'analyst']",good analyst bad analyst,5.551115123125783e-17,5.551115123125783e-17,5,24,4.0,0,0,0,0,0,0,0,0
2504,how does the scoring system work in leader board,Hackathons,how does the scoring system work in leader board,"['how', 'does', 'the', 'scoring', 'system', 'work', 'in', 'leader', 'board']",0,"['how', 'doe', 'the', 'scoring', 'system', 'work', 'in', 'leader', 'board']","['doe', 'scoring', 'system', 'work', 'leader', 'board']",doe scoring system work leader board,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
2505,issue with elapsed time in systemtime function of r,Tools,issue with elapsed time in systemtime function of r,"['issue', 'with', 'elapsed', 'time', 'in', 'systemtime', 'function', 'of', 'r']",0,"['issue', 'with', 'elapsed', 'time', 'in', 'systemtime', 'function', 'of', 'r']","['issue', 'elapsed', 'time', 'systemtime', 'function', 'r']",issue elapsed time systemtime function r,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
2506,unable to submit solution lord of machines,Hackathons,unable to submit solution lord of machines,"['unable', 'to', 'submit', 'solution', 'lord', 'of', 'machines']",0,"['unable', 'to', 'submit', 'solution', 'lord', 'of', 'machine']","['unable', 'submit', 'solution', 'lord', 'machine']",unable submit solution lord machine,-0.5,-0.5,7,35,4.375,0,0,0,0,0,0,0,0
2507,a beginners doubts in python ,Tools,a beginners doubts in python ,"['a', 'beginners', 'doubts', 'in', 'python']",1,"['a', 'beginner', 'doubt', 'in', 'python']","['beginner', 'doubt', 'python']",beginner doubt python,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
2508,ordinal variables and stepaic function related query,Techniques,ordinal variables and stepaic function related query,"['ordinal', 'variables', 'and', 'stepaic', 'function', 'related', 'query']",0,"['ordinal', 'variable', 'and', 'stepaic', 'function', 'related', 'query']","['ordinal', 'variable', 'stepaic', 'function', 'related', 'query']",ordinal variable stepaic function related query,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
2509,i need solution to the identify the digits problem,Techniques,i need solution to the identify the digits problem,"['i', 'need', 'solution', 'to', 'the', 'identify', 'the', 'digits', 'problem']",0,"['i', 'need', 'solution', 'to', 'the', 'identify', 'the', 'digit', 'problem']","['need', 'solution', 'identify', 'digit', 'problem']",need solution identify digit problem,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
2510,tying twitter feeds to marketing strategies,Tools,tying twitter feeds to marketing strategies,"['tying', 'twitter', 'feeds', 'to', 'marketing', 'strategies']",0,"['tying', 'twitter', 'feed', 'to', 'marketing', 'strategy']","['tying', 'twitter', 'feed', 'marketing', 'strategy']",tying twitter feed marketing strategy,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
2511,plot of nonparametric vs parametric prob outcomes,Techniques,plot of nonparametric vs parametric prob outcomes,"['plot', 'of', 'nonparametric', 'vs', 'parametric', 'prob', 'outcomes']",0,"['plot', 'of', 'nonparametric', 'v', 'parametric', 'prob', 'outcome']","['plot', 'nonparametric', 'v', 'parametric', 'prob', 'outcome']",plot nonparametric v parametric prob outcome,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
2512,attribution modelling,Techniques,attribution modelling,"['attribution', 'modelling']",0,"['attribution', 'modelling']","['attribution', 'modelling']",attribution modelling,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
2513,what are the different methodstechniques for cluster validation in cluster analysis,Techniques,what are the different methodstechniques for cluster validation in cluster analysis,"['what', 'are', 'the', 'different', 'methodstechniques', 'for', 'cluster', 'validation', 'in', 'cluster', 'analysis']",0,"['what', 'are', 'the', 'different', 'methodstechniques', 'for', 'cluster', 'validation', 'in', 'cluster', 'analysis']","['different', 'methodstechniques', 'cluster', 'validation', 'cluster', 'analysis']",different methodstechniques cluster validation cluster analysis,0.0,0.0,11,63,5.25,0,0,0,0,0,0,0,0
2514,monte carlo simulation,Resources,monte carlo simulation,"['monte', 'carlo', 'simulation']",0,"['monte', 'carlo', 'simulation']","['monte', 'carlo', 'simulation']",monte carlo simulation,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
2515,career transition to data science after  years experience in telecom bssoss,Career,career transition to data science after  years experience in telecom bssoss,"['career', 'transition', 'to', 'data', 'science', 'after', 'years', 'experience', 'in', 'telecom', 'bssoss']",1,"['career', 'transition', 'to', 'data', 'science', 'after', 'year', 'experience', 'in', 'telecom', 'bssoss']","['career', 'transition', 'data', 'science', 'year', 'experience', 'telecom', 'bssoss']",career transition data science year experience telecom bssoss,0.0,0.0,11,61,5.083333333333333,0,0,0,0,0,0,0,0
2516,bayesian model forecasting is going of from what we are expecting,Tools,bayesian model forecasting is going of from what we are expecting,"['bayesian', 'model', 'forecasting', 'is', 'going', 'of', 'from', 'what', 'we', 'are', 'expecting']",0,"['bayesian', 'model', 'forecasting', 'is', 'going', 'of', 'from', 'what', 'we', 'are', 'expecting']","['bayesian', 'model', 'forecasting', 'going', 'expecting']",bayesian model forecasting going expecting,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
2517,how to generate buy sell trading signals using ggplot in r,Techniques,how to generate buy sell trading signals using ggplot in r,"['how', 'to', 'generate', 'buy', 'sell', 'trading', 'signals', 'using', 'ggplot', 'in', 'r']",0,"['how', 'to', 'generate', 'buy', 'sell', 'trading', 'signal', 'using', 'ggplot', 'in', 'r']","['generate', 'buy', 'sell', 'trading', 'signal', 'using', 'ggplot', 'r']",generate buy sell trading signal using ggplot r,0.0,0.0,11,47,3.9166666666666665,0,0,0,0,0,0,0,0
2518,difference between variable definition in variable overview and script in qlikview,Tools,difference between variable definition in variable overview and script in qlikview,"['difference', 'between', 'variable', 'definition', 'in', 'variable', 'overview', 'and', 'script', 'in', 'qlikview']",0,"['difference', 'between', 'variable', 'definition', 'in', 'variable', 'overview', 'and', 'script', 'in', 'qlikview']","['difference', 'variable', 'definition', 'variable', 'overview', 'script', 'qlikview']",difference variable definition variable overview script qlikview,0.0,0.0,11,64,5.333333333333333,0,0,0,0,0,0,0,0
2519,research on data science certification,Career,research on data science certification,"['research', 'on', 'data', 'science', 'certification']",0,"['research', 'on', 'data', 'science', 'certification']","['research', 'data', 'science', 'certification']",research data science certification,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
2520,one vs one svm for  classes,Techniques,one vs one svm for  classes,"['one', 'vs', 'one', 'svm', 'for', 'classes']",1,"['one', 'v', 'one', 'svm', 'for', 'class']","['one', 'v', 'one', 'svm', 'class']",one v one svm class,0.0,0.0,6,19,2.7142857142857144,0,0,0,0,0,0,0,0
2521,technique for predicting categorical variable in a time series data,Techniques,technique for predicting categorical variable in a time series data,"['technique', 'for', 'predicting', 'categorical', 'variable', 'in', 'a', 'time', 'series', 'data']",0,"['technique', 'for', 'predicting', 'categorical', 'variable', 'in', 'a', 'time', 'series', 'data']","['technique', 'predicting', 'categorical', 'variable', 'time', 'series', 'data']",technique predicting categorical variable time series data,0.0,0.0,10,58,5.2727272727272725,0,0,0,0,0,0,0,0
2522,predict values in multidimensional scaling mds in r,Techniques,predict values in multidimensional scaling mds in r,"['predict', 'values', 'in', 'multidimensional', 'scaling', 'mds', 'in', 'r']",0,"['predict', 'value', 'in', 'multidimensional', 'scaling', 'md', 'in', 'r']","['predict', 'value', 'multidimensional', 'scaling', 'md', 'r']",predict value multidimensional scaling md r,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
2523,how to generate same random numbers in r,Tools,how to generate same random numbers in r,"['how', 'to', 'generate', 'same', 'random', 'numbers', 'in', 'r']",0,"['how', 'to', 'generate', 'same', 'random', 'number', 'in', 'r']","['generate', 'random', 'number', 'r']",generate random number r,-0.25,-0.5,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
2524,how does boosting method work,Techniques,how does boosting method work,"['how', 'does', 'boosting', 'method', 'work']",0,"['how', 'doe', 'boosting', 'method', 'work']","['doe', 'boosting', 'method', 'work']",doe boosting method work,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
2525,workshop ,Career,workshop ,['workshop'],0,['workshop'],['workshop'],workshop,0.0,0.0,1,8,4.0,0,0,0,0,0,0,0,0
2526,shiny and bubbles library,Tools,shiny and bubbles library,"['shiny', 'and', 'bubbles', 'library']",0,"['shiny', 'and', 'bubble', 'library']","['shiny', 'bubble', 'library']",shiny bubble library,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
2527,is it necessary to know big data to learn data science,Career,is it necessary to know big data to learn data science,"['is', 'it', 'necessary', 'to', 'know', 'big', 'data', 'to', 'learn', 'data', 'science']",0,"['is', 'it', 'necessary', 'to', 'know', 'big', 'data', 'to', 'learn', 'data', 'science']","['necessary', 'know', 'big', 'data', 'learn', 'data', 'science']",necessary know big data learn data science,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
2528,how to impute transaction date  time values,Techniques,how to impute transaction date  time values,"['how', 'to', 'impute', 'transaction', 'date', 'time', 'values']",0,"['how', 'to', 'impute', 'transaction', 'date', 'time', 'value']","['impute', 'transaction', 'date', 'time', 'value']",impute transaction date time value,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
2529,share your approach  the ultimate student hunt,Hackathons,share your approach  the ultimate student hunt,"['share', 'your', 'approach', 'the', 'ultimate', 'student', 'hunt']",0,"['share', 'your', 'approach', 'the', 'ultimate', 'student', 'hunt']","['share', 'approach', 'ultimate', 'student', 'hunt']",share approach ultimate student hunt,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
2530,how to start career that asks for statistical techniques,Career,how to start career that asks for statistical techniques,"['how', 'to', 'start', 'career', 'that', 'asks', 'for', 'statistical', 'techniques']",0,"['how', 'to', 'start', 'career', 'that', 'asks', 'for', 'statistical', 'technique']","['start', 'career', 'asks', 'statistical', 'technique']",start career asks statistical technique,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
2531,how to find observation with no missing value for any variable in sas,Tools,how to find observation with no missing value for any variable in sas,"['how', 'to', 'find', 'observation', 'with', 'no', 'missing', 'value', 'for', 'any', 'variable', 'in', 'sas']",0,"['how', 'to', 'find', 'observation', 'with', 'no', 'missing', 'value', 'for', 'any', 'variable', 'in', 'sa']","['find', 'observation', 'missing', 'value', 'variable', 'sa']",find observation missing value variable sa,0.1,-0.2,13,42,3.0,0,0,0,0,0,0,0,0
2532,what does link specifies in logistic regression modelling,Techniques,what does link specifies in logistic regression modelling,"['what', 'does', 'link', 'specifies', 'in', 'logistic', 'regression', 'modelling']",0,"['what', 'doe', 'link', 'specifies', 'in', 'logistic', 'regression', 'modelling']","['doe', 'link', 'specifies', 'logistic', 'regression', 'modelling']",doe link specifies logistic regression modelling,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
2533,how are levels combined for categorical variables,Techniques,how are levels combined for categorical variables,"['how', 'are', 'levels', 'combined', 'for', 'categorical', 'variables']",0,"['how', 'are', 'level', 'combined', 'for', 'categorical', 'variable']","['level', 'combined', 'categorical', 'variable']",level combined categorical variable,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
2534,approach for missing value imputation in big mart sales data,Hackathons,approach for missing value imputation in big mart sales data,"['approach', 'for', 'missing', 'value', 'imputation', 'in', 'big', 'mart', 'sales', 'data']",0,"['approach', 'for', 'missing', 'value', 'imputation', 'in', 'big', 'mart', 'sale', 'data']","['approach', 'missing', 'value', 'imputation', 'big', 'mart', 'sale', 'data']",approach missing value imputation big mart sale data,-0.1,-0.1,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
2535,ideal sample size for statistical hypothesis tests,Techniques,ideal sample size for statistical hypothesis tests,"['ideal', 'sample', 'size', 'for', 'statistical', 'hypothesis', 'tests']",0,"['ideal', 'sample', 'size', 'for', 'statistical', 'hypothesis', 'test']","['ideal', 'sample', 'size', 'statistical', 'hypothesis', 'test']",ideal sample size statistical hypothesis test,0.9,0.9,7,45,5.625,0,0,0,0,0,0,0,0
2536,why does cleaning and collecting data take so long,Tools,why does cleaning and collecting data take so long,"['why', 'does', 'cleaning', 'and', 'collecting', 'data', 'take', 'so', 'long']",0,"['why', 'doe', 'cleaning', 'and', 'collecting', 'data', 'take', 'so', 'long']","['doe', 'cleaning', 'collecting', 'data', 'take', 'long']",doe cleaning collecting data take long,-0.05,-0.05,9,38,3.8,0,0,0,0,0,0,0,0
2537,distance learning programs for master in statistics,Career,distance learning programs for master in statistics,"['distance', 'learning', 'programs', 'for', 'master', 'in', 'statistics']",0,"['distance', 'learning', 'program', 'for', 'master', 'in', 'statistic']","['distance', 'learning', 'program', 'master', 'statistic']",distance learning program master statistic,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
2538,iim calcutta advanced program in data science,Career,iim calcutta advanced program in data science,"['iim', 'calcutta', 'advanced', 'program', 'in', 'data', 'science']",0,"['iim', 'calcutta', 'advanced', 'program', 'in', 'data', 'science']","['iim', 'calcutta', 'advanced', 'program', 'data', 'science']",iim calcutta advanced program data science,0.4,0.4,7,42,5.25,0,0,0,0,0,0,0,0
2539,feature extraction from text,Techniques,feature extraction from text,"['feature', 'extraction', 'from', 'text']",0,"['feature', 'extraction', 'from', 'text']","['feature', 'extraction', 'text']",feature extraction text,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
2540,issue while importing file in r,Techniques,issue while importing file in r,"['issue', 'while', 'importing', 'file', 'in', 'r']",0,"['issue', 'while', 'importing', 'file', 'in', 'r']","['issue', 'importing', 'file', 'r']",issue importing file r,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
2541,what are the problems of autocorrelation  heteroskedasticity in regression analysis,Techniques,what are the problems of autocorrelation  heteroskedasticity in regression analysis,"['what', 'are', 'the', 'problems', 'of', 'autocorrelation', 'heteroskedasticity', 'in', 'regression', 'analysis']",0,"['what', 'are', 'the', 'problem', 'of', 'autocorrelation', 'heteroskedasticity', 'in', 'regression', 'analysis']","['problem', 'autocorrelation', 'heteroskedasticity', 'regression', 'analysis']",problem autocorrelation heteroskedasticity regression analysis,0.0,0.0,10,62,5.636363636363637,0,0,0,0,0,0,0,0
2542,estimate the number of aircrafts in air across the globe at this moment in time,Techniques,estimate the number of aircrafts in air across the globe at this moment in time,"['estimate', 'the', 'number', 'of', 'aircrafts', 'in', 'air', 'across', 'the', 'globe', 'at', 'this', 'moment', 'in', 'time']",0,"['estimate', 'the', 'number', 'of', 'aircraft', 'in', 'air', 'across', 'the', 'globe', 'at', 'this', 'moment', 'in', 'time']","['estimate', 'number', 'aircraft', 'air', 'across', 'globe', 'moment', 'time']",estimate number aircraft air across globe moment time,0.0,0.0,15,53,3.3125,0,0,0,0,0,0,0,0
2543,difference in random forest via caret and randomforest package,Tools,difference in random forest via caret and randomforest package,"['difference', 'in', 'random', 'forest', 'via', 'caret', 'and', 'randomforest', 'package']",0,"['difference', 'in', 'random', 'forest', 'via', 'caret', 'and', 'randomforest', 'package']","['difference', 'random', 'forest', 'via', 'caret', 'randomforest', 'package']",difference random forest via caret randomforest package,-0.5,-0.5,9,55,5.5,0,0,0,0,0,0,0,0
2544,how to choose appropriate learning rate to improve accuracy in cnn,Techniques,how to choose appropriate learning rate to improve accuracy in cnn,"['how', 'to', 'choose', 'appropriate', 'learning', 'rate', 'to', 'improve', 'accuracy', 'in', 'cnn']",0,"['how', 'to', 'choose', 'appropriate', 'learning', 'rate', 'to', 'improve', 'accuracy', 'in', 'cnn']","['choose', 'appropriate', 'learning', 'rate', 'improve', 'accuracy', 'cnn']",choose appropriate learning rate improve accuracy cnn,0.5,0.5,11,53,4.416666666666667,0,0,0,0,0,0,0,0
2545,imputing missing values,Hackathons,imputing missing values,"['imputing', 'missing', 'values']",0,"['imputing', 'missing', 'value']","['imputing', 'missing', 'value']",imputing missing value,-0.2,-0.2,3,22,5.5,0,0,0,0,0,0,0,0
2546,handling of large numbers in r,Tools,handling of large numbers in r,"['handling', 'of', 'large', 'numbers', 'in', 'r']",0,"['handling', 'of', 'large', 'number', 'in', 'r']","['handling', 'large', 'number', 'r']",handling large number r,0.2142857142857142,0.2142857142857142,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
2547,digit recognitionneuralnetworksusingtensorflow,Techniques,digit recognitionneuralnetworksusingtensorflow,"['digit', 'recognitionneuralnetworksusingtensorflow']",0,"['digit', 'recognitionneuralnetworksusingtensorflow']","['digit', 'recognitionneuralnetworksusingtensorflow']",digit recognitionneuralnetworksusingtensorflow,0.0,0.0,2,46,15.333333333333334,0,0,0,0,0,0,0,0
2548,how to use varmax with categorical multivariate time series,Techniques,how to use varmax with categorical multivariate time series,"['how', 'to', 'use', 'varmax', 'with', 'categorical', 'multivariate', 'time', 'series']",0,"['how', 'to', 'use', 'varmax', 'with', 'categorical', 'multivariate', 'time', 'series']","['use', 'varmax', 'categorical', 'multivariate', 'time', 'series']",use varmax categorical multivariate time series,0.0,0.0,9,47,4.7,0,0,0,0,0,0,0,0
2549,preparing data for repeatedmeasures anova in r and spss,Tools,preparing data for repeatedmeasures anova in r and spss,"['preparing', 'data', 'for', 'repeatedmeasures', 'anova', 'in', 'r', 'and', 'spss']",0,"['preparing', 'data', 'for', 'repeatedmeasures', 'anova', 'in', 'r', 'and', 'spss']","['preparing', 'data', 'repeatedmeasures', 'anova', 'r', 'spss']",preparing data repeatedmeasures anova r spss,0.0,0.0,9,44,4.4,0,0,0,0,0,0,0,0
2550,what does the cl option in knn signify,Tools,what does the cl option in knn signify,"['what', 'does', 'the', 'cl', 'option', 'in', 'knn', 'signify']",0,"['what', 'doe', 'the', 'cl', 'option', 'in', 'knn', 'signify']","['doe', 'cl', 'option', 'knn', 'signify']",doe cl option knn signify,0.0,0.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
2551,time series forecasting in python,Resources,time series forecasting in python,"['time', 'series', 'forecasting', 'in', 'python']",0,"['time', 'series', 'forecasting', 'in', 'python']","['time', 'series', 'forecasting', 'python']",time series forecasting python,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
2552,over by over match predictions,Techniques,over by over match predictions,"['over', 'by', 'over', 'match', 'predictions']",0,"['over', 'by', 'over', 'match', 'prediction']","['match', 'prediction']",match prediction,0.0,0.0,5,16,2.6666666666666665,0,0,0,0,0,0,0,0
2553,using facebook api in r,Techniques,using facebook api in r,"['using', 'facebook', 'api', 'in', 'r']",0,"['using', 'facebook', 'api', 'in', 'r']","['using', 'facebook', 'api', 'r']",using facebook api r,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
2554,how dashboard software can drive efficiency in the energy and utilities sector,Resources,how dashboard software can drive efficiency in the energy and utilities sector,"['how', 'dashboard', 'software', 'can', 'drive', 'efficiency', 'in', 'the', 'energy', 'and', 'utilities', 'sector']",0,"['how', 'dashboard', 'software', 'can', 'drive', 'efficiency', 'in', 'the', 'energy', 'and', 'utility', 'sector']","['dashboard', 'software', 'drive', 'efficiency', 'energy', 'utility', 'sector']",dashboard software drive efficiency energy utility sector,0.0,0.0,12,57,4.384615384615385,0,0,0,0,0,0,0,0
2555,foreign exchange rates ensemble for classification of trends,Techniques,foreign exchange rates ensemble for classification of trends,"['foreign', 'exchange', 'rates', 'ensemble', 'for', 'classification', 'of', 'trends']",0,"['foreign', 'exchange', 'rate', 'ensemble', 'for', 'classification', 'of', 'trend']","['foreign', 'exchange', 'rate', 'ensemble', 'classification', 'trend']",foreign exchange rate ensemble classification trend,-0.125,-0.125,8,51,5.666666666666667,0,0,0,0,0,0,0,0
2556,tableau vs qlikview the differences between these platforms,Tools,tableau vs qlikview the differences between these platforms,"['tableau', 'vs', 'qlikview', 'the', 'differences', 'between', 'these', 'platforms']",0,"['tableau', 'v', 'qlikview', 'the', 'difference', 'between', 'these', 'platform']","['tableau', 'v', 'qlikview', 'difference', 'platform']",tableau v qlikview difference platform,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
2557,admission in praxis,Career,admission in praxis,"['admission', 'in', 'praxis']",0,"['admission', 'in', 'praxis']","['admission', 'praxis']",admission praxis,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
2558,effort estimations in r,Techniques,effort estimations in r,"['effort', 'estimations', 'in', 'r']",0,"['effort', 'estimation', 'in', 'r']","['effort', 'estimation', 'r']",effort estimation r,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
2559,gini impurity in decision tree,Resources,gini impurity in decision tree,"['gini', 'impurity', 'in', 'decision', 'tree']",0,"['gini', 'impurity', 'in', 'decision', 'tree']","['gini', 'impurity', 'decision', 'tree']",gini impurity decision tree,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
2560,how to get best image annotation tools,Tools,how to get best image annotation tools,"['how', 'to', 'get', 'best', 'image', 'annotation', 'tools']",0,"['how', 'to', 'get', 'best', 'image', 'annotation', 'tool']","['get', 'best', 'image', 'annotation', 'tool']",get best image annotation tool,1.0,1.0,7,30,3.75,0,0,0,0,0,0,0,0
2561,analyzing stocks with time series  what should be seasonality,Techniques,analyzing stocks with time series  what should be seasonality,"['analyzing', 'stocks', 'with', 'time', 'series', 'what', 'should', 'be', 'seasonality']",0,"['analyzing', 'stock', 'with', 'time', 'series', 'what', 'should', 'be', 'seasonality']","['analyzing', 'stock', 'time', 'series', 'seasonality']",analyzing stock time series seasonality,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
2562,how can we protect roads from getting damaged by water,Techniques,how can we protect roads from getting damaged by water,"['how', 'can', 'we', 'protect', 'roads', 'from', 'getting', 'damaged', 'by', 'water']",0,"['how', 'can', 'we', 'protect', 'road', 'from', 'getting', 'damaged', 'by', 'water']","['protect', 'road', 'getting', 'damaged', 'water']",protect road getting damaged water,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
2563,how can i calculate the cumulative sum by a group variable in sas,Tools,how can i calculate the cumulative sum by a group variable in sas,"['how', 'can', 'i', 'calculate', 'the', 'cumulative', 'sum', 'by', 'a', 'group', 'variable', 'in', 'sas']",0,"['how', 'can', 'i', 'calculate', 'the', 'cumulative', 'sum', 'by', 'a', 'group', 'variable', 'in', 'sa']","['calculate', 'cumulative', 'sum', 'group', 'variable', 'sa']",calculate cumulative sum group variable sa,0.0,0.0,13,42,3.0,0,0,0,0,0,0,0,0
2564,iiitb  upgrad data science course placement statistics july ,Career,iiitb  upgrad data science course placement statistics july ,"['iiitb', 'upgrad', 'data', 'science', 'course', 'placement', 'statistics', 'july']",1,"['iiitb', 'upgrad', 'data', 'science', 'course', 'placement', 'statistic', 'july']","['iiitb', 'upgrad', 'data', 'science', 'course', 'placement', 'statistic', 'july']",iiitb upgrad data science course placement statistic july,0.0,0.0,8,57,6.333333333333333,0,0,0,0,0,0,0,0
2565,how to use facetwrap or grid to combine these two separate code,Techniques,how to use facetwrap or grid to combine these two separate code,"['how', 'to', 'use', 'facetwrap', 'or', 'grid', 'to', 'combine', 'these', 'two', 'separate', 'code']",0,"['how', 'to', 'use', 'facetwrap', 'or', 'grid', 'to', 'combine', 'these', 'two', 'separate', 'code']","['use', 'facetwrap', 'grid', 'combine', 'two', 'separate', 'code']",use facetwrap grid combine two separate code,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
2566,how to specify that the model should return class labels using errorest in r,Tools,how to specify that the model should return class labels using errorest in r,"['how', 'to', 'specify', 'that', 'the', 'model', 'should', 'return', 'class', 'labels', 'using', 'errorest', 'in', 'r']",0,"['how', 'to', 'specify', 'that', 'the', 'model', 'should', 'return', 'class', 'label', 'using', 'errorest', 'in', 'r']","['specify', 'model', 'return', 'class', 'label', 'using', 'errorest', 'r']",specify model return class label using errorest r,0.0,0.0,14,49,3.2666666666666666,0,0,0,0,0,0,0,0
2567,xgboost plot performance in python,Tools,xgboost plot performance in python,"['xgboost', 'plot', 'performance', 'in', 'python']",0,"['xgboost', 'plot', 'performance', 'in', 'python']","['xgboost', 'plot', 'performance', 'python']",xgboost plot performance python,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
2568,which course is better for making a career shift to analytics,Career,which course is better for making a career shift to analytics,"['which', 'course', 'is', 'better', 'for', 'making', 'a', 'career', 'shift', 'to', 'analytics']",0,"['which', 'course', 'is', 'better', 'for', 'making', 'a', 'career', 'shift', 'to', 'analytics']","['course', 'better', 'making', 'career', 'shift', 'analytics']",course better making career shift analytics,0.5,0.5,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
2569,how to get access of all file of a directory in r,Tools,how to get access of all file of a directory in r,"['how', 'to', 'get', 'access', 'of', 'all', 'file', 'of', 'a', 'directory', 'in', 'r']",0,"['how', 'to', 'get', 'access', 'of', 'all', 'file', 'of', 'a', 'directory', 'in', 'r']","['get', 'access', 'file', 'directory', 'r']",get access file directory r,0.0,0.0,12,27,2.076923076923077,0,0,0,0,0,0,0,0
2570,help regarding modelling sequential user data,Techniques,help regarding modelling sequential user data,"['help', 'regarding', 'modelling', 'sequential', 'user', 'data']",0,"['help', 'regarding', 'modelling', 'sequential', 'user', 'data']","['help', 'regarding', 'modelling', 'sequential', 'user', 'data']",help regarding modelling sequential user data,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
2571,best visualisation for d contingency table using ggplot,Techniques,best visualisation for d contingency table using ggplot,"['best', 'visualisation', 'for', 'd', 'contingency', 'table', 'using', 'ggplot']",0,"['best', 'visualisation', 'for', 'd', 'contingency', 'table', 'using', 'ggplot']","['best', 'visualisation', 'contingency', 'table', 'using', 'ggplot']",best visualisation contingency table using ggplot,1.0,1.0,8,49,5.444444444444445,0,0,0,0,0,0,0,0
2572,sap hana as an analytics tool,Tools,sap hana as an analytics tool,"['sap', 'hana', 'as', 'an', 'analytics', 'tool']",0,"['sap', 'hana', 'a', 'an', 'analytics', 'tool']","['sap', 'hana', 'analytics', 'tool']",sap hana analytics tool,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
2573,how to remove the missing value of object in random forest,Techniques,how to remove the missing value of object in random forest,"['how', 'to', 'remove', 'the', 'missing', 'value', 'of', 'object', 'in', 'random', 'forest']",0,"['how', 'to', 'remove', 'the', 'missing', 'value', 'of', 'object', 'in', 'random', 'forest']","['remove', 'missing', 'value', 'object', 'random', 'forest']",remove missing value object random forest,-0.35,-0.35,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
2574,difficulty in choosing courses,Career,difficulty in choosing courses,"['difficulty', 'in', 'choosing', 'courses']",0,"['difficulty', 'in', 'choosing', 'course']","['difficulty', 'choosing', 'course']",difficulty choosing course,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
2575,reading a dat file in r,Tools,reading a dat file in r,"['reading', 'a', 'dat', 'file', 'in', 'r']",0,"['reading', 'a', 'dat', 'file', 'in', 'r']","['reading', 'dat', 'file', 'r']",reading dat file r,0.0,0.0,6,18,2.5714285714285716,0,0,0,0,0,0,0,0
2576,predicted variable  number of shares,Hackathons,predicted variable  number of shares,"['predicted', 'variable', 'number', 'of', 'shares']",0,"['predicted', 'variable', 'number', 'of', 'share']","['predicted', 'variable', 'number', 'share']",predicted variable number share,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
2577,how to find trailing and leading words of a word using r,Techniques,how to find trailing and leading words of a word using r,"['how', 'to', 'find', 'trailing', 'and', 'leading', 'words', 'of', 'a', 'word', 'using', 'r']",0,"['how', 'to', 'find', 'trailing', 'and', 'leading', 'word', 'of', 'a', 'word', 'using', 'r']","['find', 'trailing', 'leading', 'word', 'word', 'using', 'r']",find trailing leading word word using r,0.0,0.0,12,39,3.0,0,0,0,0,0,0,0,0
2578,how to remove complete observation with all missing values in a scenario of s of observations in sas,Techniques,how to remove complete observation with all missing values in a scenario of s of observations in sas,"['how', 'to', 'remove', 'complete', 'observation', 'with', 'all', 'missing', 'values', 'in', 'a', 'scenario', 'of', 's', 'of', 'observations', 'in', 'sas']",0,"['how', 'to', 'remove', 'complete', 'observation', 'with', 'all', 'missing', 'value', 'in', 'a', 'scenario', 'of', 's', 'of', 'observation', 'in', 'sa']","['remove', 'complete', 'observation', 'missing', 'value', 'scenario', 'observation', 'sa']",remove complete observation missing value scenario observation sa,-0.05,-0.05,18,65,3.4210526315789473,0,0,0,0,0,0,0,0
2579,help in sas projects,Resources,help in sas projects,"['help', 'in', 'sas', 'projects']",0,"['help', 'in', 'sa', 'project']","['help', 'sa', 'project']",help sa project,0.0,0.0,4,15,3.0,0,0,0,0,0,0,0,0
2580,making data science easier,Tools,making data science easier,"['making', 'data', 'science', 'easier']",0,"['making', 'data', 'science', 'easier']","['making', 'data', 'science', 'easier']",making data science easier,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
2581,what x signifies in svm plot,Techniques,what x signifies in svm plot,"['what', 'x', 'signifies', 'in', 'svm', 'plot']",0,"['what', 'x', 'signifies', 'in', 'svm', 'plot']","['x', 'signifies', 'svm', 'plot']",x signifies svm plot,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
2582,getting problem on outlier treatment after imputing the missing value by hmisc package,Tools,getting problem on outlier treatment after imputing the missing value by hmisc package,"['getting', 'problem', 'on', 'outlier', 'treatment', 'after', 'imputing', 'the', 'missing', 'value', 'by', 'hmisc', 'package']",0,"['getting', 'problem', 'on', 'outlier', 'treatment', 'after', 'imputing', 'the', 'missing', 'value', 'by', 'hmisc', 'package']","['getting', 'problem', 'outlier', 'treatment', 'imputing', 'missing', 'value', 'hmisc', 'package']",getting problem outlier treatment imputing missing value hmisc package,-0.2,-0.2,13,70,5.0,0,0,0,0,0,0,0,0
2583,how to do feature engineering with catagorical data,Techniques,how to do feature engineering with catagorical data,"['how', 'to', 'do', 'feature', 'engineering', 'with', 'catagorical', 'data']",0,"['how', 'to', 'do', 'feature', 'engineering', 'with', 'catagorical', 'data']","['feature', 'engineering', 'catagorical', 'data']",feature engineering catagorical data,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
2584,face recognition feature in android app,Techniques,face recognition feature in android app,"['face', 'recognition', 'feature', 'in', 'android', 'app']",0,"['face', 'recognition', 'feature', 'in', 'android', 'app']","['face', 'recognition', 'feature', 'android', 'app']",face recognition feature android app,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
2585,request for articles  march ,Resources,request for articles  march ,"['request', 'for', 'articles', 'march']",1,"['request', 'for', 'article', 'march']","['request', 'article', 'march']",request article march,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
2586,log transformation for skewed data,Techniques,log transformation for skewed data,"['log', 'transformation', 'for', 'skewed', 'data']",0,"['log', 'transformation', 'for', 'skewed', 'data']","['log', 'transformation', 'skewed', 'data']",log transformation skewed data,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
2587,how can i create word cloud in python,Tools,how can i create word cloud in python,"['how', 'can', 'i', 'create', 'word', 'cloud', 'in', 'python']",0,"['how', 'can', 'i', 'create', 'word', 'cloud', 'in', 'python']","['create', 'word', 'cloud', 'python']",create word cloud python,0.0,0.0,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
2588,how to check the time of each code in r,Tools,how to check the time of each code in r,"['how', 'to', 'check', 'the', 'time', 'of', 'each', 'code', 'in', 'r']",0,"['how', 'to', 'check', 'the', 'time', 'of', 'each', 'code', 'in', 'r']","['check', 'time', 'code', 'r']",check time code r,0.0,0.0,10,17,1.5454545454545454,0,0,0,0,0,0,0,0
2589,how do you become a uiux designer,Career,how do you become a uiux designer,"['how', 'do', 'you', 'become', 'a', 'uiux', 'designer']",0,"['how', 'do', 'you', 'become', 'a', 'uiux', 'designer']","['become', 'uiux', 'designer']",become uiux designer,0.0,0.0,7,20,2.5,0,0,0,0,0,0,0,0
2590,optimal number of clusters elbow r execution,Misc,optimal number of clusters elbow r execution,"['optimal', 'number', 'of', 'clusters', 'elbow', 'r', 'execution']",0,"['optimal', 'number', 'of', 'cluster', 'elbow', 'r', 'execution']","['optimal', 'number', 'cluster', 'elbow', 'r', 'execution']",optimal number cluster elbow r execution,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
2591,high value high model approach formarketing,Techniques,high value high model approach formarketing,"['high', 'value', 'high', 'model', 'approach', 'formarketing']",0,"['high', 'value', 'high', 'model', 'approach', 'formarketing']","['high', 'value', 'high', 'model', 'approach', 'formarketing']",high value high model approach formarketing,0.16,0.16,6,43,6.142857142857143,0,0,0,0,0,0,0,0
2592,how can we extract column name to a vector by calling column name using  sign in r,Tools,how can we extract column name to a vector by calling column name using  sign in r,"['how', 'can', 'we', 'extract', 'column', 'name', 'to', 'a', 'vector', 'by', 'calling', 'column', 'name', 'using', 'sign', 'in', 'r']",0,"['how', 'can', 'we', 'extract', 'column', 'name', 'to', 'a', 'vector', 'by', 'calling', 'column', 'name', 'using', 'sign', 'in', 'r']","['extract', 'column', 'name', 'vector', 'calling', 'column', 'name', 'using', 'sign', 'r']",extract column name vector calling column name using sign r,0.0,0.0,17,59,3.2777777777777777,0,0,0,0,0,0,0,0
2593,why cant i get a plot using plotarange in python,Tools,why cant i get a plot using plotarange in python,"['why', 'cant', 'i', 'get', 'a', 'plot', 'using', 'plotarange', 'in', 'python']",0,"['why', 'cant', 'i', 'get', 'a', 'plot', 'using', 'plotarange', 'in', 'python']","['cant', 'get', 'plot', 'using', 'plotarange', 'python']",cant get plot using plotarange python,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
2594,code sheet for the hackathon,Hackathons,code sheet for the hackathon,"['code', 'sheet', 'for', 'the', 'hackathon']",0,"['code', 'sheet', 'for', 'the', 'hackathon']","['code', 'sheet', 'hackathon']",code sheet hackathon,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
2595,how to update elo ratings after each season in r,Techniques,how to update elo ratings after each season in r,"['how', 'to', 'update', 'elo', 'ratings', 'after', 'each', 'season', 'in', 'r']",0,"['how', 'to', 'update', 'elo', 'rating', 'after', 'each', 'season', 'in', 'r']","['update', 'elo', 'rating', 'season', 'r']",update elo rating season r,0.0,0.0,10,26,2.3636363636363638,0,0,0,0,0,0,0,0
2596,application of r language in projects in india,Other,application of r language in projects in india,"['application', 'of', 'r', 'language', 'in', 'projects', 'in', 'india']",0,"['application', 'of', 'r', 'language', 'in', 'project', 'in', 'india']","['application', 'r', 'language', 'project', 'india']",application r language project india,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
2597,about business analytics course,Career,about business analytics course,"['about', 'business', 'analytics', 'course']",0,"['about', 'business', 'analytics', 'course']","['business', 'analytics', 'course']",business analytics course,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
2598,predict root event in a sequence of events using ml,Techniques,predict root event in a sequence of events using ml,"['predict', 'root', 'event', 'in', 'a', 'sequence', 'of', 'events', 'using', 'ml']",0,"['predict', 'root', 'event', 'in', 'a', 'sequence', 'of', 'event', 'using', 'ml']","['predict', 'root', 'event', 'sequence', 'event', 'using', 'ml']",predict root event sequence event using ml,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
2599,day certificate course on business analytics  iit hyderabad,Career,day certificate course on business analytics  iit hyderabad,"['day', 'certificate', 'course', 'on', 'business', 'analytics', 'iit', 'hyderabad']",0,"['day', 'certificate', 'course', 'on', 'business', 'analytics', 'iit', 'hyderabad']","['day', 'certificate', 'course', 'business', 'analytics', 'iit', 'hyderabad']",day certificate course business analytics iit hyderabad,0.0,0.0,8,55,6.111111111111111,0,0,0,0,0,0,0,0
2600,redundant variables in tutorial code,Hackathons,redundant variables in tutorial code,"['redundant', 'variables', 'in', 'tutorial', 'code']",0,"['redundant', 'variable', 'in', 'tutorial', 'code']","['redundant', 'variable', 'tutorial', 'code']",redundant variable tutorial code,-0.2,-0.2,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2601,light gbm sample r code,Techniques,light gbm sample r code,"['light', 'gbm', 'sample', 'r', 'code']",0,"['light', 'gbm', 'sample', 'r', 'code']","['light', 'gbm', 'sample', 'r', 'code']",light gbm sample r code,0.4,0.4,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
2602,error  labs don not fit even at cex there may be some overplotting while creating decission tree,Techniques,error  labs don not fit even at cex there may be some overplotting while creating decission tree,"['error', 'labs', 'don', 'not', 'fit', 'even', 'at', 'cex', 'there', 'may', 'be', 'some', 'overplotting', 'while', 'creating', 'decission', 'tree']",0,"['error', 'lab', 'don', 'not', 'fit', 'even', 'at', 'cex', 'there', 'may', 'be', 'some', 'overplotting', 'while', 'creating', 'decission', 'tree']","['error', 'lab', 'fit', 'even', 'cex', 'may', 'overplotting', 'creating', 'decission', 'tree']",error lab fit even cex may overplotting creating decission tree,-0.2,0.4,17,63,3.5,0,0,0,0,0,0,0,0
2603,reference material for advance algorithm  clustering classification time series analysis,Techniques,reference material for advance algorithm  clustering classification time series analysis,"['reference', 'material', 'for', 'advance', 'algorithm', 'clustering', 'classification', 'time', 'series', 'analysis']",0,"['reference', 'material', 'for', 'advance', 'algorithm', 'clustering', 'classification', 'time', 'series', 'analysis']","['reference', 'material', 'advance', 'algorithm', 'clustering', 'classification', 'time', 'series', 'analysis']",reference material advance algorithm clustering classification time series analysis,0.0,0.0,10,83,7.545454545454546,0,0,0,0,0,0,0,0
2604,what’s the right approach to building a data analytics dashboard,Techniques,what’s the right approach to building a data analytics dashboard,"['what', '’', 's', 'the', 'right', 'approach', 'to', 'building', 'a', 'data', 'analytics', 'dashboard']",0,"['what', '’', 's', 'the', 'right', 'approach', 'to', 'building', 'a', 'data', 'analytics', 'dashboard']","['’', 'right', 'approach', 'building', 'data', 'analytics', 'dashboard']",’ right approach building data analytics dashboard,0.2857142857142857,0.2857142857142857,12,50,3.8461538461538463,0,0,0,0,0,0,0,0
2605,how to calculate sample size threshold for data analysis,Techniques,how to calculate sample size threshold for data analysis,"['how', 'to', 'calculate', 'sample', 'size', 'threshold', 'for', 'data', 'analysis']",0,"['how', 'to', 'calculate', 'sample', 'size', 'threshold', 'for', 'data', 'analysis']","['calculate', 'sample', 'size', 'threshold', 'data', 'analysis']",calculate sample size threshold data analysis,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
2606,improving supervised algos using clustering,Other,improving supervised algos using clustering,"['improving', 'supervised', 'algos', 'using', 'clustering']",0,"['improving', 'supervised', 'algos', 'using', 'clustering']","['improving', 'supervised', 'algos', 'using', 'clustering']",improving supervised algos using clustering,0.0,0.0,5,43,7.166666666666667,0,0,0,0,0,0,0,0
2607,in masters program in computer vision,Techniques,in masters program in computer vision,"['in', 'masters', 'program', 'in', 'computer', 'vision']",0,"['in', 'master', 'program', 'in', 'computer', 'vision']","['master', 'program', 'computer', 'vision']",master program computer vision,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
2608,how can i perform regression analysis in excel,Tools,how can i perform regression analysis in excel,"['how', 'can', 'i', 'perform', 'regression', 'analysis', 'in', 'excel']",0,"['how', 'can', 'i', 'perform', 'regression', 'analysis', 'in', 'excel']","['perform', 'regression', 'analysis', 'excel']",perform regression analysis excel,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
2609,please explain the difference between svd and pca,Techniques,please explain the difference between svd and pca,"['please', 'explain', 'the', 'difference', 'between', 'svd', 'and', 'pca']",0,"['please', 'explain', 'the', 'difference', 'between', 'svd', 'and', 'pca']","['please', 'explain', 'difference', 'svd', 'pca']",please explain difference svd pca,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
2610,working on loan predictions,Hackathons,working on loan predictions,"['working', 'on', 'loan', 'predictions']",0,"['working', 'on', 'loan', 'prediction']","['working', 'loan', 'prediction']",working loan prediction,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
2611,principal component analysis using pyspark,Techniques,principal component analysis using pyspark,"['principal', 'component', 'analysis', 'using', 'pyspark']",0,"['principal', 'component', 'analysis', 'using', 'pyspark']","['principal', 'component', 'analysis', 'using', 'pyspark']",principal component analysis using pyspark,0.0,0.0,5,42,7.0,0,0,0,0,0,0,0,0
2612,fastai structured module,Tools,fastai structured module,"['fastai', 'structured', 'module']",0,"['fastai', 'structured', 'module']","['fastai', 'structured', 'module']",fastai structured module,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
2613,need help for understanding colclasses in readcsv instruction,Techniques,need help for understanding colclasses in readcsv instruction,"['need', 'help', 'for', 'understanding', 'colclasses', 'in', 'readcsv', 'instruction']",0,"['need', 'help', 'for', 'understanding', 'colclasses', 'in', 'readcsv', 'instruction']","['need', 'help', 'understanding', 'colclasses', 'readcsv', 'instruction']",need help understanding colclasses readcsv instruction,0.0,0.0,8,54,6.0,0,0,0,0,0,0,0,0
2614,how to import sklearn in python,Tools,how to import sklearn in python,"['how', 'to', 'import', 'sklearn', 'in', 'python']",0,"['how', 'to', 'import', 'sklearn', 'in', 'python']","['import', 'sklearn', 'python']",import sklearn python,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
2615,rule based chatbots,Techniques,rule based chatbots,"['rule', 'based', 'chatbots']",0,"['rule', 'based', 'chatbots']","['rule', 'based', 'chatbots']",rule based chatbots,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
2616,locality sensitive hashing for cosine similarity,Techniques,locality sensitive hashing for cosine similarity,"['locality', 'sensitive', 'hashing', 'for', 'cosine', 'similarity']",0,"['locality', 'sensitive', 'hashing', 'for', 'cosine', 'similarity']","['locality', 'sensitive', 'hashing', 'cosine', 'similarity']",locality sensitive hashing cosine similarity,0.1,0.1,6,44,6.285714285714286,0,0,0,0,0,0,0,0
2617,how to calculate running total and compare it to another column and retrieve in hive,Tools,how to calculate running total and compare it to another column and retrieve in hive,"['how', 'to', 'calculate', 'running', 'total', 'and', 'compare', 'it', 'to', 'another', 'column', 'and', 'retrieve', 'in', 'hive']",0,"['how', 'to', 'calculate', 'running', 'total', 'and', 'compare', 'it', 'to', 'another', 'column', 'and', 'retrieve', 'in', 'hive']","['calculate', 'running', 'total', 'compare', 'another', 'column', 'retrieve', 'hive']",calculate running total compare another column retrieve hive,0.0,0.0,15,60,3.75,0,0,0,0,0,0,0,0
2618,how to count number of products for each category in python,Techniques,how to count number of products for each category in python,"['how', 'to', 'count', 'number', 'of', 'products', 'for', 'each', 'category', 'in', 'python']",0,"['how', 'to', 'count', 'number', 'of', 'product', 'for', 'each', 'category', 'in', 'python']","['count', 'number', 'product', 'category', 'python']",count number product category python,0.0,0.0,11,36,3.0,0,0,0,0,0,0,0,0
2619,what is github,Tools,what is github,"['what', 'is', 'github']",0,"['what', 'is', 'github']",['github'],github,0.0,0.0,3,6,1.5,0,0,0,0,0,0,0,0
2620,data source sizing greater then tb,Resources,data source sizing greater then tb,"['data', 'source', 'sizing', 'greater', 'then', 'tb']",0,"['data', 'source', 'sizing', 'greater', 'then', 'tb']","['data', 'source', 'sizing', 'greater', 'tb']",data source sizing greater tb,0.5,0.5,6,29,4.142857142857143,0,0,0,0,0,0,0,0
2621,whether to switch from sas to r and hadoop or not,Career,whether to switch from sas to r and hadoop or not,"['whether', 'to', 'switch', 'from', 'sas', 'to', 'r', 'and', 'hadoop', 'or', 'not']",0,"['whether', 'to', 'switch', 'from', 'sa', 'to', 'r', 'and', 'hadoop', 'or', 'not']","['whether', 'switch', 'sa', 'r', 'hadoop']",whether switch sa r hadoop,0.0,0.0,11,26,2.1666666666666665,0,0,0,0,0,0,0,0
2622,how to find the most significant variables out of ,Techniques,how to find the most significant variables out of ,"['how', 'to', 'find', 'the', 'most', 'significant', 'variables', 'out', 'of']",1,"['how', 'to', 'find', 'the', 'most', 'significant', 'variable', 'out', 'of']","['find', 'significant', 'variable']",find significant variable,0.4375,0.375,9,25,2.5,0,0,0,0,0,0,0,0
2623,stacked histogram for pandas dataframe in python,Tools,stacked histogram for pandas dataframe in python,"['stacked', 'histogram', 'for', 'pandas', 'dataframe', 'in', 'python']",0,"['stacked', 'histogram', 'for', 'panda', 'dataframe', 'in', 'python']","['stacked', 'histogram', 'panda', 'dataframe', 'python']",stacked histogram panda dataframe python,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
2624,downloading images from different url and saving it,Tools,downloading images from different url and saving it,"['downloading', 'images', 'from', 'different', 'url', 'and', 'saving', 'it']",0,"['downloading', 'image', 'from', 'different', 'url', 'and', 'saving', 'it']","['downloading', 'image', 'different', 'url', 'saving']",downloading image different url saving,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
2625,what is deep learning and how it helps in machine learning,Techniques,what is deep learning and how it helps in machine learning,"['what', 'is', 'deep', 'learning', 'and', 'how', 'it', 'helps', 'in', 'machine', 'learning']",0,"['what', 'is', 'deep', 'learning', 'and', 'how', 'it', 'help', 'in', 'machine', 'learning']","['deep', 'learning', 'help', 'machine', 'learning']",deep learning help machine learning,0.0,0.0,11,35,2.9166666666666665,0,0,0,0,0,0,0,0
2626,request for guidance in career transition to data analytics,Career,request for guidance in career transition to data analytics,"['request', 'for', 'guidance', 'in', 'career', 'transition', 'to', 'data', 'analytics']",0,"['request', 'for', 'guidance', 'in', 'career', 'transition', 'to', 'data', 'analytics']","['request', 'guidance', 'career', 'transition', 'data', 'analytics']",request guidance career transition data analytics,0.0,0.0,9,49,4.9,0,0,0,0,0,0,0,0
2627,when do you push a model into production,Techniques,when do you push a model into production,"['when', 'do', 'you', 'push', 'a', 'model', 'into', 'production']",0,"['when', 'do', 'you', 'push', 'a', 'model', 'into', 'production']","['push', 'model', 'production']",push model production,0.0,0.0,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
2628,comparing models performance,Hackathons,comparing models performance,"['comparing', 'models', 'performance']",0,"['comparing', 'model', 'performance']","['comparing', 'model', 'performance']",comparing model performance,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
2629,time series second order differences,Techniques,time series second order differences,"['time', 'series', 'second', 'order', 'differences']",0,"['time', 'series', 'second', 'order', 'difference']","['time', 'series', 'second', 'order', 'difference']",time series second order difference,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
2630,need help in ascertaining the right ml technique,Techniques,need help in ascertaining the right ml technique,"['need', 'help', 'in', 'ascertaining', 'the', 'right', 'ml', 'technique']",0,"['need', 'help', 'in', 'ascertaining', 'the', 'right', 'ml', 'technique']","['need', 'help', 'ascertaining', 'right', 'ml', 'technique']",need help ascertaining right ml technique,0.2857142857142857,0.2857142857142857,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2631,python online training,Career,python online training,"['python', 'online', 'training']",0,"['python', 'online', 'training']","['python', 'online', 'training']",python online training,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
2632,monitor the progress of model,Misc,monitor the progress of model,"['monitor', 'the', 'progress', 'of', 'model']",0,"['monitor', 'the', 'progress', 'of', 'model']","['monitor', 'progress', 'model']",monitor progress model,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
2633,outer join in pandas,Tools,outer join in pandas,"['outer', 'join', 'in', 'pandas']",0,"['outer', 'join', 'in', 'panda']","['outer', 'join', 'panda']",outer join panda,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
2634,argument is not numeric or logical returning na r,Techniques,argument is not numeric or logical returning na r,"['argument', 'is', 'not', 'numeric', 'or', 'logical', 'returning', 'na', 'r']",0,"['argument', 'is', 'not', 'numeric', 'or', 'logical', 'returning', 'na', 'r']","['argument', 'numeric', 'logical', 'returning', 'na', 'r']",argument numeric logical returning na r,0.25,0.25,9,39,3.9,0,0,0,0,0,0,0,0
2635,error in predictrandomforestfit test  type of predictors in new data do not match that of the training data,Techniques,error in predictrandomforestfit test  type of predictors in new data do not match that of the training data,"['error', 'in', 'predictrandomforestfit', 'test', 'type', 'of', 'predictors', 'in', 'new', 'data', 'do', 'not', 'match', 'that', 'of', 'the', 'training', 'data']",0,"['error', 'in', 'predictrandomforestfit', 'test', 'type', 'of', 'predictor', 'in', 'new', 'data', 'do', 'not', 'match', 'that', 'of', 'the', 'training', 'data']","['error', 'predictrandomforestfit', 'test', 'type', 'predictor', 'new', 'data', 'match', 'training', 'data']",error predictrandomforestfit test type predictor new data match training data,0.1363636363636363,0.1363636363636363,18,77,4.052631578947368,0,0,0,0,0,0,0,0
2636,can a data be neither discrete nor continuous,Misc,can a data be neither discrete nor continuous,"['can', 'a', 'data', 'be', 'neither', 'discrete', 'nor', 'continuous']",0,"['can', 'a', 'data', 'be', 'neither', 'discrete', 'nor', 'continuous']","['data', 'neither', 'discrete', 'continuous']",data neither discrete continuous,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
2637,scope for energy analytics in india,Career,scope for energy analytics in india,"['scope', 'for', 'energy', 'analytics', 'in', 'india']",0,"['scope', 'for', 'energy', 'analytics', 'in', 'india']","['scope', 'energy', 'analytics', 'india']",scope energy analytics india,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
2638,how to find the attribute that most impacts target variable when multicollinearity is present,Techniques,how to find the attribute that most impacts target variable when multicollinearity is present,"['how', 'to', 'find', 'the', 'attribute', 'that', 'most', 'impacts', 'target', 'variable', 'when', 'multicollinearity', 'is', 'present']",0,"['how', 'to', 'find', 'the', 'attribute', 'that', 'most', 'impact', 'target', 'variable', 'when', 'multicollinearity', 'is', 'present']","['find', 'attribute', 'impact', 'target', 'variable', 'multicollinearity', 'present']",find attribute impact target variable multicollinearity present,0.25,0.0,14,63,4.2,0,0,0,0,0,0,0,0
2639,adressing seasonality in predictive modellingspecifically decision trees,Techniques,adressing seasonality in predictive modellingspecifically decision trees,"['adressing', 'seasonality', 'in', 'predictive', 'modellingspecifically', 'decision', 'trees']",0,"['adressing', 'seasonality', 'in', 'predictive', 'modellingspecifically', 'decision', 'tree']","['adressing', 'seasonality', 'predictive', 'modellingspecifically', 'decision', 'tree']",adressing seasonality predictive modellingspecifically decision tree,0.0,0.0,7,68,8.5,0,0,0,0,0,0,0,0
2640,cart model  how to choose variables which can make difference,Techniques,cart model  how to choose variables which can make difference,"['cart', 'model', 'how', 'to', 'choose', 'variables', 'which', 'can', 'make', 'difference']",0,"['cart', 'model', 'how', 'to', 'choose', 'variable', 'which', 'can', 'make', 'difference']","['cart', 'model', 'choose', 'variable', 'make', 'difference']",cart model choose variable make difference,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
2641,what value of information value should be select for modeling,Techniques,what value of information value should be select for modeling,"['what', 'value', 'of', 'information', 'value', 'should', 'be', 'select', 'for', 'modeling']",0,"['what', 'value', 'of', 'information', 'value', 'should', 'be', 'select', 'for', 'modeling']","['value', 'information', 'value', 'select', 'modeling']",value information value select modeling,0.0,0.0,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
2642,how to learn big data analytics with r,Techniques,how to learn big data analytics with r,"['how', 'to', 'learn', 'big', 'data', 'analytics', 'with', 'r']",0,"['how', 'to', 'learn', 'big', 'data', 'analytics', 'with', 'r']","['learn', 'big', 'data', 'analytics', 'r']",learn big data analytics r,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
2643,how to extract employment details from thousand resumes in one file using machine learning algorithms,Techniques,how to extract employment details from thousand resumes in one file using machine learning algorithms,"['how', 'to', 'extract', 'employment', 'details', 'from', 'thousand', 'resumes', 'in', 'one', 'file', 'using', 'machine', 'learning', 'algorithms']",0,"['how', 'to', 'extract', 'employment', 'detail', 'from', 'thousand', 'resume', 'in', 'one', 'file', 'using', 'machine', 'learning', 'algorithm']","['extract', 'employment', 'detail', 'thousand', 'resume', 'one', 'file', 'using', 'machine', 'learning', 'algorithm']",extract employment detail thousand resume one file using machine learning algorithm,0.0,0.0,15,83,5.1875,0,0,0,0,0,0,0,0
2644,time series analysis  queries on practice problem,Techniques,time series analysis  queries on practice problem,"['time', 'series', 'analysis', 'queries', 'on', 'practice', 'problem']",0,"['time', 'series', 'analysis', 'query', 'on', 'practice', 'problem']","['time', 'series', 'analysis', 'query', 'practice', 'problem']",time series analysis query practice problem,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
2645,what should be training error in boosting,Techniques,what should be training error in boosting,"['what', 'should', 'be', 'training', 'error', 'in', 'boosting']",0,"['what', 'should', 'be', 'training', 'error', 'in', 'boosting']","['training', 'error', 'boosting']",training error boosting,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
2646,how to increment the sequences by a fixed value in r,Tools,how to increment the sequences by a fixed value in r,"['how', 'to', 'increment', 'the', 'sequences', 'by', 'a', 'fixed', 'value', 'in', 'r']",0,"['how', 'to', 'increment', 'the', 'sequence', 'by', 'a', 'fixed', 'value', 'in', 'r']","['increment', 'sequence', 'fixed', 'value', 'r']",increment sequence fixed value r,0.1,0.1,11,32,2.6666666666666665,0,0,0,0,0,0,0,0
2647,how to test accuracy on test data when test data does not have the output,Hackathons,how to test accuracy on test data when test data does not have the output,"['how', 'to', 'test', 'accuracy', 'on', 'test', 'data', 'when', 'test', 'data', 'does', 'not', 'have', 'the', 'output']",0,"['how', 'to', 'test', 'accuracy', 'on', 'test', 'data', 'when', 'test', 'data', 'doe', 'not', 'have', 'the', 'output']","['test', 'accuracy', 'test', 'data', 'test', 'data', 'doe', 'output']",test accuracy test data test data doe output,0.0,0.0,15,44,2.75,0,0,0,0,0,0,0,0
2648,a comprehensive learning path for deep learning in ,Career,a comprehensive learning path for deep learning in ,"['a', 'comprehensive', 'learning', 'path', 'for', 'deep', 'learning', 'in']",1,"['a', 'comprehensive', 'learning', 'path', 'for', 'deep', 'learning', 'in']","['comprehensive', 'learning', 'path', 'deep', 'learning']",comprehensive learning path deep learning,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2649,classification prediction  delivering to the business users,Other,classification prediction  delivering to the business users,"['classification', 'prediction', 'delivering', 'to', 'the', 'business', 'users']",0,"['classification', 'prediction', 'delivering', 'to', 'the', 'business', 'user']","['classification', 'prediction', 'delivering', 'business', 'user']",classification prediction delivering business user,0.0,0.0,7,50,6.25,0,0,0,0,0,0,0,0
2650,human activity recognition on smartphones understanding the dataset,Hackathons,human activity recognition on smartphones understanding the dataset,"['human', 'activity', 'recognition', 'on', 'smartphones', 'understanding', 'the', 'dataset']",0,"['human', 'activity', 'recognition', 'on', 'smartphones', 'understanding', 'the', 'dataset']","['human', 'activity', 'recognition', 'smartphones', 'understanding', 'dataset']",human activity recognition smartphones understanding dataset,0.0,0.0,8,60,6.666666666666667,0,0,0,0,0,0,0,0
2651,how can we handle large matrices in r,Tools,how can we handle large matrices in r,"['how', 'can', 'we', 'handle', 'large', 'matrices', 'in', 'r']",0,"['how', 'can', 'we', 'handle', 'large', 'matrix', 'in', 'r']","['handle', 'large', 'matrix', 'r']",handle large matrix r,0.2142857142857142,0.2142857142857142,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
2652,download analytics and big data salary report ,Resources,download analytics and big data salary report ,"['download', 'analytics', 'and', 'big', 'data', 'salary', 'report']",1,"['download', 'analytics', 'and', 'big', 'data', 'salary', 'report']","['download', 'analytics', 'big', 'data', 'salary', 'report']",download analytics big data salary report,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
2653,xgboost error  need help,Tools,xgboost error  need help,"['xgboost', 'error', 'need', 'help']",0,"['xgboost', 'error', 'need', 'help']","['xgboost', 'error', 'need', 'help']",xgboost error need help,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
2654,which is the best course for r certification onlineclassroom based,Career,which is the best course for r certification onlineclassroom based,"['which', 'is', 'the', 'best', 'course', 'for', 'r', 'certification', 'onlineclassroom', 'based']",0,"['which', 'is', 'the', 'best', 'course', 'for', 'r', 'certification', 'onlineclassroom', 'based']","['best', 'course', 'r', 'certification', 'onlineclassroom', 'based']",best course r certification onlineclassroom based,1.0,1.0,10,49,4.454545454545454,0,0,0,0,0,0,0,0
2655,error when xgboost result applied on test set,Techniques,error when xgboost result applied on test set,"['error', 'when', 'xgboost', 'result', 'applied', 'on', 'test', 'set']",0,"['error', 'when', 'xgboost', 'result', 'applied', 'on', 'test', 'set']","['error', 'xgboost', 'result', 'applied', 'test', 'set']",error xgboost result applied test set,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
2656,how to import a json file into r,Tools,how to import a json file into r,"['how', 'to', 'import', 'a', 'json', 'file', 'into', 'r']",0,"['how', 'to', 'import', 'a', 'json', 'file', 'into', 'r']","['import', 'json', 'file', 'r']",import json file r,0.0,0.0,8,18,2.0,0,0,0,0,0,0,0,0
2657,ocr output vs ground truth population and error identification,Techniques,ocr output vs ground truth population and error identification,"['ocr', 'output', 'vs', 'ground', 'truth', 'population', 'and', 'error', 'identification']",0,"['ocr', 'output', 'v', 'ground', 'truth', 'population', 'and', 'error', 'identification']","['ocr', 'output', 'v', 'ground', 'truth', 'population', 'error', 'identification']",ocr output v ground truth population error identification,0.0,0.0,9,57,5.7,0,0,0,0,0,0,0,0
2658,age predictor indian actor how to improve the model,Hackathons,age predictor indian actor how to improve the model,"['age', 'predictor', 'indian', 'actor', 'how', 'to', 'improve', 'the', 'model']",0,"['age', 'predictor', 'indian', 'actor', 'how', 'to', 'improve', 'the', 'model']","['age', 'predictor', 'indian', 'actor', 'improve', 'model']",age predictor indian actor improve model,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
2659,check accuracy of a randomforest model in r,Techniques,check accuracy of a randomforest model in r,"['check', 'accuracy', 'of', 'a', 'randomforest', 'model', 'in', 'r']",0,"['check', 'accuracy', 'of', 'a', 'randomforest', 'model', 'in', 'r']","['check', 'accuracy', 'randomforest', 'model', 'r']",check accuracy randomforest model r,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
2660,your input is needed for a research project,Other,your input is needed for a research project,"['your', 'input', 'is', 'needed', 'for', 'a', 'research', 'project']",0,"['your', 'input', 'is', 'needed', 'for', 'a', 'research', 'project']","['input', 'needed', 'research', 'project']",input needed research project,0.0,0.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
2661,does oversampling really help in increasing model performance,Techniques,does oversampling really help in increasing model performance,"['does', 'oversampling', 'really', 'help', 'in', 'increasing', 'model', 'performance']",0,"['doe', 'oversampling', 'really', 'help', 'in', 'increasing', 'model', 'performance']","['doe', 'oversampling', 'really', 'help', 'increasing', 'model', 'performance']",doe oversampling really help increasing model performance,0.2,0.2,8,57,6.333333333333333,0,0,0,0,0,0,0,0
2662,r gettingsetting working directory,Tools,r gettingsetting working directory,"['r', 'gettingsetting', 'working', 'directory']",0,"['r', 'gettingsetting', 'working', 'directory']","['r', 'gettingsetting', 'working', 'directory']",r gettingsetting working directory,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
2663,what is s and s object system in r,Tools,what is s and s object system in r,"['what', 'is', 's', 'and', 's', 'object', 'system', 'in', 'r']",0,"['what', 'is', 's', 'and', 's', 'object', 'system', 'in', 'r']","['object', 'system', 'r']",object system r,0.0,0.0,9,15,1.5,0,0,0,0,0,0,0,0
2665,what does training a model on probabilities mean,Techniques,what does training a model on probabilities mean,"['what', 'does', 'training', 'a', 'model', 'on', 'probabilities', 'mean']",0,"['what', 'doe', 'training', 'a', 'model', 'on', 'probability', 'mean']","['doe', 'training', 'model', 'probability', 'mean']",doe training model probability mean,-0.3125,-0.3125,8,35,3.888888888888889,0,0,0,0,0,0,0,0
2666,how to use data augmentation on uneven multiclass dataset,Techniques,how to use data augmentation on uneven multiclass dataset,"['how', 'to', 'use', 'data', 'augmentation', 'on', 'uneven', 'multiclass', 'dataset']",0,"['how', 'to', 'use', 'data', 'augmentation', 'on', 'uneven', 'multiclass', 'dataset']","['use', 'data', 'augmentation', 'uneven', 'multiclass', 'dataset']",use data augmentation uneven multiclass dataset,-0.2,-0.2,9,47,4.7,0,0,0,0,0,0,0,0
2667,understanding the output of boosting,Tools,understanding the output of boosting,"['understanding', 'the', 'output', 'of', 'boosting']",0,"['understanding', 'the', 'output', 'of', 'boosting']","['understanding', 'output', 'boosting']",understanding output boosting,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
2668,what are the p value in factor analysis signifies,Techniques,what are the p value in factor analysis signifies,"['what', 'are', 'the', 'p', 'value', 'in', 'factor', 'analysis', 'signifies']",0,"['what', 'are', 'the', 'p', 'value', 'in', 'factor', 'analysis', 'signifies']","['p', 'value', 'factor', 'analysis', 'signifies']",p value factor analysis signifies,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
2669,how to specify the columns of data frame in python,Tools,how to specify the columns of data frame in python,"['how', 'to', 'specify', 'the', 'columns', 'of', 'data', 'frame', 'in', 'python']",0,"['how', 'to', 'specify', 'the', 'column', 'of', 'data', 'frame', 'in', 'python']","['specify', 'column', 'data', 'frame', 'python']",specify column data frame python,0.0,0.0,10,32,2.909090909090909,0,0,0,0,0,0,0,0
2670,integer class vs numeric class in r,Tools,integer class vs numeric class in r,"['integer', 'class', 'vs', 'numeric', 'class', 'in', 'r']",0,"['integer', 'class', 'v', 'numeric', 'class', 'in', 'r']","['integer', 'class', 'v', 'numeric', 'class', 'r']",integer class v numeric class r,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
2671,how to remove error cant have empty classes in y in random forest,Tools,how to remove error cant have empty classes in y in random forest,"['how', 'to', 'remove', 'error', 'cant', 'have', 'empty', 'classes', 'in', 'y', 'in', 'random', 'forest']",0,"['how', 'to', 'remove', 'error', 'cant', 'have', 'empty', 'class', 'in', 'y', 'in', 'random', 'forest']","['remove', 'error', 'cant', 'empty', 'class', 'random', 'forest']",remove error cant empty class random forest,-0.3,-0.3,13,43,3.0714285714285716,0,0,0,0,0,0,0,0
2672,how i could embed graphssubgraphs to deep learning model,Techniques,how i could embed graphssubgraphs to deep learning model,"['how', 'i', 'could', 'embed', 'graphssubgraphs', 'to', 'deep', 'learning', 'model']",0,"['how', 'i', 'could', 'embed', 'graphssubgraphs', 'to', 'deep', 'learning', 'model']","['could', 'embed', 'graphssubgraphs', 'deep', 'learning', 'model']",could embed graphssubgraphs deep learning model,0.0,0.0,9,47,4.7,0,0,0,0,0,0,0,0
2673,in the tutorial twitter sentiment analysis how can we solve the problem of data imbalance,Techniques,in the tutorial twitter sentiment analysis how can we solve the problem of data imbalance,"['in', 'the', 'tutorial', 'twitter', 'sentiment', 'analysis', 'how', 'can', 'we', 'solve', 'the', 'problem', 'of', 'data', 'imbalance']",0,"['in', 'the', 'tutorial', 'twitter', 'sentiment', 'analysis', 'how', 'can', 'we', 'solve', 'the', 'problem', 'of', 'data', 'imbalance']","['tutorial', 'twitter', 'sentiment', 'analysis', 'solve', 'problem', 'data', 'imbalance']",tutorial twitter sentiment analysis solve problem data imbalance,0.0,0.0,15,64,4.0,0,0,0,0,0,0,0,0
2674,can bootstrap is used for estimation prediction error,Techniques,can bootstrap is used for estimation prediction error,"['can', 'bootstrap', 'is', 'used', 'for', 'estimation', 'prediction', 'error']",0,"['can', 'bootstrap', 'is', 'used', 'for', 'estimation', 'prediction', 'error']","['bootstrap', 'used', 'estimation', 'prediction', 'error']",bootstrap used estimation prediction error,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
2675,mini hack  data visualization final leader board and best visualization,Hackathons,mini hack  data visualization final leader board and best visualization,"['mini', 'hack', 'data', 'visualization', 'final', 'leader', 'board', 'and', 'best', 'visualization']",0,"['mini', 'hack', 'data', 'visualization', 'final', 'leader', 'board', 'and', 'best', 'visualization']","['mini', 'hack', 'data', 'visualization', 'final', 'leader', 'board', 'best', 'visualization']",mini hack data visualization final leader board best visualization,0.5,0.5,10,66,6.0,0,0,0,0,0,0,0,0
2676,need to read a dataframe line by line,Techniques,need to read a dataframe line by line,"['need', 'to', 'read', 'a', 'dataframe', 'line', 'by', 'line']",0,"['need', 'to', 'read', 'a', 'dataframe', 'line', 'by', 'line']","['need', 'read', 'dataframe', 'line', 'line']",need read dataframe line line,0.0,0.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
2677,need to call post method of rest api,Techniques,need to call post method of rest api,"['need', 'to', 'call', 'post', 'method', 'of', 'rest', 'api']",0,"['need', 'to', 'call', 'post', 'method', 'of', 'rest', 'api']","['need', 'call', 'post', 'method', 'rest', 'api']",need call post method rest api,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
2678,how to extract values from a large character object with different separators between values in r,Tools,how to extract values from a large character object with different separators between values in r,"['how', 'to', 'extract', 'values', 'from', 'a', 'large', 'character', 'object', 'with', 'different', 'separators', 'between', 'values', 'in', 'r']",0,"['how', 'to', 'extract', 'value', 'from', 'a', 'large', 'character', 'object', 'with', 'different', 'separator', 'between', 'value', 'in', 'r']","['extract', 'value', 'large', 'character', 'object', 'different', 'separator', 'value', 'r']",extract value large character object different separator value r,0.1071428571428571,0.1071428571428571,16,64,3.764705882352941,0,0,0,0,0,0,0,0
2679,best practices for data preprocessing and its resources,Resources,best practices for data preprocessing and its resources,"['best', 'practices', 'for', 'data', 'preprocessing', 'and', 'its', 'resources']",0,"['best', 'practice', 'for', 'data', 'preprocessing', 'and', 'it', 'resource']","['best', 'practice', 'data', 'preprocessing', 'resource']",best practice data preprocessing resource,1.0,1.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2680,features extraction,Techniques,features extraction,"['features', 'extraction']",0,"['feature', 'extraction']","['feature', 'extraction']",feature extraction,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
2681,knime for text analytics,Tools,knime for text analytics,"['knime', 'for', 'text', 'analytics']",0,"['knime', 'for', 'text', 'analytics']","['knime', 'text', 'analytics']",knime text analytics,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
2682,how to set the final submission,Hackathons,how to set the final submission,"['how', 'to', 'set', 'the', 'final', 'submission']",0,"['how', 'to', 'set', 'the', 'final', 'submission']","['set', 'final', 'submission']",set final submission,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
2683,big mart sell doubt,Techniques,big mart sell doubt,"['big', 'mart', 'sell', 'doubt']",0,"['big', 'mart', 'sell', 'doubt']","['big', 'mart', 'sell', 'doubt']",big mart sell doubt,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
2684,feature selection,Techniques,feature selection,"['feature', 'selection']",0,"['feature', 'selection']","['feature', 'selection']",feature selection,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
2685,random forest based on recency frequency modelling,Techniques,random forest based on recency frequency modelling,"['random', 'forest', 'based', 'on', 'recency', 'frequency', 'modelling']",0,"['random', 'forest', 'based', 'on', 'recency', 'frequency', 'modelling']","['random', 'forest', 'based', 'recency', 'frequency', 'modelling']",random forest based recency frequency modelling,-0.5,-0.5,7,47,5.875,0,0,0,0,0,0,0,0
2686,k modes clustering,Tools,k modes clustering,"['k', 'modes', 'clustering']",0,"['k', 'mode', 'clustering']","['k', 'mode', 'clustering']",k mode clustering,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
2687,short duration analytics courses,Career,short duration analytics courses,"['short', 'duration', 'analytics', 'courses']",0,"['short', 'duration', 'analytics', 'course']","['short', 'duration', 'analytics', 'course']",short duration analytics course,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
2688,applying ulmfit on custom data,Tools,applying ulmfit on custom data,"['applying', 'ulmfit', 'on', 'custom', 'data']",0,"['applying', 'ulmfit', 'on', 'custom', 'data']","['applying', 'ulmfit', 'custom', 'data']",applying ulmfit custom data,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
2689,anova on time series data,Techniques,anova on time series data,"['anova', 'on', 'time', 'series', 'data']",0,"['anova', 'on', 'time', 'series', 'data']","['anova', 'time', 'series', 'data']",anova time series data,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
2690,web scrapping using python,Techniques,web scrapping using python,"['web', 'scrapping', 'using', 'python']",0,"['web', 'scrapping', 'using', 'python']","['web', 'scrapping', 'using', 'python']",web scrapping using python,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
2691,is there any inbuilt function for calculation of mode in r,Techniques,is there any inbuilt function for calculation of mode in r,"['is', 'there', 'any', 'inbuilt', 'function', 'for', 'calculation', 'of', 'mode', 'in', 'r']",0,"['is', 'there', 'any', 'inbuilt', 'function', 'for', 'calculation', 'of', 'mode', 'in', 'r']","['inbuilt', 'function', 'calculation', 'mode', 'r']",inbuilt function calculation mode r,0.0,0.0,11,35,2.9166666666666665,0,0,0,0,0,0,0,0
2692,understanding the data in informationtraintestcsv,Hackathons,understanding the data in informationtraintestcsv,"['understanding', 'the', 'data', 'in', 'informationtraintestcsv']",0,"['understanding', 'the', 'data', 'in', 'informationtraintestcsv']","['understanding', 'data', 'informationtraintestcsv']",understanding data informationtraintestcsv,0.0,0.0,5,42,7.0,0,0,0,0,0,0,0,0
2693,how to copy subset of a array in ipython,Tools,how to copy subset of a array in ipython,"['how', 'to', 'copy', 'subset', 'of', 'a', 'array', 'in', 'ipython']",0,"['how', 'to', 'copy', 'subset', 'of', 'a', 'array', 'in', 'ipython']","['copy', 'subset', 'array', 'ipython']",copy subset array ipython,0.0,0.0,9,25,2.5,0,0,0,0,0,0,0,0
2694,r programming how can i separate column names in to different columns to perform downstream analysis,Resources,r programming how can i separate column names in to different columns to perform downstream analysis,"['r', 'programming', 'how', 'can', 'i', 'separate', 'column', 'names', 'in', 'to', 'different', 'columns', 'to', 'perform', 'downstream', 'analysis']",0,"['r', 'programming', 'how', 'can', 'i', 'separate', 'column', 'name', 'in', 'to', 'different', 'column', 'to', 'perform', 'downstream', 'analysis']","['r', 'programming', 'separate', 'column', 'name', 'different', 'column', 'perform', 'downstream', 'analysis']",r programming separate column name different column perform downstream analysis,0.0,0.0,16,79,4.647058823529412,0,0,0,0,0,0,0,0
2695,how to prepare for sas analyst,Career,how to prepare for sas analyst,"['how', 'to', 'prepare', 'for', 'sas', 'analyst']",0,"['how', 'to', 'prepare', 'for', 'sa', 'analyst']","['prepare', 'sa', 'analyst']",prepare sa analyst,0.0,0.0,6,18,2.5714285714285716,0,0,0,0,0,0,0,0
2696,customer retail transaction data required,Resources,customer retail transaction data required,"['customer', 'retail', 'transaction', 'data', 'required']",0,"['customer', 'retail', 'transaction', 'data', 'required']","['customer', 'retail', 'transaction', 'data', 'required']",customer retail transaction data required,0.0,0.0,5,41,6.833333333333333,0,0,0,0,0,0,0,0
2697,domain related analytics course,Resources,domain related analytics course,"['domain', 'related', 'analytics', 'course']",0,"['domain', 'related', 'analytics', 'course']","['domain', 'related', 'analytics', 'course']",domain related analytics course,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
2698,career shift from mainframes to analytics,Career,career shift from mainframes to analytics,"['career', 'shift', 'from', 'mainframes', 'to', 'analytics']",0,"['career', 'shift', 'from', 'mainframe', 'to', 'analytics']","['career', 'shift', 'mainframe', 'analytics']",career shift mainframe analytics,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
2699,mini hack  excel,Hackathons,mini hack  excel,"['mini', 'hack', 'excel']",0,"['mini', 'hack', 'excel']","['mini', 'hack', 'excel']",mini hack excel,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
2700,practice problem   why grouping as class others not done for all variables,Hackathons,practice problem   why grouping as class others not done for all variables,"['practice', 'problem', 'why', 'grouping', 'as', 'class', 'others', 'not', 'done', 'for', 'all', 'variables']",1,"['practice', 'problem', 'why', 'grouping', 'a', 'class', 'others', 'not', 'done', 'for', 'all', 'variable']","['practice', 'problem', 'grouping', 'class', 'others', 'done', 'variable']",practice problem grouping class others done variable,0.0,0.0,12,52,4.0,0,0,0,0,0,0,0,0
2701,algorithm to predict ranks instead of value or class,Techniques,algorithm to predict ranks instead of value or class,"['algorithm', 'to', 'predict', 'ranks', 'instead', 'of', 'value', 'or', 'class']",0,"['algorithm', 'to', 'predict', 'rank', 'instead', 'of', 'value', 'or', 'class']","['algorithm', 'predict', 'rank', 'instead', 'value', 'class']",algorithm predict rank instead value class,0.0,-0.8,9,42,4.2,0,0,0,0,0,0,0,0
2702,elasticnet regularized logistic regression,Techniques,elasticnet regularized logistic regression,"['elasticnet', 'regularized', 'logistic', 'regression']",0,"['elasticnet', 'regularized', 'logistic', 'regression']","['elasticnet', 'regularized', 'logistic', 'regression']",elasticnet regularized logistic regression,0.0,0.0,4,42,8.4,0,0,0,0,0,0,0,0
2703,need help in preparing training data for machine learning,Techniques,need help in preparing training data for machine learning,"['need', 'help', 'in', 'preparing', 'training', 'data', 'for', 'machine', 'learning']",0,"['need', 'help', 'in', 'preparing', 'training', 'data', 'for', 'machine', 'learning']","['need', 'help', 'preparing', 'training', 'data', 'machine', 'learning']",need help preparing training data machine learning,0.0,0.0,9,50,5.0,0,0,0,0,0,0,0,0
2704,high survival probabilities for uncensored test observations when using randomforestsrc,Techniques,high survival probabilities for uncensored test observations when using randomforestsrc,"['high', 'survival', 'probabilities', 'for', 'uncensored', 'test', 'observations', 'when', 'using', 'randomforestsrc']",0,"['high', 'survival', 'probability', 'for', 'uncensored', 'test', 'observation', 'when', 'using', 'randomforestsrc']","['high', 'survival', 'probability', 'uncensored', 'test', 'observation', 'using', 'randomforestsrc']",high survival probability uncensored test observation using randomforestsrc,0.16,0.16,10,75,6.818181818181818,0,0,0,0,0,0,0,0
2705,chisquare test fischers exact test failed what are the alternatives to find out the relation between independent categorical variables,Techniques,chisquare test fischers exact test failed what are the alternatives to find out the relation between independent categorical variables,"['chisquare', 'test', 'fischers', 'exact', 'test', 'failed', 'what', 'are', 'the', 'alternatives', 'to', 'find', 'out', 'the', 'relation', 'between', 'independent', 'categorical', 'variables']",0,"['chisquare', 'test', 'fischer', 'exact', 'test', 'failed', 'what', 'are', 'the', 'alternative', 'to', 'find', 'out', 'the', 'relation', 'between', 'independent', 'categorical', 'variable']","['chisquare', 'test', 'fischer', 'exact', 'test', 'failed', 'alternative', 'find', 'relation', 'independent', 'categorical', 'variable']",chisquare test fischer exact test failed alternative find relation independent categorical variable,-0.0833333333333333,-0.0833333333333333,19,99,4.95,0,0,0,0,0,0,0,0
2706,error in dataframe,Techniques,error in dataframe,"['error', 'in', 'dataframe']",0,"['error', 'in', 'dataframe']","['error', 'dataframe']",error dataframe,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
2707,interpreting the output of a logistic regression,Techniques,interpreting the output of a logistic regression,"['interpreting', 'the', 'output', 'of', 'a', 'logistic', 'regression']",0,"['interpreting', 'the', 'output', 'of', 'a', 'logistic', 'regression']","['interpreting', 'output', 'logistic', 'regression']",interpreting output logistic regression,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
2708,not able to upload submission,Hackathons,not able to upload submission,"['not', 'able', 'to', 'upload', 'submission']",0,"['not', 'able', 'to', 'upload', 'submission']","['able', 'upload', 'submission']",able upload submission,-0.25,0.5,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
2709,pca used for regression,Techniques,pca used for regression,"['pca', 'used', 'for', 'regression']",0,"['pca', 'used', 'for', 'regression']","['pca', 'used', 'regression']",pca used regression,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
2710,mean function not giving the correct answer in r,Tools,mean function not giving the correct answer in r,"['mean', 'function', 'not', 'giving', 'the', 'correct', 'answer', 'in', 'r']",0,"['mean', 'function', 'not', 'giving', 'the', 'correct', 'answer', 'in', 'r']","['mean', 'function', 'giving', 'correct', 'answer', 'r']",mean function giving correct answer r,-0.3125,-0.3125,9,37,3.7,0,0,0,0,0,0,0,0
2711,how to plot multiple png images into the same plot in r,Tools,how to plot multiple png images into the same plot in r,"['how', 'to', 'plot', 'multiple', 'png', 'images', 'into', 'the', 'same', 'plot', 'in', 'r']",0,"['how', 'to', 'plot', 'multiple', 'png', 'image', 'into', 'the', 'same', 'plot', 'in', 'r']","['plot', 'multiple', 'png', 'image', 'plot', 'r']",plot multiple png image plot r,0.0,0.0,12,30,2.3076923076923075,0,0,0,0,0,0,0,0
2712,how to determine bias and variance for an infinite training data set,Techniques,how to determine bias and variance for an infinite training data set,"['how', 'to', 'determine', 'bias', 'and', 'variance', 'for', 'an', 'infinite', 'training', 'data', 'set']",0,"['how', 'to', 'determine', 'bias', 'and', 'variance', 'for', 'an', 'infinite', 'training', 'data', 'set']","['determine', 'bias', 'variance', 'infinite', 'training', 'data', 'set']",determine bias variance infinite training data set,0.0,0.0,12,50,3.8461538461538463,0,0,0,0,0,0,0,0
2713,how to handle unknown categories viz that are in test but not in train,Techniques,how to handle unknown categories viz that are in test but not in train,"['how', 'to', 'handle', 'unknown', 'categories', 'viz', 'that', 'are', 'in', 'test', 'but', 'not', 'in', 'train']",0,"['how', 'to', 'handle', 'unknown', 'category', 'viz', 'that', 'are', 'in', 'test', 'but', 'not', 'in', 'train']","['handle', 'unknown', 'category', 'viz', 'test', 'train']",handle unknown category viz test train,-0.1,-0.1,14,38,2.533333333333333,0,0,0,0,0,0,0,0
2714,imbalance dataset,Techniques,imbalance dataset,"['imbalance', 'dataset']",0,"['imbalance', 'dataset']","['imbalance', 'dataset']",imbalance dataset,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
2715,what is the best book recomended for begineers in machine learningpreferrably in python,Resources,what is the best book recomended for begineers in machine learningpreferrably in python,"['what', 'is', 'the', 'best', 'book', 'recomended', 'for', 'begineers', 'in', 'machine', 'learningpreferrably', 'in', 'python']",0,"['what', 'is', 'the', 'best', 'book', 'recomended', 'for', 'begineers', 'in', 'machine', 'learningpreferrably', 'in', 'python']","['best', 'book', 'recomended', 'begineers', 'machine', 'learningpreferrably', 'python']",best book recomended begineers machine learningpreferrably python,1.0,1.0,13,65,4.642857142857143,0,0,0,0,0,0,0,0
2716,urban sound challange hackathon,Hackathons,urban sound challange hackathon,"['urban', 'sound', 'challange', 'hackathon']",0,"['urban', 'sound', 'challange', 'hackathon']","['urban', 'sound', 'challange', 'hackathon']",urban sound challange hackathon,0.2,0.2,4,31,6.2,0,0,0,0,0,0,0,0
2717,what does the strata option in randomforest function do in r,Tools,what does the strata option in randomforest function do in r,"['what', 'does', 'the', 'strata', 'option', 'in', 'randomforest', 'function', 'do', 'in', 'r']",0,"['what', 'doe', 'the', 'stratum', 'option', 'in', 'randomforest', 'function', 'do', 'in', 'r']","['doe', 'stratum', 'option', 'randomforest', 'function', 'r']",doe stratum option randomforest function r,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
2718,time series with multiple attributes and multiple groups,Techniques,time series with multiple attributes and multiple groups,"['time', 'series', 'with', 'multiple', 'attributes', 'and', 'multiple', 'groups']",0,"['time', 'series', 'with', 'multiple', 'attribute', 'and', 'multiple', 'group']","['time', 'series', 'multiple', 'attribute', 'multiple', 'group']",time series multiple attribute multiple group,0.0,0.0,8,45,5.0,0,0,0,0,0,0,0,0
2719,random forest in r,Techniques,random forest in r,"['random', 'forest', 'in', 'r']",0,"['random', 'forest', 'in', 'r']","['random', 'forest', 'r']",random forest r,-0.5,-0.5,4,15,3.0,0,0,0,0,0,0,0,0
2720,which of the distance between cluster is best for clustering,Techniques,which of the distance between cluster is best for clustering,"['which', 'of', 'the', 'distance', 'between', 'cluster', 'is', 'best', 'for', 'clustering']",0,"['which', 'of', 'the', 'distance', 'between', 'cluster', 'is', 'best', 'for', 'clustering']","['distance', 'cluster', 'best', 'clustering']",distance cluster best clustering,1.0,1.0,10,32,2.909090909090909,0,0,0,0,0,0,0,0
2721,analytics  data science startups taking freshers,Career,analytics  data science startups taking freshers,"['analytics', 'data', 'science', 'startups', 'taking', 'freshers']",0,"['analytics', 'data', 'science', 'startup', 'taking', 'fresher']","['analytics', 'data', 'science', 'startup', 'taking', 'fresher']",analytics data science startup taking fresher,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
2722,what are some ways to handle different factor levels in train and test data,Techniques,what are some ways to handle different factor levels in train and test data,"['what', 'are', 'some', 'ways', 'to', 'handle', 'different', 'factor', 'levels', 'in', 'train', 'and', 'test', 'data']",0,"['what', 'are', 'some', 'way', 'to', 'handle', 'different', 'factor', 'level', 'in', 'train', 'and', 'test', 'data']","['way', 'handle', 'different', 'factor', 'level', 'train', 'test', 'data']",way handle different factor level train test data,0.0,0.0,14,49,3.2666666666666666,0,0,0,0,0,0,0,0
2723,flair word embedding query,Techniques,flair word embedding query,"['flair', 'word', 'embedding', 'query']",0,"['flair', 'word', 'embedding', 'query']","['flair', 'word', 'embedding', 'query']",flair word embedding query,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
2724,updated code of julia loan prediction challenge,Hackathons,updated code of julia loan prediction challenge,"['updated', 'code', 'of', 'julia', 'loan', 'prediction', 'challenge']",0,"['updated', 'code', 'of', 'julia', 'loan', 'prediction', 'challenge']","['updated', 'code', 'julia', 'loan', 'prediction', 'challenge']",updated code julia loan prediction challenge,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
2725,python decisiontreeclassifier  something wrong,Other,python decisiontreeclassifier  something wrong,"['python', 'decisiontreeclassifier', 'something', 'wrong']",0,"['python', 'decisiontreeclassifier', 'something', 'wrong']","['python', 'decisiontreeclassifier', 'something', 'wrong']",python decisiontreeclassifier something wrong,-0.5,-0.5,4,45,9.0,0,0,0,0,0,0,0,0
2726,python essentials for data science related work,Techniques,python essentials for data science related work,"['python', 'essentials', 'for', 'data', 'science', 'related', 'work']",0,"['python', 'essential', 'for', 'data', 'science', 'related', 'work']","['python', 'essential', 'data', 'science', 'related', 'work']",python essential data science related work,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
2727,correlations for more than  variables in r,Techniques,correlations for more than  variables in r,"['correlations', 'for', 'more', 'than', 'variables', 'in', 'r']",1,"['correlation', 'for', 'more', 'than', 'variable', 'in', 'r']","['correlation', 'variable', 'r']",correlation variable r,0.5,0.0,7,22,2.75,0,0,0,0,0,0,0,0
2728,how can max pooling help in making convolutional features as translational invariant in a deep learning,Techniques,how can max pooling help in making convolutional features as translational invariant in a deep learning,"['how', 'can', 'max', 'pooling', 'help', 'in', 'making', 'convolutional', 'features', 'as', 'translational', 'invariant', 'in', 'a', 'deep', 'learning']",0,"['how', 'can', 'max', 'pooling', 'help', 'in', 'making', 'convolutional', 'feature', 'a', 'translational', 'invariant', 'in', 'a', 'deep', 'learning']","['max', 'pooling', 'help', 'making', 'convolutional', 'feature', 'translational', 'invariant', 'deep', 'learning']",max pooling help making convolutional feature translational invariant deep learning,0.0,0.0,16,83,4.882352941176471,0,0,0,0,0,0,0,0
2729, challenging job interview puzzles which every analyst should solve atleast once,Career, challenging job interview puzzles which every analyst should solve atleast once,"['challenging', 'job', 'interview', 'puzzles', 'which', 'every', 'analyst', 'should', 'solve', 'atleast', 'once']",1,"['challenging', 'job', 'interview', 'puzzle', 'which', 'every', 'analyst', 'should', 'solve', 'atleast', 'once']","['challenging', 'job', 'interview', 'puzzle', 'every', 'analyst', 'solve', 'atleast']",challenging job interview puzzle every analyst solve atleast,0.5,0.5,11,60,5.0,0,0,0,0,0,0,0,0
2730,problem with linear regression,Techniques,problem with linear regression,"['problem', 'with', 'linear', 'regression']",0,"['problem', 'with', 'linear', 'regression']","['problem', 'linear', 'regression']",problem linear regression,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
2731,comparison between ridge linear and lasso regression,Techniques,comparison between ridge linear and lasso regression,"['comparison', 'between', 'ridge', 'linear', 'and', 'lasso', 'regression']",0,"['comparison', 'between', 'ridge', 'linear', 'and', 'lasso', 'regression']","['comparison', 'ridge', 'linear', 'lasso', 'regression']",comparison ridge linear lasso regression,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
2732,how to write a large r dataframe into sqlserver,Tools,how to write a large r dataframe into sqlserver,"['how', 'to', 'write', 'a', 'large', 'r', 'dataframe', 'into', 'sqlserver']",0,"['how', 'to', 'write', 'a', 'large', 'r', 'dataframe', 'into', 'sqlserver']","['write', 'large', 'r', 'dataframe', 'sqlserver']",write large r dataframe sqlserver,0.2142857142857142,0.2142857142857142,9,33,3.3,0,0,0,0,0,0,0,0
2733,confusion regarding choice of book,Resources,confusion regarding choice of book,"['confusion', 'regarding', 'choice', 'of', 'book']",0,"['confusion', 'regarding', 'choice', 'of', 'book']","['confusion', 'regarding', 'choice', 'book']",confusion regarding choice book,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
2734,probability content for beginners,Techniques,probability content for beginners,"['probability', 'content', 'for', 'beginners']",0,"['probability', 'content', 'for', 'beginner']","['probability', 'content', 'beginner']",probability content beginner,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
2735,video for back propagation,Resources,video for back propagation,"['video', 'for', 'back', 'propagation']",0,"['video', 'for', 'back', 'propagation']","['video', 'back', 'propagation']",video back propagation,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
2736,how to count the missing value in r,Tools,how to count the missing value in r,"['how', 'to', 'count', 'the', 'missing', 'value', 'in', 'r']",0,"['how', 'to', 'count', 'the', 'missing', 'value', 'in', 'r']","['count', 'missing', 'value', 'r']",count missing value r,-0.2,-0.2,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
2737,change of profile from software engineer to data scientist,Career,change of profile from software engineer to data scientist,"['change', 'of', 'profile', 'from', 'software', 'engineer', 'to', 'data', 'scientist']",0,"['change', 'of', 'profile', 'from', 'software', 'engineer', 'to', 'data', 'scientist']","['change', 'profile', 'software', 'engineer', 'data', 'scientist']",change profile software engineer data scientist,0.0,0.0,9,47,4.7,0,0,0,0,0,0,0,0
2738,team for click prediction,Hackathons,team for click prediction,"['team', 'for', 'click', 'prediction']",0,"['team', 'for', 'click', 'prediction']","['team', 'click', 'prediction']",team click prediction,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
2739,how can we extract the classes of all the variables in a data frame into a vector in r,Tools,how can we extract the classes of all the variables in a data frame into a vector in r,"['how', 'can', 'we', 'extract', 'the', 'classes', 'of', 'all', 'the', 'variables', 'in', 'a', 'data', 'frame', 'into', 'a', 'vector', 'in', 'r']",0,"['how', 'can', 'we', 'extract', 'the', 'class', 'of', 'all', 'the', 'variable', 'in', 'a', 'data', 'frame', 'into', 'a', 'vector', 'in', 'r']","['extract', 'class', 'variable', 'data', 'frame', 'vector', 'r']",extract class variable data frame vector r,0.0,0.0,19,42,2.1,0,0,0,0,0,0,0,0
2740,noob needs help with data preprocessing feature selection and feature engineering,Techniques,noob needs help with data preprocessing feature selection and feature engineering,"['noob', 'needs', 'help', 'with', 'data', 'preprocessing', 'feature', 'selection', 'and', 'feature', 'engineering']",0,"['noob', 'need', 'help', 'with', 'data', 'preprocessing', 'feature', 'selection', 'and', 'feature', 'engineering']","['noob', 'need', 'help', 'data', 'preprocessing', 'feature', 'selection', 'feature', 'engineering']",noob need help data preprocessing feature selection feature engineering,0.0,0.0,11,71,5.916666666666667,0,0,0,0,0,0,0,0
2741,how to access the vector by logical indexing in r,Tools,how to access the vector by logical indexing in r,"['how', 'to', 'access', 'the', 'vector', 'by', 'logical', 'indexing', 'in', 'r']",0,"['how', 'to', 'access', 'the', 'vector', 'by', 'logical', 'indexing', 'in', 'r']","['access', 'vector', 'logical', 'indexing', 'r']",access vector logical indexing r,0.25,0.25,10,32,2.909090909090909,0,0,0,0,0,0,0,0
2742,how to design a complex machine learning system where individual classifiers can be retrained without modifying rest of the system,Techniques,how to design a complex machine learning system where individual classifiers can be retrained without modifying rest of the system,"['how', 'to', 'design', 'a', 'complex', 'machine', 'learning', 'system', 'where', 'individual', 'classifiers', 'can', 'be', 'retrained', 'without', 'modifying', 'rest', 'of', 'the', 'system']",0,"['how', 'to', 'design', 'a', 'complex', 'machine', 'learning', 'system', 'where', 'individual', 'classifier', 'can', 'be', 'retrained', 'without', 'modifying', 'rest', 'of', 'the', 'system']","['design', 'complex', 'machine', 'learning', 'system', 'individual', 'classifier', 'retrained', 'without', 'modifying', 'rest', 'system']",design complex machine learning system individual classifier retrained without modifying rest system,-0.15,-0.15,20,100,4.761904761904762,0,0,0,0,0,0,0,0
2743,return function vs print function in python,Tools,return function vs print function in python,"['return', 'function', 'vs', 'print', 'function', 'in', 'python']",0,"['return', 'function', 'v', 'print', 'function', 'in', 'python']","['return', 'function', 'v', 'print', 'function', 'python']",return function v print function python,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
2744,how to customize linear regression sklearn,Tools,how to customize linear regression sklearn,"['how', 'to', 'customize', 'linear', 'regression', 'sklearn']",0,"['how', 'to', 'customize', 'linear', 'regression', 'sklearn']","['customize', 'linear', 'regression', 'sklearn']",customize linear regression sklearn,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
2745,central limit theorem practical applications,Techniques,central limit theorem practical applications,"['central', 'limit', 'theorem', 'practical', 'applications']",0,"['central', 'limit', 'theorem', 'practical', 'application']","['central', 'limit', 'theorem', 'practical', 'application']",central limit theorem practical application,0.0,0.0,5,43,7.166666666666667,0,0,0,0,0,0,0,0
2746,beginner question,Techniques,beginner question,"['beginner', 'question']",0,"['beginner', 'question']","['beginner', 'question']",beginner question,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
2747,dropping one of the two highly corelated columns for dimensionality reduction,Techniques,dropping one of the two highly corelated columns for dimensionality reduction,"['dropping', 'one', 'of', 'the', 'two', 'highly', 'corelated', 'columns', 'for', 'dimensionality', 'reduction']",0,"['dropping', 'one', 'of', 'the', 'two', 'highly', 'corelated', 'column', 'for', 'dimensionality', 'reduction']","['dropping', 'one', 'two', 'highly', 'corelated', 'column', 'dimensionality', 'reduction']",dropping one two highly corelated column dimensionality reduction,0.16,0.16,11,65,5.416666666666667,0,0,0,0,0,0,0,0
2748,how to read images in r,Tools,how to read images in r,"['how', 'to', 'read', 'images', 'in', 'r']",0,"['how', 'to', 'read', 'image', 'in', 'r']","['read', 'image', 'r']",read image r,0.0,0.0,6,12,1.7142857142857142,0,0,0,0,0,0,0,0
2749,python  or   which one to choose for data science,Tools,python  or   which one to choose for data science,"['python', 'or', 'which', 'one', 'to', 'choose', 'for', 'data', 'science']",2,"['python', 'or', 'which', 'one', 'to', 'choose', 'for', 'data', 'science']","['python', 'one', 'choose', 'data', 'science']",python one choose data science,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
2750,best classroom training institute for business analytics course in bangalore,Resources,best classroom training institute for business analytics course in bangalore,"['best', 'classroom', 'training', 'institute', 'for', 'business', 'analytics', 'course', 'in', 'bangalore']",0,"['best', 'classroom', 'training', 'institute', 'for', 'business', 'analytics', 'course', 'in', 'bangalore']","['best', 'classroom', 'training', 'institute', 'business', 'analytics', 'course', 'bangalore']",best classroom training institute business analytics course bangalore,1.0,1.0,10,69,6.2727272727272725,0,0,0,0,0,0,0,0
2751,how can i predict earthquake using machine learning,Techniques,how can i predict earthquake using machine learning,"['how', 'can', 'i', 'predict', 'earthquake', 'using', 'machine', 'learning']",0,"['how', 'can', 'i', 'predict', 'earthquake', 'using', 'machine', 'learning']","['predict', 'earthquake', 'using', 'machine', 'learning']",predict earthquake using machine learning,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2752,how to tune tree parameters in gbm in r,Techniques,how to tune tree parameters in gbm in r,"['how', 'to', 'tune', 'tree', 'parameters', 'in', 'gbm', 'in', 'r']",0,"['how', 'to', 'tune', 'tree', 'parameter', 'in', 'gbm', 'in', 'r']","['tune', 'tree', 'parameter', 'gbm', 'r']",tune tree parameter gbm r,0.0,0.0,9,25,2.5,0,0,0,0,0,0,0,0
2753,automation in data sciencemachine learningbig data,Career,automation in data sciencemachine learningbig data,"['automation', 'in', 'data', 'sciencemachine', 'learningbig', 'data']",0,"['automation', 'in', 'data', 'sciencemachine', 'learningbig', 'data']","['automation', 'data', 'sciencemachine', 'learningbig', 'data']",automation data sciencemachine learningbig data,0.0,0.0,6,47,6.714285714285714,0,0,0,0,0,0,0,0
2754,r reusing trained models for sentiment prediction,Techniques,r reusing trained models for sentiment prediction,"['r', 'reusing', 'trained', 'models', 'for', 'sentiment', 'prediction']",0,"['r', 'reusing', 'trained', 'model', 'for', 'sentiment', 'prediction']","['r', 'reusing', 'trained', 'model', 'sentiment', 'prediction']",r reusing trained model sentiment prediction,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
2755,converting yolov model implemented in darknet framework to tensorflow framework,Techniques,converting yolov model implemented in darknet framework to tensorflow framework,"['converting', 'yolov', 'model', 'implemented', 'in', 'darknet', 'framework', 'to', 'tensorflow', 'framework']",0,"['converting', 'yolov', 'model', 'implemented', 'in', 'darknet', 'framework', 'to', 'tensorflow', 'framework']","['converting', 'yolov', 'model', 'implemented', 'darknet', 'framework', 'tensorflow', 'framework']",converting yolov model implemented darknet framework tensorflow framework,0.0,0.0,10,73,6.636363636363637,0,0,0,0,0,0,0,0
2756,how to apply conditional formatting for entire row not only cell in excel,Tools,how to apply conditional formatting for entire row not only cell in excel,"['how', 'to', 'apply', 'conditional', 'formatting', 'for', 'entire', 'row', 'not', 'only', 'cell', 'in', 'excel']",0,"['how', 'to', 'apply', 'conditional', 'formatting', 'for', 'entire', 'row', 'not', 'only', 'cell', 'in', 'excel']","['apply', 'conditional', 'formatting', 'entire', 'row', 'cell', 'excel']",apply conditional formatting entire row cell excel,0.0,0.0,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
2757,what features did you engineer in the loan prediction data set,Techniques,what features did you engineer in the loan prediction data set,"['what', 'features', 'did', 'you', 'engineer', 'in', 'the', 'loan', 'prediction', 'data', 'set']",0,"['what', 'feature', 'did', 'you', 'engineer', 'in', 'the', 'loan', 'prediction', 'data', 'set']","['feature', 'engineer', 'loan', 'prediction', 'data', 'set']",feature engineer loan prediction data set,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
2758,must know clustering machine learning algorithms,Techniques,must know clustering machine learning algorithms,"['must', 'know', 'clustering', 'machine', 'learning', 'algorithms']",0,"['must', 'know', 'clustering', 'machine', 'learning', 'algorithm']","['must', 'know', 'clustering', 'machine', 'learning', 'algorithm']",must know clustering machine learning algorithm,0.0,0.0,6,47,6.714285714285714,0,0,0,0,0,0,0,0
2759,web scrapping from amazonin in r,Tools,web scrapping from amazonin in r,"['web', 'scrapping', 'from', 'amazonin', 'in', 'r']",0,"['web', 'scrapping', 'from', 'amazonin', 'in', 'r']","['web', 'scrapping', 'amazonin', 'r']",web scrapping amazonin r,0.0,0.0,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
2760,data type conversion,Tools,data type conversion,"['data', 'type', 'conversion']",0,"['data', 'type', 'conversion']","['data', 'type', 'conversion']",data type conversion,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
2761,how to calculate confusion metric  error in calculation,Techniques,how to calculate confusion metric  error in calculation,"['how', 'to', 'calculate', 'confusion', 'metric', 'error', 'in', 'calculation']",0,"['how', 'to', 'calculate', 'confusion', 'metric', 'error', 'in', 'calculation']","['calculate', 'confusion', 'metric', 'error', 'calculation']",calculate confusion metric error calculation,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
2762,bookmark option,Other,bookmark option,"['bookmark', 'option']",0,"['bookmark', 'option']","['bookmark', 'option']",bookmark option,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
2763,how to identify variables to include or exclude from linear regression model,Techniques,how to identify variables to include or exclude from linear regression model,"['how', 'to', 'identify', 'variables', 'to', 'include', 'or', 'exclude', 'from', 'linear', 'regression', 'model']",0,"['how', 'to', 'identify', 'variable', 'to', 'include', 'or', 'exclude', 'from', 'linear', 'regression', 'model']","['identify', 'variable', 'include', 'exclude', 'linear', 'regression', 'model']",identify variable include exclude linear regression model,0.0,0.0,12,57,4.384615384615385,0,0,0,0,0,0,0,0
2764,how do i use the output from tsne dimensionality reduction for a random forest,Techniques,how do i use the output from tsne dimensionality reduction for a random forest,"['how', 'do', 'i', 'use', 'the', 'output', 'from', 'tsne', 'dimensionality', 'reduction', 'for', 'a', 'random', 'forest']",0,"['how', 'do', 'i', 'use', 'the', 'output', 'from', 'tsne', 'dimensionality', 'reduction', 'for', 'a', 'random', 'forest']","['use', 'output', 'tsne', 'dimensionality', 'reduction', 'random', 'forest']",use output tsne dimensionality reduction random forest,-0.5,-0.5,14,54,3.6,0,0,0,0,0,0,0,0
2765,solutions manuals of statistics and analytics,Resources,solutions manuals of statistics and analytics,"['solutions', 'manuals', 'of', 'statistics', 'and', 'analytics']",0,"['solution', 'manual', 'of', 'statistic', 'and', 'analytics']","['solution', 'manual', 'statistic', 'analytics']",solution manual statistic analytics,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
2766,use of level function in r,Tools,use of level function in r,"['use', 'of', 'level', 'function', 'in', 'r']",0,"['use', 'of', 'level', 'function', 'in', 'r']","['use', 'level', 'function', 'r']",use level function r,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
2767,what to choose for null hypothesis and alternate hypothesis,Techniques,what to choose for null hypothesis and alternate hypothesis,"['what', 'to', 'choose', 'for', 'null', 'hypothesis', 'and', 'alternate', 'hypothesis']",0,"['what', 'to', 'choose', 'for', 'null', 'hypothesis', 'and', 'alternate', 'hypothesis']","['choose', 'null', 'hypothesis', 'alternate', 'hypothesis']",choose null hypothesis alternate hypothesis,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
2768,what kind of algorithm or machine learning techniques can be used in scorecard development,Techniques,what kind of algorithm or machine learning techniques can be used in scorecard development,"['what', 'kind', 'of', 'algorithm', 'or', 'machine', 'learning', 'techniques', 'can', 'be', 'used', 'in', 'scorecard', 'development']",0,"['what', 'kind', 'of', 'algorithm', 'or', 'machine', 'learning', 'technique', 'can', 'be', 'used', 'in', 'scorecard', 'development']","['kind', 'algorithm', 'machine', 'learning', 'technique', 'used', 'scorecard', 'development']",kind algorithm machine learning technique used scorecard development,0.6,0.6,14,68,4.533333333333333,0,0,0,0,0,0,0,0
2769,need your help to find all matched item in lhs of apriorir,Techniques,need your help to find all matched item in lhs of apriorir,"['need', 'your', 'help', 'to', 'find', 'all', 'matched', 'item', 'in', 'lhs', 'of', 'apriorir']",0,"['need', 'your', 'help', 'to', 'find', 'all', 'matched', 'item', 'in', 'lh', 'of', 'apriorir']","['need', 'help', 'find', 'matched', 'item', 'lh', 'apriorir']",need help find matched item lh apriorir,0.0,0.0,12,39,3.0,0,0,0,0,0,0,0,0
2770,how to make your entire business datafocused,Resources,how to make your entire business datafocused,"['how', 'to', 'make', 'your', 'entire', 'business', 'datafocused']",0,"['how', 'to', 'make', 'your', 'entire', 'business', 'datafocused']","['make', 'entire', 'business', 'datafocused']",make entire business datafocused,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
2771,identify the digits problem,Techniques,identify the digits problem,"['identify', 'the', 'digits', 'problem']",0,"['identify', 'the', 'digit', 'problem']","['identify', 'digit', 'problem']",identify digit problem,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
2772,great lakes business analytics certificate program,Career,great lakes business analytics certificate program,"['great', 'lakes', 'business', 'analytics', 'certificate', 'program']",0,"['great', 'lake', 'business', 'analytics', 'certificate', 'program']","['great', 'lake', 'business', 'analytics', 'certificate', 'program']",great lake business analytics certificate program,0.8,0.8,6,49,7.0,0,0,0,0,0,0,0,0
2773,mismatch in levels of categorical variable in train and test data,Techniques,mismatch in levels of categorical variable in train and test data,"['mismatch', 'in', 'levels', 'of', 'categorical', 'variable', 'in', 'train', 'and', 'test', 'data']",0,"['mismatch', 'in', 'level', 'of', 'categorical', 'variable', 'in', 'train', 'and', 'test', 'data']","['mismatch', 'level', 'categorical', 'variable', 'train', 'test', 'data']",mismatch level categorical variable train test data,0.0,0.0,11,51,4.25,0,0,0,0,0,0,0,0
2774,certifications in india to build a career in analytics,Career,certifications in india to build a career in analytics,"['certifications', 'in', 'india', 'to', 'build', 'a', 'career', 'in', 'analytics']",0,"['certification', 'in', 'india', 'to', 'build', 'a', 'career', 'in', 'analytics']","['certification', 'india', 'build', 'career', 'analytics']",certification india build career analytics,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
2775,plot bars extending on both sides of the yaxis in r,Tools,plot bars extending on both sides of the yaxis in r,"['plot', 'bars', 'extending', 'on', 'both', 'sides', 'of', 'the', 'yaxis', 'in', 'r']",0,"['plot', 'bar', 'extending', 'on', 'both', 'side', 'of', 'the', 'yaxis', 'in', 'r']","['plot', 'bar', 'extending', 'side', 'yaxis', 'r']",plot bar extending side yaxis r,0.0,0.0,11,31,2.5833333333333335,0,0,0,0,0,0,0,0
2776,changing factor levels using for loop in r,Techniques,changing factor levels using for loop in r,"['changing', 'factor', 'levels', 'using', 'for', 'loop', 'in', 'r']",0,"['changing', 'factor', 'level', 'using', 'for', 'loop', 'in', 'r']","['changing', 'factor', 'level', 'using', 'loop', 'r']",changing factor level using loop r,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
2777,upload error your file has  less value compared to ,Hackathons,upload error your file has  less value compared to ,"['upload', 'error', 'your', 'file', 'has', 'less', 'value', 'compared', 'to']",2,"['upload', 'error', 'your', 'file', 'ha', 'le', 'value', 'compared', 'to']","['upload', 'error', 'file', 'ha', 'le', 'value', 'compared']",upload error file ha le value compared,-0.1666666666666666,0.0,9,38,3.8,0,0,0,0,0,0,0,0
2778,linearity nongraphical,Techniques,linearity nongraphical,"['linearity', 'nongraphical']",0,"['linearity', 'nongraphical']","['linearity', 'nongraphical']",linearity nongraphical,0.0,0.0,2,22,7.333333333333333,0,0,0,0,0,0,0,0
2779,machine learning skilltest,Hackathons,machine learning skilltest,"['machine', 'learning', 'skilltest']",0,"['machine', 'learning', 'skilltest']","['machine', 'learning', 'skilltest']",machine learning skilltest,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
2780,what are the ways to handle missing values in a model,Techniques,what are the ways to handle missing values in a model,"['what', 'are', 'the', 'ways', 'to', 'handle', 'missing', 'values', 'in', 'a', 'model']",0,"['what', 'are', 'the', 'way', 'to', 'handle', 'missing', 'value', 'in', 'a', 'model']","['way', 'handle', 'missing', 'value', 'model']",way handle missing value model,-0.2,-0.2,11,30,2.5,0,0,0,0,0,0,0,0
2781,urban sound classification,Hackathons,urban sound classification,"['urban', 'sound', 'classification']",0,"['urban', 'sound', 'classification']","['urban', 'sound', 'classification']",urban sound classification,0.2,0.2,3,26,6.5,0,0,0,0,0,0,0,0
2782,how to convert a dataframe to html,Techniques,how to convert a dataframe to html,"['how', 'to', 'convert', 'a', 'dataframe', 'to', 'html']",0,"['how', 'to', 'convert', 'a', 'dataframe', 'to', 'html']","['convert', 'dataframe', 'html']",convert dataframe html,0.0,0.0,7,22,2.75,0,0,0,0,0,0,0,0
2783,classification benchmark mode based on passenger class titanic dataset,Techniques,classification benchmark mode based on passenger class titanic dataset,"['classification', 'benchmark', 'mode', 'based', 'on', 'passenger', 'class', 'titanic', 'dataset']",0,"['classification', 'benchmark', 'mode', 'based', 'on', 'passenger', 'class', 'titanic', 'dataset']","['classification', 'benchmark', 'mode', 'based', 'passenger', 'class', 'titanic', 'dataset']",classification benchmark mode based passenger class titanic dataset,0.0,0.0,9,67,6.7,0,0,0,0,0,0,0,0
2784,create pie charts in r,Tools,create pie charts in r,"['create', 'pie', 'charts', 'in', 'r']",0,"['create', 'pie', 'chart', 'in', 'r']","['create', 'pie', 'chart', 'r']",create pie chart r,0.0,0.0,5,18,3.0,0,0,0,0,0,0,0,0
2785,how to find the model works better from the rmse and cv score,Hackathons,how to find the model works better from the rmse and cv score,"['how', 'to', 'find', 'the', 'model', 'works', 'better', 'from', 'the', 'rmse', 'and', 'cv', 'score']",0,"['how', 'to', 'find', 'the', 'model', 'work', 'better', 'from', 'the', 'rmse', 'and', 'cv', 'score']","['find', 'model', 'work', 'better', 'rmse', 'cv', 'score']",find model work better rmse cv score,0.5,0.5,13,36,2.5714285714285716,0,0,0,0,0,0,0,0
2786,please guide me regarding career in business analytics,Career,please guide me regarding career in business analytics,"['please', 'guide', 'me', 'regarding', 'career', 'in', 'business', 'analytics']",0,"['please', 'guide', 'me', 'regarding', 'career', 'in', 'business', 'analytics']","['please', 'guide', 'regarding', 'career', 'business', 'analytics']",please guide regarding career business analytics,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
2787,technique for baseline sales estimation for retail environment,Other,technique for baseline sales estimation for retail environment,"['technique', 'for', 'baseline', 'sales', 'estimation', 'for', 'retail', 'environment']",0,"['technique', 'for', 'baseline', 'sale', 'estimation', 'for', 'retail', 'environment']","['technique', 'baseline', 'sale', 'estimation', 'retail', 'environment']",technique baseline sale estimation retail environment,0.0,0.0,8,53,5.888888888888889,0,0,0,0,0,0,0,0
2788,what the values of prob and votes signifies in boosting,Techniques,what the values of prob and votes signifies in boosting,"['what', 'the', 'values', 'of', 'prob', 'and', 'votes', 'signifies', 'in', 'boosting']",0,"['what', 'the', 'value', 'of', 'prob', 'and', 'vote', 'signifies', 'in', 'boosting']","['value', 'prob', 'vote', 'signifies', 'boosting']",value prob vote signifies boosting,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
2789,introductions  new members for may ,Misc,introductions  new members for may ,"['introductions', 'new', 'members', 'for', 'may']",1,"['introduction', 'new', 'member', 'for', 'may']","['introduction', 'new', 'member', 'may']",introduction new member may,0.1363636363636363,0.1363636363636363,5,27,4.5,0,0,0,0,0,0,0,0
2790,sas base certification,Tools,sas base certification,"['sas', 'base', 'certification']",0,"['sa', 'base', 'certification']","['sa', 'base', 'certification']",sa base certification,-0.8,-0.8,3,21,5.25,0,0,0,0,0,0,0,0
2791,explain central limit theorem of statistics to a layman,Techniques,explain central limit theorem of statistics to a layman,"['explain', 'central', 'limit', 'theorem', 'of', 'statistics', 'to', 'a', 'layman']",0,"['explain', 'central', 'limit', 'theorem', 'of', 'statistic', 'to', 'a', 'layman']","['explain', 'central', 'limit', 'theorem', 'statistic', 'layman']",explain central limit theorem statistic layman,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
2792,skewness  treatment,Techniques,skewness  treatment,"['skewness', 'treatment']",0,"['skewness', 'treatment']","['skewness', 'treatment']",skewness treatment,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
2793,what happens when a course is archived,Resources,what happens when a course is archived,"['what', 'happens', 'when', 'a', 'course', 'is', 'archived']",0,"['what', 'happens', 'when', 'a', 'course', 'is', 'archived']","['happens', 'course', 'archived']",happens course archived,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
2794,saving a model in r,Tools,saving a model in r,"['saving', 'a', 'model', 'in', 'r']",0,"['saving', 'a', 'model', 'in', 'r']","['saving', 'model', 'r']",saving model r,0.0,0.0,5,14,2.3333333333333335,0,0,0,0,0,0,0,0
2795,how to highlight the actual data point in a plot using python,Tools,how to highlight the actual data point in a plot using python,"['how', 'to', 'highlight', 'the', 'actual', 'data', 'point', 'in', 'a', 'plot', 'using', 'python']",0,"['how', 'to', 'highlight', 'the', 'actual', 'data', 'point', 'in', 'a', 'plot', 'using', 'python']","['highlight', 'actual', 'data', 'point', 'plot', 'using', 'python']",highlight actual data point plot using python,0.0,0.0,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
2796,datafestmachine learning minihack publication recommendation solution,Hackathons,datafestmachine learning minihack publication recommendation solution,"['datafestmachine', 'learning', 'minihack', 'publication', 'recommendation', 'solution']",0,"['datafestmachine', 'learning', 'minihack', 'publication', 'recommendation', 'solution']","['datafestmachine', 'learning', 'minihack', 'publication', 'recommendation', 'solution']",datafestmachine learning minihack publication recommendation solution,0.0,0.0,6,69,9.857142857142858,0,0,0,0,0,0,0,0
2797,codecademy  functions in python excercise,Tools,codecademy  functions in python excercise,"['codecademy', 'functions', 'in', 'python', 'excercise']",0,"['codecademy', 'function', 'in', 'python', 'excercise']","['codecademy', 'function', 'python', 'excercise']",codecademy function python excercise,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
2798,are we eligible for abc points for game of deep learning hackathon,Other,are we eligible for abc points for game of deep learning hackathon,"['are', 'we', 'eligible', 'for', 'abc', 'points', 'for', 'game', 'of', 'deep', 'learning', 'hackathon']",0,"['are', 'we', 'eligible', 'for', 'abc', 'point', 'for', 'game', 'of', 'deep', 'learning', 'hackathon']","['eligible', 'abc', 'point', 'game', 'deep', 'learning', 'hackathon']",eligible abc point game deep learning hackathon,-0.2,-0.2,12,47,3.6153846153846154,0,0,0,0,0,0,0,0
2799,where can i find labeled twitter or facebook data,Techniques,where can i find labeled twitter or facebook data,"['where', 'can', 'i', 'find', 'labeled', 'twitter', 'or', 'facebook', 'data']",0,"['where', 'can', 'i', 'find', 'labeled', 'twitter', 'or', 'facebook', 'data']","['find', 'labeled', 'twitter', 'facebook', 'data']",find labeled twitter facebook data,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
2800,share your approach redate your data,Hackathons,share your approach redate your data,"['share', 'your', 'approach', 'redate', 'your', 'data']",0,"['share', 'your', 'approach', 'redate', 'your', 'data']","['share', 'approach', 'redate', 'data']",share approach redate data,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
2801,choosing for hypothesis test,Techniques,choosing for hypothesis test,"['choosing', 'for', 'hypothesis', 'test']",0,"['choosing', 'for', 'hypothesis', 'test']","['choosing', 'hypothesis', 'test']",choosing hypothesis test,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
2802,how can we check whether a group of characters or a string is present in a vector of strings in r,Hackathons,how can we check whether a group of characters or a string is present in a vector of strings in r,"['how', 'can', 'we', 'check', 'whether', 'a', 'group', 'of', 'characters', 'or', 'a', 'string', 'is', 'present', 'in', 'a', 'vector', 'of', 'strings', 'in', 'r']",0,"['how', 'can', 'we', 'check', 'whether', 'a', 'group', 'of', 'character', 'or', 'a', 'string', 'is', 'present', 'in', 'a', 'vector', 'of', 'string', 'in', 'r']","['check', 'whether', 'group', 'character', 'string', 'present', 'vector', 'string', 'r']",check whether group character string present vector string r,0.0,0.0,21,60,2.727272727272727,0,0,0,0,0,0,0,0
2803,can you access leaderboard for loan prediction,Hackathons,can you access leaderboard for loan prediction,"['can', 'you', 'access', 'leaderboard', 'for', 'loan', 'prediction']",0,"['can', 'you', 'access', 'leaderboard', 'for', 'loan', 'prediction']","['access', 'leaderboard', 'loan', 'prediction']",access leaderboard loan prediction,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
2804,about abinbev data science talent hunt hackathon,Hackathons,about abinbev data science talent hunt hackathon,"['about', 'abinbev', 'data', 'science', 'talent', 'hunt', 'hackathon']",0,"['about', 'abinbev', 'data', 'science', 'talent', 'hunt', 'hackathon']","['abinbev', 'data', 'science', 'talent', 'hunt', 'hackathon']",abinbev data science talent hunt hackathon,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
2805,optimum pricing for website meant to rents shopspop up spaces,Misc,optimum pricing for website meant to rents shopspop up spaces,"['optimum', 'pricing', 'for', 'website', 'meant', 'to', 'rents', 'shopspop', 'up', 'spaces']",0,"['optimum', 'pricing', 'for', 'website', 'meant', 'to', 'rent', 'shopspop', 'up', 'space']","['optimum', 'pricing', 'website', 'meant', 'rent', 'shopspop', 'space']",optimum pricing website meant rent shopspop space,0.7,0.7,10,49,4.454545454545454,0,0,0,0,0,0,0,0
2806,how to further improve arima model,Techniques,how to further improve arima model,"['how', 'to', 'further', 'improve', 'arima', 'model']",0,"['how', 'to', 'further', 'improve', 'arima', 'model']","['improve', 'arima', 'model']",improve arima model,0.0,0.0,6,19,2.7142857142857144,0,0,0,0,0,0,0,0
2807,help with submission format because i receive a  score,Hackathons,help with submission format because i receive a  score,"['help', 'with', 'submission', 'format', 'because', 'i', 'receive', 'a', 'score']",1,"['help', 'with', 'submission', 'format', 'because', 'i', 'receive', 'a', 'score']","['help', 'submission', 'format', 'receive', 'score']",help submission format receive score,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
2808,market basket analysis  qlikview integration with r,Tools,market basket analysis  qlikview integration with r,"['market', 'basket', 'analysis', 'qlikview', 'integration', 'with', 'r']",0,"['market', 'basket', 'analysis', 'qlikview', 'integration', 'with', 'r']","['market', 'basket', 'analysis', 'qlikview', 'integration', 'r']",market basket analysis qlikview integration r,0.0,0.0,7,45,5.625,0,0,0,0,0,0,0,0
2809,microsoft certifications in data science,Career,microsoft certifications in data science,"['microsoft', 'certifications', 'in', 'data', 'science']",0,"['microsoft', 'certification', 'in', 'data', 'science']","['microsoft', 'certification', 'data', 'science']",microsoft certification data science,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
2810,how can iris data set be classified using naive bayes,Tools,how can iris data set be classified using naive bayes,"['how', 'can', 'iris', 'data', 'set', 'be', 'classified', 'using', 'naive', 'bayes']",0,"['how', 'can', 'iris', 'data', 'set', 'be', 'classified', 'using', 'naive', 'bayes']","['iris', 'data', 'set', 'classified', 'using', 'naive', 'bayes']",iris data set classified using naive bayes,-0.3,-0.3,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
2811,getting error when submitting solution,Hackathons,getting error when submitting solution,"['getting', 'error', 'when', 'submitting', 'solution']",0,"['getting', 'error', 'when', 'submitting', 'solution']","['getting', 'error', 'submitting', 'solution']",getting error submitting solution,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
2812,how to improve model performance for regression problem,Techniques,how to improve model performance for regression problem,"['how', 'to', 'improve', 'model', 'performance', 'for', 'regression', 'problem']",0,"['how', 'to', 'improve', 'model', 'performance', 'for', 'regression', 'problem']","['improve', 'model', 'performance', 'regression', 'problem']",improve model performance regression problem,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
2813,can anyone suggest me some good institutes in bangalore for business analyst course,Career,can anyone suggest me some good institutes in bangalore for business analyst course,"['can', 'anyone', 'suggest', 'me', 'some', 'good', 'institutes', 'in', 'bangalore', 'for', 'business', 'analyst', 'course']",0,"['can', 'anyone', 'suggest', 'me', 'some', 'good', 'institute', 'in', 'bangalore', 'for', 'business', 'analyst', 'course']","['anyone', 'suggest', 'good', 'institute', 'bangalore', 'business', 'analyst', 'course']",anyone suggest good institute bangalore business analyst course,0.7,0.7,13,63,4.5,0,0,0,0,0,0,0,0
2814,predict type of data set,Techniques,predict type of data set,"['predict', 'type', 'of', 'data', 'set']",0,"['predict', 'type', 'of', 'data', 'set']","['predict', 'type', 'data', 'set']",predict type data set,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
2815,how to use categorical variables in multivariate time series forecasting,Techniques,how to use categorical variables in multivariate time series forecasting,"['how', 'to', 'use', 'categorical', 'variables', 'in', 'multivariate', 'time', 'series', 'forecasting']",0,"['how', 'to', 'use', 'categorical', 'variable', 'in', 'multivariate', 'time', 'series', 'forecasting']","['use', 'categorical', 'variable', 'multivariate', 'time', 'series', 'forecasting']",use categorical variable multivariate time series forecasting,0.0,0.0,10,61,5.545454545454546,0,0,0,0,0,0,0,0
2816,what level of mathematics neededrequired to make career in big data and data science,Career,what level of mathematics neededrequired to make career in big data and data science,"['what', 'level', 'of', 'mathematics', 'neededrequired', 'to', 'make', 'career', 'in', 'big', 'data', 'and', 'data', 'science']",0,"['what', 'level', 'of', 'mathematics', 'neededrequired', 'to', 'make', 'career', 'in', 'big', 'data', 'and', 'data', 'science']","['level', 'mathematics', 'neededrequired', 'make', 'career', 'big', 'data', 'data', 'science']",level mathematics neededrequired make career big data data science,0.0,0.0,14,66,4.4,0,0,0,0,0,0,0,0
2817,using linear regression for a classification problem,Techniques,using linear regression for a classification problem,"['using', 'linear', 'regression', 'for', 'a', 'classification', 'problem']",0,"['using', 'linear', 'regression', 'for', 'a', 'classification', 'problem']","['using', 'linear', 'regression', 'classification', 'problem']",using linear regression classification problem,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
2818,how to interpret the reduction in error for progressive error splits in ada,Techniques,how to interpret the reduction in error for progressive error splits in ada,"['how', 'to', 'interpret', 'the', 'reduction', 'in', 'error', 'for', 'progressive', 'error', 'splits', 'in', 'ada']",0,"['how', 'to', 'interpret', 'the', 'reduction', 'in', 'error', 'for', 'progressive', 'error', 'split', 'in', 'ada']","['interpret', 'reduction', 'error', 'progressive', 'error', 'split', 'ada']",interpret reduction error progressive error split ada,0.0,0.0,13,53,3.7857142857142856,0,0,0,0,0,0,0,0
2819,addding target column to test dataset,Hackathons,addding target column to test dataset,"['addding', 'target', 'column', 'to', 'test', 'dataset']",0,"['addding', 'target', 'column', 'to', 'test', 'dataset']","['addding', 'target', 'column', 'test', 'dataset']",addding target column test dataset,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
2820,elastic net for feature selection,Techniques,elastic net for feature selection,"['elastic', 'net', 'for', 'feature', 'selection']",0,"['elastic', 'net', 'for', 'feature', 'selection']","['elastic', 'net', 'feature', 'selection']",elastic net feature selection,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
2821,how to include the regularization term while implementing it in a model,Techniques,how to include the regularization term while implementing it in a model,"['how', 'to', 'include', 'the', 'regularization', 'term', 'while', 'implementing', 'it', 'in', 'a', 'model']",0,"['how', 'to', 'include', 'the', 'regularization', 'term', 'while', 'implementing', 'it', 'in', 'a', 'model']","['include', 'regularization', 'term', 'implementing', 'model']",include regularization term implementing model,0.0,0.0,12,46,3.5384615384615383,0,0,0,0,0,0,0,0
2822,poisson maximum likelihood in excel,Techniques,poisson maximum likelihood in excel,"['poisson', 'maximum', 'likelihood', 'in', 'excel']",0,"['poisson', 'maximum', 'likelihood', 'in', 'excel']","['poisson', 'maximum', 'likelihood', 'excel']",poisson maximum likelihood excel,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2823,suggestions for project,Resources,suggestions for project,"['suggestions', 'for', 'project']",0,"['suggestion', 'for', 'project']","['suggestion', 'project']",suggestion project,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
2824,missing value treatment techniques,Techniques,missing value treatment techniques,"['missing', 'value', 'treatment', 'techniques']",0,"['missing', 'value', 'treatment', 'technique']","['missing', 'value', 'treatment', 'technique']",missing value treatment technique,-0.2,-0.2,4,33,6.6,0,0,0,0,0,0,0,0
2825,need your suggestions,Career,need your suggestions,"['need', 'your', 'suggestions']",0,"['need', 'your', 'suggestion']","['need', 'suggestion']",need suggestion,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
2826,how to simulate elo ratings system for cricket in rpython,Tools,how to simulate elo ratings system for cricket in rpython,"['how', 'to', 'simulate', 'elo', 'ratings', 'system', 'for', 'cricket', 'in', 'rpython']",0,"['how', 'to', 'simulate', 'elo', 'rating', 'system', 'for', 'cricket', 'in', 'rpython']","['simulate', 'elo', 'rating', 'system', 'cricket', 'rpython']",simulate elo rating system cricket rpython,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
2827,how to join slack group,Other,how to join slack group,"['how', 'to', 'join', 'slack', 'group']",0,"['how', 'to', 'join', 'slack', 'group']","['join', 'slack', 'group']",join slack group,0.0,0.0,5,16,2.6666666666666665,0,0,0,0,0,0,0,0
2828,how to get sas missing values in a separate dataset,Tools,how to get sas missing values in a separate dataset,"['how', 'to', 'get', 'sas', 'missing', 'values', 'in', 'a', 'separate', 'dataset']",0,"['how', 'to', 'get', 'sa', 'missing', 'value', 'in', 'a', 'separate', 'dataset']","['get', 'sa', 'missing', 'value', 'separate', 'dataset']",get sa missing value separate dataset,-0.2,-0.2,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
2829,regularizations,Techniques,regularizations,['regularizations'],0,['regularization'],['regularization'],regularization,0.0,0.0,1,14,7.0,0,0,0,0,0,0,0,0
2830,churn prediction model,Techniques,churn prediction model,"['churn', 'prediction', 'model']",0,"['churn', 'prediction', 'model']","['churn', 'prediction', 'model']",churn prediction model,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
2831,need your support in ongoing blogathon,Techniques,need your support in ongoing blogathon,"['need', 'your', 'support', 'in', 'ongoing', 'blogathon']",0,"['need', 'your', 'support', 'in', 'ongoing', 'blogathon']","['need', 'support', 'ongoing', 'blogathon']",need support ongoing blogathon,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
2832, useful pandas techniques in python for data manipulation,Techniques, useful pandas techniques in python for data manipulation,"['useful', 'pandas', 'techniques', 'in', 'python', 'for', 'data', 'manipulation']",1,"['useful', 'panda', 'technique', 'in', 'python', 'for', 'data', 'manipulation']","['useful', 'panda', 'technique', 'python', 'data', 'manipulation']",useful panda technique python data manipulation,0.3,0.3,8,47,5.222222222222222,0,0,0,0,0,0,0,0
2833,regarding resume samples for business analyst position,Career,regarding resume samples for business analyst position,"['regarding', 'resume', 'samples', 'for', 'business', 'analyst', 'position']",0,"['regarding', 'resume', 'sample', 'for', 'business', 'analyst', 'position']","['regarding', 'resume', 'sample', 'business', 'analyst', 'position']",regarding resume sample business analyst position,0.0,0.0,7,49,6.125,0,0,0,0,0,0,0,0
2834,how to apply to alternate color for rows in excel,Tools,how to apply to alternate color for rows in excel,"['how', 'to', 'apply', 'to', 'alternate', 'color', 'for', 'rows', 'in', 'excel']",0,"['how', 'to', 'apply', 'to', 'alternate', 'color', 'for', 'row', 'in', 'excel']","['apply', 'alternate', 'color', 'row', 'excel']",apply alternate color row excel,0.0,0.0,10,31,2.8181818181818183,0,0,0,0,0,0,0,0
2835,changing categorial into numerical variables,Hackathons,changing categorial into numerical variables,"['changing', 'categorial', 'into', 'numerical', 'variables']",0,"['changing', 'categorial', 'into', 'numerical', 'variable']","['changing', 'categorial', 'numerical', 'variable']",changing categorial numerical variable,0.0,0.0,5,38,6.333333333333333,0,0,0,0,0,0,0,0
2836,icc world cup   predict man of the match,Other,icc world cup   predict man of the match,"['icc', 'world', 'cup', 'predict', 'man', 'of', 'the', 'match']",1,"['icc', 'world', 'cup', 'predict', 'man', 'of', 'the', 'match']","['icc', 'world', 'cup', 'predict', 'man', 'match']",icc world cup predict man match,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
2837,is there anyway to overcome system limitations for running random forest for a large dataset in r,Techniques,is there anyway to overcome system limitations for running random forest for a large dataset in r,"['is', 'there', 'anyway', 'to', 'overcome', 'system', 'limitations', 'for', 'running', 'random', 'forest', 'for', 'a', 'large', 'dataset', 'in', 'r']",0,"['is', 'there', 'anyway', 'to', 'overcome', 'system', 'limitation', 'for', 'running', 'random', 'forest', 'for', 'a', 'large', 'dataset', 'in', 'r']","['anyway', 'overcome', 'system', 'limitation', 'running', 'random', 'forest', 'large', 'dataset', 'r']",anyway overcome system limitation running random forest large dataset r,-0.1428571428571428,-0.1428571428571428,17,71,3.9444444444444446,0,0,0,0,0,0,0,0
2838,how to apply the regression coefficients to test dataset in sas for prediction,Techniques,how to apply the regression coefficients to test dataset in sas for prediction,"['how', 'to', 'apply', 'the', 'regression', 'coefficients', 'to', 'test', 'dataset', 'in', 'sas', 'for', 'prediction']",0,"['how', 'to', 'apply', 'the', 'regression', 'coefficient', 'to', 'test', 'dataset', 'in', 'sa', 'for', 'prediction']","['apply', 'regression', 'coefficient', 'test', 'dataset', 'sa', 'prediction']",apply regression coefficient test dataset sa prediction,0.0,0.0,13,55,3.9285714285714284,0,0,0,0,0,0,0,0
2839,how do i start with analytics,Career,how do i start with analytics,"['how', 'do', 'i', 'start', 'with', 'analytics']",0,"['how', 'do', 'i', 'start', 'with', 'analytics']","['start', 'analytics']",start analytics,0.0,0.0,6,15,2.142857142857143,0,0,0,0,0,0,0,0
2840,project and research  machine learning and advanced analytics,Career,project and research  machine learning and advanced analytics,"['project', 'and', 'research', 'machine', 'learning', 'and', 'advanced', 'analytics']",0,"['project', 'and', 'research', 'machine', 'learning', 'and', 'advanced', 'analytics']","['project', 'research', 'machine', 'learning', 'advanced', 'analytics']",project research machine learning advanced analytics,0.4,0.4,8,52,5.777777777777778,0,0,0,0,0,0,0,0
2841,what is the standard way for doing validation for a machine learning model,Resources,what is the standard way for doing validation for a machine learning model,"['what', 'is', 'the', 'standard', 'way', 'for', 'doing', 'validation', 'for', 'a', 'machine', 'learning', 'model']",0,"['what', 'is', 'the', 'standard', 'way', 'for', 'doing', 'validation', 'for', 'a', 'machine', 'learning', 'model']","['standard', 'way', 'validation', 'machine', 'learning', 'model']",standard way validation machine learning model,0.0,0.0,13,46,3.2857142857142856,0,0,0,0,0,0,0,0
2842,i want to build an advertisement system for a social mediawhat package should i use,Techniques,i want to build an advertisement system for a social mediawhat package should i use,"['i', 'want', 'to', 'build', 'an', 'advertisement', 'system', 'for', 'a', 'social', 'mediawhat', 'package', 'should', 'i', 'use']",0,"['i', 'want', 'to', 'build', 'an', 'advertisement', 'system', 'for', 'a', 'social', 'mediawhat', 'package', 'should', 'i', 'use']","['want', 'build', 'advertisement', 'system', 'social', 'mediawhat', 'package', 'use']",want build advertisement system social mediawhat package use,0.0333333333333333,0.0333333333333333,15,60,3.75,0,0,0,0,0,0,0,0
2843,svm in r taking too much time,Tools,svm in r taking too much time,"['svm', 'in', 'r', 'taking', 'too', 'much', 'time']",0,"['svm', 'in', 'r', 'taking', 'too', 'much', 'time']","['svm', 'r', 'taking', 'much', 'time']",svm r taking much time,0.2,0.2,7,22,2.75,0,0,0,0,0,0,0,0
2844,being a non csit guy how can someone setup his career in analyticsmachine learning  as a fresher,Career,being a non csit guy how can someone setup his career in analyticsmachine learning  as a fresher,"['being', 'a', 'non', 'csit', 'guy', 'how', 'can', 'someone', 'setup', 'his', 'career', 'in', 'analyticsmachine', 'learning', 'as', 'a', 'fresher']",0,"['being', 'a', 'non', 'csit', 'guy', 'how', 'can', 'someone', 'setup', 'his', 'career', 'in', 'analyticsmachine', 'learning', 'a', 'a', 'fresher']","['non', 'csit', 'guy', 'someone', 'setup', 'career', 'analyticsmachine', 'learning', 'fresher']",non csit guy someone setup career analyticsmachine learning fresher,0.0,0.0,17,67,3.7222222222222223,0,0,0,0,0,0,0,0
2845,how to select the best bins while creating a new categorical variable from a continuous variable,Techniques,how to select the best bins while creating a new categorical variable from a continuous variable,"['how', 'to', 'select', 'the', 'best', 'bins', 'while', 'creating', 'a', 'new', 'categorical', 'variable', 'from', 'a', 'continuous', 'variable']",0,"['how', 'to', 'select', 'the', 'best', 'bin', 'while', 'creating', 'a', 'new', 'categorical', 'variable', 'from', 'a', 'continuous', 'variable']","['select', 'best', 'bin', 'creating', 'new', 'categorical', 'variable', 'continuous', 'variable']",select best bin creating new categorical variable continuous variable,0.5681818181818181,0.5681818181818181,16,69,4.0588235294117645,0,0,0,0,0,0,0,0
2846,difference between plotting rolling statistics and dickeyfuller test for stationarity,Techniques,difference between plotting rolling statistics and dickeyfuller test for stationarity,"['difference', 'between', 'plotting', 'rolling', 'statistics', 'and', 'dickeyfuller', 'test', 'for', 'stationarity']",0,"['difference', 'between', 'plotting', 'rolling', 'statistic', 'and', 'dickeyfuller', 'test', 'for', 'stationarity']","['difference', 'plotting', 'rolling', 'statistic', 'dickeyfuller', 'test', 'stationarity']",difference plotting rolling statistic dickeyfuller test stationarity,0.0,0.0,10,68,6.181818181818182,0,0,0,0,0,0,0,0
2847,how to order by date in r,Tools,how to order by date in r,"['how', 'to', 'order', 'by', 'date', 'in', 'r']",0,"['how', 'to', 'order', 'by', 'date', 'in', 'r']","['order', 'date', 'r']",order date r,0.0,0.0,7,12,1.5,0,0,0,0,0,0,0,0
2848,interview  how to explain an analytics project main stats to share,Career,interview  how to explain an analytics project main stats to share,"['interview', 'how', 'to', 'explain', 'an', 'analytics', 'project', 'main', 'stats', 'to', 'share']",0,"['interview', 'how', 'to', 'explain', 'an', 'analytics', 'project', 'main', 'stats', 'to', 'share']","['interview', 'explain', 'analytics', 'project', 'main', 'stats', 'share']",interview explain analytics project main stats share,0.1666666666666666,0.1666666666666666,11,52,4.333333333333333,0,0,0,0,0,0,0,0
2849,is spss tool worth learing what are the pros and cons of this tool,Career,is spss tool worth learing what are the pros and cons of this tool,"['is', 'spss', 'tool', 'worth', 'learing', 'what', 'are', 'the', 'pros', 'and', 'cons', 'of', 'this', 'tool']",0,"['is', 'spss', 'tool', 'worth', 'learing', 'what', 'are', 'the', 'pro', 'and', 'con', 'of', 'this', 'tool']","['spss', 'tool', 'worth', 'learing', 'pro', 'con', 'tool']",spss tool worth learing pro con tool,0.3,0.3,14,36,2.4,0,0,0,0,0,0,0,0
2850,why boosting does not improve the performance of the model,Techniques,why boosting does not improve the performance of the model,"['why', 'boosting', 'does', 'not', 'improve', 'the', 'performance', 'of', 'the', 'model']",0,"['why', 'boosting', 'doe', 'not', 'improve', 'the', 'performance', 'of', 'the', 'model']","['boosting', 'doe', 'improve', 'performance', 'model']",boosting doe improve performance model,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
2851,use of mongodb in data science using r,Career,use of mongodb in data science using r,"['use', 'of', 'mongodb', 'in', 'data', 'science', 'using', 'r']",0,"['use', 'of', 'mongodb', 'in', 'data', 'science', 'using', 'r']","['use', 'mongodb', 'data', 'science', 'using', 'r']",use mongodb data science using r,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
2852,figaddsubplot function in python,Tools,figaddsubplot function in python,"['figaddsubplot', 'function', 'in', 'python']",0,"['figaddsubplot', 'function', 'in', 'python']","['figaddsubplot', 'function', 'python']",figaddsubplot function python,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
2853,python error valueerror the truth value of a series is ambiguous,Tools,python error valueerror the truth value of a series is ambiguous,"['python', 'error', 'valueerror', 'the', 'truth', 'value', 'of', 'a', 'series', 'is', 'ambiguous']",0,"['python', 'error', 'valueerror', 'the', 'truth', 'value', 'of', 'a', 'series', 'is', 'ambiguous']","['python', 'error', 'valueerror', 'truth', 'value', 'series', 'ambiguous']",python error valueerror truth value series ambiguous,0.0,0.0,11,52,4.333333333333333,0,0,0,0,0,0,0,0
2854,how to desipher keras predictions,Techniques,how to desipher keras predictions,"['how', 'to', 'desipher', 'keras', 'predictions']",0,"['how', 'to', 'desipher', 'kera', 'prediction']","['desipher', 'kera', 'prediction']",desipher kera prediction,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
2855,how do i improve the visibility of a mosaic plot in r,Tools,how do i improve the visibility of a mosaic plot in r,"['how', 'do', 'i', 'improve', 'the', 'visibility', 'of', 'a', 'mosaic', 'plot', 'in', 'r']",0,"['how', 'do', 'i', 'improve', 'the', 'visibility', 'of', 'a', 'mosaic', 'plot', 'in', 'r']","['improve', 'visibility', 'mosaic', 'plot', 'r']",improve visibility mosaic plot r,0.0,0.0,12,32,2.4615384615384617,0,0,0,0,0,0,0,0
2856,can anyone provide an arma model tutorial with python,Techniques,can anyone provide an arma model tutorial with python,"['can', 'anyone', 'provide', 'an', 'arma', 'model', 'tutorial', 'with', 'python']",0,"['can', 'anyone', 'provide', 'an', 'arma', 'model', 'tutorial', 'with', 'python']","['anyone', 'provide', 'arma', 'model', 'tutorial', 'python']",anyone provide arma model tutorial python,0.0,0.0,9,41,4.1,0,0,0,0,0,0,0,0
2857,how to implement pruning while building cart models in r,Techniques,how to implement pruning while building cart models in r,"['how', 'to', 'implement', 'pruning', 'while', 'building', 'cart', 'models', 'in', 'r']",0,"['how', 'to', 'implement', 'pruning', 'while', 'building', 'cart', 'model', 'in', 'r']","['implement', 'pruning', 'building', 'cart', 'model', 'r']",implement pruning building cart model r,0.0,0.0,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
2858,type error in linear regression,Techniques,type error in linear regression,"['type', 'error', 'in', 'linear', 'regression']",0,"['type', 'error', 'in', 'linear', 'regression']","['type', 'error', 'linear', 'regression']",type error linear regression,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
2859,why the significance of variable is changed due to the change in number of variable,Techniques,why the significance of variable is changed due to the change in number of variable,"['why', 'the', 'significance', 'of', 'variable', 'is', 'changed', 'due', 'to', 'the', 'change', 'in', 'number', 'of', 'variable']",0,"['why', 'the', 'significance', 'of', 'variable', 'is', 'changed', 'due', 'to', 'the', 'change', 'in', 'number', 'of', 'variable']","['significance', 'variable', 'changed', 'due', 'change', 'number', 'variable']",significance variable changed due change number variable,-0.125,-0.125,15,56,3.5,0,0,0,0,0,0,0,0
2860,benchmark solution for the data identity hackathon student datafest ,Hackathons,benchmark solution for the data identity hackathon student datafest ,"['benchmark', 'solution', 'for', 'the', 'data', 'identity', 'hackathon', 'student', 'datafest']",1,"['benchmark', 'solution', 'for', 'the', 'data', 'identity', 'hackathon', 'student', 'datafest']","['benchmark', 'solution', 'data', 'identity', 'hackathon', 'student', 'datafest']",benchmark solution data identity hackathon student datafest,0.0,0.0,9,59,5.9,0,0,0,0,0,0,0,0
2861,convert  mb text file to excel,Tools,convert  mb text file to excel,"['convert', 'mb', 'text', 'file', 'to', 'excel']",1,"['convert', 'mb', 'text', 'file', 'to', 'excel']","['convert', 'mb', 'text', 'file', 'excel']",convert mb text file excel,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
2862,the analytics edge  verified track  worth for switching career into data science,Career,the analytics edge  verified track  worth for switching career into data science,"['the', 'analytics', 'edge', 'verified', 'track', 'worth', 'for', 'switching', 'career', 'into', 'data', 'science']",0,"['the', 'analytics', 'edge', 'verified', 'track', 'worth', 'for', 'switching', 'career', 'into', 'data', 'science']","['analytics', 'edge', 'verified', 'track', 'worth', 'switching', 'career', 'data', 'science']",analytics edge verified track worth switching career data science,0.3,0.3,12,65,5.0,0,0,0,0,0,0,0,0
2863,summarise function in plyr package in r,Tools,summarise function in plyr package in r,"['summarise', 'function', 'in', 'plyr', 'package', 'in', 'r']",0,"['summarise', 'function', 'in', 'plyr', 'package', 'in', 'r']","['summarise', 'function', 'plyr', 'package', 'r']",summarise function plyr package r,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
2864,leaderboard would be great ,Hackathons,leaderboard would be great ,"['leaderboard', 'would', 'be', 'great']",0,"['leaderboard', 'would', 'be', 'great']","['leaderboard', 'would', 'great']",leaderboard would great,0.8,0.8,4,23,4.6,0,0,0,0,0,0,0,0
2865,implementation of data science model,Techniques,implementation of data science model,"['implementation', 'of', 'data', 'science', 'model']",0,"['implementation', 'of', 'data', 'science', 'model']","['implementation', 'data', 'science', 'model']",implementation data science model,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
2866,randomforest feature importance,Techniques,randomforest feature importance,"['randomforest', 'feature', 'importance']",0,"['randomforest', 'feature', 'importance']","['randomforest', 'feature', 'importance']",randomforest feature importance,0.0,0.0,3,31,7.75,0,0,0,0,0,0,0,0
2867,embedding model in a webapplication,Tools,embedding model in a webapplication,"['embedding', 'model', 'in', 'a', 'webapplication']",0,"['embedding', 'model', 'in', 'a', 'webapplication']","['embedding', 'model', 'webapplication']",embedding model webapplication,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
2868,train xgboost model in r error,Techniques,train xgboost model in r error,"['train', 'xgboost', 'model', 'in', 'r', 'error']",0,"['train', 'xgboost', 'model', 'in', 'r', 'error']","['train', 'xgboost', 'model', 'r', 'error']",train xgboost model r error,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
2869,looking to switch to data science,Career,looking to switch to data science,"['looking', 'to', 'switch', 'to', 'data', 'science']",0,"['looking', 'to', 'switch', 'to', 'data', 'science']","['looking', 'switch', 'data', 'science']",looking switch data science,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
2870,niit analytics certificate course feedback,Career,niit analytics certificate course feedback,"['niit', 'analytics', 'certificate', 'course', 'feedback']",0,"['niit', 'analytics', 'certificate', 'course', 'feedback']","['niit', 'analytics', 'certificate', 'course', 'feedback']",niit analytics certificate course feedback,0.0,0.0,5,42,7.0,0,0,0,0,0,0,0,0
2871,convolutional neural network for image recognition,Career,convolutional neural network for image recognition,"['convolutional', 'neural', 'network', 'for', 'image', 'recognition']",0,"['convolutional', 'neural', 'network', 'for', 'image', 'recognition']","['convolutional', 'neural', 'network', 'image', 'recognition']",convolutional neural network image recognition,0.0,0.0,6,46,6.571428571428571,0,0,0,0,0,0,0,0
2872,reason for performance of logistic regression,Techniques,reason for performance of logistic regression,"['reason', 'for', 'performance', 'of', 'logistic', 'regression']",0,"['reason', 'for', 'performance', 'of', 'logistic', 'regression']","['reason', 'performance', 'logistic', 'regression']",reason performance logistic regression,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
2873,how to chunk large dissimilarity  distance matrices in r,Techniques,how to chunk large dissimilarity  distance matrices in r,"['how', 'to', 'chunk', 'large', 'dissimilarity', 'distance', 'matrices', 'in', 'r']",0,"['how', 'to', 'chunk', 'large', 'dissimilarity', 'distance', 'matrix', 'in', 'r']","['chunk', 'large', 'dissimilarity', 'distance', 'matrix', 'r']",chunk large dissimilarity distance matrix r,0.2142857142857142,0.2142857142857142,9,43,4.3,0,0,0,0,0,0,0,0
2874,technique for forecasting,Techniques,technique for forecasting,"['technique', 'for', 'forecasting']",0,"['technique', 'for', 'forecasting']","['technique', 'forecasting']",technique forecasting,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
2875,the invaluable role of machine learning in modern business intelligence bi,Resources,the invaluable role of machine learning in modern business intelligence bi,"['the', 'invaluable', 'role', 'of', 'machine', 'learning', 'in', 'modern', 'business', 'intelligence', 'bi']",0,"['the', 'invaluable', 'role', 'of', 'machine', 'learning', 'in', 'modern', 'business', 'intelligence', 'bi']","['invaluable', 'role', 'machine', 'learning', 'modern', 'business', 'intelligence', 'bi']",invaluable role machine learning modern business intelligence bi,0.2,0.2,11,64,5.333333333333333,0,0,0,0,0,0,0,0
2876,data science requirement,Techniques,data science requirement,"['data', 'science', 'requirement']",0,"['data', 'science', 'requirement']","['data', 'science', 'requirement']",data science requirement,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
2877,how to use covariance for feature engineering,Techniques,how to use covariance for feature engineering,"['how', 'to', 'use', 'covariance', 'for', 'feature', 'engineering']",0,"['how', 'to', 'use', 'covariance', 'for', 'feature', 'engineering']","['use', 'covariance', 'feature', 'engineering']",use covariance feature engineering,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
2878,is learning rattle enough for data mining,Tools,is learning rattle enough for data mining,"['is', 'learning', 'rattle', 'enough', 'for', 'data', 'mining']",0,"['is', 'learning', 'rattle', 'enough', 'for', 'data', 'mining']","['learning', 'rattle', 'enough', 'data', 'mining']",learning rattle enough data mining,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
2879,titanicmachine learning from disaster,Techniques,titanicmachine learning from disaster,"['titanicmachine', 'learning', 'from', 'disaster']",0,"['titanicmachine', 'learning', 'from', 'disaster']","['titanicmachine', 'learning', 'disaster']",titanicmachine learning disaster,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
2880,what is the difference between boosting and ada boosting,Techniques,what is the difference between boosting and ada boosting,"['what', 'is', 'the', 'difference', 'between', 'boosting', 'and', 'ada', 'boosting']",0,"['what', 'is', 'the', 'difference', 'between', 'boosting', 'and', 'ada', 'boosting']","['difference', 'boosting', 'ada', 'boosting']",difference boosting ada boosting,0.0,0.0,9,32,3.2,0,0,0,0,0,0,0,0
2881,analysing the data and predicting future values,Techniques,analysing the data and predicting future values,"['analysing', 'the', 'data', 'and', 'predicting', 'future', 'values']",0,"['analysing', 'the', 'data', 'and', 'predicting', 'future', 'value']","['analysing', 'data', 'predicting', 'future', 'value']",analysing data predicting future value,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
2882,intentcontext extraction from text,Techniques,intentcontext extraction from text,"['intentcontext', 'extraction', 'from', 'text']",0,"['intentcontext', 'extraction', 'from', 'text']","['intentcontext', 'extraction', 'text']",intentcontext extraction text,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
2883,what is the difference between predict and predictproba,Techniques,what is the difference between predict and predictproba,"['what', 'is', 'the', 'difference', 'between', 'predict', 'and', 'predictproba']",0,"['what', 'is', 'the', 'difference', 'between', 'predict', 'and', 'predictproba']","['difference', 'predict', 'predictproba']",difference predict predictproba,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
2884,how to randomly split corpus data,Techniques,how to randomly split corpus data,"['how', 'to', 'randomly', 'split', 'corpus', 'data']",0,"['how', 'to', 'randomly', 'split', 'corpus', 'data']","['randomly', 'split', 'corpus', 'data']",randomly split corpus data,-0.5,-0.5,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
2885,how to display full dataframe in pandas,Tools,how to display full dataframe in pandas,"['how', 'to', 'display', 'full', 'dataframe', 'in', 'pandas']",0,"['how', 'to', 'display', 'full', 'dataframe', 'in', 'panda']","['display', 'full', 'dataframe', 'panda']",display full dataframe panda,0.35,0.35,7,28,3.5,0,0,0,0,0,0,0,0
2886,missing value treatment in the dataset,Techniques,missing value treatment in the dataset,"['missing', 'value', 'treatment', 'in', 'the', 'dataset']",0,"['missing', 'value', 'treatment', 'in', 'the', 'dataset']","['missing', 'value', 'treatment', 'dataset']",missing value treatment dataset,-0.2,-0.2,6,31,4.428571428571429,0,0,0,0,0,0,0,0
2887,understand decision tree in jupiter notebook,Tools,understand decision tree in jupiter notebook,"['understand', 'decision', 'tree', 'in', 'jupiter', 'notebook']",0,"['understand', 'decision', 'tree', 'in', 'jupiter', 'notebook']","['understand', 'decision', 'tree', 'jupiter', 'notebook']",understand decision tree jupiter notebook,0.0,0.0,6,41,5.857142857142857,0,0,0,0,0,0,0,0
2888,responsecss not working from an existing article on the site,Other,responsecss not working from an existing article on the site,"['responsecss', 'not', 'working', 'from', 'an', 'existing', 'article', 'on', 'the', 'site']",0,"['responsecss', 'not', 'working', 'from', 'an', 'existing', 'article', 'on', 'the', 'site']","['responsecss', 'working', 'existing', 'article', 'site']",responsecss working existing article site,0.0,0.0,10,41,3.727272727272727,0,0,0,0,0,0,0,0
2889,typeerror argument other has incorrect type expected spacytokenstokentoken got str in spacy,Tools,typeerror argument other has incorrect type expected spacytokenstokentoken got str in spacy,"['typeerror', 'argument', 'other', 'has', 'incorrect', 'type', 'expected', 'spacytokenstokentoken', 'got', 'str', 'in', 'spacy']",0,"['typeerror', 'argument', 'other', 'ha', 'incorrect', 'type', 'expected', 'spacytokenstokentoken', 'got', 'str', 'in', 'spacy']","['typeerror', 'argument', 'ha', 'incorrect', 'type', 'expected', 'spacytokenstokentoken', 'got', 'str', 'spacy']",typeerror argument ha incorrect type expected spacytokenstokentoken got str spacy,-0.1125,-0.1,12,81,6.230769230769231,0,0,0,0,0,0,0,0
2890,code required on github for comprehensive learning path to become a data scientist in  course,Resources,code required on github for comprehensive learning path to become a data scientist in  course,"['code', 'required', 'on', 'github', 'for', 'comprehensive', 'learning', 'path', 'to', 'become', 'a', 'data', 'scientist', 'in', 'course']",1,"['code', 'required', 'on', 'github', 'for', 'comprehensive', 'learning', 'path', 'to', 'become', 'a', 'data', 'scientist', 'in', 'course']","['code', 'required', 'github', 'comprehensive', 'learning', 'path', 'become', 'data', 'scientist', 'course']",code required github comprehensive learning path become data scientist course,0.0,0.0,15,77,4.8125,0,0,0,0,0,0,0,0
2891,how to set up my own hadoop cluster in my windows configured machine with gb internal ram and gb hd,Techniques,how to set up my own hadoop cluster in my windows configured machine with gb internal ram and gb hd,"['how', 'to', 'set', 'up', 'my', 'own', 'hadoop', 'cluster', 'in', 'my', 'windows', 'configured', 'machine', 'with', 'gb', 'internal', 'ram', 'and', 'gb', 'hd']",0,"['how', 'to', 'set', 'up', 'my', 'own', 'hadoop', 'cluster', 'in', 'my', 'window', 'configured', 'machine', 'with', 'gb', 'internal', 'ram', 'and', 'gb', 'hd']","['set', 'hadoop', 'cluster', 'window', 'configured', 'machine', 'gb', 'internal', 'ram', 'gb', 'hd']",set hadoop cluster window configured machine gb internal ram gb hd,0.3,0.0,20,66,3.142857142857143,0,0,0,0,0,0,0,0
2892,natural language processing,Techniques,natural language processing,"['natural', 'language', 'processing']",0,"['natural', 'language', 'processing']","['natural', 'language', 'processing']",natural language processing,0.1,0.1,3,27,6.75,0,0,0,0,0,0,0,0
2893,pricing analytics,Techniques,pricing analytics,"['pricing', 'analytics']",0,"['pricing', 'analytics']","['pricing', 'analytics']",pricing analytics,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
2894,categorical binning in sentiment analysis,Techniques,categorical binning in sentiment analysis,"['categorical', 'binning', 'in', 'sentiment', 'analysis']",0,"['categorical', 'binning', 'in', 'sentiment', 'analysis']","['categorical', 'binning', 'sentiment', 'analysis']",categorical binning sentiment analysis,0.0,0.0,5,38,6.333333333333333,0,0,0,0,0,0,0,0
2895,i am getting some problem in roc curve diagnostic can you help,Techniques,i am getting some problem in roc curve diagnostic can you help,"['i', 'am', 'getting', 'some', 'problem', 'in', 'roc', 'curve', 'diagnostic', 'can', 'you', 'help']",0,"['i', 'am', 'getting', 'some', 'problem', 'in', 'roc', 'curve', 'diagnostic', 'can', 'you', 'help']","['getting', 'problem', 'roc', 'curve', 'diagnostic', 'help']",getting problem roc curve diagnostic help,0.0,0.0,12,41,3.1538461538461537,0,0,0,0,0,0,0,0
2896,understanding and interpreting a boxplots,Tools,understanding and interpreting a boxplots,"['understanding', 'and', 'interpreting', 'a', 'boxplots']",0,"['understanding', 'and', 'interpreting', 'a', 'boxplots']","['understanding', 'interpreting', 'boxplots']",understanding interpreting boxplots,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
2897,student final project,Career,student final project,"['student', 'final', 'project']",0,"['student', 'final', 'project']","['student', 'final', 'project']",student final project,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
2898,career shift from auditing to analytics,Career,career shift from auditing to analytics,"['career', 'shift', 'from', 'auditing', 'to', 'analytics']",0,"['career', 'shift', 'from', 'auditing', 'to', 'analytics']","['career', 'shift', 'auditing', 'analytics']",career shift auditing analytics,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
2899,what does multidimensional scaling after lsa depict,Techniques,what does multidimensional scaling after lsa depict,"['what', 'does', 'multidimensional', 'scaling', 'after', 'lsa', 'depict']",0,"['what', 'doe', 'multidimensional', 'scaling', 'after', 'lsa', 'depict']","['doe', 'multidimensional', 'scaling', 'lsa', 'depict']",doe multidimensional scaling lsa depict,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
2900,how to implement simulated annealing in r,Tools,how to implement simulated annealing in r,"['how', 'to', 'implement', 'simulated', 'annealing', 'in', 'r']",0,"['how', 'to', 'implement', 'simulated', 'annealing', 'in', 'r']","['implement', 'simulated', 'annealing', 'r']",implement simulated annealing r,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
2901,how to combine levels according to its frequency,Techniques,how to combine levels according to its frequency,"['how', 'to', 'combine', 'levels', 'according', 'to', 'its', 'frequency']",0,"['how', 'to', 'combine', 'level', 'according', 'to', 'it', 'frequency']","['combine', 'level', 'according', 'frequency']",combine level according frequency,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
2902,anomaly detection in time series data  help required,Techniques,anomaly detection in time series data  help required,"['anomaly', 'detection', 'in', 'time', 'series', 'data', 'help', 'required']",0,"['anomaly', 'detection', 'in', 'time', 'series', 'data', 'help', 'required']","['anomaly', 'detection', 'time', 'series', 'data', 'help', 'required']",anomaly detection time series data help required,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
2903,use of facetwrap function of ggplot package in r,Tools,use of facetwrap function of ggplot package in r,"['use', 'of', 'facetwrap', 'function', 'of', 'ggplot', 'package', 'in', 'r']",0,"['use', 'of', 'facetwrap', 'function', 'of', 'ggplot', 'package', 'in', 'r']","['use', 'facetwrap', 'function', 'ggplot', 'package', 'r']",use facetwrap function ggplot package r,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
2904,python script hangs when running lstm on multiple cores,Techniques,python script hangs when running lstm on multiple cores,"['python', 'script', 'hangs', 'when', 'running', 'lstm', 'on', 'multiple', 'cores']",0,"['python', 'script', 'hang', 'when', 'running', 'lstm', 'on', 'multiple', 'core']","['python', 'script', 'hang', 'running', 'lstm', 'multiple', 'core']",python script hang running lstm multiple core,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
2905,how to calculate sum of sales based on minimum value of another field in qlikview,Tools,how to calculate sum of sales based on minimum value of another field in qlikview,"['how', 'to', 'calculate', 'sum', 'of', 'sales', 'based', 'on', 'minimum', 'value', 'of', 'another', 'field', 'in', 'qlikview']",0,"['how', 'to', 'calculate', 'sum', 'of', 'sale', 'based', 'on', 'minimum', 'value', 'of', 'another', 'field', 'in', 'qlikview']","['calculate', 'sum', 'sale', 'based', 'minimum', 'value', 'another', 'field', 'qlikview']",calculate sum sale based minimum value another field qlikview,0.0,0.0,15,61,3.8125,0,0,0,0,0,0,0,0
2906,what is the exact meaning of  confidence interval,Techniques,what is the exact meaning of  confidence interval,"['what', 'is', 'the', 'exact', 'meaning', 'of', 'confidence', 'interval']",1,"['what', 'is', 'the', 'exact', 'meaning', 'of', 'confidence', 'interval']","['exact', 'meaning', 'confidence', 'interval']",exact meaning confidence interval,0.25,0.25,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
2907,machine failure analysis,Techniques,machine failure analysis,"['machine', 'failure', 'analysis']",0,"['machine', 'failure', 'analysis']","['machine', 'failure', 'analysis']",machine failure analysis,-0.3166666666666667,-0.3166666666666667,3,24,6.0,0,0,0,0,0,0,0,0
2908,rstudio and tm package  using the inspect function,Tools,rstudio and tm package  using the inspect function,"['rstudio', 'and', 'tm', 'package', 'using', 'the', 'inspect', 'function']",0,"['rstudio', 'and', 'tm', 'package', 'using', 'the', 'inspect', 'function']","['rstudio', 'tm', 'package', 'using', 'inspect', 'function']",rstudio tm package using inspect function,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2909,what does the expandgrid function in caret do,Tools,what does the expandgrid function in caret do,"['what', 'does', 'the', 'expandgrid', 'function', 'in', 'caret', 'do']",0,"['what', 'doe', 'the', 'expandgrid', 'function', 'in', 'caret', 'do']","['doe', 'expandgrid', 'function', 'caret']",doe expandgrid function caret,0.0,0.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
2910,unable to install mlr package in rstudio on windows,Tools,unable to install mlr package in rstudio on windows,"['unable', 'to', 'install', 'mlr', 'package', 'in', 'rstudio', 'on', 'windows']",0,"['unable', 'to', 'install', 'mlr', 'package', 'in', 'rstudio', 'on', 'window']","['unable', 'install', 'mlr', 'package', 'rstudio', 'window']",unable install mlr package rstudio window,-0.5,-0.5,9,41,4.1,0,0,0,0,0,0,0,0
2911,how is jigsaw academys data science self paced program,Career,how is jigsaw academys data science self paced program,"['how', 'is', 'jigsaw', 'academys', 'data', 'science', 'self', 'paced', 'program']",0,"['how', 'is', 'jigsaw', 'academy', 'data', 'science', 'self', 'paced', 'program']","['jigsaw', 'academy', 'data', 'science', 'self', 'paced', 'program']",jigsaw academy data science self paced program,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
2912,how to create charts based on multiple categories in r,Tools,how to create charts based on multiple categories in r,"['how', 'to', 'create', 'charts', 'based', 'on', 'multiple', 'categories', 'in', 'r']",0,"['how', 'to', 'create', 'chart', 'based', 'on', 'multiple', 'category', 'in', 'r']","['create', 'chart', 'based', 'multiple', 'category', 'r']",create chart based multiple category r,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
2913,anybody working related to law  use cases in legal industry,Career,anybody working related to law  use cases in legal industry,"['anybody', 'working', 'related', 'to', 'law', 'use', 'cases', 'in', 'legal', 'industry']",0,"['anybody', 'working', 'related', 'to', 'law', 'use', 'case', 'in', 'legal', 'industry']","['anybody', 'working', 'related', 'law', 'use', 'case', 'legal', 'industry']",anybody working related law use case legal industry,0.1,0.1,10,51,4.636363636363637,0,0,0,0,0,0,0,0
2914,what is the difference between ztestttest and anova used for bivariate analysis,Techniques,what is the difference between ztestttest and anova used for bivariate analysis,"['what', 'is', 'the', 'difference', 'between', 'ztestttest', 'and', 'anova', 'used', 'for', 'bivariate', 'analysis']",0,"['what', 'is', 'the', 'difference', 'between', 'ztestttest', 'and', 'anova', 'used', 'for', 'bivariate', 'analysis']","['difference', 'ztestttest', 'anova', 'used', 'bivariate', 'analysis']",difference ztestttest anova used bivariate analysis,0.0,0.0,12,51,3.923076923076923,0,0,0,0,0,0,0,0
2915,queries on business analytics job,Career,queries on business analytics job,"['queries', 'on', 'business', 'analytics', 'job']",0,"['query', 'on', 'business', 'analytics', 'job']","['query', 'business', 'analytics', 'job']",query business analytics job,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
2916,how to merge the data files in r or sas,Hackathons,how to merge the data files in r or sas,"['how', 'to', 'merge', 'the', 'data', 'files', 'in', 'r', 'or', 'sas']",0,"['how', 'to', 'merge', 'the', 'data', 'file', 'in', 'r', 'or', 'sa']","['merge', 'data', 'file', 'r', 'sa']",merge data file r sa,0.0,0.0,10,20,1.8181818181818181,0,0,0,0,0,0,0,0
2917,data inconsistency in amexpert data,Hackathons,data inconsistency in amexpert data,"['data', 'inconsistency', 'in', 'amexpert', 'data']",0,"['data', 'inconsistency', 'in', 'amexpert', 'data']","['data', 'inconsistency', 'amexpert', 'data']",data inconsistency amexpert data,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2918,suggest tool preferences based on the job opportunities in india tableau vs qlikview vs msbipowerbi,Tools,suggest tool preferences based on the job opportunities in india tableau vs qlikview vs msbipowerbi,"['suggest', 'tool', 'preferences', 'based', 'on', 'the', 'job', 'opportunities', 'in', 'india', 'tableau', 'vs', 'qlikview', 'vs', 'msbipowerbi']",0,"['suggest', 'tool', 'preference', 'based', 'on', 'the', 'job', 'opportunity', 'in', 'india', 'tableau', 'v', 'qlikview', 'v', 'msbipowerbi']","['suggest', 'tool', 'preference', 'based', 'job', 'opportunity', 'india', 'tableau', 'v', 'qlikview', 'v', 'msbipowerbi']",suggest tool preference based job opportunity india tableau v qlikview v msbipowerbi,0.0,0.0,15,84,5.25,0,0,0,0,0,0,0,0
2919,how to get only specific value of time in r,Tools,how to get only specific value of time in r,"['how', 'to', 'get', 'only', 'specific', 'value', 'of', 'time', 'in', 'r']",0,"['how', 'to', 'get', 'only', 'specific', 'value', 'of', 'time', 'in', 'r']","['get', 'specific', 'value', 'time', 'r']",get specific value time r,0.0,0.0,10,25,2.272727272727273,0,0,0,0,0,0,0,0
2920,convert variables to latitude and longitude in tableau,Tools,convert variables to latitude and longitude in tableau,"['convert', 'variables', 'to', 'latitude', 'and', 'longitude', 'in', 'tableau']",0,"['convert', 'variable', 'to', 'latitude', 'and', 'longitude', 'in', 'tableau']","['convert', 'variable', 'latitude', 'longitude', 'tableau']",convert variable latitude longitude tableau,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
2921,apply conditional formatting in column chart in excel highlight the max value,Tools,apply conditional formatting in column chart in excel highlight the max value,"['apply', 'conditional', 'formatting', 'in', 'column', 'chart', 'in', 'excel', 'highlight', 'the', 'max', 'value']",0,"['apply', 'conditional', 'formatting', 'in', 'column', 'chart', 'in', 'excel', 'highlight', 'the', 'max', 'value']","['apply', 'conditional', 'formatting', 'column', 'chart', 'excel', 'highlight', 'max', 'value']",apply conditional formatting column chart excel highlight max value,0.0,0.0,12,67,5.153846153846154,0,0,0,0,0,0,0,0
2922,linear regression and optimization techniques question,Techniques,linear regression and optimization techniques question,"['linear', 'regression', 'and', 'optimization', 'techniques', 'question']",0,"['linear', 'regression', 'and', 'optimization', 'technique', 'question']","['linear', 'regression', 'optimization', 'technique', 'question']",linear regression optimization technique question,0.0,0.0,6,49,7.0,0,0,0,0,0,0,0,0
2923,doubts in timeseries forecasting transformation,Techniques,doubts in timeseries forecasting transformation,"['doubts', 'in', 'timeseries', 'forecasting', 'transformation']",0,"['doubt', 'in', 'timeseries', 'forecasting', 'transformation']","['doubt', 'timeseries', 'forecasting', 'transformation']",doubt timeseries forecasting transformation,0.0,0.0,5,43,7.166666666666667,0,0,0,0,0,0,0,0
2924,non time series data which repeats itself,Techniques,non time series data which repeats itself,"['non', 'time', 'series', 'data', 'which', 'repeats', 'itself']",0,"['non', 'time', 'series', 'data', 'which', 'repeat', 'itself']","['non', 'time', 'series', 'data', 'repeat']",non time series data repeat,0.0,0.0,7,27,3.375,0,0,0,0,0,0,0,0
2925,predict time series classification for single test instance,Techniques,predict time series classification for single test instance,"['predict', 'time', 'series', 'classification', 'for', 'single', 'test', 'instance']",0,"['predict', 'time', 'series', 'classification', 'for', 'single', 'test', 'instance']","['predict', 'time', 'series', 'classification', 'single', 'test', 'instance']",predict time series classification single test instance,-0.0714285714285714,-0.0714285714285714,8,55,6.111111111111111,0,0,0,0,0,0,0,0
2926,advantage of feature evaluation over to pca,Techniques,advantage of feature evaluation over to pca,"['advantage', 'of', 'feature', 'evaluation', 'over', 'to', 'pca']",0,"['advantage', 'of', 'feature', 'evaluation', 'over', 'to', 'pca']","['advantage', 'feature', 'evaluation', 'pca']",advantage feature evaluation pca,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
2927,how to change the name of specific column in pandas dataframe,Tools,how to change the name of specific column in pandas dataframe,"['how', 'to', 'change', 'the', 'name', 'of', 'specific', 'column', 'in', 'pandas', 'dataframe']",0,"['how', 'to', 'change', 'the', 'name', 'of', 'specific', 'column', 'in', 'panda', 'dataframe']","['change', 'name', 'specific', 'column', 'panda', 'dataframe']",change name specific column panda dataframe,0.0,0.0,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
2928,how to fill the missing values in pandas dataframe using python,Tools,how to fill the missing values in pandas dataframe using python,"['how', 'to', 'fill', 'the', 'missing', 'values', 'in', 'pandas', 'dataframe', 'using', 'python']",0,"['how', 'to', 'fill', 'the', 'missing', 'value', 'in', 'panda', 'dataframe', 'using', 'python']","['fill', 'missing', 'value', 'panda', 'dataframe', 'using', 'python']",fill missing value panda dataframe using python,-0.2,-0.2,11,47,3.9166666666666665,0,0,0,0,0,0,0,0
2929,source of old hackathon for learning,Hackathons,source of old hackathon for learning,"['source', 'of', 'old', 'hackathon', 'for', 'learning']",0,"['source', 'of', 'old', 'hackathon', 'for', 'learning']","['source', 'old', 'hackathon', 'learning']",source old hackathon learning,0.1,0.1,6,29,4.142857142857143,0,0,0,0,0,0,0,0
2930,help with the most common excel shortcut keys,Tools,help with the most common excel shortcut keys,"['help', 'with', 'the', 'most', 'common', 'excel', 'shortcut', 'keys']",0,"['help', 'with', 'the', 'most', 'common', 'excel', 'shortcut', 'key']","['help', 'common', 'excel', 'shortcut', 'key']",help common excel shortcut key,0.1,-0.15,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
2931,experiments with data  query,Tools,experiments with data  query,"['experiments', 'with', 'data', 'query']",0,"['experiment', 'with', 'data', 'query']","['experiment', 'data', 'query']",experiment data query,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
2932,how get the nan missing values during column sum of a data frame in python,Tools,how get the nan missing values during column sum of a data frame in python,"['how', 'get', 'the', 'nan', 'missing', 'values', 'during', 'column', 'sum', 'of', 'a', 'data', 'frame', 'in', 'python']",0,"['how', 'get', 'the', 'nan', 'missing', 'value', 'during', 'column', 'sum', 'of', 'a', 'data', 'frame', 'in', 'python']","['get', 'nan', 'missing', 'value', 'column', 'sum', 'data', 'frame', 'python']",get nan missing value column sum data frame python,-0.2,-0.2,15,50,3.125,0,0,0,0,0,0,0,0
2933,business analytics vs data analytics  data science,Career,business analytics vs data analytics  data science,"['business', 'analytics', 'vs', 'data', 'analytics', 'data', 'science']",0,"['business', 'analytics', 'v', 'data', 'analytics', 'data', 'science']","['business', 'analytics', 'v', 'data', 'analytics', 'data', 'science']",business analytics v data analytics data science,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
2934,feature request mark individual threads as read,Other,feature request mark individual threads as read,"['feature', 'request', 'mark', 'individual', 'threads', 'as', 'read']",0,"['feature', 'request', 'mark', 'individual', 'thread', 'a', 'read']","['feature', 'request', 'mark', 'individual', 'thread', 'read']",feature request mark individual thread read,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
2935,contrasts dropped from factor x in decision tree,Techniques,contrasts dropped from factor x in decision tree,"['contrasts', 'dropped', 'from', 'factor', 'x', 'in', 'decision', 'tree']",0,"['contrast', 'dropped', 'from', 'factor', 'x', 'in', 'decision', 'tree']","['contrast', 'dropped', 'factor', 'x', 'decision', 'tree']",contrast dropped factor x decision tree,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
2936,how many algorithms an analyst should know,Career,how many algorithms an analyst should know,"['how', 'many', 'algorithms', 'an', 'analyst', 'should', 'know']",0,"['how', 'many', 'algorithm', 'an', 'analyst', 'should', 'know']","['many', 'algorithm', 'analyst', 'know']",many algorithm analyst know,0.5,0.5,7,27,3.375,0,0,0,0,0,0,0,0
2937,project delinquency telecom model,Techniques,project delinquency telecom model,"['project', 'delinquency', 'telecom', 'model']",0,"['project', 'delinquency', 'telecom', 'model']","['project', 'delinquency', 'telecom', 'model']",project delinquency telecom model,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
2938,risk constraint in portfolioanalytics portfolio optimazationstocks,Tools,risk constraint in portfolioanalytics portfolio optimazationstocks,"['risk', 'constraint', 'in', 'portfolioanalytics', 'portfolio', 'optimazationstocks']",0,"['risk', 'constraint', 'in', 'portfolioanalytics', 'portfolio', 'optimazationstocks']","['risk', 'constraint', 'portfolioanalytics', 'portfolio', 'optimazationstocks']",risk constraint portfolioanalytics portfolio optimazationstocks,0.0,0.0,6,63,9.0,0,0,0,0,0,0,0,0
2939,resources for employee attrition analysis,Techniques,resources for employee attrition analysis,"['resources', 'for', 'employee', 'attrition', 'analysis']",0,"['resource', 'for', 'employee', 'attrition', 'analysis']","['resource', 'employee', 'attrition', 'analysis']",resource employee attrition analysis,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
2940,suggestion needed regarding data cleaning for correcting addresses,Techniques,suggestion needed regarding data cleaning for correcting addresses,"['suggestion', 'needed', 'regarding', 'data', 'cleaning', 'for', 'correcting', 'addresses']",0,"['suggestion', 'needed', 'regarding', 'data', 'cleaning', 'for', 'correcting', 'address']","['suggestion', 'needed', 'regarding', 'data', 'cleaning', 'correcting', 'address']",suggestion needed regarding data cleaning correcting address,0.0,0.0,8,60,6.666666666666667,0,0,0,0,0,0,0,0
2941,error in defaultdata  allvarsterms drop  false  incorrect number of dimensions,Tools,error in defaultdata  allvarsterms drop  false  incorrect number of dimensions,"['error', 'in', 'defaultdata', 'allvarsterms', 'drop', 'false', 'incorrect', 'number', 'of', 'dimensions']",0,"['error', 'in', 'defaultdata', 'allvarsterms', 'drop', 'false', 'incorrect', 'number', 'of', 'dimension']","['error', 'defaultdata', 'allvarsterms', 'drop', 'false', 'incorrect', 'number', 'dimension']",error defaultdata allvarsterms drop false incorrect number dimension,-0.4000000000000001,-0.4000000000000001,10,68,6.181818181818182,0,0,0,0,0,0,0,0
2942,any data science meetups or groups in bangalore,Misc,any data science meetups or groups in bangalore,"['any', 'data', 'science', 'meetups', 'or', 'groups', 'in', 'bangalore']",0,"['any', 'data', 'science', 'meetups', 'or', 'group', 'in', 'bangalore']","['data', 'science', 'meetups', 'group', 'bangalore']",data science meetups group bangalore,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
2943,what is the difference between parametric and nonparametric regression,Techniques,what is the difference between parametric and nonparametric regression,"['what', 'is', 'the', 'difference', 'between', 'parametric', 'and', 'nonparametric', 'regression']",0,"['what', 'is', 'the', 'difference', 'between', 'parametric', 'and', 'nonparametric', 'regression']","['difference', 'parametric', 'nonparametric', 'regression']",difference parametric nonparametric regression,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
2944,comparison  is possible only for atomic and list types,Techniques,comparison  is possible only for atomic and list types,"['comparison', 'is', 'possible', 'only', 'for', 'atomic', 'and', 'list', 'types']",1,"['comparison', 'is', 'possible', 'only', 'for', 'atomic', 'and', 'list', 'type']","['comparison', 'possible', 'atomic', 'list', 'type']",comparison possible atomic list type,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
2945,decision tree pruning and other related queries,Techniques,decision tree pruning and other related queries,"['decision', 'tree', 'pruning', 'and', 'other', 'related', 'queries']",0,"['decision', 'tree', 'pruning', 'and', 'other', 'related', 'query']","['decision', 'tree', 'pruning', 'related', 'query']",decision tree pruning related query,-0.0625,0.0,7,35,4.375,0,0,0,0,0,0,0,0
2946,what is the bagging signifies in random forest,Techniques,what is the bagging signifies in random forest,"['what', 'is', 'the', 'bagging', 'signifies', 'in', 'random', 'forest']",0,"['what', 'is', 'the', 'bagging', 'signifies', 'in', 'random', 'forest']","['bagging', 'signifies', 'random', 'forest']",bagging signifies random forest,-0.5,-0.5,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
2947,when to use pandas getdummies and sklearn labelencoder,Tools,when to use pandas getdummies and sklearn labelencoder,"['when', 'to', 'use', 'pandas', 'getdummies', 'and', 'sklearn', 'labelencoder']",0,"['when', 'to', 'use', 'panda', 'getdummies', 'and', 'sklearn', 'labelencoder']","['use', 'panda', 'getdummies', 'sklearn', 'labelencoder']",use panda getdummies sklearn labelencoder,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
2948,zs associates or musigma for a beginner in analytics,Career,zs associates or musigma for a beginner in analytics,"['zs', 'associates', 'or', 'musigma', 'for', 'a', 'beginner', 'in', 'analytics']",0,"['z', 'associate', 'or', 'musigma', 'for', 'a', 'beginner', 'in', 'analytics']","['z', 'associate', 'musigma', 'beginner', 'analytics']",z associate musigma beginner analytics,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
2949,shiny app for spell check using fuzzy match,Tools,shiny app for spell check using fuzzy match,"['shiny', 'app', 'for', 'spell', 'check', 'using', 'fuzzy', 'match']",0,"['shiny', 'app', 'for', 'spell', 'check', 'using', 'fuzzy', 'match']","['shiny', 'app', 'spell', 'check', 'using', 'fuzzy', 'match']",shiny app spell check using fuzzy match,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
2950,tsne and subsequent clustering,Techniques,tsne and subsequent clustering,"['tsne', 'and', 'subsequent', 'clustering']",0,"['tsne', 'and', 'subsequent', 'clustering']","['tsne', 'subsequent', 'clustering']",tsne subsequent clustering,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
2951,which algorithm is used to handle angles classtarget function using decision tree,Techniques,which algorithm is used to handle angles classtarget function using decision tree,"['which', 'algorithm', 'is', 'used', 'to', 'handle', 'angles', 'classtarget', 'function', 'using', 'decision', 'tree']",0,"['which', 'algorithm', 'is', 'used', 'to', 'handle', 'angle', 'classtarget', 'function', 'using', 'decision', 'tree']","['algorithm', 'used', 'handle', 'angle', 'classtarget', 'function', 'using', 'decision', 'tree']",algorithm used handle angle classtarget function using decision tree,0.0,0.0,12,68,5.230769230769231,0,0,0,0,0,0,0,0
2952,how to convert the multi index series into a data frame in python,Tools,how to convert the multi index series into a data frame in python,"['how', 'to', 'convert', 'the', 'multi', 'index', 'series', 'into', 'a', 'data', 'frame', 'in', 'python']",0,"['how', 'to', 'convert', 'the', 'multi', 'index', 'series', 'into', 'a', 'data', 'frame', 'in', 'python']","['convert', 'multi', 'index', 'series', 'data', 'frame', 'python']",convert multi index series data frame python,0.0,0.0,13,44,3.142857142857143,0,0,0,0,0,0,0,0
2953,how to keep only rows containing a certain number of observation of a data frame in python,Tools,how to keep only rows containing a certain number of observation of a data frame in python,"['how', 'to', 'keep', 'only', 'rows', 'containing', 'a', 'certain', 'number', 'of', 'observation', 'of', 'a', 'data', 'frame', 'in', 'python']",0,"['how', 'to', 'keep', 'only', 'row', 'containing', 'a', 'certain', 'number', 'of', 'observation', 'of', 'a', 'data', 'frame', 'in', 'python']","['keep', 'row', 'containing', 'certain', 'number', 'observation', 'data', 'frame', 'python']",keep row containing certain number observation data frame python,0.1071428571428571,0.2142857142857142,17,64,3.5555555555555554,0,0,0,0,0,0,0,0
2954,kpi degradationnetwork failure predicition,Techniques,kpi degradationnetwork failure predicition,"['kpi', 'degradationnetwork', 'failure', 'predicition']",0,"['kpi', 'degradationnetwork', 'failure', 'predicition']","['kpi', 'degradationnetwork', 'failure', 'predicition']",kpi degradationnetwork failure predicition,-0.3166666666666667,-0.3166666666666667,4,42,8.4,0,0,0,0,0,0,0,0
2955,regression model giving the same prediction for all new inputs until i load the model again,Techniques,regression model giving the same prediction for all new inputs until i load the model again,"['regression', 'model', 'giving', 'the', 'same', 'prediction', 'for', 'all', 'new', 'inputs', 'until', 'i', 'load', 'the', 'model', 'again']",0,"['regression', 'model', 'giving', 'the', 'same', 'prediction', 'for', 'all', 'new', 'input', 'until', 'i', 'load', 'the', 'model', 'again']","['regression', 'model', 'giving', 'prediction', 'new', 'input', 'load', 'model']",regression model giving prediction new input load model,0.0681818181818181,0.1363636363636363,16,55,3.235294117647059,0,0,0,0,0,0,0,0
2956,how can i create cyclic expression in qlikview,Tools,how can i create cyclic expression in qlikview,"['how', 'can', 'i', 'create', 'cyclic', 'expression', 'in', 'qlikview']",0,"['how', 'can', 'i', 'create', 'cyclic', 'expression', 'in', 'qlikview']","['create', 'cyclic', 'expression', 'qlikview']",create cyclic expression qlikview,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
2957,predict parameters for a particular target value,Techniques,predict parameters for a particular target value,"['predict', 'parameters', 'for', 'a', 'particular', 'target', 'value']",0,"['predict', 'parameter', 'for', 'a', 'particular', 'target', 'value']","['predict', 'parameter', 'particular', 'target', 'value']",predict parameter particular target value,0.1666666666666666,0.1666666666666666,7,41,5.125,0,0,0,0,0,0,0,0
2958,feature engineering with latitude and longitude,Techniques,feature engineering with latitude and longitude,"['feature', 'engineering', 'with', 'latitude', 'and', 'longitude']",0,"['feature', 'engineering', 'with', 'latitude', 'and', 'longitude']","['feature', 'engineering', 'latitude', 'longitude']",feature engineering latitude longitude,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
2959,certifications in data science,Career,certifications in data science,"['certifications', 'in', 'data', 'science']",0,"['certification', 'in', 'data', 'science']","['certification', 'data', 'science']",certification data science,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
2960,arithmeticaio waitlist,Misc,arithmeticaio waitlist,"['arithmeticaio', 'waitlist']",0,"['arithmeticaio', 'waitlist']","['arithmeticaio', 'waitlist']",arithmeticaio waitlist,0.0,0.0,2,22,7.333333333333333,0,0,0,0,0,0,0,0
2961,how to calculate the column sum in ipython,Tools,how to calculate the column sum in ipython,"['how', 'to', 'calculate', 'the', 'column', 'sum', 'in', 'ipython']",0,"['how', 'to', 'calculate', 'the', 'column', 'sum', 'in', 'ipython']","['calculate', 'column', 'sum', 'ipython']",calculate column sum ipython,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
2962,bubble sort using tensorflow,Resources,bubble sort using tensorflow,"['bubble', 'sort', 'using', 'tensorflow']",0,"['bubble', 'sort', 'using', 'tensorflow']","['bubble', 'sort', 'using', 'tensorflow']",bubble sort using tensorflow,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
2963,analysis of wine quality dataset,Techniques,analysis of wine quality dataset,"['analysis', 'of', 'wine', 'quality', 'dataset']",0,"['analysis', 'of', 'wine', 'quality', 'dataset']","['analysis', 'wine', 'quality', 'dataset']",analysis wine quality dataset,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
2964,post graduate programme in business analytics  great lakes or bridge institute,Career,post graduate programme in business analytics  great lakes or bridge institute,"['post', 'graduate', 'programme', 'in', 'business', 'analytics', 'great', 'lakes', 'or', 'bridge', 'institute']",0,"['post', 'graduate', 'programme', 'in', 'business', 'analytics', 'great', 'lake', 'or', 'bridge', 'institute']","['post', 'graduate', 'programme', 'business', 'analytics', 'great', 'lake', 'bridge', 'institute']",post graduate programme business analytics great lake bridge institute,0.8,0.8,11,70,5.833333333333333,0,0,0,0,0,0,0,0
2965,how to create dataframe with different datatypes in python,Tools,how to create dataframe with different datatypes in python,"['how', 'to', 'create', 'dataframe', 'with', 'different', 'datatypes', 'in', 'python']",0,"['how', 'to', 'create', 'dataframe', 'with', 'different', 'datatypes', 'in', 'python']","['create', 'dataframe', 'different', 'datatypes', 'python']",create dataframe different datatypes python,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
2966,googlenet evaluation results,Techniques,googlenet evaluation results,"['googlenet', 'evaluation', 'results']",0,"['googlenet', 'evaluation', 'result']","['googlenet', 'evaluation', 'result']",googlenet evaluation result,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
2967,how to rank  give weights to column values manually,Techniques,how to rank  give weights to column values manually,"['how', 'to', 'rank', 'give', 'weights', 'to', 'column', 'values', 'manually']",0,"['how', 'to', 'rank', 'give', 'weight', 'to', 'column', 'value', 'manually']","['rank', 'give', 'weight', 'column', 'value', 'manually']",rank give weight column value manually,-0.8,-0.8,9,38,3.8,0,0,0,0,0,0,0,0
2968,unable to download loan prediction practice problem,Resources,unable to download loan prediction practice problem,"['unable', 'to', 'download', 'loan', 'prediction', 'practice', 'problem']",0,"['unable', 'to', 'download', 'loan', 'prediction', 'practice', 'problem']","['unable', 'download', 'loan', 'prediction', 'practice', 'problem']",unable download loan prediction practice problem,-0.5,-0.5,7,48,6.0,0,0,0,0,0,0,0,0
2969,hello i got stuck here could i get any help,Techniques,hello i got stuck here could i get any help,"['hello', 'i', 'got', 'stuck', 'here', 'could', 'i', 'get', 'any', 'help']",0,"['hello', 'i', 'got', 'stuck', 'here', 'could', 'i', 'get', 'any', 'help']","['hello', 'got', 'stuck', 'could', 'get', 'help']",hello got stuck could get help,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
2970,scraping job categories and its sub categories,Techniques,scraping job categories and its sub categories,"['scraping', 'job', 'categories', 'and', 'its', 'sub', 'categories']",0,"['scraping', 'job', 'category', 'and', 'it', 'sub', 'category']","['scraping', 'job', 'category', 'sub', 'category']",scraping job category sub category,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
2971,doubts in applying linear regression,Techniques,doubts in applying linear regression,"['doubts', 'in', 'applying', 'linear', 'regression']",0,"['doubt', 'in', 'applying', 'linear', 'regression']","['doubt', 'applying', 'linear', 'regression']",doubt applying linear regression,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
2972,hypothesis testingurgent,Career,hypothesis testingurgent,"['hypothesis', 'testingurgent']",0,"['hypothesis', 'testingurgent']","['hypothesis', 'testingurgent']",hypothesis testingurgent,0.0,0.0,2,24,8.0,0,0,0,0,0,0,0,0
2973,time series multiple periodicity,Techniques,time series multiple periodicity,"['time', 'series', 'multiple', 'periodicity']",0,"['time', 'series', 'multiple', 'periodicity']","['time', 'series', 'multiple', 'periodicity']",time series multiple periodicity,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
2974,how to extract multiple email addresses stored in a string variable in sas,Tools,how to extract multiple email addresses stored in a string variable in sas,"['how', 'to', 'extract', 'multiple', 'email', 'addresses', 'stored', 'in', 'a', 'string', 'variable', 'in', 'sas']",0,"['how', 'to', 'extract', 'multiple', 'email', 'address', 'stored', 'in', 'a', 'string', 'variable', 'in', 'sa']","['extract', 'multiple', 'email', 'address', 'stored', 'string', 'variable', 'sa']",extract multiple email address stored string variable sa,0.0,0.0,13,56,4.0,0,0,0,0,0,0,0,0
2975,how to insert a column between two columns in r,Tools,how to insert a column between two columns in r,"['how', 'to', 'insert', 'a', 'column', 'between', 'two', 'columns', 'in', 'r']",0,"['how', 'to', 'insert', 'a', 'column', 'between', 'two', 'column', 'in', 'r']","['insert', 'column', 'two', 'column', 'r']",insert column two column r,0.0,0.0,10,26,2.3636363636363638,0,0,0,0,0,0,0,0
2976,r how to write loop for posthoc tukey test and multiple comparision,Tools,r how to write loop for posthoc tukey test and multiple comparision,"['r', 'how', 'to', 'write', 'loop', 'for', 'posthoc', 'tukey', 'test', 'and', 'multiple', 'comparision']",0,"['r', 'how', 'to', 'write', 'loop', 'for', 'posthoc', 'tukey', 'test', 'and', 'multiple', 'comparision']","['r', 'write', 'loop', 'posthoc', 'tukey', 'test', 'multiple', 'comparision']",r write loop posthoc tukey test multiple comparision,0.0,0.0,12,52,4.0,0,0,0,0,0,0,0,0
2977,need help in timeseries analysis,Techniques,need help in timeseries analysis,"['need', 'help', 'in', 'timeseries', 'analysis']",0,"['need', 'help', 'in', 'timeseries', 'analysis']","['need', 'help', 'timeseries', 'analysis']",need help timeseries analysis,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
2978,milestones while learning data science,Misc,milestones while learning data science,"['milestones', 'while', 'learning', 'data', 'science']",0,"['milestone', 'while', 'learning', 'data', 'science']","['milestone', 'learning', 'data', 'science']",milestone learning data science,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
2979,resume classification,Techniques,resume classification,"['resume', 'classification']",0,"['resume', 'classification']","['resume', 'classification']",resume classification,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
2980,need expert advice  to shift my profile to business analytics,Career,need expert advice  to shift my profile to business analytics,"['need', 'expert', 'advice', 'to', 'shift', 'my', 'profile', 'to', 'business', 'analytics']",0,"['need', 'expert', 'advice', 'to', 'shift', 'my', 'profile', 'to', 'business', 'analytics']","['need', 'expert', 'advice', 'shift', 'profile', 'business', 'analytics']",need expert advice shift profile business analytics,0.0,0.0,10,51,4.636363636363637,0,0,0,0,0,0,0,0
2981,extracting text after a symbol in r,Tools,extracting text after a symbol in r,"['extracting', 'text', 'after', 'a', 'symbol', 'in', 'r']",0,"['extracting', 'text', 'after', 'a', 'symbol', 'in', 'r']","['extracting', 'text', 'symbol', 'r']",extracting text symbol r,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
2982,web scraping country name form google search,Techniques,web scraping country name form google search,"['web', 'scraping', 'country', 'name', 'form', 'google', 'search']",0,"['web', 'scraping', 'country', 'name', 'form', 'google', 'search']","['web', 'scraping', 'country', 'name', 'form', 'google', 'search']",web scraping country name form google search,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
2983,building a chat bot,Techniques,building a chat bot,"['building', 'a', 'chat', 'bot']",0,"['building', 'a', 'chat', 'bot']","['building', 'chat', 'bot']",building chat bot,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
2984,item item filtering vs collaborative filtering,Techniques,item item filtering vs collaborative filtering,"['item', 'item', 'filtering', 'vs', 'collaborative', 'filtering']",0,"['item', 'item', 'filtering', 'v', 'collaborative', 'filtering']","['item', 'item', 'filtering', 'v', 'collaborative', 'filtering']",item item filtering v collaborative filtering,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
2985,graph  network analytics topological data analysis,Resources,graph  network analytics topological data analysis,"['graph', 'network', 'analytics', 'topological', 'data', 'analysis']",0,"['graph', 'network', 'analytics', 'topological', 'data', 'analysis']","['graph', 'network', 'analytics', 'topological', 'data', 'analysis']",graph network analytics topological data analysis,0.0,0.0,6,49,7.0,0,0,0,0,0,0,0,0
2986,how to predict class labels in test data which does not contain the class labels,Techniques,how to predict class labels in test data which does not contain the class labels,"['how', 'to', 'predict', 'class', 'labels', 'in', 'test', 'data', 'which', 'does', 'not', 'contain', 'the', 'class', 'labels']",0,"['how', 'to', 'predict', 'class', 'label', 'in', 'test', 'data', 'which', 'doe', 'not', 'contain', 'the', 'class', 'label']","['predict', 'class', 'label', 'test', 'data', 'doe', 'contain', 'class', 'label']",predict class label test data doe contain class label,0.0,0.0,15,53,3.3125,0,0,0,0,0,0,0,0
2987,clarifying doubts regarding codes,Techniques,clarifying doubts regarding codes,"['clarifying', 'doubts', 'regarding', 'codes']",0,"['clarifying', 'doubt', 'regarding', 'code']","['clarifying', 'doubt', 'regarding', 'code']",clarifying doubt regarding code,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
2988,latency cluster analysis,Techniques,latency cluster analysis,"['latency', 'cluster', 'analysis']",0,"['latency', 'cluster', 'analysis']","['latency', 'cluster', 'analysis']",latency cluster analysis,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
2989,how to predict the items a customer will buy in next transaction,Techniques,how to predict the items a customer will buy in next transaction,"['how', 'to', 'predict', 'the', 'items', 'a', 'customer', 'will', 'buy', 'in', 'next', 'transaction']",0,"['how', 'to', 'predict', 'the', 'item', 'a', 'customer', 'will', 'buy', 'in', 'next', 'transaction']","['predict', 'item', 'customer', 'buy', 'next', 'transaction']",predict item customer buy next transaction,0.0,0.0,12,42,3.230769230769231,0,0,0,0,0,0,0,0
2990,how to apply any function over an array in python,Tools,how to apply any function over an array in python,"['how', 'to', 'apply', 'any', 'function', 'over', 'an', 'array', 'in', 'python']",0,"['how', 'to', 'apply', 'any', 'function', 'over', 'an', 'array', 'in', 'python']","['apply', 'function', 'array', 'python']",apply function array python,0.0,0.0,10,27,2.4545454545454546,0,0,0,0,0,0,0,0
2991,is the majority of the data scientists work is going to be automated in near future,Career,is the majority of the data scientists work is going to be automated in near future,"['is', 'the', 'majority', 'of', 'the', 'data', 'scientists', 'work', 'is', 'going', 'to', 'be', 'automated', 'in', 'near', 'future']",0,"['is', 'the', 'majority', 'of', 'the', 'data', 'scientist', 'work', 'is', 'going', 'to', 'be', 'automated', 'in', 'near', 'future']","['majority', 'data', 'scientist', 'work', 'going', 'automated', 'near', 'future']",majority data scientist work going automated near future,0.05,0.05,16,56,3.2941176470588234,0,0,0,0,0,0,0,0
2992,what is a matriz o norm vector,Techniques,what is a matriz o norm vector,"['what', 'is', 'a', 'matriz', 'o', 'norm', 'vector']",0,"['what', 'is', 'a', 'matriz', 'o', 'norm', 'vector']","['matriz', 'norm', 'vector']",matriz norm vector,0.0,0.0,7,18,2.25,0,0,0,0,0,0,0,0
2993,career transition from net developer to data science in us,Career,career transition from net developer to data science in us,"['career', 'transition', 'from', 'net', 'developer', 'to', 'data', 'science', 'in', 'us']",0,"['career', 'transition', 'from', 'net', 'developer', 'to', 'data', 'science', 'in', 'u']","['career', 'transition', 'net', 'developer', 'data', 'science', 'u']",career transition net developer data science u,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
2994,improving model performance,Techniques,improving model performance,"['improving', 'model', 'performance']",0,"['improving', 'model', 'performance']","['improving', 'model', 'performance']",improving model performance,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
2995,how does tableau work so fast,Tools,how does tableau work so fast,"['how', 'does', 'tableau', 'work', 'so', 'fast']",0,"['how', 'doe', 'tableau', 'work', 'so', 'fast']","['doe', 'tableau', 'work', 'fast']",doe tableau work fast,0.2,0.2,6,21,3.0,0,0,0,0,0,0,0,0
2996,help to improve multiple regression model,Hackathons,help to improve multiple regression model,"['help', 'to', 'improve', 'multiple', 'regression', 'model']",0,"['help', 'to', 'improve', 'multiple', 'regression', 'model']","['help', 'improve', 'multiple', 'regression', 'model']",help improve multiple regression model,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
2997,learning path of python,Resources,learning path of python,"['learning', 'path', 'of', 'python']",0,"['learning', 'path', 'of', 'python']","['learning', 'path', 'python']",learning path python,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
2998,unable to install lightgbm package in r,Tools,unable to install lightgbm package in r,"['unable', 'to', 'install', 'lightgbm', 'package', 'in', 'r']",0,"['unable', 'to', 'install', 'lightgbm', 'package', 'in', 'r']","['unable', 'install', 'lightgbm', 'package', 'r']",unable install lightgbm package r,-0.5,-0.5,7,33,4.125,0,0,0,0,0,0,0,0
2999,whats the use of matrices for regression analysis,Techniques,whats the use of matrices for regression analysis,"['whats', 'the', 'use', 'of', 'matrices', 'for', 'regression', 'analysis']",0,"['whats', 'the', 'use', 'of', 'matrix', 'for', 'regression', 'analysis']","['whats', 'use', 'matrix', 'regression', 'analysis']",whats use matrix regression analysis,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
3000,big data hadoop processing media files questions,Hackathons,big data hadoop processing media files questions,"['big', 'data', 'hadoop', 'processing', 'media', 'files', 'questions']",0,"['big', 'data', 'hadoop', 'processing', 'medium', 'file', 'question']","['big', 'data', 'hadoop', 'processing', 'medium', 'file', 'question']",big data hadoop processing medium file question,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
3001,friday funalytics share your favourite data science  analytics  statistics jokes or cartoons,Misc,friday funalytics share your favourite data science  analytics  statistics jokes or cartoons,"['friday', 'funalytics', 'share', 'your', 'favourite', 'data', 'science', 'analytics', 'statistics', 'jokes', 'or', 'cartoons']",0,"['friday', 'funalytics', 'share', 'your', 'favourite', 'data', 'science', 'analytics', 'statistic', 'joke', 'or', 'cartoon']","['friday', 'funalytics', 'share', 'favourite', 'data', 'science', 'analytics', 'statistic', 'joke', 'cartoon']",friday funalytics share favourite data science analytics statistic joke cartoon,0.0,0.0,12,79,6.076923076923077,0,0,0,0,0,0,0,0
3002,how do i get started with big data analysis,Other,how do i get started with big data analysis,"['how', 'do', 'i', 'get', 'started', 'with', 'big', 'data', 'analysis']",0,"['how', 'do', 'i', 'get', 'started', 'with', 'big', 'data', 'analysis']","['get', 'started', 'big', 'data', 'analysis']",get started big data analysis,0.0,0.0,9,29,2.9,0,0,0,0,0,0,0,0
3003,kmeans clustering with both numerical and categorical data in pyspark,Techniques,kmeans clustering with both numerical and categorical data in pyspark,"['kmeans', 'clustering', 'with', 'both', 'numerical', 'and', 'categorical', 'data', 'in', 'pyspark']",0,"['kmeans', 'clustering', 'with', 'both', 'numerical', 'and', 'categorical', 'data', 'in', 'pyspark']","['kmeans', 'clustering', 'numerical', 'categorical', 'data', 'pyspark']",kmeans clustering numerical categorical data pyspark,0.0,0.0,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
3004,hot to create a variable for cumulative values using retain statement in sas,Tools,hot to create a variable for cumulative values using retain statement in sas,"['hot', 'to', 'create', 'a', 'variable', 'for', 'cumulative', 'values', 'using', 'retain', 'statement', 'in', 'sas']",0,"['hot', 'to', 'create', 'a', 'variable', 'for', 'cumulative', 'value', 'using', 'retain', 'statement', 'in', 'sa']","['hot', 'create', 'variable', 'cumulative', 'value', 'using', 'retain', 'statement', 'sa']",hot create variable cumulative value using retain statement sa,0.25,0.25,13,62,4.428571428571429,0,0,0,0,0,0,0,0
3005,diagnostic metaregression with mada in r,Techniques,diagnostic metaregression with mada in r,"['diagnostic', 'metaregression', 'with', 'mada', 'in', 'r']",0,"['diagnostic', 'metaregression', 'with', 'mada', 'in', 'r']","['diagnostic', 'metaregression', 'mada', 'r']",diagnostic metaregression mada r,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
3006,how can we use google maps in r,Tools,how can we use google maps in r,"['how', 'can', 'we', 'use', 'google', 'maps', 'in', 'r']",0,"['how', 'can', 'we', 'use', 'google', 'map', 'in', 'r']","['use', 'google', 'map', 'r']",use google map r,0.0,0.0,8,16,1.7777777777777777,0,0,0,0,0,0,0,0
3007,how to choose the method argument in rpart,Techniques,how to choose the method argument in rpart,"['how', 'to', 'choose', 'the', 'method', 'argument', 'in', 'rpart']",0,"['how', 'to', 'choose', 'the', 'method', 'argument', 'in', 'rpart']","['choose', 'method', 'argument', 'rpart']",choose method argument rpart,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
3008,dealing with new packages in r,Other,dealing with new packages in r,"['dealing', 'with', 'new', 'packages', 'in', 'r']",0,"['dealing', 'with', 'new', 'package', 'in', 'r']","['dealing', 'new', 'package', 'r']",dealing new package r,0.1363636363636363,0.1363636363636363,6,21,3.0,0,0,0,0,0,0,0,0
3009,understanding the t test,Techniques,understanding the t test,"['understanding', 'the', 't', 'test']",0,"['understanding', 'the', 't', 'test']","['understanding', 'test']",understanding test,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
3010,batch normalization in data science,Career,batch normalization in data science,"['batch', 'normalization', 'in', 'data', 'science']",0,"['batch', 'normalization', 'in', 'data', 'science']","['batch', 'normalization', 'data', 'science']",batch normalization data science,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
3011,how to model a stationary series with no dependence among values,Techniques,how to model a stationary series with no dependence among values,"['how', 'to', 'model', 'a', 'stationary', 'series', 'with', 'no', 'dependence', 'among', 'values']",0,"['how', 'to', 'model', 'a', 'stationary', 'series', 'with', 'no', 'dependence', 'among', 'value']","['model', 'stationary', 'series', 'dependence', 'among', 'value']",model stationary series dependence among value,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
3012,how to corelate bmi with age,Techniques,how to corelate bmi with age,"['how', 'to', 'corelate', 'bmi', 'with', 'age']",0,"['how', 'to', 'corelate', 'bmi', 'with', 'age']","['corelate', 'bmi', 'age']",corelate bmi age,0.0,0.0,6,16,2.2857142857142856,0,0,0,0,0,0,0,0
3013,how to estimate multivariate conditional spatial mcar,Techniques,how to estimate multivariate conditional spatial mcar,"['how', 'to', 'estimate', 'multivariate', 'conditional', 'spatial', 'mcar']",0,"['how', 'to', 'estimate', 'multivariate', 'conditional', 'spatial', 'mcar']","['estimate', 'multivariate', 'conditional', 'spatial', 'mcar']",estimate multivariate conditional spatial mcar,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
3014,how to do perform smart data analysis for a huge set of variables,Techniques,how to do perform smart data analysis for a huge set of variables,"['how', 'to', 'do', 'perform', 'smart', 'data', 'analysis', 'for', 'a', 'huge', 'set', 'of', 'variables']",0,"['how', 'to', 'do', 'perform', 'smart', 'data', 'analysis', 'for', 'a', 'huge', 'set', 'of', 'variable']","['perform', 'smart', 'data', 'analysis', 'huge', 'set', 'variable']",perform smart data analysis huge set variable,0.3071428571428571,0.3071428571428571,13,45,3.2142857142857144,0,0,0,0,0,0,0,0
3015,classification hackthon using aucroc evaluation,Hackathons,classification hackthon using aucroc evaluation,"['classification', 'hackthon', 'using', 'aucroc', 'evaluation']",0,"['classification', 'hackthon', 'using', 'aucroc', 'evaluation']","['classification', 'hackthon', 'using', 'aucroc', 'evaluation']",classification hackthon using aucroc evaluation,0.0,0.0,5,47,7.833333333333333,0,0,0,0,0,0,0,0
3016,how to get output variables of pca from class hodimreductionmodel in r,Tools,how to get output variables of pca from class hodimreductionmodel in r,"['how', 'to', 'get', 'output', 'variables', 'of', 'pca', 'from', 'class', 'hodimreductionmodel', 'in', 'r']",0,"['how', 'to', 'get', 'output', 'variable', 'of', 'pca', 'from', 'class', 'hodimreductionmodel', 'in', 'r']","['get', 'output', 'variable', 'pca', 'class', 'hodimreductionmodel', 'r']",get output variable pca class hodimreductionmodel r,0.0,0.0,12,51,3.923076923076923,0,0,0,0,0,0,0,0
3017,what does a data scientist do on a daily basis share your experience and hear from experts,Career,what does a data scientist do on a daily basis share your experience and hear from experts,"['what', 'does', 'a', 'data', 'scientist', 'do', 'on', 'a', 'daily', 'basis', 'share', 'your', 'experience', 'and', 'hear', 'from', 'experts']",0,"['what', 'doe', 'a', 'data', 'scientist', 'do', 'on', 'a', 'daily', 'basis', 'share', 'your', 'experience', 'and', 'hear', 'from', 'expert']","['doe', 'data', 'scientist', 'daily', 'basis', 'share', 'experience', 'hear', 'expert']",doe data scientist daily basis share experience hear expert,0.0,0.0,17,59,3.2777777777777777,0,0,0,0,0,0,0,0
3018,validation in random forest and interpretation of oob and error estimate,Techniques,validation in random forest and interpretation of oob and error estimate,"['validation', 'in', 'random', 'forest', 'and', 'interpretation', 'of', 'oob', 'and', 'error', 'estimate']",0,"['validation', 'in', 'random', 'forest', 'and', 'interpretation', 'of', 'oob', 'and', 'error', 'estimate']","['validation', 'random', 'forest', 'interpretation', 'oob', 'error', 'estimate']",validation random forest interpretation oob error estimate,-0.5,-0.5,11,58,4.833333333333333,0,0,0,0,0,0,0,0
3019,how to select the optimal value of k for kmeans clustering,Techniques,how to select the optimal value of k for kmeans clustering,"['how', 'to', 'select', 'the', 'optimal', 'value', 'of', 'k', 'for', 'kmeans', 'clustering']",0,"['how', 'to', 'select', 'the', 'optimal', 'value', 'of', 'k', 'for', 'kmeans', 'clustering']","['select', 'optimal', 'value', 'k', 'kmeans', 'clustering']",select optimal value k kmeans clustering,0.0,0.0,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
3020,how to choose the number of splits in a tree,Techniques,how to choose the number of splits in a tree,"['how', 'to', 'choose', 'the', 'number', 'of', 'splits', 'in', 'a', 'tree']",0,"['how', 'to', 'choose', 'the', 'number', 'of', 'split', 'in', 'a', 'tree']","['choose', 'number', 'split', 'tree']",choose number split tree,0.0,0.0,10,24,2.1818181818181817,0,0,0,0,0,0,0,0
3021,how to auto adjust range of data source for pivot table in excel,Tools,how to auto adjust range of data source for pivot table in excel,"['how', 'to', 'auto', 'adjust', 'range', 'of', 'data', 'source', 'for', 'pivot', 'table', 'in', 'excel']",0,"['how', 'to', 'auto', 'adjust', 'range', 'of', 'data', 'source', 'for', 'pivot', 'table', 'in', 'excel']","['auto', 'adjust', 'range', 'data', 'source', 'pivot', 'table', 'excel']",auto adjust range data source pivot table excel,0.0,0.0,13,47,3.357142857142857,0,0,0,0,0,0,0,0
3022,career in babibusiness analytics and business intelligence,Career,career in babibusiness analytics and business intelligence,"['career', 'in', 'babibusiness', 'analytics', 'and', 'business', 'intelligence']",0,"['career', 'in', 'babibusiness', 'analytics', 'and', 'business', 'intelligence']","['career', 'babibusiness', 'analytics', 'business', 'intelligence']",career babibusiness analytics business intelligence,0.0,0.0,7,51,6.375,0,0,0,0,0,0,0,0
3023,how does factor works in rglm,Tools,how does factor works in rglm,"['how', 'does', 'factor', 'works', 'in', 'rglm']",0,"['how', 'doe', 'factor', 'work', 'in', 'rglm']","['doe', 'factor', 'work', 'rglm']",doe factor work rglm,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
3024,gradient boosting classifier in python  unable to run,Tools,gradient boosting classifier in python  unable to run,"['gradient', 'boosting', 'classifier', 'in', 'python', 'unable', 'to', 'run']",0,"['gradient', 'boosting', 'classifier', 'in', 'python', 'unable', 'to', 'run']","['gradient', 'boosting', 'classifier', 'python', 'unable', 'run']",gradient boosting classifier python unable run,-0.5,-0.5,8,46,5.111111111111111,0,0,0,0,0,0,0,0
3025,being a doctor and from nonit background how can i learn and become expert in data analytics and machine learning,Career,being a doctor and from nonit background how can i learn and become expert in data analytics and machine learning,"['being', 'a', 'doctor', 'and', 'from', 'nonit', 'background', 'how', 'can', 'i', 'learn', 'and', 'become', 'expert', 'in', 'data', 'analytics', 'and', 'machine', 'learning']",0,"['being', 'a', 'doctor', 'and', 'from', 'nonit', 'background', 'how', 'can', 'i', 'learn', 'and', 'become', 'expert', 'in', 'data', 'analytics', 'and', 'machine', 'learning']","['doctor', 'nonit', 'background', 'learn', 'become', 'expert', 'data', 'analytics', 'machine', 'learning']",doctor nonit background learn become expert data analytics machine learning,0.0,0.0,20,75,3.5714285714285716,0,0,0,0,0,0,0,0
3026,is there a way to perform edit distancelevenshtein character by character between two string columns,Techniques,is there a way to perform edit distancelevenshtein character by character between two string columns,"['is', 'there', 'a', 'way', 'to', 'perform', 'edit', 'distancelevenshtein', 'character', 'by', 'character', 'between', 'two', 'string', 'columns']",0,"['is', 'there', 'a', 'way', 'to', 'perform', 'edit', 'distancelevenshtein', 'character', 'by', 'character', 'between', 'two', 'string', 'column']","['way', 'perform', 'edit', 'distancelevenshtein', 'character', 'character', 'two', 'string', 'column']",way perform edit distancelevenshtein character character two string column,0.0,0.0,15,74,4.625,0,0,0,0,0,0,0,0
3027,mc requirements to practise model building,Resources,mc requirements to practise model building,"['mc', 'requirements', 'to', 'practise', 'model', 'building']",0,"['mc', 'requirement', 'to', 'practise', 'model', 'building']","['mc', 'requirement', 'practise', 'model', 'building']",mc requirement practise model building,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
3028,how subsample parameter affect xgbregressor for a time series data,Tools,how subsample parameter affect xgbregressor for a time series data,"['how', 'subsample', 'parameter', 'affect', 'xgbregressor', 'for', 'a', 'time', 'series', 'data']",0,"['how', 'subsample', 'parameter', 'affect', 'xgbregressor', 'for', 'a', 'time', 'series', 'data']","['subsample', 'parameter', 'affect', 'xgbregressor', 'time', 'series', 'data']",subsample parameter affect xgbregressor time series data,0.0,0.0,10,56,5.090909090909091,0,0,0,0,0,0,0,0
3029,advanced statistics,Techniques,advanced statistics,"['advanced', 'statistics']",0,"['advanced', 'statistic']","['advanced', 'statistic']",advanced statistic,0.4,0.4,2,18,6.0,0,0,0,0,0,0,0,0
3030,qlikviewqliksense integration with python or r,Tools,qlikviewqliksense integration with python or r,"['qlikviewqliksense', 'integration', 'with', 'python', 'or', 'r']",0,"['qlikviewqliksense', 'integration', 'with', 'python', 'or', 'r']","['qlikviewqliksense', 'integration', 'python', 'r']",qlikviewqliksense integration python r,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
3031,does this forum support queries about statistics or only datascience and predictions,Resources,does this forum support queries about statistics or only datascience and predictions,"['does', 'this', 'forum', 'support', 'queries', 'about', 'statistics', 'or', 'only', 'datascience', 'and', 'predictions']",0,"['doe', 'this', 'forum', 'support', 'query', 'about', 'statistic', 'or', 'only', 'datascience', 'and', 'prediction']","['doe', 'forum', 'support', 'query', 'statistic', 'datascience', 'prediction']",doe forum support query statistic datascience prediction,0.0,0.0,12,56,4.3076923076923075,0,0,0,0,0,0,0,0
3032,video handwriting recognition and classification in r,Tools,video handwriting recognition and classification in r,"['video', 'handwriting', 'recognition', 'and', 'classification', 'in', 'r']",0,"['video', 'handwriting', 'recognition', 'and', 'classification', 'in', 'r']","['video', 'handwriting', 'recognition', 'classification', 'r']",video handwriting recognition classification r,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
3033,how to check that two variable are same in r,Tools,how to check that two variable are same in r,"['how', 'to', 'check', 'that', 'two', 'variable', 'are', 'same', 'in', 'r']",0,"['how', 'to', 'check', 'that', 'two', 'variable', 'are', 'same', 'in', 'r']","['check', 'two', 'variable', 'r']",check two variable r,0.0,0.0,10,20,1.8181818181818181,0,0,0,0,0,0,0,0
3034,how to create fixed length between two values in r,Tools,how to create fixed length between two values in r,"['how', 'to', 'create', 'fixed', 'length', 'between', 'two', 'values', 'in', 'r']",0,"['how', 'to', 'create', 'fixed', 'length', 'between', 'two', 'value', 'in', 'r']","['create', 'fixed', 'length', 'two', 'value', 'r']",create fixed length two value r,0.1,0.1,10,31,2.8181818181818183,0,0,0,0,0,0,0,0
3035,data preprocessing,Techniques,data preprocessing,"['data', 'preprocessing']",0,"['data', 'preprocessing']","['data', 'preprocessing']",data preprocessing,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
3036,feedforward neural network not training with keras function generators,Techniques,feedforward neural network not training with keras function generators,"['feedforward', 'neural', 'network', 'not', 'training', 'with', 'keras', 'function', 'generators']",0,"['feedforward', 'neural', 'network', 'not', 'training', 'with', 'kera', 'function', 'generator']","['feedforward', 'neural', 'network', 'training', 'kera', 'function', 'generator']",feedforward neural network training kera function generator,0.0,0.0,9,59,5.9,0,0,0,0,0,0,0,0
3037,random forest to predict using the independent and dependent raster variables,Techniques,random forest to predict using the independent and dependent raster variables,"['random', 'forest', 'to', 'predict', 'using', 'the', 'independent', 'and', 'dependent', 'raster', 'variables']",0,"['random', 'forest', 'to', 'predict', 'using', 'the', 'independent', 'and', 'dependent', 'raster', 'variable']","['random', 'forest', 'predict', 'using', 'independent', 'dependent', 'raster', 'variable']",random forest predict using independent dependent raster variable,-0.25,-0.25,11,65,5.416666666666667,0,0,0,0,0,0,0,0
3038,missing value imputation  data missing,Hackathons,missing value imputation  data missing,"['missing', 'value', 'imputation', 'data', 'missing']",1,"['missing', 'value', 'imputation', 'data', 'missing']","['missing', 'value', 'imputation', 'data', 'missing']",missing value imputation data missing,-0.2,-0.2,5,37,6.166666666666667,0,0,0,0,0,0,0,0
3039,meaning and usage of residual deviance in analysis of deviance table after logistic regression,Techniques,meaning and usage of residual deviance in analysis of deviance table after logistic regression,"['meaning', 'and', 'usage', 'of', 'residual', 'deviance', 'in', 'analysis', 'of', 'deviance', 'table', 'after', 'logistic', 'regression']",0,"['meaning', 'and', 'usage', 'of', 'residual', 'deviance', 'in', 'analysis', 'of', 'deviance', 'table', 'after', 'logistic', 'regression']","['meaning', 'usage', 'residual', 'deviance', 'analysis', 'deviance', 'table', 'logistic', 'regression']",meaning usage residual deviance analysis deviance table logistic regression,0.0,0.0,14,75,5.0,0,0,0,0,0,0,0,0
3040,query regarding ml feature extraction and aggregated features,Techniques,query regarding ml feature extraction and aggregated features,"['query', 'regarding', 'ml', 'feature', 'extraction', 'and', 'aggregated', 'features']",0,"['query', 'regarding', 'ml', 'feature', 'extraction', 'and', 'aggregated', 'feature']","['query', 'regarding', 'ml', 'feature', 'extraction', 'aggregated', 'feature']",query regarding ml feature extraction aggregated feature,0.0,0.0,8,56,6.222222222222222,0,0,0,0,0,0,0,0
3041,building models using split date,Techniques,building models using split date,"['building', 'models', 'using', 'split', 'date']",0,"['building', 'model', 'using', 'split', 'date']","['building', 'model', 'using', 'split', 'date']",building model using split date,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
3042,sentimental analysis,Techniques,sentimental analysis,"['sentimental', 'analysis']",0,"['sentimental', 'analysis']","['sentimental', 'analysis']",sentimental analysis,-0.25,-0.25,2,20,6.666666666666667,0,0,0,0,0,0,0,0
3043,want to move from bi to ba domain,Career,want to move from bi to ba domain,"['want', 'to', 'move', 'from', 'bi', 'to', 'ba', 'domain']",0,"['want', 'to', 'move', 'from', 'bi', 'to', 'ba', 'domain']","['want', 'move', 'bi', 'ba', 'domain']",want move bi ba domain,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
3044,piping operator,Techniques,piping operator,"['piping', 'operator']",0,"['piping', 'operator']","['piping', 'operator']",piping operator,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
3045,onlyy columns are visible after spliiting the combined data set back into train and test,Hackathons,onlyy columns are visible after spliiting the combined data set back into train and test,"['onlyy', 'columns', 'are', 'visible', 'after', 'spliiting', 'the', 'combined', 'data', 'set', 'back', 'into', 'train', 'and', 'test']",0,"['onlyy', 'column', 'are', 'visible', 'after', 'spliiting', 'the', 'combined', 'data', 'set', 'back', 'into', 'train', 'and', 'test']","['onlyy', 'column', 'visible', 'spliiting', 'combined', 'data', 'set', 'back', 'train', 'test']",onlyy column visible spliiting combined data set back train test,0.0,0.0,15,64,4.0,0,0,0,0,0,0,0,0
3046,learning path for statisticsr and sql basics,Career,learning path for statisticsr and sql basics,"['learning', 'path', 'for', 'statisticsr', 'and', 'sql', 'basics']",0,"['learning', 'path', 'for', 'statisticsr', 'and', 'sql', 'basic']","['learning', 'path', 'statisticsr', 'sql', 'basic']",learning path statisticsr sql basic,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
3047,plotting error with matplot library,Techniques,plotting error with matplot library,"['plotting', 'error', 'with', 'matplot', 'library']",0,"['plotting', 'error', 'with', 'matplot', 'library']","['plotting', 'error', 'matplot', 'library']",plotting error matplot library,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
3048,how to add a patch in a plot in python,Tools,how to add a patch in a plot in python,"['how', 'to', 'add', 'a', 'patch', 'in', 'a', 'plot', 'in', 'python']",0,"['how', 'to', 'add', 'a', 'patch', 'in', 'a', 'plot', 'in', 'python']","['add', 'patch', 'plot', 'python']",add patch plot python,0.0,0.0,10,21,1.9090909090909092,0,0,0,0,0,0,0,0
3049,r studio working capacity on cloud,Techniques,r studio working capacity on cloud,"['r', 'studio', 'working', 'capacity', 'on', 'cloud']",0,"['r', 'studio', 'working', 'capacity', 'on', 'cloud']","['r', 'studio', 'working', 'capacity', 'cloud']",r studio working capacity cloud,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
3050,introductions  new members for july ,Misc,introductions  new members for july ,"['introductions', 'new', 'members', 'for', 'july']",1,"['introduction', 'new', 'member', 'for', 'july']","['introduction', 'new', 'member', 'july']",introduction new member july,0.1363636363636363,0.1363636363636363,5,28,4.666666666666667,0,0,0,0,0,0,0,0
3051,mask r cnn training sets,Techniques,mask r cnn training sets,"['mask', 'r', 'cnn', 'training', 'sets']",0,"['mask', 'r', 'cnn', 'training', 'set']","['mask', 'r', 'cnn', 'training', 'set']",mask r cnn training set,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
3052,how to get a job in analytics,Career,how to get a job in analytics,"['how', 'to', 'get', 'a', 'job', 'in', 'analytics']",0,"['how', 'to', 'get', 'a', 'job', 'in', 'analytics']","['get', 'job', 'analytics']",get job analytics,0.0,0.0,7,17,2.125,0,0,0,0,0,0,0,0
3053,manifold learning for dimension reduction,Techniques,manifold learning for dimension reduction,"['manifold', 'learning', 'for', 'dimension', 'reduction']",0,"['manifold', 'learning', 'for', 'dimension', 'reduction']","['manifold', 'learning', 'dimension', 'reduction']",manifold learning dimension reduction,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
3054,how to cluster graphs,Techniques,how to cluster graphs,"['how', 'to', 'cluster', 'graphs']",0,"['how', 'to', 'cluster', 'graph']","['cluster', 'graph']",cluster graph,0.0,0.0,4,13,2.6,0,0,0,0,0,0,0,0
3055,plotting quantile lines in a scatter plot,Techniques,plotting quantile lines in a scatter plot,"['plotting', 'quantile', 'lines', 'in', 'a', 'scatter', 'plot']",0,"['plotting', 'quantile', 'line', 'in', 'a', 'scatter', 'plot']","['plotting', 'quantile', 'line', 'scatter', 'plot']",plotting quantile line scatter plot,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
3056,what do i need to create a system that classifies bank packages for customers using previous customer data in python,Techniques,what do i need to create a system that classifies bank packages for customers using previous customer data in python,"['what', 'do', 'i', 'need', 'to', 'create', 'a', 'system', 'that', 'classifies', 'bank', 'packages', 'for', 'customers', 'using', 'previous', 'customer', 'data', 'in', 'python']",0,"['what', 'do', 'i', 'need', 'to', 'create', 'a', 'system', 'that', 'classifies', 'bank', 'package', 'for', 'customer', 'using', 'previous', 'customer', 'data', 'in', 'python']","['need', 'create', 'system', 'classifies', 'bank', 'package', 'customer', 'using', 'previous', 'customer', 'data', 'python']",need create system classifies bank package customer using previous customer data python,-0.1666666666666666,-0.1666666666666666,20,87,4.142857142857143,0,0,0,0,0,0,0,0
3057,how to detect outliers in categorical data,Techniques,how to detect outliers in categorical data,"['how', 'to', 'detect', 'outliers', 'in', 'categorical', 'data']",0,"['how', 'to', 'detect', 'outlier', 'in', 'categorical', 'data']","['detect', 'outlier', 'categorical', 'data']",detect outlier categorical data,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
3058,how to generate insights using box plots,Techniques,how to generate insights using box plots,"['how', 'to', 'generate', 'insights', 'using', 'box', 'plots']",0,"['how', 'to', 'generate', 'insight', 'using', 'box', 'plot']","['generate', 'insight', 'using', 'box', 'plot']",generate insight using box plot,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
3059,training models in r,Techniques,training models in r,"['training', 'models', 'in', 'r']",0,"['training', 'model', 'in', 'r']","['training', 'model', 'r']",training model r,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
3060,value error in logisticregression,Misc,value error in logisticregression,"['value', 'error', 'in', 'logisticregression']",0,"['value', 'error', 'in', 'logisticregression']","['value', 'error', 'logisticregression']",value error logisticregression,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
3061,speaker recognition for attendance,Techniques,speaker recognition for attendance,"['speaker', 'recognition', 'for', 'attendance']",0,"['speaker', 'recognition', 'for', 'attendance']","['speaker', 'recognition', 'attendance']",speaker recognition attendance,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
3062,one hot encoding,Tools,one hot encoding,"['one', 'hot', 'encoding']",0,"['one', 'hot', 'encoding']","['one', 'hot', 'encoding']",one hot encoding,0.25,0.25,3,16,4.0,0,0,0,0,0,0,0,0
3063,pandas left merge and sqldf left join giving different results,Tools,pandas left merge and sqldf left join giving different results,"['pandas', 'left', 'merge', 'and', 'sqldf', 'left', 'join', 'giving', 'different', 'results']",0,"['panda', 'left', 'merge', 'and', 'sqldf', 'left', 'join', 'giving', 'different', 'result']","['panda', 'left', 'merge', 'sqldf', 'left', 'join', 'giving', 'different', 'result']",panda left merge sqldf left join giving different result,0.0,0.0,10,56,5.090909090909091,0,0,0,0,0,0,0,0
3064,q what does the output of summary signifies,Techniques,q what does the output of summary signifies,"['q', 'what', 'does', 'the', 'output', 'of', 'summary', 'signifies']",0,"['q', 'what', 'doe', 'the', 'output', 'of', 'summary', 'signifies']","['q', 'doe', 'output', 'summary', 'signifies']",q doe output summary signifies,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
3065,can we get the location name based on longitude and latitude in python,Tools,can we get the location name based on longitude and latitude in python,"['can', 'we', 'get', 'the', 'location', 'name', 'based', 'on', 'longitude', 'and', 'latitude', 'in', 'python']",0,"['can', 'we', 'get', 'the', 'location', 'name', 'based', 'on', 'longitude', 'and', 'latitude', 'in', 'python']","['get', 'location', 'name', 'based', 'longitude', 'latitude', 'python']",get location name based longitude latitude python,0.0,0.0,13,49,3.5,0,0,0,0,0,0,0,0
3066,black friday practice problem features,Hackathons,black friday practice problem features,"['black', 'friday', 'practice', 'problem', 'features']",0,"['black', 'friday', 'practice', 'problem', 'feature']","['black', 'friday', 'practice', 'problem', 'feature']",black friday practice problem feature,-0.1666666666666666,-0.1666666666666666,5,37,6.166666666666667,0,0,0,0,0,0,0,0
3067,using target variable to perform principal component analysis in r,Resources,using target variable to perform principal component analysis in r,"['using', 'target', 'variable', 'to', 'perform', 'principal', 'component', 'analysis', 'in', 'r']",0,"['using', 'target', 'variable', 'to', 'perform', 'principal', 'component', 'analysis', 'in', 'r']","['using', 'target', 'variable', 'perform', 'principal', 'component', 'analysis', 'r']",using target variable perform principal component analysis r,0.0,0.0,10,60,5.454545454545454,0,0,0,0,0,0,0,0
3068,comparison between random forests and decision trees,Techniques,comparison between random forests and decision trees,"['comparison', 'between', 'random', 'forests', 'and', 'decision', 'trees']",0,"['comparison', 'between', 'random', 'forest', 'and', 'decision', 'tree']","['comparison', 'random', 'forest', 'decision', 'tree']",comparison random forest decision tree,-0.5,-0.5,7,38,4.75,0,0,0,0,0,0,0,0
3069,error with shape of dataset on loan prediction dataset,Techniques,error with shape of dataset on loan prediction dataset,"['error', 'with', 'shape', 'of', 'dataset', 'on', 'loan', 'prediction', 'dataset']",0,"['error', 'with', 'shape', 'of', 'dataset', 'on', 'loan', 'prediction', 'dataset']","['error', 'shape', 'dataset', 'loan', 'prediction', 'dataset']",error shape dataset loan prediction dataset,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
3070,how to train and test dataset with multiple fold data set,Techniques,how to train and test dataset with multiple fold data set,"['how', 'to', 'train', 'and', 'test', 'dataset', 'with', 'multiple', 'fold', 'data', 'set']",0,"['how', 'to', 'train', 'and', 'test', 'dataset', 'with', 'multiple', 'fold', 'data', 'set']","['train', 'test', 'dataset', 'multiple', 'fold', 'data', 'set']",train test dataset multiple fold data set,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
3071,combine classification agorithms,Techniques,combine classification agorithms,"['combine', 'classification', 'agorithms']",0,"['combine', 'classification', 'agorithms']","['combine', 'classification', 'agorithms']",combine classification agorithms,0.0,0.0,3,32,8.0,0,0,0,0,0,0,0,0
3072,what is feature space and how to map into feature spaces,Techniques,what is feature space and how to map into feature spaces,"['what', 'is', 'feature', 'space', 'and', 'how', 'to', 'map', 'into', 'feature', 'spaces']",0,"['what', 'is', 'feature', 'space', 'and', 'how', 'to', 'map', 'into', 'feature', 'space']","['feature', 'space', 'map', 'feature', 'space']",feature space map feature space,0.0,0.0,11,31,2.5833333333333335,0,0,0,0,0,0,0,0
3073,looking for collaborations,Resources,looking for collaborations,"['looking', 'for', 'collaborations']",0,"['looking', 'for', 'collaboration']","['looking', 'collaboration']",looking collaboration,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
3074,log analysis using ml,Techniques,log analysis using ml,"['log', 'analysis', 'using', 'ml']",0,"['log', 'analysis', 'using', 'ml']","['log', 'analysis', 'using', 'ml']",log analysis using ml,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
3075,research on recognizing criminals from facial features a boon or a curse,Resources,research on recognizing criminals from facial features a boon or a curse,"['research', 'on', 'recognizing', 'criminals', 'from', 'facial', 'features', 'a', 'boon', 'or', 'a', 'curse']",0,"['research', 'on', 'recognizing', 'criminal', 'from', 'facial', 'feature', 'a', 'boon', 'or', 'a', 'curse']","['research', 'recognizing', 'criminal', 'facial', 'feature', 'boon', 'curse']",research recognizing criminal facial feature boon curse,0.0,-0.2,12,55,4.230769230769231,0,0,0,0,0,0,0,0
3076,why we need to classify validation dataset along with train and test,Techniques,why we need to classify validation dataset along with train and test,"['why', 'we', 'need', 'to', 'classify', 'validation', 'dataset', 'along', 'with', 'train', 'and', 'test']",0,"['why', 'we', 'need', 'to', 'classify', 'validation', 'dataset', 'along', 'with', 'train', 'and', 'test']","['need', 'classify', 'validation', 'dataset', 'along', 'train', 'test']",need classify validation dataset along train test,0.0,0.0,12,49,3.769230769230769,0,0,0,0,0,0,0,0
3077,how does data visualization help in framing hypothesis,Techniques,how does data visualization help in framing hypothesis,"['how', 'does', 'data', 'visualization', 'help', 'in', 'framing', 'hypothesis']",0,"['how', 'doe', 'data', 'visualization', 'help', 'in', 'framing', 'hypothesis']","['doe', 'data', 'visualization', 'help', 'framing', 'hypothesis']",doe data visualization help framing hypothesis,0.0,0.0,8,46,5.111111111111111,0,0,0,0,0,0,0,0
3078,skill test in r,Tools,skill test in r,"['skill', 'test', 'in', 'r']",0,"['skill', 'test', 'in', 'r']","['skill', 'test', 'r']",skill test r,0.0,0.0,4,12,2.4,0,0,0,0,0,0,0,0
3079,how to get the ma coefficients for arma model given a timeseries dataset,Techniques,how to get the ma coefficients for arma model given a timeseries dataset,"['how', 'to', 'get', 'the', 'ma', 'coefficients', 'for', 'arma', 'model', 'given', 'a', 'timeseries', 'dataset']",0,"['how', 'to', 'get', 'the', 'ma', 'coefficient', 'for', 'arma', 'model', 'given', 'a', 'timeseries', 'dataset']","['get', 'coefficient', 'arma', 'model', 'given', 'timeseries', 'dataset']",get coefficient arma model given timeseries dataset,0.0,0.0,13,51,3.642857142857143,0,0,0,0,0,0,0,0
3080,how does boosting actually work,Techniques,how does boosting actually work,"['how', 'does', 'boosting', 'actually', 'work']",0,"['how', 'doe', 'boosting', 'actually', 'work']","['doe', 'boosting', 'actually', 'work']",doe boosting actually work,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
3081,when will the private lb get published,Hackathons,when will the private lb get published,"['when', 'will', 'the', 'private', 'lb', 'get', 'published']",0,"['when', 'will', 'the', 'private', 'lb', 'get', 'published']","['private', 'lb', 'get', 'published']",private lb get published,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
3082,prediction interval,Techniques,prediction interval,"['prediction', 'interval']",0,"['prediction', 'interval']","['prediction', 'interval']",prediction interval,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
3083,transfer learning on mask rcnn,Techniques,transfer learning on mask rcnn,"['transfer', 'learning', 'on', 'mask', 'rcnn']",0,"['transfer', 'learning', 'on', 'mask', 'rcnn']","['transfer', 'learning', 'mask', 'rcnn']",transfer learning mask rcnn,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
3084,not updating leaderboard,Hackathons,not updating leaderboard,"['not', 'updating', 'leaderboard']",0,"['not', 'updating', 'leaderboard']","['updating', 'leaderboard']",updating leaderboard,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
3085,analytics training at leadership level,Career,analytics training at leadership level,"['analytics', 'training', 'at', 'leadership', 'level']",0,"['analytics', 'training', 'at', 'leadership', 'level']","['analytics', 'training', 'leadership', 'level']",analytics training leadership level,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
3086,error in plotnew  figure margins too large while plotting multiple graphs on the same plot in r,Tools,error in plotnew  figure margins too large while plotting multiple graphs on the same plot in r,"['error', 'in', 'plotnew', 'figure', 'margins', 'too', 'large', 'while', 'plotting', 'multiple', 'graphs', 'on', 'the', 'same', 'plot', 'in', 'r']",0,"['error', 'in', 'plotnew', 'figure', 'margin', 'too', 'large', 'while', 'plotting', 'multiple', 'graph', 'on', 'the', 'same', 'plot', 'in', 'r']","['error', 'plotnew', 'figure', 'margin', 'large', 'plotting', 'multiple', 'graph', 'plot', 'r']",error plotnew figure margin large plotting multiple graph plot r,0.0714285714285714,0.1071428571428571,17,64,3.5555555555555554,0,0,0,0,0,0,0,0
3087,how does lstm learn over batches and epochs if it resets,Techniques,how does lstm learn over batches and epochs if it resets,"['how', 'does', 'lstm', 'learn', 'over', 'batches', 'and', 'epochs', 'if', 'it', 'resets']",0,"['how', 'doe', 'lstm', 'learn', 'over', 'batch', 'and', 'epoch', 'if', 'it', 'reset']","['doe', 'lstm', 'learn', 'batch', 'epoch', 'reset']",doe lstm learn batch epoch reset,0.0,0.0,11,32,2.6666666666666665,0,0,0,0,0,0,0,0
3088,leaderboard scoring  clarification needed,Hackathons,leaderboard scoring  clarification needed,"['leaderboard', 'scoring', 'clarification', 'needed']",0,"['leaderboard', 'scoring', 'clarification', 'needed']","['leaderboard', 'scoring', 'clarification', 'needed']",leaderboard scoring clarification needed,0.0,0.0,4,40,8.0,0,0,0,0,0,0,0,0
3089,data science program for non computer background people,Career,data science program for non computer background people,"['data', 'science', 'program', 'for', 'non', 'computer', 'background', 'people']",0,"['data', 'science', 'program', 'for', 'non', 'computer', 'background', 'people']","['data', 'science', 'program', 'non', 'computer', 'background', 'people']",data science program non computer background people,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
3090,chi square test of independence for large data,Techniques,chi square test of independence for large data,"['chi', 'square', 'test', 'of', 'independence', 'for', 'large', 'data']",0,"['chi', 'square', 'test', 'of', 'independence', 'for', 'large', 'data']","['chi', 'square', 'test', 'independence', 'large', 'data']",chi square test independence large data,0.2142857142857142,0.2142857142857142,8,39,4.333333333333333,0,0,0,0,0,0,0,0
3091,resource to learn statsmodels in python,Tools,resource to learn statsmodels in python,"['resource', 'to', 'learn', 'statsmodels', 'in', 'python']",0,"['resource', 'to', 'learn', 'statsmodels', 'in', 'python']","['resource', 'learn', 'statsmodels', 'python']",resource learn statsmodels python,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
3092,getting pvalue rsquared and adjusted rsquared value in python,Tools,getting pvalue rsquared and adjusted rsquared value in python,"['getting', 'pvalue', 'rsquared', 'and', 'adjusted', 'rsquared', 'value', 'in', 'python']",0,"['getting', 'pvalue', 'rsquared', 'and', 'adjusted', 'rsquared', 'value', 'in', 'python']","['getting', 'pvalue', 'rsquared', 'adjusted', 'rsquared', 'value', 'python']",getting pvalue rsquared adjusted rsquared value python,0.0,0.0,9,54,5.4,0,0,0,0,0,0,0,0
3093,how to do worker assignment for a product servicing and return back,Techniques,how to do worker assignment for a product servicing and return back,"['how', 'to', 'do', 'worker', 'assignment', 'for', 'a', 'product', 'servicing', 'and', 'return', 'back']",0,"['how', 'to', 'do', 'worker', 'assignment', 'for', 'a', 'product', 'servicing', 'and', 'return', 'back']","['worker', 'assignment', 'product', 'servicing', 'return', 'back']",worker assignment product servicing return back,0.0,0.0,12,47,3.6153846153846154,0,0,0,0,0,0,0,0
3094,how to find size of an object length breadth height using realsense and darknet,Techniques,how to find size of an object length breadth height using realsense and darknet,"['how', 'to', 'find', 'size', 'of', 'an', 'object', 'length', 'breadth', 'height', 'using', 'realsense', 'and', 'darknet']",0,"['how', 'to', 'find', 'size', 'of', 'an', 'object', 'length', 'breadth', 'height', 'using', 'realsense', 'and', 'darknet']","['find', 'size', 'object', 'length', 'breadth', 'height', 'using', 'realsense', 'darknet']",find size object length breadth height using realsense darknet,0.0,0.0,14,62,4.133333333333334,0,0,0,0,0,0,0,0
3095,free databases like iac database out there,Tools,free databases like iac database out there,"['free', 'databases', 'like', 'iac', 'database', 'out', 'there']",0,"['free', 'database', 'like', 'iac', 'database', 'out', 'there']","['free', 'database', 'like', 'iac', 'database']",free database like iac database,0.4,0.4,7,31,3.875,0,0,0,0,0,0,0,0
3096,error in tunerf,Tools,error in tunerf,"['error', 'in', 'tunerf']",0,"['error', 'in', 'tunerf']","['error', 'tunerf']",error tunerf,0.0,0.0,3,12,3.0,0,0,0,0,0,0,0,0
3097,steps to be followed when analyzing the datasets,Techniques,steps to be followed when analyzing the datasets,"['steps', 'to', 'be', 'followed', 'when', 'analyzing', 'the', 'datasets']",0,"['step', 'to', 'be', 'followed', 'when', 'analyzing', 'the', 'datasets']","['step', 'followed', 'analyzing', 'datasets']",step followed analyzing datasets,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
3098,how to set the parameters of gbm boost in r,Tools,how to set the parameters of gbm boost in r,"['how', 'to', 'set', 'the', 'parameters', 'of', 'gbm', 'boost', 'in', 'r']",0,"['how', 'to', 'set', 'the', 'parameter', 'of', 'gbm', 'boost', 'in', 'r']","['set', 'parameter', 'gbm', 'boost', 'r']",set parameter gbm boost r,0.0,0.0,10,25,2.272727272727273,0,0,0,0,0,0,0,0
3099,analytics in energy domainoil wells,Techniques,analytics in energy domainoil wells,"['analytics', 'in', 'energy', 'domainoil', 'wells']",0,"['analytics', 'in', 'energy', 'domainoil', 'well']","['analytics', 'energy', 'domainoil', 'well']",analytics energy domainoil well,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
3100,handing null values in multivariate time series,Techniques,handing null values in multivariate time series,"['handing', 'null', 'values', 'in', 'multivariate', 'time', 'series']",0,"['handing', 'null', 'value', 'in', 'multivariate', 'time', 'series']","['handing', 'null', 'value', 'multivariate', 'time', 'series']",handing null value multivariate time series,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
3101,r connection with mongodb,Techniques,r connection with mongodb,"['r', 'connection', 'with', 'mongodb']",0,"['r', 'connection', 'with', 'mongodb']","['r', 'connection', 'mongodb']",r connection mongodb,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
3102,regarding rnn article,Resources,regarding rnn article,"['regarding', 'rnn', 'article']",0,"['regarding', 'rnn', 'article']","['regarding', 'rnn', 'article']",regarding rnn article,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
3103,grass is greener on the other side of the world,Career,grass is greener on the other side of the world,"['grass', 'is', 'greener', 'on', 'the', 'other', 'side', 'of', 'the', 'world']",0,"['grass', 'is', 'greener', 'on', 'the', 'other', 'side', 'of', 'the', 'world']","['grass', 'greener', 'side', 'world']",grass greener side world,-0.125,0.0,10,24,2.1818181818181817,0,0,0,0,0,0,0,0
3104,what are alternate course sort of for upgrads  month data science program that one can think of taking up,Resources,what are alternate course sort of for upgrads  month data science program that one can think of taking up,"['what', 'are', 'alternate', 'course', 'sort', 'of', 'for', 'upgrads', 'month', 'data', 'science', 'program', 'that', 'one', 'can', 'think', 'of', 'taking', 'up']",1,"['what', 'are', 'alternate', 'course', 'sort', 'of', 'for', 'upgrads', 'month', 'data', 'science', 'program', 'that', 'one', 'can', 'think', 'of', 'taking', 'up']","['alternate', 'course', 'sort', 'upgrads', 'month', 'data', 'science', 'program', 'one', 'think', 'taking']",alternate course sort upgrads month data science program one think taking,0.0,0.0,19,73,3.65,0,0,0,0,0,0,0,0
3105,interpretation of corr function in r and corrplot function in r,Techniques,interpretation of corr function in r and corrplot function in r,"['interpretation', 'of', 'corr', 'function', 'in', 'r', 'and', 'corrplot', 'function', 'in', 'r']",0,"['interpretation', 'of', 'corr', 'function', 'in', 'r', 'and', 'corrplot', 'function', 'in', 'r']","['interpretation', 'corr', 'function', 'r', 'corrplot', 'function', 'r']",interpretation corr function r corrplot function r,0.0,0.0,11,50,4.166666666666667,0,0,0,0,0,0,0,0
3106,how to multiply the regression coefficients with the covariate in the original dataset using r,Techniques,how to multiply the regression coefficients with the covariate in the original dataset using r,"['how', 'to', 'multiply', 'the', 'regression', 'coefficients', 'with', 'the', 'covariate', 'in', 'the', 'original', 'dataset', 'using', 'r']",0,"['how', 'to', 'multiply', 'the', 'regression', 'coefficient', 'with', 'the', 'covariate', 'in', 'the', 'original', 'dataset', 'using', 'r']","['multiply', 'regression', 'coefficient', 'covariate', 'original', 'dataset', 'using', 'r']",multiply regression coefficient covariate original dataset using r,0.1875,0.1875,15,66,4.125,0,0,0,0,0,0,0,0
3107,splitting the data in kfold cv according to label,Techniques,splitting the data in kfold cv according to label,"['splitting', 'the', 'data', 'in', 'kfold', 'cv', 'according', 'to', 'label']",0,"['splitting', 'the', 'data', 'in', 'kfold', 'cv', 'according', 'to', 'label']","['splitting', 'data', 'kfold', 'cv', 'according', 'label']",splitting data kfold cv according label,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
3108,how can we do data mining and analysis on data from sites other than facebook and twitter,Other,how can we do data mining and analysis on data from sites other than facebook and twitter,"['how', 'can', 'we', 'do', 'data', 'mining', 'and', 'analysis', 'on', 'data', 'from', 'sites', 'other', 'than', 'facebook', 'and', 'twitter']",0,"['how', 'can', 'we', 'do', 'data', 'mining', 'and', 'analysis', 'on', 'data', 'from', 'site', 'other', 'than', 'facebook', 'and', 'twitter']","['data', 'mining', 'analysis', 'data', 'site', 'facebook', 'twitter']",data mining analysis data site facebook twitter,-0.125,0.0,17,47,2.611111111111111,0,0,0,0,0,0,0,0
3109,how to implement a predictive model,Other,how to implement a predictive model,"['how', 'to', 'implement', 'a', 'predictive', 'model']",0,"['how', 'to', 'implement', 'a', 'predictive', 'model']","['implement', 'predictive', 'model']",implement predictive model,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
3110,can a college dropout become a data scientist,Career,can a college dropout become a data scientist,"['can', 'a', 'college', 'dropout', 'become', 'a', 'data', 'scientist']",0,"['can', 'a', 'college', 'dropout', 'become', 'a', 'data', 'scientist']","['college', 'dropout', 'become', 'data', 'scientist']",college dropout become data scientist,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
3111,final year project ideas in machine learning,Career,final year project ideas in machine learning,"['final', 'year', 'project', 'ideas', 'in', 'machine', 'learning']",0,"['final', 'year', 'project', 'idea', 'in', 'machine', 'learning']","['final', 'year', 'project', 'idea', 'machine', 'learning']",final year project idea machine learning,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
3112,sas predictive modeling,Tools,sas predictive modeling,"['sas', 'predictive', 'modeling']",0,"['sa', 'predictive', 'modeling']","['sa', 'predictive', 'modeling']",sa predictive modeling,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
3113,random forest r problem,Techniques,random forest r problem,"['random', 'forest', 'r', 'problem']",0,"['random', 'forest', 'r', 'problem']","['random', 'forest', 'r', 'problem']",random forest r problem,-0.5,-0.5,4,23,4.6,0,0,0,0,0,0,0,0
3114,non linear pca and its applications,Techniques,non linear pca and its applications,"['non', 'linear', 'pca', 'and', 'its', 'applications']",0,"['non', 'linear', 'pca', 'and', 'it', 'application']","['non', 'linear', 'pca', 'application']",non linear pca application,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
3115,logistic regression in r,Tools,logistic regression in r,"['logistic', 'regression', 'in', 'r']",0,"['logistic', 'regression', 'in', 'r']","['logistic', 'regression', 'r']",logistic regression r,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
3116,correlation matrix on a very large dataset,Techniques,correlation matrix on a very large dataset,"['correlation', 'matrix', 'on', 'a', 'very', 'large', 'dataset']",0,"['correlation', 'matrix', 'on', 'a', 'very', 'large', 'dataset']","['correlation', 'matrix', 'large', 'dataset']",correlation matrix large dataset,0.2785714285714286,0.2142857142857142,7,32,4.0,0,0,0,0,0,0,0,0
3117,ltfs hackathon discussion,Hackathons,ltfs hackathon discussion,"['ltfs', 'hackathon', 'discussion']",0,"['ltfs', 'hackathon', 'discussion']","['ltfs', 'hackathon', 'discussion']",ltfs hackathon discussion,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
3118,heatmap and dendogram creation,Other,heatmap and dendogram creation,"['heatmap', 'and', 'dendogram', 'creation']",0,"['heatmap', 'and', 'dendogram', 'creation']","['heatmap', 'dendogram', 'creation']",heatmap dendogram creation,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
3119,extract only text from textnumeric value of cell in excel,Tools,extract only text from textnumeric value of cell in excel,"['extract', 'only', 'text', 'from', 'textnumeric', 'value', 'of', 'cell', 'in', 'excel']",0,"['extract', 'only', 'text', 'from', 'textnumeric', 'value', 'of', 'cell', 'in', 'excel']","['extract', 'text', 'textnumeric', 'value', 'cell', 'excel']",extract text textnumeric value cell excel,0.0,0.0,10,41,3.727272727272727,0,0,0,0,0,0,0,0
3120,convert timeseries data as stationary,Techniques,convert timeseries data as stationary,"['convert', 'timeseries', 'data', 'as', 'stationary']",0,"['convert', 'timeseries', 'data', 'a', 'stationary']","['convert', 'timeseries', 'data', 'stationary']",convert timeseries data stationary,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
3121,how can we control the number of observation for a straight table in qlikview,Tools,how can we control the number of observation for a straight table in qlikview,"['how', 'can', 'we', 'control', 'the', 'number', 'of', 'observation', 'for', 'a', 'straight', 'table', 'in', 'qlikview']",0,"['how', 'can', 'we', 'control', 'the', 'number', 'of', 'observation', 'for', 'a', 'straight', 'table', 'in', 'qlikview']","['control', 'number', 'observation', 'straight', 'table', 'qlikview']",control number observation straight table qlikview,0.2,0.2,14,50,3.3333333333333335,0,0,0,0,0,0,0,0
3122,how do convolutional neural networks work for text classification,Techniques,how do convolutional neural networks work for text classification,"['how', 'do', 'convolutional', 'neural', 'networks', 'work', 'for', 'text', 'classification']",0,"['how', 'do', 'convolutional', 'neural', 'network', 'work', 'for', 'text', 'classification']","['convolutional', 'neural', 'network', 'work', 'text', 'classification']",convolutional neural network work text classification,0.0,0.0,9,53,5.3,0,0,0,0,0,0,0,0
3123,arima model in python,Techniques,arima model in python,"['arima', 'model', 'in', 'python']",0,"['arima', 'model', 'in', 'python']","['arima', 'model', 'python']",arima model python,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
3124,data science  newbie advice,Other,data science  newbie advice,"['data', 'science', 'newbie', 'advice']",0,"['data', 'science', 'newbie', 'advice']","['data', 'science', 'newbie', 'advice']",data science newbie advice,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
3125,what is the difference between logit and probit models,Techniques,what is the difference between logit and probit models,"['what', 'is', 'the', 'difference', 'between', 'logit', 'and', 'probit', 'models']",0,"['what', 'is', 'the', 'difference', 'between', 'logit', 'and', 'probit', 'model']","['difference', 'logit', 'probit', 'model']",difference logit probit model,0.0,0.0,9,29,2.9,0,0,0,0,0,0,0,0
3126,business analytics for civil engineers,Career,business analytics for civil engineers,"['business', 'analytics', 'for', 'civil', 'engineers']",0,"['business', 'analytics', 'for', 'civil', 'engineer']","['business', 'analytics', 'civil', 'engineer']",business analytics civil engineer,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
3127,feature selection with lda,Techniques,feature selection with lda,"['feature', 'selection', 'with', 'lda']",0,"['feature', 'selection', 'with', 'lda']","['feature', 'selection', 'lda']",feature selection lda,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
3128,how to transpose two variable together in sas,Tools,how to transpose two variable together in sas,"['how', 'to', 'transpose', 'two', 'variable', 'together', 'in', 'sas']",0,"['how', 'to', 'transpose', 'two', 'variable', 'together', 'in', 'sa']","['transpose', 'two', 'variable', 'together', 'sa']",transpose two variable together sa,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
3129,how to access any element of data frame in r,Tools,how to access any element of data frame in r,"['how', 'to', 'access', 'any', 'element', 'of', 'data', 'frame', 'in', 'r']",0,"['how', 'to', 'access', 'any', 'element', 'of', 'data', 'frame', 'in', 'r']","['access', 'element', 'data', 'frame', 'r']",access element data frame r,0.0,0.0,10,27,2.4545454545454546,0,0,0,0,0,0,0,0
3130,best course for masters degree in analytics,Career,best course for masters degree in analytics,"['best', 'course', 'for', 'masters', 'degree', 'in', 'analytics']",0,"['best', 'course', 'for', 'master', 'degree', 'in', 'analytics']","['best', 'course', 'master', 'degree', 'analytics']",best course master degree analytics,1.0,1.0,7,35,4.375,0,0,0,0,0,0,0,0
3131,clarification of calculation used in transformer tutorial,Techniques,clarification of calculation used in transformer tutorial,"['clarification', 'of', 'calculation', 'used', 'in', 'transformer', 'tutorial']",0,"['clarification', 'of', 'calculation', 'used', 'in', 'transformer', 'tutorial']","['clarification', 'calculation', 'used', 'transformer', 'tutorial']",clarification calculation used transformer tutorial,0.0,0.0,7,51,6.375,0,0,0,0,0,0,0,0
3132,time series frequency   in r,Techniques,time series frequency   in r,"['time', 'series', 'frequency', 'in', 'r']",0,"['time', 'series', 'frequency', 'in', 'r']","['time', 'series', 'frequency', 'r']",time series frequency r,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
3133,internship suggestions,Career,internship suggestions,"['internship', 'suggestions']",0,"['internship', 'suggestion']","['internship', 'suggestion']",internship suggestion,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
3134,issue in set analysisnot getting value displayed,Techniques,issue in set analysisnot getting value displayed,"['issue', 'in', 'set', 'analysisnot', 'getting', 'value', 'displayed']",0,"['issue', 'in', 'set', 'analysisnot', 'getting', 'value', 'displayed']","['issue', 'set', 'analysisnot', 'getting', 'value', 'displayed']",issue set analysisnot getting value displayed,0.0,0.0,7,45,5.625,0,0,0,0,0,0,0,0
3135,problem in loading mnist data,Techniques,problem in loading mnist data,"['problem', 'in', 'loading', 'mnist', 'data']",0,"['problem', 'in', 'loading', 'mnist', 'data']","['problem', 'loading', 'mnist', 'data']",problem loading mnist data,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
3136,how to fix the length of cells in excel,Tools,how to fix the length of cells in excel,"['how', 'to', 'fix', 'the', 'length', 'of', 'cells', 'in', 'excel']",0,"['how', 'to', 'fix', 'the', 'length', 'of', 'cell', 'in', 'excel']","['fix', 'length', 'cell', 'excel']",fix length cell excel,0.0,0.0,9,21,2.1,0,0,0,0,0,0,0,0
3137,which log transformation to use for moderately skewed data with zero values,Techniques,which log transformation to use for moderately skewed data with zero values,"['which', 'log', 'transformation', 'to', 'use', 'for', 'moderately', 'skewed', 'data', 'with', 'zero', 'values']",0,"['which', 'log', 'transformation', 'to', 'use', 'for', 'moderately', 'skewed', 'data', 'with', 'zero', 'value']","['log', 'transformation', 'use', 'moderately', 'skewed', 'data', 'zero', 'value']",log transformation use moderately skewed data zero value,0.0,0.0,12,56,4.3076923076923075,0,0,0,0,0,0,0,0
3138,how to fill the missing value with fixed number of consecutive period of a data frame in python,Tools,how to fill the missing value with fixed number of consecutive period of a data frame in python,"['how', 'to', 'fill', 'the', 'missing', 'value', 'with', 'fixed', 'number', 'of', 'consecutive', 'period', 'of', 'a', 'data', 'frame', 'in', 'python']",0,"['how', 'to', 'fill', 'the', 'missing', 'value', 'with', 'fixed', 'number', 'of', 'consecutive', 'period', 'of', 'a', 'data', 'frame', 'in', 'python']","['fill', 'missing', 'value', 'fixed', 'number', 'consecutive', 'period', 'data', 'frame', 'python']",fill missing value fixed number consecutive period data frame python,-0.05,-0.05,18,68,3.5789473684210527,0,0,0,0,0,0,0,0
3139,how to subtract series and data frame column wise in python,Tools,how to subtract series and data frame column wise in python,"['how', 'to', 'subtract', 'series', 'and', 'data', 'frame', 'column', 'wise', 'in', 'python']",0,"['how', 'to', 'subtract', 'series', 'and', 'data', 'frame', 'column', 'wise', 'in', 'python']","['subtract', 'series', 'data', 'frame', 'column', 'wise', 'python']",subtract series data frame column wise python,0.7,0.7,11,45,3.75,0,0,0,0,0,0,0,0
3140,regression modelling question,Other,regression modelling question,"['regression', 'modelling', 'question']",0,"['regression', 'modelling', 'question']","['regression', 'modelling', 'question']",regression modelling question,0.0,0.0,3,29,7.25,0,0,0,0,0,0,0,0
3141,how much is anova used in real data science projects,Techniques,how much is anova used in real data science projects,"['how', 'much', 'is', 'anova', 'used', 'in', 'real', 'data', 'science', 'projects']",0,"['how', 'much', 'is', 'anova', 'used', 'in', 'real', 'data', 'science', 'project']","['much', 'anova', 'used', 'real', 'data', 'science', 'project']",much anova used real data science project,0.2,0.2,10,41,3.727272727272727,0,0,0,0,0,0,0,0
3142,executive mba in business analytics,Career,executive mba in business analytics,"['executive', 'mba', 'in', 'business', 'analytics']",0,"['executive', 'mba', 'in', 'business', 'analytics']","['executive', 'mba', 'business', 'analytics']",executive mba business analytics,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
3143,what is difference between factor analysis and principal component analysis,Techniques,what is difference between factor analysis and principal component analysis,"['what', 'is', 'difference', 'between', 'factor', 'analysis', 'and', 'principal', 'component', 'analysis']",0,"['what', 'is', 'difference', 'between', 'factor', 'analysis', 'and', 'principal', 'component', 'analysis']","['difference', 'factor', 'analysis', 'principal', 'component', 'analysis']",difference factor analysis principal component analysis,0.0,0.0,10,55,5.0,0,0,0,0,0,0,0,0
3144,logic for grouping cities,Techniques,logic for grouping cities,"['logic', 'for', 'grouping', 'cities']",0,"['logic', 'for', 'grouping', 'city']","['logic', 'grouping', 'city']",logic grouping city,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
3145,career transition with  years nonanalytics exp,Career,career transition with  years nonanalytics exp,"['career', 'transition', 'with', 'years', 'nonanalytics', 'exp']",1,"['career', 'transition', 'with', 'year', 'nonanalytics', 'exp']","['career', 'transition', 'year', 'nonanalytics', 'exp']",career transition year nonanalytics exp,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
3146,xgboost multiclass classification,Techniques,xgboost multiclass classification,"['xgboost', 'multiclass', 'classification']",0,"['xgboost', 'multiclass', 'classification']","['xgboost', 'multiclass', 'classification']",xgboost multiclass classification,0.0,0.0,3,33,8.25,0,0,0,0,0,0,0,0
3147,how geompoint differ from geomjitter in ggplot package,Techniques,how geompoint differ from geomjitter in ggplot package,"['how', 'geompoint', 'differ', 'from', 'geomjitter', 'in', 'ggplot', 'package']",0,"['how', 'geompoint', 'differ', 'from', 'geomjitter', 'in', 'ggplot', 'package']","['geompoint', 'differ', 'geomjitter', 'ggplot', 'package']",geompoint differ geomjitter ggplot package,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
3148,next best product  best approach,Techniques,next best product  best approach,"['next', 'best', 'product', 'best', 'approach']",0,"['next', 'best', 'product', 'best', 'approach']","['next', 'best', 'product', 'best', 'approach']",next best product best approach,0.6666666666666666,0.6666666666666666,5,31,5.166666666666667,0,0,0,0,0,0,0,0
3149,cleanlab  automatically find errors in ml datasets,Resources,cleanlab  automatically find errors in ml datasets,"['cleanlab', 'automatically', 'find', 'errors', 'in', 'ml', 'datasets']",1,"['cleanlab', 'automatically', 'find', 'error', 'in', 'ml', 'datasets']","['cleanlab', 'automatically', 'find', 'error', 'ml', 'datasets']",cleanlab automatically find error ml datasets,0.0,0.0,7,45,5.625,0,0,0,0,0,0,0,0
3150,stock market predictions using lstm,Techniques,stock market predictions using lstm,"['stock', 'market', 'predictions', 'using', 'lstm']",0,"['stock', 'market', 'prediction', 'using', 'lstm']","['stock', 'market', 'prediction', 'using', 'lstm']",stock market prediction using lstm,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
3151,nonnumeric argument to binary operator r,Tools,nonnumeric argument to binary operator r,"['nonnumeric', 'argument', 'to', 'binary', 'operator', 'r']",0,"['nonnumeric', 'argument', 'to', 'binary', 'operator', 'r']","['nonnumeric', 'argument', 'binary', 'operator', 'r']",nonnumeric argument binary operator r,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
3152,pursuing a career in data analytics for a non computer science student,Career,pursuing a career in data analytics for a non computer science student,"['pursuing', 'a', 'career', 'in', 'data', 'analytics', 'for', 'a', 'non', 'computer', 'science', 'student']",0,"['pursuing', 'a', 'career', 'in', 'data', 'analytics', 'for', 'a', 'non', 'computer', 'science', 'student']","['pursuing', 'career', 'data', 'analytics', 'non', 'computer', 'science', 'student']",pursuing career data analytics non computer science student,0.0,0.0,12,59,4.538461538461538,0,0,0,0,0,0,0,0
3153,issue in accessing introduction to data science course,Other,issue in accessing introduction to data science course,"['issue', 'in', 'accessing', 'introduction', 'to', 'data', 'science', 'course']",0,"['issue', 'in', 'accessing', 'introduction', 'to', 'data', 'science', 'course']","['issue', 'accessing', 'introduction', 'data', 'science', 'course']",issue accessing introduction data science course,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
3154,error in visualizing the predictions,Techniques,error in visualizing the predictions,"['error', 'in', 'visualizing', 'the', 'predictions']",0,"['error', 'in', 'visualizing', 'the', 'prediction']","['error', 'visualizing', 'prediction']",error visualizing prediction,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
3155,transforming dataset,Techniques,transforming dataset,"['transforming', 'dataset']",0,"['transforming', 'dataset']","['transforming', 'dataset']",transforming dataset,0.0,0.0,2,20,6.666666666666667,0,0,0,0,0,0,0,0
3156,how to extract data from an html file using python,Other,how to extract data from an html file using python,"['how', 'to', 'extract', 'data', 'from', 'an', 'html', 'file', 'using', 'python']",0,"['how', 'to', 'extract', 'data', 'from', 'an', 'html', 'file', 'using', 'python']","['extract', 'data', 'html', 'file', 'using', 'python']",extract data html file using python,0.0,0.0,10,35,3.1818181818181817,0,0,0,0,0,0,0,0
3157,how to resolve python error cannot compare a dtyped int array with a scalar of type bool,Techniques,how to resolve python error cannot compare a dtyped int array with a scalar of type bool,"['how', 'to', 'resolve', 'python', 'error', 'can', 'not', 'compare', 'a', 'dtyped', 'int', 'array', 'with', 'a', 'scalar', 'of', 'type', 'bool']",0,"['how', 'to', 'resolve', 'python', 'error', 'can', 'not', 'compare', 'a', 'dtyped', 'int', 'array', 'with', 'a', 'scalar', 'of', 'type', 'bool']","['resolve', 'python', 'error', 'compare', 'dtyped', 'int', 'array', 'scalar', 'type', 'bool']",resolve python error compare dtyped int array scalar type bool,0.0,0.0,18,62,3.263157894736842,0,0,0,0,0,0,0,0
3158,mathematical modeling,Other,mathematical modeling,"['mathematical', 'modeling']",0,"['mathematical', 'modeling']","['mathematical', 'modeling']",mathematical modeling,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
3159,allocation in retail,Resources,allocation in retail,"['allocation', 'in', 'retail']",0,"['allocation', 'in', 'retail']","['allocation', 'retail']",allocation retail,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
3160,ggplot  dont know how to automatically pick scale for object of type function  error,Tools,ggplot  dont know how to automatically pick scale for object of type function  error,"['ggplot', 'dont', 'know', 'how', 'to', 'automatically', 'pick', 'scale', 'for', 'object', 'of', 'type', 'function', 'error']",0,"['ggplot', 'dont', 'know', 'how', 'to', 'automatically', 'pick', 'scale', 'for', 'object', 'of', 'type', 'function', 'error']","['ggplot', 'dont', 'know', 'automatically', 'pick', 'scale', 'object', 'type', 'function', 'error']",ggplot dont know automatically pick scale object type function error,0.0,0.0,14,68,4.533333333333333,0,0,0,0,0,0,0,0
3161,why is the error term considered to be of mean zero in linear regression,Techniques,why is the error term considered to be of mean zero in linear regression,"['why', 'is', 'the', 'error', 'term', 'considered', 'to', 'be', 'of', 'mean', 'zero', 'in', 'linear', 'regression']",0,"['why', 'is', 'the', 'error', 'term', 'considered', 'to', 'be', 'of', 'mean', 'zero', 'in', 'linear', 'regression']","['error', 'term', 'considered', 'mean', 'zero', 'linear', 'regression']",error term considered mean zero linear regression,-0.3125,-0.3125,14,49,3.2666666666666666,0,0,0,0,0,0,0,0
3162,how to save figure in python,Tools,how to save figure in python,"['how', 'to', 'save', 'figure', 'in', 'python']",0,"['how', 'to', 'save', 'figure', 'in', 'python']","['save', 'figure', 'python']",save figure python,0.0,0.0,6,18,2.5714285714285716,0,0,0,0,0,0,0,0
3163,approach and algorithm queries,Techniques,approach and algorithm queries,"['approach', 'and', 'algorithm', 'queries']",0,"['approach', 'and', 'algorithm', 'query']","['approach', 'algorithm', 'query']",approach algorithm query,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
3164,xgbcv and xgbtrain  why it is showing different train and test rmse values,Techniques,xgbcv and xgbtrain  why it is showing different train and test rmse values,"['xgbcv', 'and', 'xgbtrain', 'why', 'it', 'is', 'showing', 'different', 'train', 'and', 'test', 'rmse', 'values']",0,"['xgbcv', 'and', 'xgbtrain', 'why', 'it', 'is', 'showing', 'different', 'train', 'and', 'test', 'rmse', 'value']","['xgbcv', 'xgbtrain', 'showing', 'different', 'train', 'test', 'rmse', 'value']",xgbcv xgbtrain showing different train test rmse value,0.0,0.0,13,54,3.857142857142857,0,0,0,0,0,0,0,0
3165,fucntion for building a gbm model,Techniques,fucntion for building a gbm model,"['fucntion', 'for', 'building', 'a', 'gbm', 'model']",0,"['fucntion', 'for', 'building', 'a', 'gbm', 'model']","['fucntion', 'building', 'gbm', 'model']",fucntion building gbm model,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
3166,career guidance for midcareer switch,Career,career guidance for midcareer switch,"['career', 'guidance', 'for', 'midcareer', 'switch']",0,"['career', 'guidance', 'for', 'midcareer', 'switch']","['career', 'guidance', 'midcareer', 'switch']",career guidance midcareer switch,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
3167,what is additive smoothing,Techniques,what is additive smoothing,"['what', 'is', 'additive', 'smoothing']",0,"['what', 'is', 'additive', 'smoothing']","['additive', 'smoothing']",additive smoothing,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
3168,closed poll which tool do you use the most for data mining,Tools,closed poll which tool do you use the most for data mining,"['closed', 'poll', 'which', 'tool', 'do', 'you', 'use', 'the', 'most', 'for', 'data', 'mining']",0,"['closed', 'poll', 'which', 'tool', 'do', 'you', 'use', 'the', 'most', 'for', 'data', 'mining']","['closed', 'poll', 'tool', 'use', 'data', 'mining']",closed poll tool use data mining,0.2,-0.1,12,32,2.4615384615384617,0,0,0,0,0,0,0,0
3169,how to select significant input variables for a multiple regression model in r,Techniques,how to select significant input variables for a multiple regression model in r,"['how', 'to', 'select', 'significant', 'input', 'variables', 'for', 'a', 'multiple', 'regression', 'model', 'in', 'r']",0,"['how', 'to', 'select', 'significant', 'input', 'variable', 'for', 'a', 'multiple', 'regression', 'model', 'in', 'r']","['select', 'significant', 'input', 'variable', 'multiple', 'regression', 'model', 'r']",select significant input variable multiple regression model r,0.1875,0.1875,13,61,4.357142857142857,0,0,0,0,0,0,0,0
3170,what percent of missing value is allowed for modeling,Techniques,what percent of missing value is allowed for modeling,"['what', 'percent', 'of', 'missing', 'value', 'is', 'allowed', 'for', 'modeling']",0,"['what', 'percent', 'of', 'missing', 'value', 'is', 'allowed', 'for', 'modeling']","['percent', 'missing', 'value', 'allowed', 'modeling']",percent missing value allowed modeling,-0.2,-0.2,9,38,3.8,0,0,0,0,0,0,0,0
3171,which role do i choose statistical analyst or data scientist,Career,which role do i choose statistical analyst or data scientist,"['which', 'role', 'do', 'i', 'choose', 'statistical', 'analyst', 'or', 'data', 'scientist']",0,"['which', 'role', 'do', 'i', 'choose', 'statistical', 'analyst', 'or', 'data', 'scientist']","['role', 'choose', 'statistical', 'analyst', 'data', 'scientist']",role choose statistical analyst data scientist,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
3172,big mart sell fat content,Techniques,big mart sell fat content,"['big', 'mart', 'sell', 'fat', 'content']",0,"['big', 'mart', 'sell', 'fat', 'content']","['big', 'mart', 'sell', 'fat', 'content']",big mart sell fat content,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
3173,how do i improve my random forest prediction rate from ,Tools,how do i improve my random forest prediction rate from ,"['how', 'do', 'i', 'improve', 'my', 'random', 'forest', 'prediction', 'rate', 'from']",1,"['how', 'do', 'i', 'improve', 'my', 'random', 'forest', 'prediction', 'rate', 'from']","['improve', 'random', 'forest', 'prediction', 'rate']",improve random forest prediction rate,-0.5,-0.5,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
3174,how to do stock chart pattern recognition algorithmically,Other,how to do stock chart pattern recognition algorithmically,"['how', 'to', 'do', 'stock', 'chart', 'pattern', 'recognition', 'algorithmically']",0,"['how', 'to', 'do', 'stock', 'chart', 'pattern', 'recognition', 'algorithmically']","['stock', 'chart', 'pattern', 'recognition', 'algorithmically']",stock chart pattern recognition algorithmically,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
3175,what does the importance column from the output of boosting tell us,Techniques,what does the importance column from the output of boosting tell us,"['what', 'does', 'the', 'importance', 'column', 'from', 'the', 'output', 'of', 'boosting', 'tell', 'us']",0,"['what', 'doe', 'the', 'importance', 'column', 'from', 'the', 'output', 'of', 'boosting', 'tell', 'u']","['doe', 'importance', 'column', 'output', 'boosting', 'tell', 'u']",doe importance column output boosting tell u,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
3176,identify column values that are in train but missing in test,Tools,identify column values that are in train but missing in test,"['identify', 'column', 'values', 'that', 'are', 'in', 'train', 'but', 'missing', 'in', 'test']",0,"['identify', 'column', 'value', 'that', 'are', 'in', 'train', 'but', 'missing', 'in', 'test']","['identify', 'column', 'value', 'train', 'missing', 'test']",identify column value train missing test,-0.2,-0.2,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
3177,frcnn testpy wont create any bounding boxes on img,Techniques,frcnn testpy wont create any bounding boxes on img,"['frcnn', 'testpy', 'wont', 'create', 'any', 'bounding', 'boxes', 'on', 'img']",0,"['frcnn', 'testpy', 'wont', 'create', 'any', 'bounding', 'box', 'on', 'img']","['frcnn', 'testpy', 'wont', 'create', 'bounding', 'box', 'img']",frcnn testpy wont create bounding box img,0.0,0.0,9,41,4.1,0,0,0,0,0,0,0,0
3178,diploma in big data analytics from cdac,Career,diploma in big data analytics from cdac,"['diploma', 'in', 'big', 'data', 'analytics', 'from', 'cdac']",0,"['diploma', 'in', 'big', 'data', 'analytics', 'from', 'cdac']","['diploma', 'big', 'data', 'analytics', 'cdac']",diploma big data analytics cdac,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
3179,internship companies,Career,internship companies,"['internship', 'companies']",0,"['internship', 'company']","['internship', 'company']",internship company,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
3180,transforming observational crossectional informational data into probabilities,Techniques,transforming observational crossectional informational data into probabilities,"['transforming', 'observational', 'crossectional', 'informational', 'data', 'into', 'probabilities']",0,"['transforming', 'observational', 'crossectional', 'informational', 'data', 'into', 'probability']","['transforming', 'observational', 'crossectional', 'informational', 'data', 'probability']",transforming observational crossectional informational data probability,0.0,0.0,7,71,8.875,0,0,0,0,0,0,0,0
3181,error could not find function samplesplit,Techniques,error could not find function samplesplit,"['error', 'could', 'not', 'find', 'function', 'samplesplit']",0,"['error', 'could', 'not', 'find', 'function', 'samplesplit']","['error', 'could', 'find', 'function', 'samplesplit']",error could find function samplesplit,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
3182,including time as a parameter,Tools,including time as a parameter,"['including', 'time', 'as', 'a', 'parameter']",0,"['including', 'time', 'a', 'a', 'parameter']","['including', 'time', 'parameter']",including time parameter,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
3183,how watson holmes and automatic statistician differ from each other,Misc,how watson holmes and automatic statistician differ from each other,"['how', 'watson', 'holmes', 'and', 'automatic', 'statistician', 'differ', 'from', 'each', 'other']",0,"['how', 'watson', 'holmes', 'and', 'automatic', 'statistician', 'differ', 'from', 'each', 'other']","['watson', 'holmes', 'automatic', 'statistician', 'differ']",watson holmes automatic statistician differ,-0.125,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
3184,low feature importance and weak models python,Techniques,low feature importance and weak models python,"['low', 'feature', 'importance', 'and', 'weak', 'models', 'python']",0,"['low', 'feature', 'importance', 'and', 'weak', 'model', 'python']","['low', 'feature', 'importance', 'weak', 'model', 'python']",low feature importance weak model python,-0.1875,-0.1875,7,40,5.0,0,0,0,0,0,0,0,0
3185,i am fresher but want to move into analytics  howwhatwhenwhere do it,Career,i am fresher but want to move into analytics  howwhatwhenwhere do it,"['i', 'am', 'fresher', 'but', 'want', 'to', 'move', 'into', 'analytics', 'howwhatwhenwhere', 'do', 'it']",0,"['i', 'am', 'fresher', 'but', 'want', 'to', 'move', 'into', 'analytics', 'howwhatwhenwhere', 'do', 'it']","['fresher', 'want', 'move', 'analytics', 'howwhatwhenwhere']",fresher want move analytics howwhatwhenwhere,0.0,0.0,12,44,3.3846153846153846,0,0,0,0,0,0,0,0
3186,error in using tuneparams of mlr package,Techniques,error in using tuneparams of mlr package,"['error', 'in', 'using', 'tuneparams', 'of', 'mlr', 'package']",0,"['error', 'in', 'using', 'tuneparams', 'of', 'mlr', 'package']","['error', 'using', 'tuneparams', 'mlr', 'package']",error using tuneparams mlr package,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
3187,looking for teammates to compete regularly,Hackathons,looking for teammates to compete regularly,"['looking', 'for', 'teammates', 'to', 'compete', 'regularly']",0,"['looking', 'for', 'teammate', 'to', 'compete', 'regularly']","['looking', 'teammate', 'compete', 'regularly']",looking teammate compete regularly,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
3188,how to convert date into days in r,Tools,how to convert date into days in r,"['how', 'to', 'convert', 'date', 'into', 'days', 'in', 'r']",0,"['how', 'to', 'convert', 'date', 'into', 'day', 'in', 'r']","['convert', 'date', 'day', 'r']",convert date day r,0.0,0.0,8,18,2.0,0,0,0,0,0,0,0,0
3189,difference between  dates in qlikview,Tools,difference between  dates in qlikview,"['difference', 'between', 'dates', 'in', 'qlikview']",1,"['difference', 'between', 'date', 'in', 'qlikview']","['difference', 'date', 'qlikview']",difference date qlikview,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
3190,how to deal with datetime variable,Techniques,how to deal with datetime variable,"['how', 'to', 'deal', 'with', 'datetime', 'variable']",0,"['how', 'to', 'deal', 'with', 'datetime', 'variable']","['deal', 'datetime', 'variable']",deal datetime variable,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
3191,understanding the dataset,Techniques,understanding the dataset,"['understanding', 'the', 'dataset']",0,"['understanding', 'the', 'dataset']","['understanding', 'dataset']",understanding dataset,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
3192,error in r code for the lasso ridge regression,Tools,error in r code for the lasso ridge regression,"['error', 'in', 'r', 'code', 'for', 'the', 'lasso', 'ridge', 'regression']",0,"['error', 'in', 'r', 'code', 'for', 'the', 'lasso', 'ridge', 'regression']","['error', 'r', 'code', 'lasso', 'ridge', 'regression']",error r code lasso ridge regression,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
3193,how to resolve error nananinf in foreign function call arg  in knn,Tools,how to resolve error nananinf in foreign function call arg  in knn,"['how', 'to', 'resolve', 'error', 'nananinf', 'in', 'foreign', 'function', 'call', 'arg', 'in', 'knn']",1,"['how', 'to', 'resolve', 'error', 'nananinf', 'in', 'foreign', 'function', 'call', 'arg', 'in', 'knn']","['resolve', 'error', 'nananinf', 'foreign', 'function', 'call', 'arg', 'knn']",resolve error nananinf foreign function call arg knn,-0.125,-0.125,12,52,4.0,0,0,0,0,0,0,0,0
3194,keras image preprocessing using flow and not flowfromdirectory,Techniques,keras image preprocessing using flow and not flowfromdirectory,"['keras', 'image', 'preprocessing', 'using', 'flow', 'and', 'not', 'flowfromdirectory']",0,"['kera', 'image', 'preprocessing', 'using', 'flow', 'and', 'not', 'flowfromdirectory']","['kera', 'image', 'preprocessing', 'using', 'flow', 'flowfromdirectory']",kera image preprocessing using flow flowfromdirectory,0.0,0.0,8,53,5.888888888888889,0,0,0,0,0,0,0,0
3195,interview questions  experience for hadoop developer,Tools,interview questions  experience for hadoop developer,"['interview', 'questions', 'experience', 'for', 'hadoop', 'developer']",0,"['interview', 'question', 'experience', 'for', 'hadoop', 'developer']","['interview', 'question', 'experience', 'hadoop', 'developer']",interview question experience hadoop developer,0.0,0.0,6,46,6.571428571428571,0,0,0,0,0,0,0,0
3196,life cycle of a data science project,Other,life cycle of a data science project,"['life', 'cycle', 'of', 'a', 'data', 'science', 'project']",0,"['life', 'cycle', 'of', 'a', 'data', 'science', 'project']","['life', 'cycle', 'data', 'science', 'project']",life cycle data science project,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
3197,resource deep drive gaming data for betterment of society,Resources,resource deep drive gaming data for betterment of society,"['resource', 'deep', 'drive', 'gaming', 'data', 'for', 'betterment', 'of', 'society']",0,"['resource', 'deep', 'drive', 'gaming', 'data', 'for', 'betterment', 'of', 'society']","['resource', 'deep', 'drive', 'gaming', 'data', 'betterment', 'society']",resource deep drive gaming data betterment society,0.0,0.0,9,50,5.0,0,0,0,0,0,0,0,0
3198,can factor scores be negative in cluster analysis,Techniques,can factor scores be negative in cluster analysis,"['can', 'factor', 'scores', 'be', 'negative', 'in', 'cluster', 'analysis']",0,"['can', 'factor', 'score', 'be', 'negative', 'in', 'cluster', 'analysis']","['factor', 'score', 'negative', 'cluster', 'analysis']",factor score negative cluster analysis,-0.3,-0.3,8,38,4.222222222222222,0,0,0,0,0,0,0,0
3199,how does bootstrap sample pick records,Techniques,how does bootstrap sample pick records,"['how', 'does', 'bootstrap', 'sample', 'pick', 'records']",0,"['how', 'doe', 'bootstrap', 'sample', 'pick', 'record']","['doe', 'bootstrap', 'sample', 'pick', 'record']",doe bootstrap sample pick record,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
3200,how to reset all the parameter in r,Techniques,how to reset all the parameter in r,"['how', 'to', 'reset', 'all', 'the', 'parameter', 'in', 'r']",0,"['how', 'to', 'reset', 'all', 'the', 'parameter', 'in', 'r']","['reset', 'parameter', 'r']",reset parameter r,0.0,0.0,8,17,1.8888888888888888,0,0,0,0,0,0,0,0
3201,help needed regarding converting a csv data file to arff,Techniques,help needed regarding converting a csv data file to arff,"['help', 'needed', 'regarding', 'converting', 'a', 'csv', 'data', 'file', 'to', 'arff']",0,"['help', 'needed', 'regarding', 'converting', 'a', 'csv', 'data', 'file', 'to', 'arff']","['help', 'needed', 'regarding', 'converting', 'csv', 'data', 'file', 'arff']",help needed regarding converting csv data file arff,0.0,0.0,10,51,4.636363636363637,0,0,0,0,0,0,0,0
3202,how to resolve error while importing csv into r through ho library,Tools,how to resolve error while importing csv into r through ho library,"['how', 'to', 'resolve', 'error', 'while', 'importing', 'csv', 'into', 'r', 'through', 'ho', 'library']",0,"['how', 'to', 'resolve', 'error', 'while', 'importing', 'csv', 'into', 'r', 'through', 'ho', 'library']","['resolve', 'error', 'importing', 'csv', 'r', 'ho', 'library']",resolve error importing csv r ho library,0.0,0.0,12,40,3.076923076923077,0,0,0,0,0,0,0,0
3203,smart recruits practise,Hackathons,smart recruits practise,"['smart', 'recruits', 'practise']",0,"['smart', 'recruit', 'practise']","['smart', 'recruit', 'practise']",smart recruit practise,0.2142857142857142,0.2142857142857142,3,22,5.5,0,0,0,0,0,0,0,0
3204,k fold cross validation for logistic regression,Techniques,k fold cross validation for logistic regression,"['k', 'fold', 'cross', 'validation', 'for', 'logistic', 'regression']",0,"['k', 'fold', 'cross', 'validation', 'for', 'logistic', 'regression']","['k', 'fold', 'cross', 'validation', 'logistic', 'regression']",k fold cross validation logistic regression,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
3205,which course i can learn to understand flying object detection and localization using ml,Career,which course i can learn to understand flying object detection and localization using ml,"['which', 'course', 'i', 'can', 'learn', 'to', 'understand', 'flying', 'object', 'detection', 'and', 'localization', 'using', 'ml']",0,"['which', 'course', 'i', 'can', 'learn', 'to', 'understand', 'flying', 'object', 'detection', 'and', 'localization', 'using', 'ml']","['course', 'learn', 'understand', 'flying', 'object', 'detection', 'localization', 'using', 'ml']",course learn understand flying object detection localization using ml,0.0,0.0,14,69,4.6,0,0,0,0,0,0,0,0
3206,how to group similar words in a particular category,Techniques,how to group similar words in a particular category,"['how', 'to', 'group', 'similar', 'words', 'in', 'a', 'particular', 'category']",0,"['how', 'to', 'group', 'similar', 'word', 'in', 'a', 'particular', 'category']","['group', 'similar', 'word', 'particular', 'category']",group similar word particular category,0.0833333333333333,0.0833333333333333,9,38,3.8,0,0,0,0,0,0,0,0
3207,how to use missforest packaage in the test data set,Techniques,how to use missforest packaage in the test data set,"['how', 'to', 'use', 'missforest', 'packaage', 'in', 'the', 'test', 'data', 'set']",0,"['how', 'to', 'use', 'missforest', 'packaage', 'in', 'the', 'test', 'data', 'set']","['use', 'missforest', 'packaage', 'test', 'data', 'set']",use missforest packaage test data set,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
3208,need some guidance with excel ann,Techniques,need some guidance with excel ann,"['need', 'some', 'guidance', 'with', 'excel', 'ann']",0,"['need', 'some', 'guidance', 'with', 'excel', 'ann']","['need', 'guidance', 'excel', 'ann']",need guidance excel ann,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
3209,how to update r vesion in ubuntu,Tools,how to update r vesion in ubuntu,"['how', 'to', 'update', 'r', 'vesion', 'in', 'ubuntu']",0,"['how', 'to', 'update', 'r', 'vesion', 'in', 'ubuntu']","['update', 'r', 'vesion', 'ubuntu']",update r vesion ubuntu,0.0,0.0,7,22,2.75,0,0,0,0,0,0,0,0
3210,merging data frames,Tools,merging data frames,"['merging', 'data', 'frames']",0,"['merging', 'data', 'frame']","['merging', 'data', 'frame']",merging data frame,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
3211,do we have machine learning libraries in c or java,Tools,do we have machine learning libraries in c or java,"['do', 'we', 'have', 'machine', 'learning', 'libraries', 'in', 'c', 'or', 'java']",0,"['do', 'we', 'have', 'machine', 'learning', 'library', 'in', 'c', 'or', 'java']","['machine', 'learning', 'library', 'c', 'java']",machine learning library c java,0.0,0.0,10,31,2.8181818181818183,0,0,0,0,0,0,0,0
3212,forecasting on test data in var,Techniques,forecasting on test data in var,"['forecasting', 'on', 'test', 'data', 'in', 'var']",0,"['forecasting', 'on', 'test', 'data', 'in', 'var']","['forecasting', 'test', 'data', 'var']",forecasting test data var,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
3213,what is null and residual deviance in logistic regression,Techniques,what is null and residual deviance in logistic regression,"['what', 'is', 'null', 'and', 'residual', 'deviance', 'in', 'logistic', 'regression']",0,"['what', 'is', 'null', 'and', 'residual', 'deviance', 'in', 'logistic', 'regression']","['null', 'residual', 'deviance', 'logistic', 'regression']",null residual deviance logistic regression,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
3214,bayesian network structure learning,Techniques,bayesian network structure learning,"['bayesian', 'network', 'structure', 'learning']",0,"['bayesian', 'network', 'structure', 'learning']","['bayesian', 'network', 'structure', 'learning']",bayesian network structure learning,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
3215,continous dependent variable modelling,Techniques,continous dependent variable modelling,"['continous', 'dependent', 'variable', 'modelling']",0,"['continous', 'dependent', 'variable', 'modelling']","['continous', 'dependent', 'variable', 'modelling']",continous dependent variable modelling,0.0,0.0,4,38,7.6,0,0,0,0,0,0,0,0
3216,where statement is not working in sas,Tools,where statement is not working in sas,"['where', 'statement', 'is', 'not', 'working', 'in', 'sas']",0,"['where', 'statement', 'is', 'not', 'working', 'in', 'sa']","['statement', 'working', 'sa']",statement working sa,0.0,0.0,7,20,2.5,0,0,0,0,0,0,0,0
3217,pruning decision tree,Techniques,pruning decision tree,"['pruning', 'decision', 'tree']",0,"['pruning', 'decision', 'tree']","['pruning', 'decision', 'tree']",pruning decision tree,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
3218,data science  new career shift,Career,data science  new career shift,"['data', 'science', 'new', 'career', 'shift']",0,"['data', 'science', 'new', 'career', 'shift']","['data', 'science', 'new', 'career', 'shift']",data science new career shift,0.1363636363636363,0.1363636363636363,5,29,4.833333333333333,0,0,0,0,0,0,0,0
3219,predicting meantimebetweenfailure mtbf,Techniques,predicting meantimebetweenfailure mtbf,"['predicting', 'meantimebetweenfailure', 'mtbf']",0,"['predicting', 'meantimebetweenfailure', 'mtbf']","['predicting', 'meantimebetweenfailure', 'mtbf']",predicting meantimebetweenfailure mtbf,0.0,0.0,3,38,9.5,0,0,0,0,0,0,0,0
3220,how to resolve error in allocation of memory while applying linear regression,Techniques,how to resolve error in allocation of memory while applying linear regression,"['how', 'to', 'resolve', 'error', 'in', 'allocation', 'of', 'memory', 'while', 'applying', 'linear', 'regression']",0,"['how', 'to', 'resolve', 'error', 'in', 'allocation', 'of', 'memory', 'while', 'applying', 'linear', 'regression']","['resolve', 'error', 'allocation', 'memory', 'applying', 'linear', 'regression']",resolve error allocation memory applying linear regression,0.0,0.0,12,58,4.461538461538462,0,0,0,0,0,0,0,0
3221,getting error while fitting a linear regression model,Techniques,getting error while fitting a linear regression model,"['getting', 'error', 'while', 'fitting', 'a', 'linear', 'regression', 'model']",0,"['getting', 'error', 'while', 'fitting', 'a', 'linear', 'regression', 'model']","['getting', 'error', 'fitting', 'linear', 'regression', 'model']",getting error fitting linear regression model,0.5,0.5,8,45,5.0,0,0,0,0,0,0,0,0
3222,what is the application of analytics in the telecom industry,Other,what is the application of analytics in the telecom industry,"['what', 'is', 'the', 'application', 'of', 'analytics', 'in', 'the', 'telecom', 'industry']",0,"['what', 'is', 'the', 'application', 'of', 'analytics', 'in', 'the', 'telecom', 'industry']","['application', 'analytics', 'telecom', 'industry']",application analytics telecom industry,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
3223,accessing mongodb data to build data science models,Tools,accessing mongodb data to build data science models,"['accessing', 'mongodb', 'data', 'to', 'build', 'data', 'science', 'models']",0,"['accessing', 'mongodb', 'data', 'to', 'build', 'data', 'science', 'model']","['accessing', 'mongodb', 'data', 'build', 'data', 'science', 'model']",accessing mongodb data build data science model,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
3224,loan prediction problem  multiple imputation for missing values,Techniques,loan prediction problem  multiple imputation for missing values,"['loan', 'prediction', 'problem', 'multiple', 'imputation', 'for', 'missing', 'values']",0,"['loan', 'prediction', 'problem', 'multiple', 'imputation', 'for', 'missing', 'value']","['loan', 'prediction', 'problem', 'multiple', 'imputation', 'missing', 'value']",loan prediction problem multiple imputation missing value,-0.1,-0.1,8,57,6.333333333333333,0,0,0,0,0,0,0,0
3225,is it is possible to use cross validation to find the number of component in pca,Techniques,is it is possible to use cross validation to find the number of component in pca,"['is', 'it', 'is', 'possible', 'to', 'use', 'cross', 'validation', 'to', 'find', 'the', 'number', 'of', 'component', 'in', 'pca']",0,"['is', 'it', 'is', 'possible', 'to', 'use', 'cross', 'validation', 'to', 'find', 'the', 'number', 'of', 'component', 'in', 'pca']","['possible', 'use', 'cross', 'validation', 'find', 'number', 'component', 'pca']",possible use cross validation find number component pca,0.0,0.0,16,55,3.235294117647059,0,0,0,0,0,0,0,0
3226,graphlab simple classification,Tools,graphlab simple classification,"['graphlab', 'simple', 'classification']",0,"['graphlab', 'simple', 'classification']","['graphlab', 'simple', 'classification']",graphlab simple classification,0.0,0.0,3,30,7.5,0,0,0,0,0,0,0,0
3227,how to import file in r using reactable function,Tools,how to import file in r using reactable function,"['how', 'to', 'import', 'file', 'in', 'r', 'using', 'reactable', 'function']",0,"['how', 'to', 'import', 'file', 'in', 'r', 'using', 'reactable', 'function']","['import', 'file', 'r', 'using', 'reactable', 'function']",import file r using reactable function,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
3228,how to start with analytics or data science with hr background,Career,how to start with analytics or data science with hr background,"['how', 'to', 'start', 'with', 'analytics', 'or', 'data', 'science', 'with', 'hr', 'background']",0,"['how', 'to', 'start', 'with', 'analytics', 'or', 'data', 'science', 'with', 'hr', 'background']","['start', 'analytics', 'data', 'science', 'hr', 'background']",start analytics data science hr background,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
3229,how to compare several models in r,Tools,how to compare several models in r,"['how', 'to', 'compare', 'several', 'models', 'in', 'r']",0,"['how', 'to', 'compare', 'several', 'model', 'in', 'r']","['compare', 'several', 'model', 'r']",compare several model r,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
3230,best way to calculate quartile,Techniques,best way to calculate quartile,"['best', 'way', 'to', 'calculate', 'quartile']",0,"['best', 'way', 'to', 'calculate', 'quartile']","['best', 'way', 'calculate', 'quartile']",best way calculate quartile,1.0,1.0,5,27,4.5,0,0,0,0,0,0,0,0
3231,moving into analytics after a career break qa,Career,moving into analytics after a career break qa,"['moving', 'into', 'analytics', 'after', 'a', 'career', 'break', 'qa']",0,"['moving', 'into', 'analytics', 'after', 'a', 'career', 'break', 'qa']","['moving', 'analytics', 'career', 'break', 'qa']",moving analytics career break qa,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
3232,limitation of linear regression model application,Techniques,limitation of linear regression model application,"['limitation', 'of', 'linear', 'regression', 'model', 'application']",0,"['limitation', 'of', 'linear', 'regression', 'model', 'application']","['limitation', 'linear', 'regression', 'model', 'application']",limitation linear regression model application,0.0,0.0,6,46,6.571428571428571,0,0,0,0,0,0,0,0
3233,identify the digits,Techniques,identify the digits,"['identify', 'the', 'digits']",0,"['identify', 'the', 'digit']","['identify', 'digit']",identify digit,0.0,0.0,3,14,3.5,0,0,0,0,0,0,0,0
3234,getting error while executing nlp on kaggle,Techniques,getting error while executing nlp on kaggle,"['getting', 'error', 'while', 'executing', 'nlp', 'on', 'kaggle']",0,"['getting', 'error', 'while', 'executing', 'nlp', 'on', 'kaggle']","['getting', 'error', 'executing', 'nlp', 'kaggle']",getting error executing nlp kaggle,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
3235,how to gain analytics experience while moving from it to analytics,Career,how to gain analytics experience while moving from it to analytics,"['how', 'to', 'gain', 'analytics', 'experience', 'while', 'moving', 'from', 'it', 'to', 'analytics']",0,"['how', 'to', 'gain', 'analytics', 'experience', 'while', 'moving', 'from', 'it', 'to', 'analytics']","['gain', 'analytics', 'experience', 'moving', 'analytics']",gain analytics experience moving analytics,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
3236,how to evaluate text summary,Techniques,how to evaluate text summary,"['how', 'to', 'evaluate', 'text', 'summary']",0,"['how', 'to', 'evaluate', 'text', 'summary']","['evaluate', 'text', 'summary']",evaluate text summary,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
3237,dummy variables is necessary to standardize them,Techniques,dummy variables is necessary to standardize them,"['dummy', 'variables', 'is', 'necessary', 'to', 'standardize', 'them']",0,"['dummy', 'variable', 'is', 'necessary', 'to', 'standardize', 'them']","['dummy', 'variable', 'necessary', 'standardize']",dummy variable necessary standardize,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
3238,is the hype for big data dead,Tools,is the hype for big data dead,"['is', 'the', 'hype', 'for', 'big', 'data', 'dead']",0,"['is', 'the', 'hype', 'for', 'big', 'data', 'dead']","['hype', 'big', 'data', 'dead']",hype big data dead,-0.1,-0.1,7,18,2.25,0,0,0,0,0,0,0,0
3239,caret wont installload properly,Tools,caret wont installload properly,"['caret', 'wont', 'installload', 'properly']",0,"['caret', 'wont', 'installload', 'properly']","['caret', 'wont', 'installload', 'properly']",caret wont installload properly,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
3240,how to extarct hours and minutes from the factor time varaible,Tools,how to extarct hours and minutes from the factor time varaible,"['how', 'to', 'extarct', 'hours', 'and', 'minutes', 'from', 'the', 'factor', 'time', 'varaible']",0,"['how', 'to', 'extarct', 'hour', 'and', 'minute', 'from', 'the', 'factor', 'time', 'varaible']","['extarct', 'hour', 'minute', 'factor', 'time', 'varaible']",extarct hour minute factor time varaible,0.0,0.0,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
3241,decision tree vs naive bayes classifier,Techniques,decision tree vs naive bayes classifier,"['decision', 'tree', 'vs', 'naive', 'bayes', 'classifier']",0,"['decision', 'tree', 'v', 'naive', 'bayes', 'classifier']","['decision', 'tree', 'v', 'naive', 'bayes', 'classifier']",decision tree v naive bayes classifier,-0.3,-0.3,6,38,5.428571428571429,0,0,0,0,0,0,0,0
3242,good read using machine learning to recommend dota  heroes,Resources,good read using machine learning to recommend dota  heroes,"['good', 'read', 'using', 'machine', 'learning', 'to', 'recommend', 'dota', 'heroes']",1,"['good', 'read', 'using', 'machine', 'learning', 'to', 'recommend', 'dota', 'hero']","['good', 'read', 'using', 'machine', 'learning', 'recommend', 'dota', 'hero']",good read using machine learning recommend dota hero,0.7,0.7,9,52,5.2,0,0,0,0,0,0,0,0
3243,onlinepart time courses providing placement assistance,Career,onlinepart time courses providing placement assistance,"['onlinepart', 'time', 'courses', 'providing', 'placement', 'assistance']",0,"['onlinepart', 'time', 'course', 'providing', 'placement', 'assistance']","['onlinepart', 'time', 'course', 'providing', 'placement', 'assistance']",onlinepart time course providing placement assistance,0.0,0.0,6,53,7.571428571428571,0,0,0,0,0,0,0,0
3244,extracting data belonging to a day from a given range of dates on a dataset,Tools,extracting data belonging to a day from a given range of dates on a dataset,"['extracting', 'data', 'belonging', 'to', 'a', 'day', 'from', 'a', 'given', 'range', 'of', 'dates', 'on', 'a', 'dataset']",0,"['extracting', 'data', 'belonging', 'to', 'a', 'day', 'from', 'a', 'given', 'range', 'of', 'date', 'on', 'a', 'dataset']","['extracting', 'data', 'belonging', 'day', 'given', 'range', 'date', 'dataset']",extracting data belonging day given range date dataset,0.0,0.0,15,54,3.375,0,0,0,0,0,0,0,0
3245,relevance  need of python programming in data science and analytics machine learning,Career,relevance  need of python programming in data science and analytics machine learning,"['relevance', 'need', 'of', 'python', 'programming', 'in', 'data', 'science', 'and', 'analytics', 'machine', 'learning']",0,"['relevance', 'need', 'of', 'python', 'programming', 'in', 'data', 'science', 'and', 'analytics', 'machine', 'learning']","['relevance', 'need', 'python', 'programming', 'data', 'science', 'analytics', 'machine', 'learning']",relevance need python programming data science analytics machine learning,0.0,0.0,12,73,5.615384615384615,0,0,0,0,0,0,0,0
3246,data studio question,Techniques,data studio question,"['data', 'studio', 'question']",0,"['data', 'studio', 'question']","['data', 'studio', 'question']",data studio question,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
3247,unable to find executable file for ipython  jupyter,Tools,unable to find executable file for ipython  jupyter,"['unable', 'to', 'find', 'executable', 'file', 'for', 'ipython', 'jupyter']",0,"['unable', 'to', 'find', 'executable', 'file', 'for', 'ipython', 'jupyter']","['unable', 'find', 'executable', 'file', 'ipython', 'jupyter']",unable find executable file ipython jupyter,-0.5,-0.5,8,43,4.777777777777778,0,0,0,0,0,0,0,0
3248,what is the meaning of standardization in knn,Techniques,what is the meaning of standardization in knn,"['what', 'is', 'the', 'meaning', 'of', 'standardization', 'in', 'knn']",0,"['what', 'is', 'the', 'meaning', 'of', 'standardization', 'in', 'knn']","['meaning', 'standardization', 'knn']",meaning standardization knn,0.0,0.0,8,27,3.0,0,0,0,0,0,0,0,0
3249,visualizing python dataframe,Techniques,visualizing python dataframe,"['visualizing', 'python', 'dataframe']",0,"['visualizing', 'python', 'dataframe']","['visualizing', 'python', 'dataframe']",visualizing python dataframe,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
3250,how to plot the grand median in the given plot,Techniques,how to plot the grand median in the given plot,"['how', 'to', 'plot', 'the', 'grand', 'median', 'in', 'the', 'given', 'plot']",0,"['how', 'to', 'plot', 'the', 'grand', 'median', 'in', 'the', 'given', 'plot']","['plot', 'grand', 'median', 'given', 'plot']",plot grand median given plot,0.5,0.5,10,28,2.5454545454545454,0,0,0,0,0,0,0,0
3251,how to populate predictions in test data after training the model on train set in r,Tools,how to populate predictions in test data after training the model on train set in r,"['how', 'to', 'populate', 'predictions', 'in', 'test', 'data', 'after', 'training', 'the', 'model', 'on', 'train', 'set', 'in', 'r']",0,"['how', 'to', 'populate', 'prediction', 'in', 'test', 'data', 'after', 'training', 'the', 'model', 'on', 'train', 'set', 'in', 'r']","['populate', 'prediction', 'test', 'data', 'training', 'model', 'train', 'set', 'r']",populate prediction test data training model train set r,0.0,0.0,16,56,3.2941176470588234,0,0,0,0,0,0,0,0
3252,aws  things to be known by a data analystscientist,Tools,aws  things to be known by a data analystscientist,"['aws', 'things', 'to', 'be', 'known', 'by', 'a', 'data', 'analystscientist']",0,"['aws', 'thing', 'to', 'be', 'known', 'by', 'a', 'data', 'analystscientist']","['aws', 'thing', 'known', 'data', 'analystscientist']",aws thing known data analystscientist,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
3253,i want to find mean of those rows in target variable corresponding to which there are null values in a particular column,Tools,i want to find mean of those rows in target variable corresponding to which there are null values in a particular column,"['i', 'want', 'to', 'find', 'mean', 'of', 'those', 'rows', 'in', 'target', 'variable', 'corresponding', 'to', 'which', 'there', 'are', 'null', 'values', 'in', 'a', 'particular', 'column']",0,"['i', 'want', 'to', 'find', 'mean', 'of', 'those', 'row', 'in', 'target', 'variable', 'corresponding', 'to', 'which', 'there', 'are', 'null', 'value', 'in', 'a', 'particular', 'column']","['want', 'find', 'mean', 'row', 'target', 'variable', 'corresponding', 'null', 'value', 'particular', 'column']",want find mean row target variable corresponding null value particular column,-0.0729166666666666,-0.0729166666666666,22,77,3.347826086956522,0,0,0,0,0,0,0,0
3254,career in sas for experienced person,Career,career in sas for experienced person,"['career', 'in', 'sas', 'for', 'experienced', 'person']",0,"['career', 'in', 'sa', 'for', 'experienced', 'person']","['career', 'sa', 'experienced', 'person']",career sa experienced person,0.8,0.8,6,28,4.0,0,0,0,0,0,0,0,0
3255,training  advice,Career,training  advice,"['training', 'advice']",0,"['training', 'advice']","['training', 'advice']",training advice,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
3256,criteria for success of bollywood movie,Techniques,criteria for success of bollywood movie,"['criteria', 'for', 'success', 'of', 'bollywood', 'movie']",0,"['criterion', 'for', 'success', 'of', 'bollywood', 'movie']","['criterion', 'success', 'bollywood', 'movie']",criterion success bollywood movie,0.3,0.3,6,33,4.714285714285714,0,0,0,0,0,0,0,0
3257,solutions for challenges,Career,solutions for challenges,"['solutions', 'for', 'challenges']",0,"['solution', 'for', 'challenge']","['solution', 'challenge']",solution challenge,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
3258,error inheritsdoc textdocument is not true in r,Tools,error inheritsdoc textdocument is not true in r,"['error', 'inheritsdoc', 'textdocument', 'is', 'not', 'true', 'in', 'r']",0,"['error', 'inheritsdoc', 'textdocument', 'is', 'not', 'true', 'in', 'r']","['error', 'inheritsdoc', 'textdocument', 'true', 'r']",error inheritsdoc textdocument true r,-0.175,0.35,8,37,4.111111111111111,0,0,0,0,0,0,0,0
3259,ann model via r  ho,Techniques,ann model via r  ho,"['ann', 'model', 'via', 'r', 'ho']",0,"['ann', 'model', 'via', 'r', 'ho']","['ann', 'model', 'via', 'r', 'ho']",ann model via r ho,0.0,0.0,5,18,3.0,0,0,0,0,0,0,0,0
3260,multivariate time series analysis,Techniques,multivariate time series analysis,"['multivariate', 'time', 'series', 'analysis']",0,"['multivariate', 'time', 'series', 'analysis']","['multivariate', 'time', 'series', 'analysis']",multivariate time series analysis,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
3261,executive pg in business analytics,Career,executive pg in business analytics,"['executive', 'pg', 'in', 'business', 'analytics']",0,"['executive', 'pg', 'in', 'business', 'analytics']","['executive', 'pg', 'business', 'analytics']",executive pg business analytics,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
3262,facing difficulty while installing sparklyr in rstudio ,Tools,facing difficulty while installing sparklyr in rstudio ,"['facing', 'difficulty', 'while', 'installing', 'sparklyr', 'in', 'rstudio']",1,"['facing', 'difficulty', 'while', 'installing', 'sparklyr', 'in', 'rstudio']","['facing', 'difficulty', 'installing', 'sparklyr', 'rstudio']",facing difficulty installing sparklyr rstudio,0.0,0.0,7,45,5.625,0,0,0,0,0,0,0,0
3263,validating custom variables to get better estimate of a parameter i am trying to compare,Misc,validating custom variables to get better estimate of a parameter i am trying to compare,"['validating', 'custom', 'variables', 'to', 'get', 'better', 'estimate', 'of', 'a', 'parameter', 'i', 'am', 'trying', 'to', 'compare']",0,"['validating', 'custom', 'variable', 'to', 'get', 'better', 'estimate', 'of', 'a', 'parameter', 'i', 'am', 'trying', 'to', 'compare']","['validating', 'custom', 'variable', 'get', 'better', 'estimate', 'parameter', 'trying', 'compare']",validating custom variable get better estimate parameter trying compare,0.5,0.5,15,71,4.4375,0,0,0,0,0,0,0,0
3264,multinomial classification on text,Techniques,multinomial classification on text,"['multinomial', 'classification', 'on', 'text']",0,"['multinomial', 'classification', 'on', 'text']","['multinomial', 'classification', 'text']",multinomial classification text,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
3265,parameters of logistic regression  aic null and residual deviances,Techniques,parameters of logistic regression  aic null and residual deviances,"['parameters', 'of', 'logistic', 'regression', 'aic', 'null', 'and', 'residual', 'deviances']",0,"['parameter', 'of', 'logistic', 'regression', 'aic', 'null', 'and', 'residual', 'deviance']","['parameter', 'logistic', 'regression', 'aic', 'null', 'residual', 'deviance']",parameter logistic regression aic null residual deviance,0.0,0.0,9,56,5.6,0,0,0,0,0,0,0,0
3266,should an ideal run of kmeans clustering produce evenly distributed points near each of the means,Techniques,should an ideal run of kmeans clustering produce evenly distributed points near each of the means,"['should', 'an', 'ideal', 'run', 'of', 'kmeans', 'clustering', 'produce', 'evenly', 'distributed', 'points', 'near', 'each', 'of', 'the', 'means']",0,"['should', 'an', 'ideal', 'run', 'of', 'kmeans', 'clustering', 'produce', 'evenly', 'distributed', 'point', 'near', 'each', 'of', 'the', 'mean']","['ideal', 'run', 'kmeans', 'clustering', 'produce', 'evenly', 'distributed', 'point', 'near', 'mean']",ideal run kmeans clustering produce evenly distributed point near mean,0.5,0.2291666666666666,16,70,4.117647058823529,0,0,0,0,0,0,0,0
3267,input to reshape is a tensor with  values but the requested shape has ,Techniques,input to reshape is a tensor with  values but the requested shape has ,"['input', 'to', 'reshape', 'is', 'a', 'tensor', 'with', 'values', 'but', 'the', 'requested', 'shape', 'has']",2,"['input', 'to', 'reshape', 'is', 'a', 'tensor', 'with', 'value', 'but', 'the', 'requested', 'shape', 'ha']","['input', 'reshape', 'tensor', 'value', 'requested', 'shape', 'ha']",input reshape tensor value requested shape ha,0.0,0.0,13,45,3.2142857142857144,0,0,0,0,0,0,0,0
3268,learnup  analytics  data science session for beginners,Hackathons,learnup  analytics  data science session for beginners,"['learnup', 'analytics', 'data', 'science', 'session', 'for', 'beginners']",0,"['learnup', 'analytics', 'data', 'science', 'session', 'for', 'beginner']","['learnup', 'analytics', 'data', 'science', 'session', 'beginner']",learnup analytics data science session beginner,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
3269,can we have negative aic value in linear regression and what it suggest,Techniques,can we have negative aic value in linear regression and what it suggest,"['can', 'we', 'have', 'negative', 'aic', 'value', 'in', 'linear', 'regression', 'and', 'what', 'it', 'suggest']",0,"['can', 'we', 'have', 'negative', 'aic', 'value', 'in', 'linear', 'regression', 'and', 'what', 'it', 'suggest']","['negative', 'aic', 'value', 'linear', 'regression', 'suggest']",negative aic value linear regression suggest,-0.3,-0.3,13,44,3.142857142857143,0,0,0,0,0,0,0,0
3270,ensemble techniquescascade models best practices,Techniques,ensemble techniquescascade models best practices,"['ensemble', 'techniquescascade', 'models', 'best', 'practices']",0,"['ensemble', 'techniquescascade', 'model', 'best', 'practice']","['ensemble', 'techniquescascade', 'model', 'best', 'practice']",ensemble techniquescascade model best practice,1.0,1.0,5,46,7.666666666666667,0,0,0,0,0,0,0,0
3271,print the below string using r,Techniques,print the below string using r,"['print', 'the', 'below', 'string', 'using', 'r']",0,"['print', 'the', 'below', 'string', 'using', 'r']","['print', 'string', 'using', 'r']",print string using r,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
3272,profile question,Misc,profile question,"['profile', 'question']",0,"['profile', 'question']","['profile', 'question']",profile question,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
3273,numberoftraininginstancesnumberoftrainingfeatures ratio,Techniques,numberoftraininginstancesnumberoftrainingfeatures ratio,"['numberoftraininginstancesnumberoftrainingfeatures', 'ratio']",0,"['numberoftraininginstancesnumberoftrainingfeatures', 'ratio']","['numberoftraininginstancesnumberoftrainingfeatures', 'ratio']",numberoftraininginstancesnumberoftrainingfeatures ratio,0.0,0.0,2,55,18.333333333333332,0,0,0,0,0,0,0,0
3274,need to build personilised recommendation rule for each individual customer based on deliverytime,Techniques,need to build personilised recommendation rule for each individual customer based on deliverytime,"['need', 'to', 'build', 'personilised', 'recommendation', 'rule', 'for', 'each', 'individual', 'customer', 'based', 'on', 'deliverytime']",0,"['need', 'to', 'build', 'personilised', 'recommendation', 'rule', 'for', 'each', 'individual', 'customer', 'based', 'on', 'deliverytime']","['need', 'build', 'personilised', 'recommendation', 'rule', 'individual', 'customer', 'based', 'deliverytime']",need build personilised recommendation rule individual customer based deliverytime,0.0,0.0,13,82,5.857142857142857,0,0,0,0,0,0,0,0
3275,read last sheet from excel file in python,Techniques,read last sheet from excel file in python,"['read', 'last', 'sheet', 'from', 'excel', 'file', 'in', 'python']",0,"['read', 'last', 'sheet', 'from', 'excel', 'file', 'in', 'python']","['read', 'last', 'sheet', 'excel', 'file', 'python']",read last sheet excel file python,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
3276,how to read data from a text file in r,Tools,how to read data from a text file in r,"['how', 'to', 'read', 'data', 'from', 'a', 'text', 'file', 'in', 'r']",0,"['how', 'to', 'read', 'data', 'from', 'a', 'text', 'file', 'in', 'r']","['read', 'data', 'text', 'file', 'r']",read data text file r,0.0,0.0,10,21,1.9090909090909092,0,0,0,0,0,0,0,0
3277,how do we check the model robustness pls explain it for logistic regression models,Techniques,how do we check the model robustness pls explain it for logistic regression models,"['how', 'do', 'we', 'check', 'the', 'model', 'robustness', 'pls', 'explain', 'it', 'for', 'logistic', 'regression', 'models']",0,"['how', 'do', 'we', 'check', 'the', 'model', 'robustness', 'pls', 'explain', 'it', 'for', 'logistic', 'regression', 'model']","['check', 'model', 'robustness', 'pls', 'explain', 'logistic', 'regression', 'model']",check model robustness pls explain logistic regression model,0.0,0.0,14,60,4.0,0,0,0,0,0,0,0,0
3278,how to build a ball tracking system for cricket,Resources,how to build a ball tracking system for cricket,"['how', 'to', 'build', 'a', 'ball', 'tracking', 'system', 'for', 'cricket']",0,"['how', 'to', 'build', 'a', 'ball', 'tracking', 'system', 'for', 'cricket']","['build', 'ball', 'tracking', 'system', 'cricket']",build ball tracking system cricket,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
3279,training model with traintestsplit,Techniques,training model with traintestsplit,"['training', 'model', 'with', 'traintestsplit']",0,"['training', 'model', 'with', 'traintestsplit']","['training', 'model', 'traintestsplit']",training model traintestsplit,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
3280,how do i implement knn using errorest in the ipred package in r,Tools,how do i implement knn using errorest in the ipred package in r,"['how', 'do', 'i', 'implement', 'knn', 'using', 'errorest', 'in', 'the', 'ipred', 'package', 'in', 'r']",0,"['how', 'do', 'i', 'implement', 'knn', 'using', 'errorest', 'in', 'the', 'ipred', 'package', 'in', 'r']","['implement', 'knn', 'using', 'errorest', 'ipred', 'package', 'r']",implement knn using errorest ipred package r,0.0,0.0,13,44,3.142857142857143,0,0,0,0,0,0,0,0
3281,top  software tools for data analysts ,Resources,top  software tools for data analysts ,"['top', 'software', 'tools', 'for', 'data', 'analysts']",2,"['top', 'software', 'tool', 'for', 'data', 'analyst']","['top', 'software', 'tool', 'data', 'analyst']",top software tool data analyst,0.5,0.5,6,30,4.285714285714286,0,0,0,0,0,0,0,0
3282,faster rcnn and data quality,Techniques,faster rcnn and data quality,"['faster', 'rcnn', 'and', 'data', 'quality']",0,"['faster', 'rcnn', 'and', 'data', 'quality']","['faster', 'rcnn', 'data', 'quality']",faster rcnn data quality,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
3283,how to use xgbimportance,Techniques,how to use xgbimportance,"['how', 'to', 'use', 'xgbimportance']",0,"['how', 'to', 'use', 'xgbimportance']","['use', 'xgbimportance']",use xgbimportance,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
3284,c decision tree  c code called exit with value ,Techniques,c decision tree  c code called exit with value ,"['c', 'decision', 'tree', 'c', 'code', 'called', 'exit', 'with', 'value']",1,"['c', 'decision', 'tree', 'c', 'code', 'called', 'exit', 'with', 'value']","['c', 'decision', 'tree', 'c', 'code', 'called', 'exit', 'value']",c decision tree c code called exit value,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
3285,vif factor in logistic regression,Techniques,vif factor in logistic regression,"['vif', 'factor', 'in', 'logistic', 'regression']",0,"['vif', 'factor', 'in', 'logistic', 'regression']","['vif', 'factor', 'logistic', 'regression']",vif factor logistic regression,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
3286,tensorflow package is not in anaconda,Tools,tensorflow package is not in anaconda,"['tensorflow', 'package', 'is', 'not', 'in', 'anaconda']",0,"['tensorflow', 'package', 'is', 'not', 'in', 'anaconda']","['tensorflow', 'package', 'anaconda']",tensorflow package anaconda,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
3287,how to sort elements in a column chart in sas,Tools,how to sort elements in a column chart in sas,"['how', 'to', 'sort', 'elements', 'in', 'a', 'column', 'chart', 'in', 'sas']",0,"['how', 'to', 'sort', 'element', 'in', 'a', 'column', 'chart', 'in', 'sa']","['sort', 'element', 'column', 'chart', 'sa']",sort element column chart sa,0.0,0.0,10,28,2.5454545454545454,0,0,0,0,0,0,0,0
3288,what is the difference between backcasting and forecasting,Techniques,what is the difference between backcasting and forecasting,"['what', 'is', 'the', 'difference', 'between', 'backcasting', 'and', 'forecasting']",0,"['what', 'is', 'the', 'difference', 'between', 'backcasting', 'and', 'forecasting']","['difference', 'backcasting', 'forecasting']",difference backcasting forecasting,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
3289,how to remove plural words from the training data for forming bag of words,Techniques,how to remove plural words from the training data for forming bag of words,"['how', 'to', 'remove', 'plural', 'words', 'from', 'the', 'training', 'data', 'for', 'forming', 'bag', 'of', 'words']",0,"['how', 'to', 'remove', 'plural', 'word', 'from', 'the', 'training', 'data', 'for', 'forming', 'bag', 'of', 'word']","['remove', 'plural', 'word', 'training', 'data', 'forming', 'bag', 'word']",remove plural word training data forming bag word,0.0,0.0,14,49,3.2666666666666666,0,0,0,0,0,0,0,0
3290,valueerror found input variables with inconsistent numbers of samples  ,Techniques,valueerror found input variables with inconsistent numbers of samples  ,"['valueerror', 'found', 'input', 'variables', 'with', 'inconsistent', 'numbers', 'of', 'samples']",2,"['valueerror', 'found', 'input', 'variable', 'with', 'inconsistent', 'number', 'of', 'sample']","['valueerror', 'found', 'input', 'variable', 'inconsistent', 'number', 'sample']",valueerror found input variable inconsistent number sample,0.0,0.0,9,58,5.8,0,0,0,0,0,0,0,0
3291,smote implementation in python,Techniques,smote implementation in python,"['smote', 'implementation', 'in', 'python']",0,"['smote', 'implementation', 'in', 'python']","['smote', 'implementation', 'python']",smote implementation python,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
3292,clarity on build data pipeline,Hackathons,clarity on build data pipeline,"['clarity', 'on', 'build', 'data', 'pipeline']",0,"['clarity', 'on', 'build', 'data', 'pipeline']","['clarity', 'build', 'data', 'pipeline']",clarity build data pipeline,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
3293,how pvalue is related to tstatistic,Techniques,how pvalue is related to tstatistic,"['how', 'pvalue', 'is', 'related', 'to', 'tstatistic']",0,"['how', 'pvalue', 'is', 'related', 'to', 'tstatistic']","['pvalue', 'related', 'tstatistic']",pvalue related tstatistic,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
3294,which machine learning model is best for this scenario,Techniques,which machine learning model is best for this scenario,"['which', 'machine', 'learning', 'model', 'is', 'best', 'for', 'this', 'scenario']",0,"['which', 'machine', 'learning', 'model', 'is', 'best', 'for', 'this', 'scenario']","['machine', 'learning', 'model', 'best', 'scenario']",machine learning model best scenario,1.0,1.0,9,36,3.6,0,0,0,0,0,0,0,0
3295,decision tree  minbucket,Techniques,decision tree  minbucket,"['decision', 'tree', 'minbucket']",0,"['decision', 'tree', 'minbucket']","['decision', 'tree', 'minbucket']",decision tree minbucket,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
3296,ipython error ipython notebook is deprecated,Tools,ipython error ipython notebook is deprecated,"['ipython', 'error', 'ipython', 'notebook', 'is', 'deprecated']",0,"['ipython', 'error', 'ipython', 'notebook', 'is', 'deprecated']","['ipython', 'error', 'ipython', 'notebook', 'deprecated']",ipython error ipython notebook deprecated,0.0,0.0,6,41,5.857142857142857,0,0,0,0,0,0,0,0
3297,when can i give the statistics skill test ii,Hackathons,when can i give the statistics skill test ii,"['when', 'can', 'i', 'give', 'the', 'statistics', 'skill', 'test', 'ii']",0,"['when', 'can', 'i', 'give', 'the', 'statistic', 'skill', 'test', 'ii']","['give', 'statistic', 'skill', 'test', 'ii']",give statistic skill test ii,0.0,0.0,9,28,2.8,0,0,0,0,0,0,0,0
3298,maximum no of classes in a multi classification problem,Techniques,maximum no of classes in a multi classification problem,"['maximum', 'no', 'of', 'classes', 'in', 'a', 'multi', 'classification', 'problem']",0,"['maximum', 'no', 'of', 'class', 'in', 'a', 'multi', 'classification', 'problem']","['maximum', 'class', 'multi', 'classification', 'problem']",maximum class multi classification problem,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
3299,discussions for article a complete tutorial to learn data science with python from scratch,Other,discussions for article a complete tutorial to learn data science with python from scratch,"['discussions', 'for', 'article', 'a', 'complete', 'tutorial', 'to', 'learn', 'data', 'science', 'with', 'python', 'from', 'scratch']",0,"['discussion', 'for', 'article', 'a', 'complete', 'tutorial', 'to', 'learn', 'data', 'science', 'with', 'python', 'from', 'scratch']","['discussion', 'article', 'complete', 'tutorial', 'learn', 'data', 'science', 'python', 'scratch']",discussion article complete tutorial learn data science python scratch,0.1,0.1,14,70,4.666666666666667,0,0,0,0,0,0,0,0
3300,doubt in following learning path,Tools,doubt in following learning path,"['doubt', 'in', 'following', 'learning', 'path']",0,"['doubt', 'in', 'following', 'learning', 'path']","['doubt', 'following', 'learning', 'path']",doubt following learning path,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
3301,why do the variables have to be standardised prior to applying pca,Techniques,why do the variables have to be standardised prior to applying pca,"['why', 'do', 'the', 'variables', 'have', 'to', 'be', 'standardised', 'prior', 'to', 'applying', 'pca']",0,"['why', 'do', 'the', 'variable', 'have', 'to', 'be', 'standardised', 'prior', 'to', 'applying', 'pca']","['variable', 'standardised', 'prior', 'applying', 'pca']",variable standardised prior applying pca,0.0,0.0,12,40,3.076923076923077,0,0,0,0,0,0,0,0
3302,when should i use point and interval estimate,Techniques,when should i use point and interval estimate,"['when', 'should', 'i', 'use', 'point', 'and', 'interval', 'estimate']",0,"['when', 'should', 'i', 'use', 'point', 'and', 'interval', 'estimate']","['use', 'point', 'interval', 'estimate']",use point interval estimate,0.0,0.0,8,27,3.0,0,0,0,0,0,0,0,0
3303,how to assign points when they are at equal distance from centroid in knn,Techniques,how to assign points when they are at equal distance from centroid in knn,"['how', 'to', 'assign', 'points', 'when', 'they', 'are', 'at', 'equal', 'distance', 'from', 'centroid', 'in', 'knn']",0,"['how', 'to', 'assign', 'point', 'when', 'they', 'are', 'at', 'equal', 'distance', 'from', 'centroid', 'in', 'knn']","['assign', 'point', 'equal', 'distance', 'centroid', 'knn']",assign point equal distance centroid knn,0.0,0.0,14,40,2.6666666666666665,0,0,0,0,0,0,0,0
3304,how to combine  shops in smaller number of groups,Techniques,how to combine  shops in smaller number of groups,"['how', 'to', 'combine', 'shops', 'in', 'smaller', 'number', 'of', 'groups']",1,"['how', 'to', 'combine', 'shop', 'in', 'smaller', 'number', 'of', 'group']","['combine', 'shop', 'smaller', 'number', 'group']",combine shop smaller number group,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
3305,how to access the attributes of a vector in r,Tools,how to access the attributes of a vector in r,"['how', 'to', 'access', 'the', 'attributes', 'of', 'a', 'vector', 'in', 'r']",0,"['how', 'to', 'access', 'the', 'attribute', 'of', 'a', 'vector', 'in', 'r']","['access', 'attribute', 'vector', 'r']",access attribute vector r,0.0,0.0,10,25,2.272727272727273,0,0,0,0,0,0,0,0
3306,what is difference between ada boost and xg boost,Techniques,what is difference between ada boost and xg boost,"['what', 'is', 'difference', 'between', 'ada', 'boost', 'and', 'xg', 'boost']",0,"['what', 'is', 'difference', 'between', 'ada', 'boost', 'and', 'xg', 'boost']","['difference', 'ada', 'boost', 'xg', 'boost']",difference ada boost xg boost,0.0,0.0,9,29,2.9,0,0,0,0,0,0,0,0
3307,what is the best matchmaking algorithm available,Techniques,what is the best matchmaking algorithm available,"['what', 'is', 'the', 'best', 'matchmaking', 'algorithm', 'available']",0,"['what', 'is', 'the', 'best', 'matchmaking', 'algorithm', 'available']","['best', 'matchmaking', 'algorithm', 'available']",best matchmaking algorithm available,0.7,0.7,7,36,4.5,0,0,0,0,0,0,0,0
3308,mean based splitting,Techniques,mean based splitting,"['mean', 'based', 'splitting']",0,"['mean', 'based', 'splitting']","['mean', 'based', 'splitting']",mean based splitting,-0.3125,-0.3125,3,20,5.0,0,0,0,0,0,0,0,0
3309,how cubic splines is different from the natural cubic splines,Techniques,how cubic splines is different from the natural cubic splines,"['how', 'cubic', 'splines', 'is', 'different', 'from', 'the', 'natural', 'cubic', 'splines']",0,"['how', 'cubic', 'spline', 'is', 'different', 'from', 'the', 'natural', 'cubic', 'spline']","['cubic', 'spline', 'different', 'natural', 'cubic', 'spline']",cubic spline different natural cubic spline,0.05,0.05,10,43,3.909090909090909,0,0,0,0,0,0,0,0
3310,whether to use covariance or correlation matrix for pca,Techniques,whether to use covariance or correlation matrix for pca,"['whether', 'to', 'use', 'covariance', 'or', 'correlation', 'matrix', 'for', 'pca']",0,"['whether', 'to', 'use', 'covariance', 'or', 'correlation', 'matrix', 'for', 'pca']","['whether', 'use', 'covariance', 'correlation', 'matrix', 'pca']",whether use covariance correlation matrix pca,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
3311,r and shiny  alerts,Tools,r and shiny  alerts,"['r', 'and', 'shiny', 'alerts']",0,"['r', 'and', 'shiny', 'alert']","['r', 'shiny', 'alert']",r shiny alert,0.0,0.0,4,13,2.6,0,0,0,0,0,0,0,0
3312,unable to update profile,Other,unable to update profile,"['unable', 'to', 'update', 'profile']",0,"['unable', 'to', 'update', 'profile']","['unable', 'update', 'profile']",unable update profile,-0.5,-0.5,4,21,4.2,0,0,0,0,0,0,0,0
3313,help needed in azure ml,Tools,help needed in azure ml,"['help', 'needed', 'in', 'azure', 'ml']",0,"['help', 'needed', 'in', 'azure', 'ml']","['help', 'needed', 'azure', 'ml']",help needed azure ml,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
3314,a good resource for ml,Techniques,a good resource for ml,"['a', 'good', 'resource', 'for', 'ml']",0,"['a', 'good', 'resource', 'for', 'ml']","['good', 'resource', 'ml']",good resource ml,0.7,0.7,5,16,2.6666666666666665,0,0,0,0,0,0,0,0
3315,discussion for pop quiz,Other,discussion for pop quiz,"['discussion', 'for', 'pop', 'quiz']",0,"['discussion', 'for', 'pop', 'quiz']","['discussion', 'pop', 'quiz']",discussion pop quiz,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
3316,how to change the position of chart objects in qlikview,Tools,how to change the position of chart objects in qlikview,"['how', 'to', 'change', 'the', 'position', 'of', 'chart', 'objects', 'in', 'qlikview']",0,"['how', 'to', 'change', 'the', 'position', 'of', 'chart', 'object', 'in', 'qlikview']","['change', 'position', 'chart', 'object', 'qlikview']",change position chart object qlikview,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
3317,set analysis chart in qlikview  im stuck,Techniques,set analysis chart in qlikview  im stuck,"['set', 'analysis', 'chart', 'in', 'qlikview', 'im', 'stuck']",0,"['set', 'analysis', 'chart', 'in', 'qlikview', 'im', 'stuck']","['set', 'analysis', 'chart', 'qlikview', 'im', 'stuck']",set analysis chart qlikview im stuck,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
3318,machine learning,Techniques,machine learning,"['machine', 'learning']",0,"['machine', 'learning']","['machine', 'learning']",machine learning,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
3319,how to start predictive maintenance using machine learning,Resources,how to start predictive maintenance using machine learning,"['how', 'to', 'start', 'predictive', 'maintenance', 'using', 'machine', 'learning']",0,"['how', 'to', 'start', 'predictive', 'maintenance', 'using', 'machine', 'learning']","['start', 'predictive', 'maintenance', 'using', 'machine', 'learning']",start predictive maintenance using machine learning,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
3320,how to generate the vector of fixed length in r,Tools,how to generate the vector of fixed length in r,"['how', 'to', 'generate', 'the', 'vector', 'of', 'fixed', 'length', 'in', 'r']",0,"['how', 'to', 'generate', 'the', 'vector', 'of', 'fixed', 'length', 'in', 'r']","['generate', 'vector', 'fixed', 'length', 'r']",generate vector fixed length r,0.1,0.1,10,30,2.727272727272727,0,0,0,0,0,0,0,0
3321,regarding huge data sets in hackathons,Hackathons,regarding huge data sets in hackathons,"['regarding', 'huge', 'data', 'sets', 'in', 'hackathons']",0,"['regarding', 'huge', 'data', 'set', 'in', 'hackathons']","['regarding', 'huge', 'data', 'set', 'hackathons']",regarding huge data set hackathons,0.4000000000000001,0.4000000000000001,6,34,4.857142857142857,0,0,0,0,0,0,0,0
3322,how to install packages for python on osx,Tools,how to install packages for python on osx,"['how', 'to', 'install', 'packages', 'for', 'python', 'on', 'osx']",0,"['how', 'to', 'install', 'package', 'for', 'python', 'on', 'osx']","['install', 'package', 'python', 'osx']",install package python osx,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
3323,cross sell modelling data preparation,Techniques,cross sell modelling data preparation,"['cross', 'sell', 'modelling', 'data', 'preparation']",0,"['cross', 'sell', 'modelling', 'data', 'preparation']","['cross', 'sell', 'modelling', 'data', 'preparation']",cross sell modelling data preparation,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
3324,what questions should i ask the employer before considering an analytics job offer,Career,what questions should i ask the employer before considering an analytics job offer,"['what', 'questions', 'should', 'i', 'ask', 'the', 'employer', 'before', 'considering', 'an', 'analytics', 'job', 'offer']",0,"['what', 'question', 'should', 'i', 'ask', 'the', 'employer', 'before', 'considering', 'an', 'analytics', 'job', 'offer']","['question', 'ask', 'employer', 'considering', 'analytics', 'job', 'offer']",question ask employer considering analytics job offer,0.0,0.0,13,53,3.7857142857142856,0,0,0,0,0,0,0,0
3325,conditional inference trees in r ctree,Techniques,conditional inference trees in r ctree,"['conditional', 'inference', 'trees', 'in', 'r', 'ctree']",0,"['conditional', 'inference', 'tree', 'in', 'r', 'ctree']","['conditional', 'inference', 'tree', 'r', 'ctree']",conditional inference tree r ctree,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
3326,variable reduction when there  categorical variable like sexsizesmallmediumlarge etc,Techniques,variable reduction when there  categorical variable like sexsizesmallmediumlarge etc,"['variable', 'reduction', 'when', 'there', 'categorical', 'variable', 'like', 'sexsizesmallmediumlarge', 'etc']",1,"['variable', 'reduction', 'when', 'there', 'categorical', 'variable', 'like', 'sexsizesmallmediumlarge', 'etc']","['variable', 'reduction', 'categorical', 'variable', 'like', 'sexsizesmallmediumlarge', 'etc']",variable reduction categorical variable like sexsizesmallmediumlarge etc,0.0,0.0,9,72,7.2,0,0,0,0,0,0,0,0
3327,what does the error variable lengths differ upon applying ada boost imply,Techniques,what does the error variable lengths differ upon applying ada boost imply,"['what', 'does', 'the', 'error', 'variable', 'lengths', 'differ', 'upon', 'applying', 'ada', 'boost', 'imply']",0,"['what', 'doe', 'the', 'error', 'variable', 'length', 'differ', 'upon', 'applying', 'ada', 'boost', 'imply']","['doe', 'error', 'variable', 'length', 'differ', 'upon', 'applying', 'ada', 'boost', 'imply']",doe error variable length differ upon applying ada boost imply,0.0,0.0,12,62,4.769230769230769,0,0,0,0,0,0,0,0
3328,most useful data mining libraries in python,Tools,most useful data mining libraries in python,"['most', 'useful', 'data', 'mining', 'libraries', 'in', 'python']",0,"['most', 'useful', 'data', 'mining', 'library', 'in', 'python']","['useful', 'data', 'mining', 'library', 'python']",useful data mining library python,0.4,0.3,7,33,4.125,0,0,0,0,0,0,0,0
3329,how to use multiple condition with pandas dataframe,Techniques,how to use multiple condition with pandas dataframe,"['how', 'to', 'use', 'multiple', 'condition', 'with', 'pandas', 'dataframe']",0,"['how', 'to', 'use', 'multiple', 'condition', 'with', 'panda', 'dataframe']","['use', 'multiple', 'condition', 'panda', 'dataframe']",use multiple condition panda dataframe,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
3330,deep learning  curated reading list,Resources,deep learning  curated reading list,"['deep', 'learning', 'curated', 'reading', 'list']",0,"['deep', 'learning', 'curated', 'reading', 'list']","['deep', 'learning', 'curated', 'reading', 'list']",deep learning curated reading list,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
3331,difference in performance of the naive bayes and aode algorithms,Techniques,difference in performance of the naive bayes and aode algorithms,"['difference', 'in', 'performance', 'of', 'the', 'naive', 'bayes', 'and', 'aode', 'algorithms']",0,"['difference', 'in', 'performance', 'of', 'the', 'naive', 'bayes', 'and', 'aode', 'algorithm']","['difference', 'performance', 'naive', 'bayes', 'aode', 'algorithm']",difference performance naive bayes aode algorithm,-0.3,-0.3,10,49,4.454545454545454,0,0,0,0,0,0,0,0
3332,how to do classification when some information only available only during training stage,Techniques,how to do classification when some information only available only during training stage,"['how', 'to', 'do', 'classification', 'when', 'some', 'information', 'only', 'available', 'only', 'during', 'training', 'stage']",0,"['how', 'to', 'do', 'classification', 'when', 'some', 'information', 'only', 'available', 'only', 'during', 'training', 'stage']","['classification', 'information', 'available', 'training', 'stage']",classification information available training stage,0.1333333333333333,0.4,13,51,3.642857142857143,0,0,0,0,0,0,0,0
3333,difference between d s r operator in python,Tools,difference between d s r operator in python,"['difference', 'between', 'd', 's', 'r', 'operator', 'in', 'python']",0,"['difference', 'between', 'd', 's', 'r', 'operator', 'in', 'python']","['difference', 'r', 'operator', 'python']",difference r operator python,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
3334,various formats to use the text format in qlikview,Tools,various formats to use the text format in qlikview,"['various', 'formats', 'to', 'use', 'the', 'text', 'format', 'in', 'qlikview']",0,"['various', 'format', 'to', 'use', 'the', 'text', 'format', 'in', 'qlikview']","['various', 'format', 'use', 'text', 'format', 'qlikview']",various format use text format qlikview,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
3335,model using sampling strategy  downup etc and its real time deployment,Techniques,model using sampling strategy  downup etc and its real time deployment,"['model', 'using', 'sampling', 'strategy', 'downup', 'etc', 'and', 'its', 'real', 'time', 'deployment']",0,"['model', 'using', 'sampling', 'strategy', 'downup', 'etc', 'and', 'it', 'real', 'time', 'deployment']","['model', 'using', 'sampling', 'strategy', 'downup', 'etc', 'real', 'time', 'deployment']",model using sampling strategy downup etc real time deployment,0.2,0.2,11,61,5.083333333333333,0,0,0,0,0,0,0,0
3336,how do i predict churning out with class imbalance using survival analysis,Techniques,how do i predict churning out with class imbalance using survival analysis,"['how', 'do', 'i', 'predict', 'churning', 'out', 'with', 'class', 'imbalance', 'using', 'survival', 'analysis']",0,"['how', 'do', 'i', 'predict', 'churning', 'out', 'with', 'class', 'imbalance', 'using', 'survival', 'analysis']","['predict', 'churning', 'class', 'imbalance', 'using', 'survival', 'analysis']",predict churning class imbalance using survival analysis,-0.5,-0.5,12,56,4.3076923076923075,0,0,0,0,0,0,0,0
3337,how do we apply pca on a highly sparse matrix,Techniques,how do we apply pca on a highly sparse matrix,"['how', 'do', 'we', 'apply', 'pca', 'on', 'a', 'highly', 'sparse', 'matrix']",0,"['how', 'do', 'we', 'apply', 'pca', 'on', 'a', 'highly', 'sparse', 'matrix']","['apply', 'pca', 'highly', 'sparse', 'matrix']",apply pca highly sparse matrix,0.16,0.16,10,30,2.727272727272727,0,0,0,0,0,0,0,0
3338,workshop  not able to detect na in train data set and,Other,workshop  not able to detect na in train data set and,"['workshop', 'not', 'able', 'to', 'detect', 'na', 'in', 'train', 'data', 'set', 'and']",0,"['workshop', 'not', 'able', 'to', 'detect', 'na', 'in', 'train', 'data', 'set', 'and']","['workshop', 'able', 'detect', 'na', 'train', 'data', 'set']",workshop able detect na train data set,-0.25,0.5,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
3339,what is the evaluation metric for apriori algorithm,Techniques,what is the evaluation metric for apriori algorithm,"['what', 'is', 'the', 'evaluation', 'metric', 'for', 'apriori', 'algorithm']",0,"['what', 'is', 'the', 'evaluation', 'metric', 'for', 'apriori', 'algorithm']","['evaluation', 'metric', 'apriori', 'algorithm']",evaluation metric apriori algorithm,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
3340,webscraping an online virtual football league site to correctly predict patterns,Tools,webscraping an online virtual football league site to correctly predict patterns,"['webscraping', 'an', 'online', 'virtual', 'football', 'league', 'site', 'to', 'correctly', 'predict', 'patterns']",0,"['webscraping', 'an', 'online', 'virtual', 'football', 'league', 'site', 'to', 'correctly', 'predict', 'pattern']","['webscraping', 'online', 'virtual', 'football', 'league', 'site', 'correctly', 'predict', 'pattern']",webscraping online virtual football league site correctly predict pattern,0.0,0.0,11,73,6.083333333333333,0,0,0,0,0,0,0,0
3341,topic modelling in python,Techniques,topic modelling in python,"['topic', 'modelling', 'in', 'python']",0,"['topic', 'modelling', 'in', 'python']","['topic', 'modelling', 'python']",topic modelling python,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
3342,new customer acquisition nca strategy,Other,new customer acquisition nca strategy,"['new', 'customer', 'acquisition', 'nca', 'strategy']",0,"['new', 'customer', 'acquisition', 'nca', 'strategy']","['new', 'customer', 'acquisition', 'nca', 'strategy']",new customer acquisition nca strategy,0.1363636363636363,0.1363636363636363,5,37,6.166666666666667,0,0,0,0,0,0,0,0
3343,connecting external application to hbase  thrift vs rest api,Tools,connecting external application to hbase  thrift vs rest api,"['connecting', 'external', 'application', 'to', 'hbase', 'thrift', 'vs', 'rest', 'api']",0,"['connecting', 'external', 'application', 'to', 'hbase', 'thrift', 'v', 'rest', 'api']","['connecting', 'external', 'application', 'hbase', 'thrift', 'v', 'rest', 'api']",connecting external application hbase thrift v rest api,0.0,0.0,9,55,5.5,0,0,0,0,0,0,0,0
3344,variable selection before or after cross validation python,Techniques,variable selection before or after cross validation python,"['variable', 'selection', 'before', 'or', 'after', 'cross', 'validation', 'python']",0,"['variable', 'selection', 'before', 'or', 'after', 'cross', 'validation', 'python']","['variable', 'selection', 'cross', 'validation', 'python']",variable selection cross validation python,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
3345,credibility of data camp certifications and ibm badges,Career,credibility of data camp certifications and ibm badges,"['credibility', 'of', 'data', 'camp', 'certifications', 'and', 'ibm', 'badges']",0,"['credibility', 'of', 'data', 'camp', 'certification', 'and', 'ibm', 'badge']","['credibility', 'data', 'camp', 'certification', 'ibm', 'badge']",credibility data camp certification ibm badge,0.0,0.0,8,45,5.0,0,0,0,0,0,0,0,0
3346,time series forecasting with different intervals,Techniques,time series forecasting with different intervals,"['time', 'series', 'forecasting', 'with', 'different', 'intervals']",0,"['time', 'series', 'forecasting', 'with', 'different', 'interval']","['time', 'series', 'forecasting', 'different', 'interval']",time series forecasting different interval,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
3347,how to implement scaling in r,Tools,how to implement scaling in r,"['how', 'to', 'implement', 'scaling', 'in', 'r']",0,"['how', 'to', 'implement', 'scaling', 'in', 'r']","['implement', 'scaling', 'r']",implement scaling r,0.0,0.0,6,19,2.7142857142857144,0,0,0,0,0,0,0,0
3348,pgdba from iim c  iit k  isi vs continue working in analytics domain,Career,pgdba from iim c  iit k  isi vs continue working in analytics domain,"['pgdba', 'from', 'iim', 'c', 'iit', 'k', 'isi', 'vs', 'continue', 'working', 'in', 'analytics', 'domain']",0,"['pgdba', 'from', 'iim', 'c', 'iit', 'k', 'isi', 'v', 'continue', 'working', 'in', 'analytics', 'domain']","['pgdba', 'iim', 'c', 'iit', 'k', 'isi', 'v', 'continue', 'working', 'analytics', 'domain']",pgdba iim c iit k isi v continue working analytics domain,0.0,0.0,13,57,4.071428571428571,0,0,0,0,0,0,0,0
3349,article data is missing,Resources,article data is missing,"['article', 'data', 'is', 'missing']",0,"['article', 'data', 'is', 'missing']","['article', 'data', 'missing']",article data missing,-0.2,-0.2,4,20,4.0,0,0,0,0,0,0,0,0
3350,how to reduce noise in spatial data,Techniques,how to reduce noise in spatial data,"['how', 'to', 'reduce', 'noise', 'in', 'spatial', 'data']",0,"['how', 'to', 'reduce', 'noise', 'in', 'spatial', 'data']","['reduce', 'noise', 'spatial', 'data']",reduce noise spatial data,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
3351,this discussion will be about a coding query in python,Misc,this discussion will be about a coding query in python,"['this', 'discussion', 'will', 'be', 'about', 'a', 'coding', 'query', 'in', 'python']",0,"['this', 'discussion', 'will', 'be', 'about', 'a', 'coding', 'query', 'in', 'python']","['discussion', 'coding', 'query', 'python']",discussion coding query python,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
3352,do project management skills help in a career in analytics,Career,do project management skills help in a career in analytics,"['do', 'project', 'management', 'skills', 'help', 'in', 'a', 'career', 'in', 'analytics']",0,"['do', 'project', 'management', 'skill', 'help', 'in', 'a', 'career', 'in', 'analytics']","['project', 'management', 'skill', 'help', 'career', 'analytics']",project management skill help career analytics,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
3353,mckinsey hackthon solution sharing,Hackathons,mckinsey hackthon solution sharing,"['mckinsey', 'hackthon', 'solution', 'sharing']",0,"['mckinsey', 'hackthon', 'solution', 'sharing']","['mckinsey', 'hackthon', 'solution', 'sharing']",mckinsey hackthon solution sharing,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
3354,time series model for quarterly sales data,Techniques,time series model for quarterly sales data,"['time', 'series', 'model', 'for', 'quarterly', 'sales', 'data']",0,"['time', 'series', 'model', 'for', 'quarterly', 'sale', 'data']","['time', 'series', 'model', 'quarterly', 'sale', 'data']",time series model quarterly sale data,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
3355,large dataset python,Techniques,large dataset python,"['large', 'dataset', 'python']",0,"['large', 'dataset', 'python']","['large', 'dataset', 'python']",large dataset python,0.2142857142857142,0.2142857142857142,3,20,5.0,0,0,0,0,0,0,0,0
3356,learning data science online,Career,learning data science online,"['learning', 'data', 'science', 'online']",0,"['learning', 'data', 'science', 'online']","['learning', 'data', 'science', 'online']",learning data science online,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
3357,test statistic best for questionnaire,Techniques,test statistic best for questionnaire,"['test', 'statistic', 'best', 'for', 'questionnaire']",0,"['test', 'statistic', 'best', 'for', 'questionnaire']","['test', 'statistic', 'best', 'questionnaire']",test statistic best questionnaire,1.0,1.0,5,33,5.5,0,0,0,0,0,0,0,0
3358,xgboost algorithm predicting too high or too low probablity,Techniques,xgboost algorithm predicting too high or too low probablity,"['xgboost', 'algorithm', 'predicting', 'too', 'high', 'or', 'too', 'low', 'probablity']",0,"['xgboost', 'algorithm', 'predicting', 'too', 'high', 'or', 'too', 'low', 'probablity']","['xgboost', 'algorithm', 'predicting', 'high', 'low', 'probablity']",xgboost algorithm predicting high low probablity,0.08,0.08,9,48,4.8,0,0,0,0,0,0,0,0
3359,gradient function for constroptim in r,Techniques,gradient function for constroptim in r,"['gradient', 'function', 'for', 'constroptim', 'in', 'r']",0,"['gradient', 'function', 'for', 'constroptim', 'in', 'r']","['gradient', 'function', 'constroptim', 'r']",gradient function constroptim r,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
3360,time series interview questions,Techniques,time series interview questions,"['time', 'series', 'interview', 'questions']",0,"['time', 'series', 'interview', 'question']","['time', 'series', 'interview', 'question']",time series interview question,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
3361,model for interdependant multivariate time series,Techniques,model for interdependant multivariate time series,"['model', 'for', 'interdependant', 'multivariate', 'time', 'series']",0,"['model', 'for', 'interdependant', 'multivariate', 'time', 'series']","['model', 'interdependant', 'multivariate', 'time', 'series']",model interdependant multivariate time series,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
3362,standard error approaching standard deviation in tdistribution with large samples,Techniques,standard error approaching standard deviation in tdistribution with large samples,"['standard', 'error', 'approaching', 'standard', 'deviation', 'in', 'tdistribution', 'with', 'large', 'samples']",0,"['standard', 'error', 'approaching', 'standard', 'deviation', 'in', 'tdistribution', 'with', 'large', 'sample']","['standard', 'error', 'approaching', 'standard', 'deviation', 'tdistribution', 'large', 'sample']",standard error approaching standard deviation tdistribution large sample,0.0535714285714285,0.0535714285714285,10,72,6.545454545454546,0,0,0,0,0,0,0,0
3363,please suggest some good institute in pune for data analytics course,Career,please suggest some good institute in pune for data analytics course,"['please', 'suggest', 'some', 'good', 'institute', 'in', 'pune', 'for', 'data', 'analytics', 'course']",0,"['please', 'suggest', 'some', 'good', 'institute', 'in', 'pune', 'for', 'data', 'analytics', 'course']","['please', 'suggest', 'good', 'institute', 'pune', 'data', 'analytics', 'course']",please suggest good institute pune data analytics course,0.7,0.7,11,56,4.666666666666667,0,0,0,0,0,0,0,0
3364,how to limit the size of the memory rstudio uses during a process run,Tools,how to limit the size of the memory rstudio uses during a process run,"['how', 'to', 'limit', 'the', 'size', 'of', 'the', 'memory', 'rstudio', 'uses', 'during', 'a', 'process', 'run']",0,"['how', 'to', 'limit', 'the', 'size', 'of', 'the', 'memory', 'rstudio', 'us', 'during', 'a', 'process', 'run']","['limit', 'size', 'memory', 'rstudio', 'us', 'process', 'run']",limit size memory rstudio us process run,0.0,0.0,14,40,2.6666666666666665,0,0,0,0,0,0,0,0
3365,hr analytics and how to make a move into it,Career,hr analytics and how to make a move into it,"['hr', 'analytics', 'and', 'how', 'to', 'make', 'a', 'move', 'into', 'it']",0,"['hr', 'analytics', 'and', 'how', 'to', 'make', 'a', 'move', 'into', 'it']","['hr', 'analytics', 'make', 'move']",hr analytics make move,0.0,0.0,10,22,2.0,0,0,0,0,0,0,0,0
3366,isotonic regression calibration for svm,Techniques,isotonic regression calibration for svm,"['isotonic', 'regression', 'calibration', 'for', 'svm']",0,"['isotonic', 'regression', 'calibration', 'for', 'svm']","['isotonic', 'regression', 'calibration', 'svm']",isotonic regression calibration svm,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
3367,learning paths to ai ml for some one familiar with r,Career,learning paths to ai ml for some one familiar with r,"['learning', 'paths', 'to', 'ai', 'ml', 'for', 'some', 'one', 'familiar', 'with', 'r']",0,"['learning', 'path', 'to', 'ai', 'ml', 'for', 'some', 'one', 'familiar', 'with', 'r']","['learning', 'path', 'ai', 'ml', 'one', 'familiar', 'r']",learning path ai ml one familiar r,0.375,0.375,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
3368,logistic regression over sampling,Techniques,logistic regression over sampling,"['logistic', 'regression', 'over', 'sampling']",0,"['logistic', 'regression', 'over', 'sampling']","['logistic', 'regression', 'sampling']",logistic regression sampling,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
3369,learning data science  survey,Career,learning data science  survey,"['learning', 'data', 'science', 'survey']",0,"['learning', 'data', 'science', 'survey']","['learning', 'data', 'science', 'survey']",learning data science survey,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
3370,tableau online instructor led training  edureka or simplilearn which one is better,Tools,tableau online instructor led training  edureka or simplilearn which one is better,"['tableau', 'online', 'instructor', 'led', 'training', 'edureka', 'or', 'simplilearn', 'which', 'one', 'is', 'better']",0,"['tableau', 'online', 'instructor', 'led', 'training', 'edureka', 'or', 'simplilearn', 'which', 'one', 'is', 'better']","['tableau', 'online', 'instructor', 'led', 'training', 'edureka', 'simplilearn', 'one', 'better']",tableau online instructor led training edureka simplilearn one better,0.5,0.5,12,69,5.3076923076923075,0,0,0,0,0,0,0,0
3371,image analytics,Techniques,image analytics,"['image', 'analytics']",0,"['image', 'analytics']","['image', 'analytics']",image analytics,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
3372,jobs for freshers in data science field in india,Techniques,jobs for freshers in data science field in india,"['jobs', 'for', 'freshers', 'in', 'data', 'science', 'field', 'in', 'india']",0,"['job', 'for', 'fresher', 'in', 'data', 'science', 'field', 'in', 'india']","['job', 'fresher', 'data', 'science', 'field', 'india']",job fresher data science field india,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
3373,how is muit data science program,Career,how is muit data science program,"['how', 'is', 'muit', 'data', 'science', 'program']",0,"['how', 'is', 'muit', 'data', 'science', 'program']","['muit', 'data', 'science', 'program']",muit data science program,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
3374,scope of shiny apps,Tools,scope of shiny apps,"['scope', 'of', 'shiny', 'apps']",0,"['scope', 'of', 'shiny', 'apps']","['scope', 'shiny', 'apps']",scope shiny apps,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
3375,data scientist and big data,Career,data scientist and big data,"['data', 'scientist', 'and', 'big', 'data']",0,"['data', 'scientist', 'and', 'big', 'data']","['data', 'scientist', 'big', 'data']",data scientist big data,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
3376,help with clustering listings,Techniques,help with clustering listings,"['help', 'with', 'clustering', 'listings']",0,"['help', 'with', 'clustering', 'listing']","['help', 'clustering', 'listing']",help clustering listing,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
3377,sas interview question,Tools,sas interview question,"['sas', 'interview', 'question']",0,"['sa', 'interview', 'question']","['sa', 'interview', 'question']",sa interview question,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
3378,how to name the list after creating the list in r,Tools,how to name the list after creating the list in r,"['how', 'to', 'name', 'the', 'list', 'after', 'creating', 'the', 'list', 'in', 'r']",0,"['how', 'to', 'name', 'the', 'list', 'after', 'creating', 'the', 'list', 'in', 'r']","['name', 'list', 'creating', 'list', 'r']",name list creating list r,0.0,0.0,11,25,2.0833333333333335,0,0,0,0,0,0,0,0
3379,getting into the field,Career,getting into the field,"['getting', 'into', 'the', 'field']",0,"['getting', 'into', 'the', 'field']","['getting', 'field']",getting field,0.0,0.0,4,13,2.6,0,0,0,0,0,0,0,0
3380,mice package to impute missing values  decode the dalai lama,Tools,mice package to impute missing values  decode the dalai lama,"['mice', 'package', 'to', 'impute', 'missing', 'values', 'decode', 'the', 'dalai', 'lama']",0,"['mouse', 'package', 'to', 'impute', 'missing', 'value', 'decode', 'the', 'dalai', 'lama']","['mouse', 'package', 'impute', 'missing', 'value', 'decode', 'dalai', 'lama']",mouse package impute missing value decode dalai lama,-0.2,-0.2,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
3381,how much memory does r allocate for operations,Tools,how much memory does r allocate for operations,"['how', 'much', 'memory', 'does', 'r', 'allocate', 'for', 'operations']",0,"['how', 'much', 'memory', 'doe', 'r', 'allocate', 'for', 'operation']","['much', 'memory', 'doe', 'r', 'allocate', 'operation']",much memory doe r allocate operation,0.2,0.2,8,36,4.0,0,0,0,0,0,0,0,0
3382,sample programs to execute simple logical conditions in sas macros,Techniques,sample programs to execute simple logical conditions in sas macros,"['sample', 'programs', 'to', 'execute', 'simple', 'logical', 'conditions', 'in', 'sas', 'macros']",0,"['sample', 'program', 'to', 'execute', 'simple', 'logical', 'condition', 'in', 'sa', 'macro']","['sample', 'program', 'execute', 'simple', 'logical', 'condition', 'sa', 'macro']",sample program execute simple logical condition sa macro,0.125,0.125,10,56,5.090909090909091,0,0,0,0,0,0,0,0
3383,please provide any good tutorial on data cleaning and preprocessing using python,Resources,please provide any good tutorial on data cleaning and preprocessing using python,"['please', 'provide', 'any', 'good', 'tutorial', 'on', 'data', 'cleaning', 'and', 'preprocessing', 'using', 'python']",0,"['please', 'provide', 'any', 'good', 'tutorial', 'on', 'data', 'cleaning', 'and', 'preprocessing', 'using', 'python']","['please', 'provide', 'good', 'tutorial', 'data', 'cleaning', 'preprocessing', 'using', 'python']",please provide good tutorial data cleaning preprocessing using python,0.7,0.7,12,69,5.3076923076923075,0,0,0,0,0,0,0,0
3384,what is the reason for effect of gamma parameter in nonlinear classification using support vector machines,Techniques,what is the reason for effect of gamma parameter in nonlinear classification using support vector machines,"['what', 'is', 'the', 'reason', 'for', 'effect', 'of', 'gamma', 'parameter', 'in', 'nonlinear', 'classification', 'using', 'support', 'vector', 'machines']",0,"['what', 'is', 'the', 'reason', 'for', 'effect', 'of', 'gamma', 'parameter', 'in', 'nonlinear', 'classification', 'using', 'support', 'vector', 'machine']","['reason', 'effect', 'gamma', 'parameter', 'nonlinear', 'classification', 'using', 'support', 'vector', 'machine']",reason effect gamma parameter nonlinear classification using support vector machine,0.0,0.0,16,83,4.882352941176471,0,0,0,0,0,0,0,0
3385,knocktober related question,Hackathons,knocktober related question,"['knocktober', 'related', 'question']",0,"['knocktober', 'related', 'question']","['knocktober', 'related', 'question']",knocktober related question,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
3386,is it required to learn data science before machine learning,Career,is it required to learn data science before machine learning,"['is', 'it', 'required', 'to', 'learn', 'data', 'science', 'before', 'machine', 'learning']",0,"['is', 'it', 'required', 'to', 'learn', 'data', 'science', 'before', 'machine', 'learning']","['required', 'learn', 'data', 'science', 'machine', 'learning']",required learn data science machine learning,0.0,0.0,10,44,4.0,0,0,0,0,0,0,0,0
3387,best analytics training centertutor in chennai,Misc,best analytics training centertutor in chennai,"['best', 'analytics', 'training', 'centertutor', 'in', 'chennai']",0,"['best', 'analytics', 'training', 'centertutor', 'in', 'chennai']","['best', 'analytics', 'training', 'centertutor', 'chennai']",best analytics training centertutor chennai,1.0,1.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
3388,data hackathon the d hack  th  th oct   register here,Hackathons,data hackathon the d hack  th  th oct   register here,"['data', 'hackathon', 'the', 'd', 'hack', 'th', 'th', 'oct', 'register', 'here']",1,"['data', 'hackathon', 'the', 'd', 'hack', 'th', 'th', 'oct', 'register', 'here']","['data', 'hackathon', 'hack', 'th', 'th', 'oct', 'register']",data hackathon hack th th oct register,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
3389,how to do multivariate sales forecasting,Techniques,how to do multivariate sales forecasting,"['how', 'to', 'do', 'multivariate', 'sales', 'forecasting']",0,"['how', 'to', 'do', 'multivariate', 'sale', 'forecasting']","['multivariate', 'sale', 'forecasting']",multivariate sale forecasting,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
3390,what is the function of recommender registry in r,Tools,what is the function of recommender registry in r,"['what', 'is', 'the', 'function', 'of', 'recommender', 'registry', 'in', 'r']",0,"['what', 'is', 'the', 'function', 'of', 'recommender', 'registry', 'in', 'r']","['function', 'recommender', 'registry', 'r']",function recommender registry r,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
3391,download data sets,Hackathons,download data sets,"['download', 'data', 'sets']",0,"['download', 'data', 'set']","['download', 'data', 'set']",download data set,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
3392,where can i get an ova file of lua torch  to install it in a vm in windows,Tools,where can i get an ova file of lua torch  to install it in a vm in windows,"['where', 'can', 'i', 'get', 'an', 'ova', 'file', 'of', 'lua', 'torch', 'to', 'install', 'it', 'in', 'a', 'vm', 'in', 'windows']",1,"['where', 'can', 'i', 'get', 'an', 'ovum', 'file', 'of', 'lua', 'torch', 'to', 'install', 'it', 'in', 'a', 'vm', 'in', 'window']","['get', 'ovum', 'file', 'lua', 'torch', 'install', 'vm', 'window']",get ovum file lua torch install vm window,0.0,0.0,18,41,2.1578947368421053,0,0,0,0,0,0,0,0
3393,how do i combine the results of various models for ensemble learning in r,Tools,how do i combine the results of various models for ensemble learning in r,"['how', 'do', 'i', 'combine', 'the', 'results', 'of', 'various', 'models', 'for', 'ensemble', 'learning', 'in', 'r']",0,"['how', 'do', 'i', 'combine', 'the', 'result', 'of', 'various', 'model', 'for', 'ensemble', 'learning', 'in', 'r']","['combine', 'result', 'various', 'model', 'ensemble', 'learning', 'r']",combine result various model ensemble learning r,0.0,0.0,14,48,3.2,0,0,0,0,0,0,0,0
3394,how to create new directory in current working directory in r,Tools,how to create new directory in current working directory in r,"['how', 'to', 'create', 'new', 'directory', 'in', 'current', 'working', 'directory', 'in', 'r']",0,"['how', 'to', 'create', 'new', 'directory', 'in', 'current', 'working', 'directory', 'in', 'r']","['create', 'new', 'directory', 'current', 'working', 'directory', 'r']",create new directory current working directory r,0.0681818181818181,0.0681818181818181,11,48,4.0,0,0,0,0,0,0,0,0
3395,merging of data sets,Techniques,merging of data sets,"['merging', 'of', 'data', 'sets']",0,"['merging', 'of', 'data', 'set']","['merging', 'data', 'set']",merging data set,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
3396,downloading iris dataset,Techniques,downloading iris dataset,"['downloading', 'iris', 'dataset']",0,"['downloading', 'iris', 'dataset']","['downloading', 'iris', 'dataset']",downloading iris dataset,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
3397,msphd combo program in analytics,Career,msphd combo program in analytics,"['msphd', 'combo', 'program', 'in', 'analytics']",0,"['msphd', 'combo', 'program', 'in', 'analytics']","['msphd', 'combo', 'program', 'analytics']",msphd combo program analytics,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
3398,machine learning datasets,Resources,machine learning datasets,"['machine', 'learning', 'datasets']",0,"['machine', 'learning', 'datasets']","['machine', 'learning', 'datasets']",machine learning datasets,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
3399,parallel computation in r on my pc,Techniques,parallel computation in r on my pc,"['parallel', 'computation', 'in', 'r', 'on', 'my', 'pc']",0,"['parallel', 'computation', 'in', 'r', 'on', 'my', 'pc']","['parallel', 'computation', 'r', 'pc']",parallel computation r pc,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
3400,error in concatenating objects using python,Tools,error in concatenating objects using python,"['error', 'in', 'concatenating', 'objects', 'using', 'python']",0,"['error', 'in', 'concatenating', 'object', 'using', 'python']","['error', 'concatenating', 'object', 'using', 'python']",error concatenating object using python,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
3401,please explain statistical modeling to an sql developer,Techniques,please explain statistical modeling to an sql developer,"['please', 'explain', 'statistical', 'modeling', 'to', 'an', 'sql', 'developer']",0,"['please', 'explain', 'statistical', 'modeling', 'to', 'an', 'sql', 'developer']","['please', 'explain', 'statistical', 'modeling', 'sql', 'developer']",please explain statistical modeling sql developer,0.0,0.0,8,49,5.444444444444445,0,0,0,0,0,0,0,0
3402,convert model in api,Techniques,convert model in api,"['convert', 'model', 'in', 'api']",0,"['convert', 'model', 'in', 'api']","['convert', 'model', 'api']",convert model api,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
3403,i have   years experience in testing planning to switch as data scientist suggestion plz,Career,i have   years experience in testing planning to switch as data scientist suggestion plz,"['i', 'have', 'years', 'experience', 'in', 'testing', 'planning', 'to', 'switch', 'as', 'data', 'scientist', 'suggestion', 'plz']",1,"['i', 'have', 'year', 'experience', 'in', 'testing', 'planning', 'to', 'switch', 'a', 'data', 'scientist', 'suggestion', 'plz']","['year', 'experience', 'testing', 'planning', 'switch', 'data', 'scientist', 'suggestion', 'plz']",year experience testing planning switch data scientist suggestion plz,0.0,0.0,14,69,4.6,0,0,0,0,0,0,0,0
3404,what does the output votes from adaboost signify,Techniques,what does the output votes from adaboost signify,"['what', 'does', 'the', 'output', 'votes', 'from', 'adaboost', 'signify']",0,"['what', 'doe', 'the', 'output', 'vote', 'from', 'adaboost', 'signify']","['doe', 'output', 'vote', 'adaboost', 'signify']",doe output vote adaboost signify,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
3405,how to partition the training data for model building,Techniques,how to partition the training data for model building,"['how', 'to', 'partition', 'the', 'training', 'data', 'for', 'model', 'building']",0,"['how', 'to', 'partition', 'the', 'training', 'data', 'for', 'model', 'building']","['partition', 'training', 'data', 'model', 'building']",partition training data model building,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
3406,what is formula for rmspe,Techniques,what is formula for rmspe,"['what', 'is', 'formula', 'for', 'rmspe']",0,"['what', 'is', 'formula', 'for', 'rmspe']","['formula', 'rmspe']",formula rmspe,0.0,0.0,5,13,2.1666666666666665,0,0,0,0,0,0,0,0
3407,drawing insights from forum posts,Techniques,drawing insights from forum posts,"['drawing', 'insights', 'from', 'forum', 'posts']",0,"['drawing', 'insight', 'from', 'forum', 'post']","['drawing', 'insight', 'forum', 'post']",drawing insight forum post,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
3408,field segmentation of a banking detail form,Other,field segmentation of a banking detail form,"['field', 'segmentation', 'of', 'a', 'banking', 'detail', 'form']",0,"['field', 'segmentation', 'of', 'a', 'banking', 'detail', 'form']","['field', 'segmentation', 'banking', 'detail', 'form']",field segmentation banking detail form,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
3409,interpreting result of chisquare test on megastar contest,Techniques,interpreting result of chisquare test on megastar contest,"['interpreting', 'result', 'of', 'chisquare', 'test', 'on', 'megastar', 'contest']",0,"['interpreting', 'result', 'of', 'chisquare', 'test', 'on', 'megastar', 'contest']","['interpreting', 'result', 'chisquare', 'test', 'megastar', 'contest']",interpreting result chisquare test megastar contest,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
3410,steps required to predict a continuous variable,Other,steps required to predict a continuous variable,"['steps', 'required', 'to', 'predict', 'a', 'continuous', 'variable']",0,"['step', 'required', 'to', 'predict', 'a', 'continuous', 'variable']","['step', 'required', 'predict', 'continuous', 'variable']",step required predict continuous variable,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
3411,how does complexity parameter cp work in decision tree,Techniques,how does complexity parameter cp work in decision tree,"['how', 'does', 'complexity', 'parameter', 'cp', 'work', 'in', 'decision', 'tree']",0,"['how', 'doe', 'complexity', 'parameter', 'cp', 'work', 'in', 'decision', 'tree']","['doe', 'complexity', 'parameter', 'cp', 'work', 'decision', 'tree']",doe complexity parameter cp work decision tree,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
3412,what is fa and pca and difference between them,Techniques,what is fa and pca and difference between them,"['what', 'is', 'fa', 'and', 'pca', 'and', 'difference', 'between', 'them']",0,"['what', 'is', 'fa', 'and', 'pca', 'and', 'difference', 'between', 'them']","['fa', 'pca', 'difference']",fa pca difference,0.0,0.0,9,17,1.7,0,0,0,0,0,0,0,0
3413,which one is better msc data science at cmi or msc statistics and computing at bhu or msc applied statistics at symbiosis statistical institute,Career,which one is better msc data science at cmi or msc statistics and computing at bhu or msc applied statistics at symbiosis statistical institute,"['which', 'one', 'is', 'better', 'msc', 'data', 'science', 'at', 'cmi', 'or', 'msc', 'statistics', 'and', 'computing', 'at', 'bhu', 'or', 'msc', 'applied', 'statistics', 'at', 'symbiosis', 'statistical', 'institute']",0,"['which', 'one', 'is', 'better', 'msc', 'data', 'science', 'at', 'cmi', 'or', 'msc', 'statistic', 'and', 'computing', 'at', 'bhu', 'or', 'msc', 'applied', 'statistic', 'at', 'symbiosis', 'statistical', 'institute']","['one', 'better', 'msc', 'data', 'science', 'cmi', 'msc', 'statistic', 'computing', 'bhu', 'msc', 'applied', 'statistic', 'symbiosis', 'statistical', 'institute']",one better msc data science cmi msc statistic computing bhu msc applied statistic symbiosis statistical institute,0.5,0.5,24,113,4.52,0,0,0,0,0,0,0,0
3414,can i forge text data to train my model,Techniques,can i forge text data to train my model,"['can', 'i', 'forge', 'text', 'data', 'to', 'train', 'my', 'model']",0,"['can', 'i', 'forge', 'text', 'data', 'to', 'train', 'my', 'model']","['forge', 'text', 'data', 'train', 'model']",forge text data train model,0.0,0.0,9,27,2.7,0,0,0,0,0,0,0,0
3415,how to check if the model is overffiting,Techniques,how to check if the model is overffiting,"['how', 'to', 'check', 'if', 'the', 'model', 'is', 'overffiting']",0,"['how', 'to', 'check', 'if', 'the', 'model', 'is', 'overffiting']","['check', 'model', 'overffiting']",check model overffiting,0.0,0.0,8,23,2.5555555555555554,0,0,0,0,0,0,0,0
3416,what is the difference between naomit and narm,Tools,what is the difference between naomit and narm,"['what', 'is', 'the', 'difference', 'between', 'naomit', 'and', 'narm']",0,"['what', 'is', 'the', 'difference', 'between', 'naomit', 'and', 'narm']","['difference', 'naomit', 'narm']",difference naomit narm,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
3417,what does response  nominal mean in knn,Techniques,what does response  nominal mean in knn,"['what', 'does', 'response', 'nominal', 'mean', 'in', 'knn']",0,"['what', 'doe', 'response', 'nominal', 'mean', 'in', 'knn']","['doe', 'response', 'nominal', 'mean', 'knn']",doe response nominal mean knn,-0.3125,-0.3125,7,29,3.625,0,0,0,0,0,0,0,0
3418,how to scrape data within a input tag from an iframe using r,Tools,how to scrape data within a input tag from an iframe using r,"['how', 'to', 'scrape', 'data', 'within', 'a', 'input', 'tag', 'from', 'an', 'iframe', 'using', 'r']",0,"['how', 'to', 'scrape', 'data', 'within', 'a', 'input', 'tag', 'from', 'an', 'iframe', 'using', 'r']","['scrape', 'data', 'within', 'input', 'tag', 'iframe', 'using', 'r']",scrape data within input tag iframe using r,0.0,0.0,13,43,3.0714285714285716,0,0,0,0,0,0,0,0
3419,recommend a realworld business problem,Other,recommend a realworld business problem,"['recommend', 'a', 'realworld', 'business', 'problem']",0,"['recommend', 'a', 'realworld', 'business', 'problem']","['recommend', 'realworld', 'business', 'problem']",recommend realworld business problem,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
3420,optimize nestimators using xgbcv,Tools,optimize nestimators using xgbcv,"['optimize', 'nestimators', 'using', 'xgbcv']",0,"['optimize', 'nestimators', 'using', 'xgbcv']","['optimize', 'nestimators', 'using', 'xgbcv']",optimize nestimators using xgbcv,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
3421,principal component analysis problem,Techniques,principal component analysis problem,"['principal', 'component', 'analysis', 'problem']",0,"['principal', 'component', 'analysis', 'problem']","['principal', 'component', 'analysis', 'problem']",principal component analysis problem,0.0,0.0,4,36,7.2,0,0,0,0,0,0,0,0
3422,the guide to quickly learn cloud computing in r programming,Resources,the guide to quickly learn cloud computing in r programming,"['the', 'guide', 'to', 'quickly', 'learn', 'cloud', 'computing', 'in', 'r', 'programming']",0,"['the', 'guide', 'to', 'quickly', 'learn', 'cloud', 'computing', 'in', 'r', 'programming']","['guide', 'quickly', 'learn', 'cloud', 'computing', 'r', 'programming']",guide quickly learn cloud computing r programming,0.3333333333333333,0.3333333333333333,10,49,4.454545454545454,0,0,0,0,0,0,0,0
3423,how to remove serial number from exported csv file in python,Tools,how to remove serial number from exported csv file in python,"['how', 'to', 'remove', 'serial', 'number', 'from', 'exported', 'csv', 'file', 'in', 'python']",0,"['how', 'to', 'remove', 'serial', 'number', 'from', 'exported', 'csv', 'file', 'in', 'python']","['remove', 'serial', 'number', 'exported', 'csv', 'file', 'python']",remove serial number exported csv file python,0.0,0.0,11,45,3.75,0,0,0,0,0,0,0,0
3424,difference in model performance measures of train and test data sets,Techniques,difference in model performance measures of train and test data sets,"['difference', 'in', 'model', 'performance', 'measures', 'of', 'train', 'and', 'test', 'data', 'sets']",0,"['difference', 'in', 'model', 'performance', 'measure', 'of', 'train', 'and', 'test', 'data', 'set']","['difference', 'model', 'performance', 'measure', 'train', 'test', 'data', 'set']",difference model performance measure train test data set,0.0,0.0,11,56,4.666666666666667,0,0,0,0,0,0,0,0
3425,big data framework from storage to processing  stock prices on  trade setups,Techniques,big data framework from storage to processing  stock prices on  trade setups,"['big', 'data', 'framework', 'from', 'storage', 'to', 'processing', 'stock', 'prices', 'on', 'trade', 'setups']",2,"['big', 'data', 'framework', 'from', 'storage', 'to', 'processing', 'stock', 'price', 'on', 'trade', 'setup']","['big', 'data', 'framework', 'storage', 'processing', 'stock', 'price', 'trade', 'setup']",big data framework storage processing stock price trade setup,0.0,0.0,12,61,4.6923076923076925,0,0,0,0,0,0,0,0
3426,how to implement the apriori algorithm in r,Techniques,how to implement the apriori algorithm in r,"['how', 'to', 'implement', 'the', 'apriori', 'algorithm', 'in', 'r']",0,"['how', 'to', 'implement', 'the', 'apriori', 'algorithm', 'in', 'r']","['implement', 'apriori', 'algorithm', 'r']",implement apriori algorithm r,0.0,0.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
3427,need help,Hackathons,need help,"['need', 'help']",0,"['need', 'help']","['need', 'help']",need help,0.0,0.0,2,9,3.0,0,0,0,0,0,0,0,0
3428,how to extract particular keywords from a text document and determine weightages using python,Tools,how to extract particular keywords from a text document and determine weightages using python,"['how', 'to', 'extract', 'particular', 'keywords', 'from', 'a', 'text', 'document', 'and', 'determine', 'weightages', 'using', 'python']",0,"['how', 'to', 'extract', 'particular', 'keywords', 'from', 'a', 'text', 'document', 'and', 'determine', 'weightages', 'using', 'python']","['extract', 'particular', 'keywords', 'text', 'document', 'determine', 'weightages', 'using', 'python']",extract particular keywords text document determine weightages using python,0.1666666666666666,0.1666666666666666,14,75,5.0,0,0,0,0,0,0,0,0
3429,emojis extraction can someone help,Techniques,emojis extraction can someone help,"['emojis', 'extraction', 'can', 'someone', 'help']",0,"['emojis', 'extraction', 'can', 'someone', 'help']","['emojis', 'extraction', 'someone', 'help']",emojis extraction someone help,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
3430,career change from tableau to hadoop,Career,career change from tableau to hadoop,"['career', 'change', 'from', 'tableau', 'to', 'hadoop']",0,"['career', 'change', 'from', 'tableau', 'to', 'hadoop']","['career', 'change', 'tableau', 'hadoop']",career change tableau hadoop,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
3431,how to calculate accuracy,Hackathons,how to calculate accuracy,"['how', 'to', 'calculate', 'accuracy']",0,"['how', 'to', 'calculate', 'accuracy']","['calculate', 'accuracy']",calculate accuracy,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
3432,difference between machine learning and deep learning,Techniques,difference between machine learning and deep learning,"['difference', 'between', 'machine', 'learning', 'and', 'deep', 'learning']",0,"['difference', 'between', 'machine', 'learning', 'and', 'deep', 'learning']","['difference', 'machine', 'learning', 'deep', 'learning']",difference machine learning deep learning,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
3433,need your support in ongoing blogathon ,Tools,need your support in ongoing blogathon ,"['need', 'your', 'support', 'in', 'ongoing', 'blogathon']",1,"['need', 'your', 'support', 'in', 'ongoing', 'blogathon']","['need', 'support', 'ongoing', 'blogathon']",need support ongoing blogathon,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
3434,data science feasibility for commerce stream guys,Career,data science feasibility for commerce stream guys,"['data', 'science', 'feasibility', 'for', 'commerce', 'stream', 'guys']",0,"['data', 'science', 'feasibility', 'for', 'commerce', 'stream', 'guy']","['data', 'science', 'feasibility', 'commerce', 'stream', 'guy']",data science feasibility commerce stream guy,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
3435,fast ai vs keras,Techniques,fast ai vs keras,"['fast', 'ai', 'vs', 'keras']",0,"['fast', 'ai', 'v', 'kera']","['fast', 'ai', 'v', 'kera']",fast ai v kera,0.2,0.2,4,14,2.8,0,0,0,0,0,0,0,0
3436,cox regression checking diagnostics for ph assumption,Techniques,cox regression checking diagnostics for ph assumption,"['cox', 'regression', 'checking', 'diagnostics', 'for', 'ph', 'assumption']",0,"['cox', 'regression', 'checking', 'diagnostics', 'for', 'ph', 'assumption']","['cox', 'regression', 'checking', 'diagnostics', 'ph', 'assumption']",cox regression checking diagnostics ph assumption,0.0,0.0,7,49,6.125,0,0,0,0,0,0,0,0
3437,ranking metrics for recommendation engines,Techniques,ranking metrics for recommendation engines,"['ranking', 'metrics', 'for', 'recommendation', 'engines']",0,"['ranking', 'metric', 'for', 'recommendation', 'engine']","['ranking', 'metric', 'recommendation', 'engine']",ranking metric recommendation engine,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
3438,predicting driver behaviour,Techniques,predicting driver behaviour,"['predicting', 'driver', 'behaviour']",0,"['predicting', 'driver', 'behaviour']","['predicting', 'driver', 'behaviour']",predicting driver behaviour,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
3439,customer life time value model,Techniques,customer life time value model,"['customer', 'life', 'time', 'value', 'model']",0,"['customer', 'life', 'time', 'value', 'model']","['customer', 'life', 'time', 'value', 'model']",customer life time value model,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
3440,how to calculate manhattan distance in r,Techniques,how to calculate manhattan distance in r,"['how', 'to', 'calculate', 'manhattan', 'distance', 'in', 'r']",0,"['how', 'to', 'calculate', 'manhattan', 'distance', 'in', 'r']","['calculate', 'manhattan', 'distance', 'r']",calculate manhattan distance r,0.0,0.0,7,30,3.75,0,0,0,0,0,0,0,0
3441,how do you see power bi future as an analytics tool,Tools,how do you see power bi future as an analytics tool,"['how', 'do', 'you', 'see', 'power', 'bi', 'future', 'as', 'an', 'analytics', 'tool']",0,"['how', 'do', 'you', 'see', 'power', 'bi', 'future', 'a', 'an', 'analytics', 'tool']","['see', 'power', 'bi', 'future', 'analytics', 'tool']",see power bi future analytics tool,0.0,0.0,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
3442,how can we add data labels to chart legend in qlikview,Tools,how can we add data labels to chart legend in qlikview,"['how', 'can', 'we', 'add', 'data', 'labels', 'to', 'chart', 'legend', 'in', 'qlikview']",0,"['how', 'can', 'we', 'add', 'data', 'label', 'to', 'chart', 'legend', 'in', 'qlikview']","['add', 'data', 'label', 'chart', 'legend', 'qlikview']",add data label chart legend qlikview,0.0,0.0,11,36,3.0,0,0,0,0,0,0,0,0
3443,applying a measure of error to raw data,Techniques,applying a measure of error to raw data,"['applying', 'a', 'measure', 'of', 'error', 'to', 'raw', 'data']",0,"['applying', 'a', 'measure', 'of', 'error', 'to', 'raw', 'data']","['applying', 'measure', 'error', 'raw', 'data']",applying measure error raw data,-0.2307692307692307,-0.2307692307692307,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
3444,can i combine various models in ensemble learning,Techniques,can i combine various models in ensemble learning,"['can', 'i', 'combine', 'various', 'models', 'in', 'ensemble', 'learning']",0,"['can', 'i', 'combine', 'various', 'model', 'in', 'ensemble', 'learning']","['combine', 'various', 'model', 'ensemble', 'learning']",combine various model ensemble learning,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
3445,r  missing values not recognized as na during readcsv  workaround,Other,r  missing values not recognized as na during readcsv  workaround,"['r', 'missing', 'values', 'not', 'recognized', 'as', 'na', 'during', 'readcsv', 'workaround']",1,"['r', 'missing', 'value', 'not', 'recognized', 'a', 'na', 'during', 'readcsv', 'workaround']","['r', 'missing', 'value', 'recognized', 'na', 'readcsv', 'workaround']",r missing value recognized na readcsv workaround,-0.2,-0.2,10,48,4.363636363636363,0,0,0,0,0,0,0,0
3446,revealing your approach predict the gem of auxesia for magazino,Hackathons,revealing your approach predict the gem of auxesia for magazino,"['revealing', 'your', 'approach', 'predict', 'the', 'gem', 'of', 'auxesia', 'for', 'magazino']",0,"['revealing', 'your', 'approach', 'predict', 'the', 'gem', 'of', 'auxesia', 'for', 'magazino']","['revealing', 'approach', 'predict', 'gem', 'auxesia', 'magazino']",revealing approach predict gem auxesia magazino,0.0,0.0,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
3447,problem in solving practice problem  loan prediction  ,Techniques,problem in solving practice problem  loan prediction  ,"['problem', 'in', 'solving', 'practice', 'problem', 'loan', 'prediction']",1,"['problem', 'in', 'solving', 'practice', 'problem', 'loan', 'prediction']","['problem', 'solving', 'practice', 'problem', 'loan', 'prediction']",problem solving practice problem loan prediction,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
3448,how the variable importance is measured during model building,Techniques,how the variable importance is measured during model building,"['how', 'the', 'variable', 'importance', 'is', 'measured', 'during', 'model', 'building']",0,"['how', 'the', 'variable', 'importance', 'is', 'measured', 'during', 'model', 'building']","['variable', 'importance', 'measured', 'model', 'building']",variable importance measured model building,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
3449,visualization using rstudio,Tools,visualization using rstudio,"['visualization', 'using', 'rstudio']",0,"['visualization', 'using', 'rstudio']","['visualization', 'using', 'rstudio']",visualization using rstudio,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
3450,how to make final submission if code file is not submitted already,Hackathons,how to make final submission if code file is not submitted already,"['how', 'to', 'make', 'final', 'submission', 'if', 'code', 'file', 'is', 'not', 'submitted', 'already']",0,"['how', 'to', 'make', 'final', 'submission', 'if', 'code', 'file', 'is', 'not', 'submitted', 'already']","['make', 'final', 'submission', 'code', 'file', 'submitted', 'already']",make final submission code file submitted already,0.0,0.0,12,49,3.769230769230769,0,0,0,0,0,0,0,0
3451,question about calculating histogram of gradients hog in x cells,Techniques,question about calculating histogram of gradients hog in x cells,"['question', 'about', 'calculating', 'histogram', 'of', 'gradients', 'hog', 'in', 'x', 'cells']",0,"['question', 'about', 'calculating', 'histogram', 'of', 'gradient', 'hog', 'in', 'x', 'cell']","['question', 'calculating', 'histogram', 'gradient', 'hog', 'x', 'cell']",question calculating histogram gradient hog x cell,0.0,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
3452,career transition advice  from accounting to data science,Career,career transition advice  from accounting to data science,"['career', 'transition', 'advice', 'from', 'accounting', 'to', 'data', 'science']",0,"['career', 'transition', 'advice', 'from', 'accounting', 'to', 'data', 'science']","['career', 'transition', 'advice', 'accounting', 'data', 'science']",career transition advice accounting data science,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
3453,is it a right choice,Career,is it a right choice,"['is', 'it', 'a', 'right', 'choice']",0,"['is', 'it', 'a', 'right', 'choice']","['right', 'choice']",right choice,0.2857142857142857,0.2857142857142857,5,12,2.0,0,0,0,0,0,0,0,0
3454,review for jigsaw academy,Career,review for jigsaw academy,"['review', 'for', 'jigsaw', 'academy']",0,"['review', 'for', 'jigsaw', 'academy']","['review', 'jigsaw', 'academy']",review jigsaw academy,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
3455,time series pooling up,Techniques,time series pooling up,"['time', 'series', 'pooling', 'up']",0,"['time', 'series', 'pooling', 'up']","['time', 'series', 'pooling']",time series pooling,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
3456,error while performing natural language processing using r,Tools,error while performing natural language processing using r,"['error', 'while', 'performing', 'natural', 'language', 'processing', 'using', 'r']",0,"['error', 'while', 'performing', 'natural', 'language', 'processing', 'using', 'r']","['error', 'performing', 'natural', 'language', 'processing', 'using', 'r']",error performing natural language processing using r,0.1,0.1,8,52,5.777777777777778,0,0,0,0,0,0,0,0
3457,why factor analysis are only applied to numeric data,Techniques,why factor analysis are only applied to numeric data,"['why', 'factor', 'analysis', 'are', 'only', 'applied', 'to', 'numeric', 'data']",0,"['why', 'factor', 'analysis', 'are', 'only', 'applied', 'to', 'numeric', 'data']","['factor', 'analysis', 'applied', 'numeric', 'data']",factor analysis applied numeric data,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
3458,shift to data analytics,Career,shift to data analytics,"['shift', 'to', 'data', 'analytics']",0,"['shift', 'to', 'data', 'analytics']","['shift', 'data', 'analytics']",shift data analytics,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
3459,how to get the trend variable in multiple linear regression,Techniques,how to get the trend variable in multiple linear regression,"['how', 'to', 'get', 'the', 'trend', 'variable', 'in', 'multiple', 'linear', 'regression']",0,"['how', 'to', 'get', 'the', 'trend', 'variable', 'in', 'multiple', 'linear', 'regression']","['get', 'trend', 'variable', 'multiple', 'linear', 'regression']",get trend variable multiple linear regression,0.0,0.0,10,45,4.090909090909091,0,0,0,0,0,0,0,0
3460,error while installing wheel file for opencv opencvpythoncontribcpcpmwinamdwhl is not a supported wheel on this platform,Techniques,error while installing wheel file for opencv opencvpythoncontribcpcpmwinamdwhl is not a supported wheel on this platform,"['error', 'while', 'installing', 'wheel', 'file', 'for', 'opencv', 'opencvpythoncontribcpcpmwinamdwhl', 'is', 'not', 'a', 'supported', 'wheel', 'on', 'this', 'platform']",0,"['error', 'while', 'installing', 'wheel', 'file', 'for', 'opencv', 'opencvpythoncontribcpcpmwinamdwhl', 'is', 'not', 'a', 'supported', 'wheel', 'on', 'this', 'platform']","['error', 'installing', 'wheel', 'file', 'opencv', 'opencvpythoncontribcpcpmwinamdwhl', 'supported', 'wheel', 'platform']",error installing wheel file opencv opencvpythoncontribcpcpmwinamdwhl supported wheel platform,0.0,0.0,16,93,5.470588235294118,0,0,0,0,0,0,0,0
3461,understanding random forest,Techniques,understanding random forest,"['understanding', 'random', 'forest']",0,"['understanding', 'random', 'forest']","['understanding', 'random', 'forest']",understanding random forest,-0.5,-0.5,3,27,6.75,0,0,0,0,0,0,0,0
3462,resources to build recommender system in python,Resources,resources to build recommender system in python,"['resources', 'to', 'build', 'recommender', 'system', 'in', 'python']",0,"['resource', 'to', 'build', 'recommender', 'system', 'in', 'python']","['resource', 'build', 'recommender', 'system', 'python']",resource build recommender system python,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
3463,how can give sequence input to neural net,Techniques,how can give sequence input to neural net,"['how', 'can', 'give', 'sequence', 'input', 'to', 'neural', 'net']",0,"['how', 'can', 'give', 'sequence', 'input', 'to', 'neural', 'net']","['give', 'sequence', 'input', 'neural', 'net']",give sequence input neural net,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
3464,is concordance the best way to predict logistic regression model reliability,Techniques,is concordance the best way to predict logistic regression model reliability,"['is', 'concordance', 'the', 'best', 'way', 'to', 'predict', 'logistic', 'regression', 'model', 'reliability']",0,"['is', 'concordance', 'the', 'best', 'way', 'to', 'predict', 'logistic', 'regression', 'model', 'reliability']","['concordance', 'best', 'way', 'predict', 'logistic', 'regression', 'model', 'reliability']",concordance best way predict logistic regression model reliability,1.0,1.0,11,66,5.5,0,0,0,0,0,0,0,0
3465,how to use grid to make layout in r,Tools,how to use grid to make layout in r,"['how', 'to', 'use', 'grid', 'to', 'make', 'layout', 'in', 'r']",0,"['how', 'to', 'use', 'grid', 'to', 'make', 'layout', 'in', 'r']","['use', 'grid', 'make', 'layout', 'r']",use grid make layout r,0.0,0.0,9,22,2.2,0,0,0,0,0,0,0,0
3466,how to transform the regression output to binary output in xgboost algorithm,Techniques,how to transform the regression output to binary output in xgboost algorithm,"['how', 'to', 'transform', 'the', 'regression', 'output', 'to', 'binary', 'output', 'in', 'xgboost', 'algorithm']",0,"['how', 'to', 'transform', 'the', 'regression', 'output', 'to', 'binary', 'output', 'in', 'xgboost', 'algorithm']","['transform', 'regression', 'output', 'binary', 'output', 'xgboost', 'algorithm']",transform regression output binary output xgboost algorithm,0.0,0.0,12,59,4.538461538461538,0,0,0,0,0,0,0,0
3467,is it wise to split training and test dataset based on time  year,Techniques,is it wise to split training and test dataset based on time  year,"['is', 'it', 'wise', 'to', 'split', 'training', 'and', 'test', 'dataset', 'based', 'on', 'time', 'year']",0,"['is', 'it', 'wise', 'to', 'split', 'training', 'and', 'test', 'dataset', 'based', 'on', 'time', 'year']","['wise', 'split', 'training', 'test', 'dataset', 'based', 'time', 'year']",wise split training test dataset based time year,0.7,0.7,13,48,3.4285714285714284,0,0,0,0,0,0,0,0
3468,creating  models to improve accuracy,Misc,creating  models to improve accuracy,"['creating', 'models', 'to', 'improve', 'accuracy']",1,"['creating', 'model', 'to', 'improve', 'accuracy']","['creating', 'model', 'improve', 'accuracy']",creating model improve accuracy,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
3469,variable transformation in linear regression,Techniques,variable transformation in linear regression,"['variable', 'transformation', 'in', 'linear', 'regression']",0,"['variable', 'transformation', 'in', 'linear', 'regression']","['variable', 'transformation', 'linear', 'regression']",variable transformation linear regression,0.0,0.0,5,41,6.833333333333333,0,0,0,0,0,0,0,0
3470,how to convert string date into sas format date,Tools,how to convert string date into sas format date,"['how', 'to', 'convert', 'string', 'date', 'into', 'sas', 'format', 'date']",0,"['how', 'to', 'convert', 'string', 'date', 'into', 'sa', 'format', 'date']","['convert', 'string', 'date', 'sa', 'format', 'date']",convert string date sa format date,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
3471,how to convert amount from digits to words in excel,Techniques,how to convert amount from digits to words in excel,"['how', 'to', 'convert', 'amount', 'from', 'digits', 'to', 'words', 'in', 'excel']",0,"['how', 'to', 'convert', 'amount', 'from', 'digit', 'to', 'word', 'in', 'excel']","['convert', 'amount', 'digit', 'word', 'excel']",convert amount digit word excel,0.0,0.0,10,31,2.8181818181818183,0,0,0,0,0,0,0,0
3472,clustering technique for mixednumeric and categorical variables,Techniques,clustering technique for mixednumeric and categorical variables,"['clustering', 'technique', 'for', 'mixednumeric', 'and', 'categorical', 'variables']",0,"['clustering', 'technique', 'for', 'mixednumeric', 'and', 'categorical', 'variable']","['clustering', 'technique', 'mixednumeric', 'categorical', 'variable']",clustering technique mixednumeric categorical variable,0.0,0.0,7,54,6.75,0,0,0,0,0,0,0,0
3474,which file formats can we import into a data table or a data frame in r,Tools,which file formats can we import into a data table or a data frame in r,"['which', 'file', 'formats', 'can', 'we', 'import', 'into', 'a', 'data', 'table', 'or', 'a', 'data', 'frame', 'in', 'r']",0,"['which', 'file', 'format', 'can', 'we', 'import', 'into', 'a', 'data', 'table', 'or', 'a', 'data', 'frame', 'in', 'r']","['file', 'format', 'import', 'data', 'table', 'data', 'frame', 'r']",file format import data table data frame r,0.0,0.0,16,42,2.4705882352941178,0,0,0,0,0,0,0,0
3475,how to read a large excel file in r,Tools,how to read a large excel file in r,"['how', 'to', 'read', 'a', 'large', 'excel', 'file', 'in', 'r']",0,"['how', 'to', 'read', 'a', 'large', 'excel', 'file', 'in', 'r']","['read', 'large', 'excel', 'file', 'r']",read large excel file r,0.2142857142857142,0.2142857142857142,9,23,2.3,0,0,0,0,0,0,0,0
3476,glm predict probabilities in r,Tools,glm predict probabilities in r,"['glm', 'predict', 'probabilities', 'in', 'r']",0,"['glm', 'predict', 'probability', 'in', 'r']","['glm', 'predict', 'probability', 'r']",glm predict probability r,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
3477,help me with the list of best blogs related to data science,Misc,help me with the list of best blogs related to data science,"['help', 'me', 'with', 'the', 'list', 'of', 'best', 'blogs', 'related', 'to', 'data', 'science']",0,"['help', 'me', 'with', 'the', 'list', 'of', 'best', 'blog', 'related', 'to', 'data', 'science']","['help', 'list', 'best', 'blog', 'related', 'data', 'science']",help list best blog related data science,0.5,0.5,12,40,3.076923076923077,0,0,0,0,0,0,0,0
3478,need a code for sas,Techniques,need a code for sas,"['need', 'a', 'code', 'for', 'sas']",0,"['need', 'a', 'code', 'for', 'sa']","['need', 'code', 'sa']",need code sa,0.0,0.0,5,12,2.0,0,0,0,0,0,0,0,0
3479,seasonal parameter in arima and adf test,Techniques,seasonal parameter in arima and adf test,"['seasonal', 'parameter', 'in', 'arima', 'and', 'adf', 'test']",0,"['seasonal', 'parameter', 'in', 'arima', 'and', 'adf', 'test']","['seasonal', 'parameter', 'arima', 'adf', 'test']",seasonal parameter arima adf test,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
3480,suggest ways to enhance the resume for a data science career,Career,suggest ways to enhance the resume for a data science career,"['suggest', 'ways', 'to', 'enhance', 'the', 'resume', 'for', 'a', 'data', 'science', 'career']",0,"['suggest', 'way', 'to', 'enhance', 'the', 'resume', 'for', 'a', 'data', 'science', 'career']","['suggest', 'way', 'enhance', 'resume', 'data', 'science', 'career']",suggest way enhance resume data science career,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
3481,solution of d dalai lama hackathon,Hackathons,solution of d dalai lama hackathon,"['solution', 'of', 'd', 'dalai', 'lama', 'hackathon']",0,"['solution', 'of', 'd', 'dalai', 'lama', 'hackathon']","['solution', 'dalai', 'lama', 'hackathon']",solution dalai lama hackathon,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
3482,improving specificity or sensitivity in linear discriminant analysis,Techniques,improving specificity or sensitivity in linear discriminant analysis,"['improving', 'specificity', 'or', 'sensitivity', 'in', 'linear', 'discriminant', 'analysis']",0,"['improving', 'specificity', 'or', 'sensitivity', 'in', 'linear', 'discriminant', 'analysis']","['improving', 'specificity', 'sensitivity', 'linear', 'discriminant', 'analysis']",improving specificity sensitivity linear discriminant analysis,0.0,0.0,8,62,6.888888888888889,0,0,0,0,0,0,0,0
3483,how to manipulate the cost function in svm in r,Tools,how to manipulate the cost function in svm in r,"['how', 'to', 'manipulate', 'the', 'cost', 'function', 'in', 'svm', 'in', 'r']",0,"['how', 'to', 'manipulate', 'the', 'cost', 'function', 'in', 'svm', 'in', 'r']","['manipulate', 'cost', 'function', 'svm', 'r']",manipulate cost function svm r,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
3484,shift my career from testing to analytics,Career,shift my career from testing to analytics,"['shift', 'my', 'career', 'from', 'testing', 'to', 'analytics']",0,"['shift', 'my', 'career', 'from', 'testing', 'to', 'analytics']","['shift', 'career', 'testing', 'analytics']",shift career testing analytics,0.0,0.0,7,30,3.75,0,0,0,0,0,0,0,0
3485,persisting problem an introduction to text summarization using the textrank algorithm with python implementation,Techniques,persisting problem an introduction to text summarization using the textrank algorithm with python implementation,"['persisting', 'problem', 'an', 'introduction', 'to', 'text', 'summarization', 'using', 'the', 'textrank', 'algorithm', 'with', 'python', 'implementation']",0,"['persisting', 'problem', 'an', 'introduction', 'to', 'text', 'summarization', 'using', 'the', 'textrank', 'algorithm', 'with', 'python', 'implementation']","['persisting', 'problem', 'introduction', 'text', 'summarization', 'using', 'textrank', 'algorithm', 'python', 'implementation']",persisting problem introduction text summarization using textrank algorithm python implementation,0.0,0.0,14,97,6.466666666666667,0,0,0,0,0,0,0,0
3486,how is adaboost sensitive to noisy data and outliers,Techniques,how is adaboost sensitive to noisy data and outliers,"['how', 'is', 'adaboost', 'sensitive', 'to', 'noisy', 'data', 'and', 'outliers']",0,"['how', 'is', 'adaboost', 'sensitive', 'to', 'noisy', 'data', 'and', 'outlier']","['adaboost', 'sensitive', 'noisy', 'data', 'outlier']",adaboost sensitive noisy data outlier,0.1,0.1,9,37,3.7,0,0,0,0,0,0,0,0
3487,how to check that given directory exist or not using r,Tools,how to check that given directory exist or not using r,"['how', 'to', 'check', 'that', 'given', 'directory', 'exist', 'or', 'not', 'using', 'r']",0,"['how', 'to', 'check', 'that', 'given', 'directory', 'exist', 'or', 'not', 'using', 'r']","['check', 'given', 'directory', 'exist', 'using', 'r']",check given directory exist using r,0.0,0.0,11,35,2.9166666666666665,0,0,0,0,0,0,0,0
3488,are there any generative algorithms or methods to utter numbers,Resources,are there any generative algorithms or methods to utter numbers,"['are', 'there', 'any', 'generative', 'algorithms', 'or', 'methods', 'to', 'utter', 'numbers']",0,"['are', 'there', 'any', 'generative', 'algorithm', 'or', 'method', 'to', 'utter', 'number']","['generative', 'algorithm', 'method', 'utter', 'number']",generative algorithm method utter number,0.0,0.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
3489,using the normal curve for calculations,Techniques,using the normal curve for calculations,"['using', 'the', 'normal', 'curve', 'for', 'calculations']",0,"['using', 'the', 'normal', 'curve', 'for', 'calculation']","['using', 'normal', 'curve', 'calculation']",using normal curve calculation,0.15,0.15,6,30,4.285714285714286,0,0,0,0,0,0,0,0
3490,best analyticsdata science training available for working professionals,Career,best analyticsdata science training available for working professionals,"['best', 'analyticsdata', 'science', 'training', 'available', 'for', 'working', 'professionals']",0,"['best', 'analyticsdata', 'science', 'training', 'available', 'for', 'working', 'professional']","['best', 'analyticsdata', 'science', 'training', 'available', 'working', 'professional']",best analyticsdata science training available working professional,0.7,0.5,8,66,7.333333333333333,0,0,0,0,0,0,0,0
3491,machine learning techniques cheatsheet,Resources,machine learning techniques cheatsheet,"['machine', 'learning', 'techniques', 'cheatsheet']",0,"['machine', 'learning', 'technique', 'cheatsheet']","['machine', 'learning', 'technique', 'cheatsheet']",machine learning technique cheatsheet,0.0,0.0,4,37,7.4,0,0,0,0,0,0,0,0
3492,how to plot more than one plot in r,Techniques,how to plot more than one plot in r,"['how', 'to', 'plot', 'more', 'than', 'one', 'plot', 'in', 'r']",0,"['how', 'to', 'plot', 'more', 'than', 'one', 'plot', 'in', 'r']","['plot', 'one', 'plot', 'r']",plot one plot r,0.5,0.0,9,15,1.5,0,0,0,0,0,0,0,0
3493,statistics in data science,Techniques,statistics in data science,"['statistics', 'in', 'data', 'science']",0,"['statistic', 'in', 'data', 'science']","['statistic', 'data', 'science']",statistic data science,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
3494,formula to match data with multiple options and extract highest value each time,Tools,formula to match data with multiple options and extract highest value each time,"['formula', 'to', 'match', 'data', 'with', 'multiple', 'options', 'and', 'extract', 'highest', 'value', 'each', 'time']",0,"['formula', 'to', 'match', 'data', 'with', 'multiple', 'option', 'and', 'extract', 'highest', 'value', 'each', 'time']","['formula', 'match', 'data', 'multiple', 'option', 'extract', 'highest', 'value', 'time']",formula match data multiple option extract highest value time,0.0,0.0,13,61,4.357142857142857,0,0,0,0,0,0,0,0
3495,style questions  building r portfolio,Career,style questions  building r portfolio,"['style', 'questions', 'building', 'r', 'portfolio']",0,"['style', 'question', 'building', 'r', 'portfolio']","['style', 'question', 'building', 'r', 'portfolio']",style question building r portfolio,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
3496,how to use lines function correctly for plotting line in a given plot,Techniques,how to use lines function correctly for plotting line in a given plot,"['how', 'to', 'use', 'lines', 'function', 'correctly', 'for', 'plotting', 'line', 'in', 'a', 'given', 'plot']",0,"['how', 'to', 'use', 'line', 'function', 'correctly', 'for', 'plotting', 'line', 'in', 'a', 'given', 'plot']","['use', 'line', 'function', 'correctly', 'plotting', 'line', 'given', 'plot']",use line function correctly plotting line given plot,0.0,0.0,13,52,3.7142857142857144,0,0,0,0,0,0,0,0
3497,how to handle data that is unevenly distributed,Techniques,how to handle data that is unevenly distributed,"['how', 'to', 'handle', 'data', 'that', 'is', 'unevenly', 'distributed']",0,"['how', 'to', 'handle', 'data', 'that', 'is', 'unevenly', 'distributed']","['handle', 'data', 'unevenly', 'distributed']",handle data unevenly distributed,-0.2,-0.2,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
3498,handling outliers,Techniques,handling outliers,"['handling', 'outliers']",0,"['handling', 'outlier']","['handling', 'outlier']",handling outlier,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
3499,scrap data from live website using r,Tools,scrap data from live website using r,"['scrap', 'data', 'from', 'live', 'website', 'using', 'r']",0,"['scrap', 'data', 'from', 'live', 'website', 'using', 'r']","['scrap', 'data', 'live', 'website', 'using', 'r']",scrap data live website using r,0.1363636363636363,0.1363636363636363,7,31,3.875,0,0,0,0,0,0,0,0
3500,data science certification,Career,data science certification,"['data', 'science', 'certification']",0,"['data', 'science', 'certification']","['data', 'science', 'certification']",data science certification,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
3501,how and when to conduct statistical tests in a project  need examples,Techniques,how and when to conduct statistical tests in a project  need examples,"['how', 'and', 'when', 'to', 'conduct', 'statistical', 'tests', 'in', 'a', 'project', 'need', 'examples']",0,"['how', 'and', 'when', 'to', 'conduct', 'statistical', 'test', 'in', 'a', 'project', 'need', 'example']","['conduct', 'statistical', 'test', 'project', 'need', 'example']",conduct statistical test project need example,0.0,0.0,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
3502,getting typeerror  not supported between instances of str and float,Hackathons,getting typeerror  not supported between instances of str and float,"['getting', 'typeerror', 'not', 'supported', 'between', 'instances', 'of', 'str', 'and', 'float']",0,"['getting', 'typeerror', 'not', 'supported', 'between', 'instance', 'of', 'str', 'and', 'float']","['getting', 'typeerror', 'supported', 'instance', 'str', 'float']",getting typeerror supported instance str float,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
3503,where can i get a dataset for implementing svd in r,Tools,where can i get a dataset for implementing svd in r,"['where', 'can', 'i', 'get', 'a', 'dataset', 'for', 'implementing', 'svd', 'in', 'r']",0,"['where', 'can', 'i', 'get', 'a', 'dataset', 'for', 'implementing', 'svd', 'in', 'r']","['get', 'dataset', 'implementing', 'svd', 'r']",get dataset implementing svd r,0.0,0.0,11,30,2.5,0,0,0,0,0,0,0,0
3504,prospects of learning bigdata and analytics for an experienced person,Career,prospects of learning bigdata and analytics for an experienced person,"['prospects', 'of', 'learning', 'bigdata', 'and', 'analytics', 'for', 'an', 'experienced', 'person']",0,"['prospect', 'of', 'learning', 'bigdata', 'and', 'analytics', 'for', 'an', 'experienced', 'person']","['prospect', 'learning', 'bigdata', 'analytics', 'experienced', 'person']",prospect learning bigdata analytics experienced person,0.8,0.8,10,54,4.909090909090909,0,0,0,0,0,0,0,0
3505,ost straightforward r package for setting subject as random effect in mixed logit model,Techniques,ost straightforward r package for setting subject as random effect in mixed logit model,"['ost', 'straightforward', 'r', 'package', 'for', 'setting', 'subject', 'as', 'random', 'effect', 'in', 'mixed', 'logit', 'model']",0,"['ost', 'straightforward', 'r', 'package', 'for', 'setting', 'subject', 'a', 'random', 'effect', 'in', 'mixed', 'logit', 'model']","['ost', 'straightforward', 'r', 'package', 'setting', 'subject', 'random', 'effect', 'mixed', 'logit', 'model']",ost straightforward r package setting subject random effect mixed logit model,-0.0729166666666666,-0.0729166666666666,14,77,5.133333333333334,0,0,0,0,0,0,0,0
3506,time series case study,Techniques,time series case study,"['time', 'series', 'case', 'study']",0,"['time', 'series', 'case', 'study']","['time', 'series', 'case', 'study']",time series case study,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
3507,what are the best libraries to do preliminary analysis on gridded climate data netcdf grib etc and make maps in python,Tools,what are the best libraries to do preliminary analysis on gridded climate data netcdf grib etc and make maps in python,"['what', 'are', 'the', 'best', 'libraries', 'to', 'do', 'preliminary', 'analysis', 'on', 'gridded', 'climate', 'data', 'netcdf', 'grib', 'etc', 'and', 'make', 'maps', 'in', 'python']",0,"['what', 'are', 'the', 'best', 'library', 'to', 'do', 'preliminary', 'analysis', 'on', 'gridded', 'climate', 'data', 'netcdf', 'grib', 'etc', 'and', 'make', 'map', 'in', 'python']","['best', 'library', 'preliminary', 'analysis', 'gridded', 'climate', 'data', 'netcdf', 'grib', 'etc', 'make', 'map', 'python']",best library preliminary analysis gridded climate data netcdf grib etc make map python,1.0,1.0,21,86,3.909090909090909,0,0,0,0,0,0,0,0
3508,how to remove special characters from a dataset in sas,Tools,how to remove special characters from a dataset in sas,"['how', 'to', 'remove', 'special', 'characters', 'from', 'a', 'dataset', 'in', 'sas']",0,"['how', 'to', 'remove', 'special', 'character', 'from', 'a', 'dataset', 'in', 'sa']","['remove', 'special', 'character', 'dataset', 'sa']",remove special character dataset sa,0.3571428571428571,0.3571428571428571,10,35,3.1818181818181817,0,0,0,0,0,0,0,0
3509,why is the diagonal elements of d from the svd are proportional to the standard deviations returned by pca,Techniques,why is the diagonal elements of d from the svd are proportional to the standard deviations returned by pca,"['why', 'is', 'the', 'diagonal', 'elements', 'of', 'd', 'from', 'the', 'svd', 'are', 'proportional', 'to', 'the', 'standard', 'deviations', 'returned', 'by', 'pca']",0,"['why', 'is', 'the', 'diagonal', 'element', 'of', 'd', 'from', 'the', 'svd', 'are', 'proportional', 'to', 'the', 'standard', 'deviation', 'returned', 'by', 'pca']","['diagonal', 'element', 'svd', 'proportional', 'standard', 'deviation', 'returned', 'pca']",diagonal element svd proportional standard deviation returned pca,0.0,0.0,19,65,3.25,0,0,0,0,0,0,0,0
3510,how to deal with a column with some zero values in train,Techniques,how to deal with a column with some zero values in train,"['how', 'to', 'deal', 'with', 'a', 'column', 'with', 'some', 'zero', 'values', 'in', 'train']",0,"['how', 'to', 'deal', 'with', 'a', 'column', 'with', 'some', 'zero', 'value', 'in', 'train']","['deal', 'column', 'zero', 'value', 'train']",deal column zero value train,0.0,0.0,12,28,2.1538461538461537,0,0,0,0,0,0,0,0
3511,hackathon  how to handle skills,Hackathons,hackathon  how to handle skills,"['hackathon', 'how', 'to', 'handle', 'skills']",0,"['hackathon', 'how', 'to', 'handle', 'skill']","['hackathon', 'handle', 'skill']",hackathon handle skill,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
3512,search keyword classificationcategorization using python,Tools,search keyword classificationcategorization using python,"['search', 'keyword', 'classificationcategorization', 'using', 'python']",0,"['search', 'keyword', 'classificationcategorization', 'using', 'python']","['search', 'keyword', 'classificationcategorization', 'using', 'python']",search keyword classificationcategorization using python,0.0,0.0,5,56,9.333333333333334,0,0,0,0,0,0,0,0
3513,videos of experiment with data,Other,videos of experiment with data,"['videos', 'of', 'experiment', 'with', 'data']",0,"['video', 'of', 'experiment', 'with', 'data']","['video', 'experiment', 'data']",video experiment data,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
3514,predict neuralnet,Techniques,predict neuralnet,"['predict', 'neuralnet']",0,"['predict', 'neuralnet']","['predict', 'neuralnet']",predict neuralnet,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
3515,a better way to tell whether a feature can separate classes better in severely data imbalanced situation,Techniques,a better way to tell whether a feature can separate classes better in severely data imbalanced situation,"['a', 'better', 'way', 'to', 'tell', 'whether', 'a', 'feature', 'can', 'separate', 'classes', 'better', 'in', 'severely', 'data', 'imbalanced', 'situation']",0,"['a', 'better', 'way', 'to', 'tell', 'whether', 'a', 'feature', 'can', 'separate', 'class', 'better', 'in', 'severely', 'data', 'imbalanced', 'situation']","['better', 'way', 'tell', 'whether', 'feature', 'separate', 'class', 'better', 'severely', 'data', 'imbalanced', 'situation']",better way tell whether feature separate class better severely data imbalanced situation,0.5,0.5,17,88,4.888888888888889,0,0,0,0,0,0,0,0
3516,appropriate variables for multiple regression,Techniques,appropriate variables for multiple regression,"['appropriate', 'variables', 'for', 'multiple', 'regression']",0,"['appropriate', 'variable', 'for', 'multiple', 'regression']","['appropriate', 'variable', 'multiple', 'regression']",appropriate variable multiple regression,0.25,0.25,5,40,6.666666666666667,0,0,0,0,0,0,0,0
3517,neural network produces biased predictions on training data,Techniques,neural network produces biased predictions on training data,"['neural', 'network', 'produces', 'biased', 'predictions', 'on', 'training', 'data']",0,"['neural', 'network', 'produce', 'biased', 'prediction', 'on', 'training', 'data']","['neural', 'network', 'produce', 'biased', 'prediction', 'training', 'data']",neural network produce biased prediction training data,0.0,0.0,8,54,6.0,0,0,0,0,0,0,0,0
3518,recommended laptops for beginners in the field,Misc,recommended laptops for beginners in the field,"['recommended', 'laptops', 'for', 'beginners', 'in', 'the', 'field']",0,"['recommended', 'laptop', 'for', 'beginner', 'in', 'the', 'field']","['recommended', 'laptop', 'beginner', 'field']",recommended laptop beginner field,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
3519,a comprehensive learning path to become a data scientist in ,Career,a comprehensive learning path to become a data scientist in ,"['a', 'comprehensive', 'learning', 'path', 'to', 'become', 'a', 'data', 'scientist', 'in']",1,"['a', 'comprehensive', 'learning', 'path', 'to', 'become', 'a', 'data', 'scientist', 'in']","['comprehensive', 'learning', 'path', 'become', 'data', 'scientist']",comprehensive learning path become data scientist,0.0,0.0,10,49,4.454545454545454,0,0,0,0,0,0,0,0
3520,how are conditional prob calculated for numeric variables in naive bayes,Techniques,how are conditional prob calculated for numeric variables in naive bayes,"['how', 'are', 'conditional', 'prob', 'calculated', 'for', 'numeric', 'variables', 'in', 'naive', 'bayes']",0,"['how', 'are', 'conditional', 'prob', 'calculated', 'for', 'numeric', 'variable', 'in', 'naive', 'bayes']","['conditional', 'prob', 'calculated', 'numeric', 'variable', 'naive', 'bayes']",conditional prob calculated numeric variable naive bayes,-0.3,-0.3,11,56,4.666666666666667,0,0,0,0,0,0,0,0
3521,xml data table scraping,Techniques,xml data table scraping,"['xml', 'data', 'table', 'scraping']",0,"['xml', 'data', 'table', 'scraping']","['xml', 'data', 'table', 'scraping']",xml data table scraping,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
3522,which institute provides trainingor diploma or pg in business analytics for someone from commerce background,Career,which institute provides trainingor diploma or pg in business analytics for someone from commerce background,"['which', 'institute', 'provides', 'trainingor', 'diploma', 'or', 'pg', 'in', 'business', 'analytics', 'for', 'someone', 'from', 'commerce', 'background']",0,"['which', 'institute', 'provides', 'trainingor', 'diploma', 'or', 'pg', 'in', 'business', 'analytics', 'for', 'someone', 'from', 'commerce', 'background']","['institute', 'provides', 'trainingor', 'diploma', 'pg', 'business', 'analytics', 'someone', 'commerce', 'background']",institute provides trainingor diploma pg business analytics someone commerce background,0.0,0.0,15,87,5.4375,0,0,0,0,0,0,0,0
3523,reading a text file in python,Tools,reading a text file in python,"['reading', 'a', 'text', 'file', 'in', 'python']",0,"['reading', 'a', 'text', 'file', 'in', 'python']","['reading', 'text', 'file', 'python']",reading text file python,0.0,0.0,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
3524,multiple lists combines errors in r,Techniques,multiple lists combines errors in r,"['multiple', 'lists', 'combines', 'errors', 'in', 'r']",0,"['multiple', 'list', 'combine', 'error', 'in', 'r']","['multiple', 'list', 'combine', 'error', 'r']",multiple list combine error r,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
3525,i want to identify missing objects ie screws nuts from a tool or an an object ie dynamo,Techniques,i want to identify missing objects ie screws nuts from a tool or an an object ie dynamo,"['i', 'want', 'to', 'identify', 'missing', 'objects', 'ie', 'screws', 'nuts', 'from', 'a', 'tool', 'or', 'an', 'an', 'object', 'ie', 'dynamo']",0,"['i', 'want', 'to', 'identify', 'missing', 'object', 'ie', 'screw', 'nut', 'from', 'a', 'tool', 'or', 'an', 'an', 'object', 'ie', 'dynamo']","['want', 'identify', 'missing', 'object', 'ie', 'screw', 'nut', 'tool', 'object', 'ie', 'dynamo']",want identify missing object ie screw nut tool object ie dynamo,-0.2,-0.2,18,63,3.3157894736842106,0,0,0,0,0,0,0,0
3526,scaling the features for every model,Techniques,scaling the features for every model,"['scaling', 'the', 'features', 'for', 'every', 'model']",0,"['scaling', 'the', 'feature', 'for', 'every', 'model']","['scaling', 'feature', 'every', 'model']",scaling feature every model,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
3527,imputing location data,Techniques,imputing location data,"['imputing', 'location', 'data']",0,"['imputing', 'location', 'data']","['imputing', 'location', 'data']",imputing location data,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
3528,learning curve in machine learning,Techniques,learning curve in machine learning,"['learning', 'curve', 'in', 'machine', 'learning']",0,"['learning', 'curve', 'in', 'machine', 'learning']","['learning', 'curve', 'machine', 'learning']",learning curve machine learning,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
3529,question on nlu,Techniques,question on nlu,"['question', 'on', 'nlu']",0,"['question', 'on', 'nlu']","['question', 'nlu']",question nlu,0.0,0.0,3,12,3.0,0,0,0,0,0,0,0,0
3530,how to use variable with exponential values for classification problem in r,Techniques,how to use variable with exponential values for classification problem in r,"['how', 'to', 'use', 'variable', 'with', 'exponential', 'values', 'for', 'classification', 'problem', 'in', 'r']",0,"['how', 'to', 'use', 'variable', 'with', 'exponential', 'value', 'for', 'classification', 'problem', 'in', 'r']","['use', 'variable', 'exponential', 'value', 'classification', 'problem', 'r']",use variable exponential value classification problem r,0.0,0.0,12,55,4.230769230769231,0,0,0,0,0,0,0,0
3531,what is the difference between bagging decision trees and random forest,Techniques,what is the difference between bagging decision trees and random forest,"['what', 'is', 'the', 'difference', 'between', 'bagging', 'decision', 'trees', 'and', 'random', 'forest']",0,"['what', 'is', 'the', 'difference', 'between', 'bagging', 'decision', 'tree', 'and', 'random', 'forest']","['difference', 'bagging', 'decision', 'tree', 'random', 'forest']",difference bagging decision tree random forest,-0.5,-0.5,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
3532,transit time for logistics,Other,transit time for logistics,"['transit', 'time', 'for', 'logistics']",0,"['transit', 'time', 'for', 'logistics']","['transit', 'time', 'logistics']",transit time logistics,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
3533,r  language detection and translation,Tools,r  language detection and translation,"['r', 'language', 'detection', 'and', 'translation']",0,"['r', 'language', 'detection', 'and', 'translation']","['r', 'language', 'detection', 'translation']",r language detection translation,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
3534,amexpert  only residents of india may participate,Hackathons,amexpert  only residents of india may participate,"['amexpert', 'only', 'residents', 'of', 'india', 'may', 'participate']",1,"['amexpert', 'only', 'resident', 'of', 'india', 'may', 'participate']","['amexpert', 'resident', 'india', 'may', 'participate']",amexpert resident india may participate,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
3535,books on data mining concepts,Resources,books on data mining concepts,"['books', 'on', 'data', 'mining', 'concepts']",0,"['book', 'on', 'data', 'mining', 'concept']","['book', 'data', 'mining', 'concept']",book data mining concept,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
3536,what is within cluster sum of squares by cluster in kmeans,Techniques,what is within cluster sum of squares by cluster in kmeans,"['what', 'is', 'within', 'cluster', 'sum', 'of', 'squares', 'by', 'cluster', 'in', 'kmeans']",0,"['what', 'is', 'within', 'cluster', 'sum', 'of', 'square', 'by', 'cluster', 'in', 'kmeans']","['within', 'cluster', 'sum', 'square', 'cluster', 'kmeans']",within cluster sum square cluster kmeans,0.0,0.0,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
3537,banking  wealth management to data science,Career,banking  wealth management to data science,"['banking', 'wealth', 'management', 'to', 'data', 'science']",0,"['banking', 'wealth', 'management', 'to', 'data', 'science']","['banking', 'wealth', 'management', 'data', 'science']",banking wealth management data science,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
3538,what sas certifications am i best suited for,Career,what sas certifications am i best suited for,"['what', 'sas', 'certifications', 'am', 'i', 'best', 'suited', 'for']",0,"['what', 'sa', 'certification', 'am', 'i', 'best', 'suited', 'for']","['sa', 'certification', 'best', 'suited']",sa certification best suited,1.0,1.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
3539,how to calculate information gain of data during random forest,Techniques,how to calculate information gain of data during random forest,"['how', 'to', 'calculate', 'information', 'gain', 'of', 'data', 'during', 'random', 'forest']",0,"['how', 'to', 'calculate', 'information', 'gain', 'of', 'data', 'during', 'random', 'forest']","['calculate', 'information', 'gain', 'data', 'random', 'forest']",calculate information gain data random forest,-0.5,-0.5,10,45,4.090909090909091,0,0,0,0,0,0,0,0
3540,why is partofspeech tagging difficult and how to overcome this,Techniques,why is partofspeech tagging difficult and how to overcome this,"['why', 'is', 'partofspeech', 'tagging', 'difficult', 'and', 'how', 'to', 'overcome', 'this']",0,"['why', 'is', 'partofspeech', 'tagging', 'difficult', 'and', 'how', 'to', 'overcome', 'this']","['partofspeech', 'tagging', 'difficult', 'overcome']",partofspeech tagging difficult overcome,-0.5,-0.5,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
3541,post graduate distance program in statistics  from where and how helpful will it be,Career,post graduate distance program in statistics  from where and how helpful will it be,"['post', 'graduate', 'distance', 'program', 'in', 'statistics', 'from', 'where', 'and', 'how', 'helpful', 'will', 'it', 'be']",0,"['post', 'graduate', 'distance', 'program', 'in', 'statistic', 'from', 'where', 'and', 'how', 'helpful', 'will', 'it', 'be']","['post', 'graduate', 'distance', 'program', 'statistic', 'helpful']",post graduate distance program statistic helpful,0.0,0.0,14,48,3.2,0,0,0,0,0,0,0,0
3542,custom algorithims,Tools,custom algorithims,"['custom', 'algorithims']",0,"['custom', 'algorithims']","['custom', 'algorithims']",custom algorithims,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
3543,unable to get bounding box in json,Tools,unable to get bounding box in json,"['unable', 'to', 'get', 'bounding', 'box', 'in', 'json']",0,"['unable', 'to', 'get', 'bounding', 'box', 'in', 'json']","['unable', 'get', 'bounding', 'box', 'json']",unable get bounding box json,-0.5,-0.5,7,28,3.5,0,0,0,0,0,0,0,0
3544,solution checker is not working please help,Hackathons,solution checker is not working please help,"['solution', 'checker', 'is', 'not', 'working', 'please', 'help']",0,"['solution', 'checker', 'is', 'not', 'working', 'please', 'help']","['solution', 'checker', 'working', 'please', 'help']",solution checker working please help,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
3545,case study for freshers level  medium – call center optimization,Techniques,case study for freshers level  medium – call center optimization,"['case', 'study', 'for', 'freshers', 'level', 'medium', '–', 'call', 'center', 'optimization']",0,"['case', 'study', 'for', 'fresher', 'level', 'medium', '–', 'call', 'center', 'optimization']","['case', 'study', 'fresher', 'level', 'medium', '–', 'call', 'center', 'optimization']",case study fresher level medium – call center optimization,-0.1,-0.1,10,58,5.2727272727272725,0,0,0,0,0,0,0,0
3546,best free tool for perfoming multiple calculations on multiple similar files,Tools,best free tool for perfoming multiple calculations on multiple similar files,"['best', 'free', 'tool', 'for', 'perfoming', 'multiple', 'calculations', 'on', 'multiple', 'similar', 'files']",0,"['best', 'free', 'tool', 'for', 'perfoming', 'multiple', 'calculation', 'on', 'multiple', 'similar', 'file']","['best', 'free', 'tool', 'perfoming', 'multiple', 'calculation', 'multiple', 'similar', 'file']",best free tool perfoming multiple calculation multiple similar file,0.2799999999999999,0.2799999999999999,11,67,5.583333333333333,0,0,0,0,0,0,0,0
3547,fixed income project,Resources,fixed income project,"['fixed', 'income', 'project']",0,"['fixed', 'income', 'project']","['fixed', 'income', 'project']",fixed income project,0.1,0.1,3,20,5.0,0,0,0,0,0,0,0,0
3548,how to move observation one columns to another column,Techniques,how to move observation one columns to another column,"['how', 'to', 'move', 'observation', 'one', 'columns', 'to', 'another', 'column']",0,"['how', 'to', 'move', 'observation', 'one', 'column', 'to', 'another', 'column']","['move', 'observation', 'one', 'column', 'another', 'column']",move observation one column another column,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
3549,request guidance on opportunities in analytics space,Career,request guidance on opportunities in analytics space,"['request', 'guidance', 'on', 'opportunities', 'in', 'analytics', 'space']",0,"['request', 'guidance', 'on', 'opportunity', 'in', 'analytics', 'space']","['request', 'guidance', 'opportunity', 'analytics', 'space']",request guidance opportunity analytics space,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
3550,feedback on pgpbigdata  machine learning in great lakes,Career,feedback on pgpbigdata  machine learning in great lakes,"['feedback', 'on', 'pgpbigdata', 'machine', 'learning', 'in', 'great', 'lakes']",0,"['feedback', 'on', 'pgpbigdata', 'machine', 'learning', 'in', 'great', 'lake']","['feedback', 'pgpbigdata', 'machine', 'learning', 'great', 'lake']",feedback pgpbigdata machine learning great lake,0.8,0.8,8,47,5.222222222222222,0,0,0,0,0,0,0,0
3551,blank cells created when i put scrapy data into a csv file,Techniques,blank cells created when i put scrapy data into a csv file,"['blank', 'cells', 'created', 'when', 'i', 'put', 'scrapy', 'data', 'into', 'a', 'csv', 'file']",0,"['blank', 'cell', 'created', 'when', 'i', 'put', 'scrapy', 'data', 'into', 'a', 'csv', 'file']","['blank', 'cell', 'created', 'put', 'scrapy', 'data', 'csv', 'file']",blank cell created put scrapy data csv file,0.0,0.0,12,43,3.3076923076923075,0,0,0,0,0,0,0,0
3552,what are dta files and can we read them into r,Tools,what are dta files and can we read them into r,"['what', 'are', 'dta', 'files', 'and', 'can', 'we', 'read', 'them', 'into', 'r']",0,"['what', 'are', 'dta', 'file', 'and', 'can', 'we', 'read', 'them', 'into', 'r']","['dta', 'file', 'read', 'r']",dta file read r,0.0,0.0,11,15,1.25,0,0,0,0,0,0,0,0
3553,error in evalexpr envir enclos  object   not found,Techniques,error in evalexpr envir enclos  object   not found,"['error', 'in', 'evalexpr', 'envir', 'enclos', 'object', 'not', 'found']",0,"['error', 'in', 'evalexpr', 'envir', 'enclos', 'object', 'not', 'found']","['error', 'evalexpr', 'envir', 'enclos', 'object', 'found']",error evalexpr envir enclos object found,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
3554,how to resolve the plotnew error in r while plotting the decision boundary,Tools,how to resolve the plotnew error in r while plotting the decision boundary,"['how', 'to', 'resolve', 'the', 'plotnew', 'error', 'in', 'r', 'while', 'plotting', 'the', 'decision', 'boundary']",0,"['how', 'to', 'resolve', 'the', 'plotnew', 'error', 'in', 'r', 'while', 'plotting', 'the', 'decision', 'boundary']","['resolve', 'plotnew', 'error', 'r', 'plotting', 'decision', 'boundary']",resolve plotnew error r plotting decision boundary,0.0,0.0,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
3555,why not linear regression can not be used for classification,Techniques,why not linear regression can not be used for classification,"['why', 'not', 'linear', 'regression', 'can', 'not', 'be', 'used', 'for', 'classification']",0,"['why', 'not', 'linear', 'regression', 'can', 'not', 'be', 'used', 'for', 'classification']","['linear', 'regression', 'used', 'classification']",linear regression used classification,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
3556,job opportunities,Career,job opportunities,"['job', 'opportunities']",0,"['job', 'opportunity']","['job', 'opportunity']",job opportunity,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
3557,how to find the a single categorical variable importance in a set of all independent categorical variables,Techniques,how to find the a single categorical variable importance in a set of all independent categorical variables,"['how', 'to', 'find', 'the', 'a', 'single', 'categorical', 'variable', 'importance', 'in', 'a', 'set', 'of', 'all', 'independent', 'categorical', 'variables']",0,"['how', 'to', 'find', 'the', 'a', 'single', 'categorical', 'variable', 'importance', 'in', 'a', 'set', 'of', 'all', 'independent', 'categorical', 'variable']","['find', 'single', 'categorical', 'variable', 'importance', 'set', 'independent', 'categorical', 'variable']",find single categorical variable importance set independent categorical variable,-0.0357142857142857,-0.0357142857142857,17,80,4.444444444444445,0,0,0,0,0,0,0,0
3558,error while uploading submission,Hackathons,error while uploading submission,"['error', 'while', 'uploading', 'submission']",0,"['error', 'while', 'uploading', 'submission']","['error', 'uploading', 'submission']",error uploading submission,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
3559,anomalies in accessing prod servers,Techniques,anomalies in accessing prod servers,"['anomalies', 'in', 'accessing', 'prod', 'servers']",0,"['anomaly', 'in', 'accessing', 'prod', 'server']","['anomaly', 'accessing', 'prod', 'server']",anomaly accessing prod server,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
3560,extract skill from resume using nlp,Techniques,extract skill from resume using nlp,"['extract', 'skill', 'from', 'resume', 'using', 'nlp']",0,"['extract', 'skill', 'from', 'resume', 'using', 'nlp']","['extract', 'skill', 'resume', 'using', 'nlp']",extract skill resume using nlp,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
3561,need help to decide analytics technique to use,Techniques,need help to decide analytics technique to use,"['need', 'help', 'to', 'decide', 'analytics', 'technique', 'to', 'use']",0,"['need', 'help', 'to', 'decide', 'analytics', 'technique', 'to', 'use']","['need', 'help', 'decide', 'analytics', 'technique', 'use']",need help decide analytics technique use,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
3562,black friday challenge problem statement,Hackathons,black friday challenge problem statement,"['black', 'friday', 'challenge', 'problem', 'statement']",0,"['black', 'friday', 'challenge', 'problem', 'statement']","['black', 'friday', 'challenge', 'problem', 'statement']",black friday challenge problem statement,-0.1666666666666666,-0.1666666666666666,5,40,6.666666666666667,0,0,0,0,0,0,0,0
3563,how to control which plot is displayed above while using multiple plots in r,Tools,how to control which plot is displayed above while using multiple plots in r,"['how', 'to', 'control', 'which', 'plot', 'is', 'displayed', 'above', 'while', 'using', 'multiple', 'plots', 'in', 'r']",0,"['how', 'to', 'control', 'which', 'plot', 'is', 'displayed', 'above', 'while', 'using', 'multiple', 'plot', 'in', 'r']","['control', 'plot', 'displayed', 'using', 'multiple', 'plot', 'r']",control plot displayed using multiple plot r,0.0,0.0,14,44,2.933333333333333,0,0,0,0,0,0,0,0
3564,feature selection chisquare,Techniques,feature selection chisquare,"['feature', 'selection', 'chisquare']",0,"['feature', 'selection', 'chisquare']","['feature', 'selection', 'chisquare']",feature selection chisquare,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
3565,how can dickey fuller test give ve value for tstat,Techniques,how can dickey fuller test give ve value for tstat,"['how', 'can', 'dickey', 'fuller', 'test', 'give', 've', 'value', 'for', 'tstat']",0,"['how', 'can', 'dickey', 'fuller', 'test', 'give', 've', 'value', 'for', 'tstat']","['dickey', 'fuller', 'test', 'give', 'value', 'tstat']",dickey fuller test give value tstat,0.0,0.0,10,35,3.1818181818181817,0,0,0,0,0,0,0,0
3566,dummy variables and accuracy,Techniques,dummy variables and accuracy,"['dummy', 'variables', 'and', 'accuracy']",0,"['dummy', 'variable', 'and', 'accuracy']","['dummy', 'variable', 'accuracy']",dummy variable accuracy,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
3567,need help in missing value imputation throughmice,Techniques,need help in missing value imputation throughmice,"['need', 'help', 'in', 'missing', 'value', 'imputation', 'throughmice']",0,"['need', 'help', 'in', 'missing', 'value', 'imputation', 'throughmice']","['need', 'help', 'missing', 'value', 'imputation', 'throughmice']",need help missing value imputation throughmice,-0.2,-0.2,7,46,5.75,0,0,0,0,0,0,0,0
3568,cant load rattle package,Tools,cant load rattle package,"['cant', 'load', 'rattle', 'package']",0,"['cant', 'load', 'rattle', 'package']","['cant', 'load', 'rattle', 'package']",cant load rattle package,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
3569,undergraduate student interested in data analyticsbig data grad education,Career,undergraduate student interested in data analyticsbig data grad education,"['undergraduate', 'student', 'interested', 'in', 'data', 'analyticsbig', 'data', 'grad', 'education']",0,"['undergraduate', 'student', 'interested', 'in', 'data', 'analyticsbig', 'data', 'grad', 'education']","['undergraduate', 'student', 'interested', 'data', 'analyticsbig', 'data', 'grad', 'education']",undergraduate student interested data analyticsbig data grad education,0.25,0.25,9,70,7.0,0,0,0,0,0,0,0,0
3570,how to combine information from different dataset having one column in common,Techniques,how to combine information from different dataset having one column in common,"['how', 'to', 'combine', 'information', 'from', 'different', 'dataset', 'having', 'one', 'column', 'in', 'common']",0,"['how', 'to', 'combine', 'information', 'from', 'different', 'dataset', 'having', 'one', 'column', 'in', 'common']","['combine', 'information', 'different', 'dataset', 'one', 'column', 'common']",combine information different dataset one column common,-0.15,-0.15,12,55,4.230769230769231,0,0,0,0,0,0,0,0
3571,making system to identify relations among legal entities,Techniques,making system to identify relations among legal entities,"['making', 'system', 'to', 'identify', 'relations', 'among', 'legal', 'entities']",0,"['making', 'system', 'to', 'identify', 'relation', 'among', 'legal', 'entity']","['making', 'system', 'identify', 'relation', 'among', 'legal', 'entity']",making system identify relation among legal entity,0.2,0.2,8,50,5.555555555555555,0,0,0,0,0,0,0,0
3572,cross validation on random forest,Tools,cross validation on random forest,"['cross', 'validation', 'on', 'random', 'forest']",0,"['cross', 'validation', 'on', 'random', 'forest']","['cross', 'validation', 'random', 'forest']",cross validation random forest,-0.25,-0.25,5,30,5.0,0,0,0,0,0,0,0,0
3573,creating dummy variables in python,Hackathons,creating dummy variables in python,"['creating', 'dummy', 'variables', 'in', 'python']",0,"['creating', 'dummy', 'variable', 'in', 'python']","['creating', 'dummy', 'variable', 'python']",creating dummy variable python,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
3574,r  removing na values,Hackathons,r  removing na values,"['r', 'removing', 'na', 'values']",0,"['r', 'removing', 'na', 'value']","['r', 'removing', 'na', 'value']",r removing na value,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
3575,data exploration  skewness,Techniques,data exploration  skewness,"['data', 'exploration', 'skewness']",0,"['data', 'exploration', 'skewness']","['data', 'exploration', 'skewness']",data exploration skewness,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
3576,what are some techniques to tackle the dimensionality curse,Techniques,what are some techniques to tackle the dimensionality curse,"['what', 'are', 'some', 'techniques', 'to', 'tackle', 'the', 'dimensionality', 'curse']",0,"['what', 'are', 'some', 'technique', 'to', 'tackle', 'the', 'dimensionality', 'curse']","['technique', 'tackle', 'dimensionality', 'curse']",technique tackle dimensionality curse,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
3577,difficulty implementing eda,Techniques,difficulty implementing eda,"['difficulty', 'implementing', 'eda']",0,"['difficulty', 'implementing', 'eda']","['difficulty', 'implementing', 'eda']",difficulty implementing eda,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
3578,feedbackinfo request on tensor flow deeplearning,Tools,feedbackinfo request on tensor flow deeplearning,"['feedbackinfo', 'request', 'on', 'tensor', 'flow', 'deeplearning']",0,"['feedbackinfo', 'request', 'on', 'tensor', 'flow', 'deeplearning']","['feedbackinfo', 'request', 'tensor', 'flow', 'deeplearning']",feedbackinfo request tensor flow deeplearning,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
3579,why naive bayes model do not take as categorical vector as outcome,Techniques,why naive bayes model do not take as categorical vector as outcome,"['why', 'naive', 'bayes', 'model', 'do', 'not', 'take', 'as', 'categorical', 'vector', 'as', 'outcome']",0,"['why', 'naive', 'bayes', 'model', 'do', 'not', 'take', 'a', 'categorical', 'vector', 'a', 'outcome']","['naive', 'bayes', 'model', 'take', 'categorical', 'vector', 'outcome']",naive bayes model take categorical vector outcome,-0.3,-0.3,12,49,3.769230769230769,0,0,0,0,0,0,0,0
3580,market basket analysis dataset,Techniques,market basket analysis dataset,"['market', 'basket', 'analysis', 'dataset']",0,"['market', 'basket', 'analysis', 'dataset']","['market', 'basket', 'analysis', 'dataset']",market basket analysis dataset,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
3581,how to interpret the decision tree,Techniques,how to interpret the decision tree,"['how', 'to', 'interpret', 'the', 'decision', 'tree']",0,"['how', 'to', 'interpret', 'the', 'decision', 'tree']","['interpret', 'decision', 'tree']",interpret decision tree,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
3582,modifying a existing rbm based deep autoencoder according to a research paper,Techniques,modifying a existing rbm based deep autoencoder according to a research paper,"['modifying', 'a', 'existing', 'rbm', 'based', 'deep', 'autoencoder', 'according', 'to', 'a', 'research', 'paper']",0,"['modifying', 'a', 'existing', 'rbm', 'based', 'deep', 'autoencoder', 'according', 'to', 'a', 'research', 'paper']","['modifying', 'existing', 'rbm', 'based', 'deep', 'autoencoder', 'according', 'research', 'paper']",modifying existing rbm based deep autoencoder according research paper,0.0,0.0,12,70,5.384615384615385,0,0,0,0,0,0,0,0
3583,how i can get from xgboost model xgboost package fmeasure score,Tools,how i can get from xgboost model xgboost package fmeasure score,"['how', 'i', 'can', 'get', 'from', 'xgboost', 'model', 'xgboost', 'package', 'fmeasure', 'score']",0,"['how', 'i', 'can', 'get', 'from', 'xgboost', 'model', 'xgboost', 'package', 'fmeasure', 'score']","['get', 'xgboost', 'model', 'xgboost', 'package', 'fmeasure', 'score']",get xgboost model xgboost package fmeasure score,0.0,0.0,11,48,4.0,0,0,0,0,0,0,0,0
3584,how to mention sheet name while exporting,Techniques,how to mention sheet name while exporting,"['how', 'to', 'mention', 'sheet', 'name', 'while', 'exporting']",0,"['how', 'to', 'mention', 'sheet', 'name', 'while', 'exporting']","['mention', 'sheet', 'name', 'exporting']",mention sheet name exporting,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
3585,doubt in definition of machine learning,Techniques,doubt in definition of machine learning,"['doubt', 'in', 'definition', 'of', 'machine', 'learning']",0,"['doubt', 'in', 'definition', 'of', 'machine', 'learning']","['doubt', 'definition', 'machine', 'learning']",doubt definition machine learning,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
3586,free book on machine learning with healthcare data,Resources,free book on machine learning with healthcare data,"['free', 'book', 'on', 'machine', 'learning', 'with', 'healthcare', 'data']",0,"['free', 'book', 'on', 'machine', 'learning', 'with', 'healthcare', 'data']","['free', 'book', 'machine', 'learning', 'healthcare', 'data']",free book machine learning healthcare data,0.4,0.4,8,42,4.666666666666667,0,0,0,0,0,0,0,0
3587,career shift from a perl developer to business analyst,Career,career shift from a perl developer to business analyst,"['career', 'shift', 'from', 'a', 'perl', 'developer', 'to', 'business', 'analyst']",0,"['career', 'shift', 'from', 'a', 'perl', 'developer', 'to', 'business', 'analyst']","['career', 'shift', 'perl', 'developer', 'business', 'analyst']",career shift perl developer business analyst,0.0,0.0,9,44,4.4,0,0,0,0,0,0,0,0
3588,how to perform backward chaining in logistic regression using r,Techniques,how to perform backward chaining in logistic regression using r,"['how', 'to', 'perform', 'backward', 'chaining', 'in', 'logistic', 'regression', 'using', 'r']",0,"['how', 'to', 'perform', 'backward', 'chaining', 'in', 'logistic', 'regression', 'using', 'r']","['perform', 'backward', 'chaining', 'logistic', 'regression', 'using', 'r']",perform backward chaining logistic regression using r,0.0,0.0,10,53,4.818181818181818,0,0,0,0,0,0,0,0
3589,sentiment anlaysis using nlp,Techniques,sentiment anlaysis using nlp,"['sentiment', 'anlaysis', 'using', 'nlp']",0,"['sentiment', 'anlaysis', 'using', 'nlp']","['sentiment', 'anlaysis', 'using', 'nlp']",sentiment anlaysis using nlp,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
3590,big data and analytics course in sp jain,Career,big data and analytics course in sp jain,"['big', 'data', 'and', 'analytics', 'course', 'in', 'sp', 'jain']",0,"['big', 'data', 'and', 'analytics', 'course', 'in', 'sp', 'jain']","['big', 'data', 'analytics', 'course', 'sp', 'jain']",big data analytics course sp jain,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
3591,what does the kappa statistic measure,Techniques,what does the kappa statistic measure,"['what', 'does', 'the', 'kappa', 'statistic', 'measure']",0,"['what', 'doe', 'the', 'kappa', 'statistic', 'measure']","['doe', 'kappa', 'statistic', 'measure']",doe kappa statistic measure,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
3592,cleaner approach to get the subplots in python,Techniques,cleaner approach to get the subplots in python,"['cleaner', 'approach', 'to', 'get', 'the', 'subplots', 'in', 'python']",0,"['cleaner', 'approach', 'to', 'get', 'the', 'subplots', 'in', 'python']","['cleaner', 'approach', 'get', 'subplots', 'python']",cleaner approach get subplots python,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
3593,r  want to delete a level from a factor variable with r,Techniques,r  want to delete a level from a factor variable with r,"['r', 'want', 'to', 'delete', 'a', 'level', 'from', 'a', 'factor', 'variable', 'with', 'r']",0,"['r', 'want', 'to', 'delete', 'a', 'level', 'from', 'a', 'factor', 'variable', 'with', 'r']","['r', 'want', 'delete', 'level', 'factor', 'variable', 'r']",r want delete level factor variable r,0.0,0.0,12,37,2.8461538461538463,0,0,0,0,0,0,0,0
3594,reading russian language from a excel file in r,Techniques,reading russian language from a excel file in r,"['reading', 'russian', 'language', 'from', 'a', 'excel', 'file', 'in', 'r']",0,"['reading', 'russian', 'language', 'from', 'a', 'excel', 'file', 'in', 'r']","['reading', 'russian', 'language', 'excel', 'file', 'r']",reading russian language excel file r,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
3595,how to return frequency of each word of a variable in sas,Tools,how to return frequency of each word of a variable in sas,"['how', 'to', 'return', 'frequency', 'of', 'each', 'word', 'of', 'a', 'variable', 'in', 'sas']",0,"['how', 'to', 'return', 'frequency', 'of', 'each', 'word', 'of', 'a', 'variable', 'in', 'sa']","['return', 'frequency', 'word', 'variable', 'sa']",return frequency word variable sa,0.0,0.0,12,33,2.5384615384615383,0,0,0,0,0,0,0,0
3596,the ultimate plan to become a data scientist in   resources  analytics,Resources,the ultimate plan to become a data scientist in   resources  analytics,"['the', 'ultimate', 'plan', 'to', 'become', 'a', 'data', 'scientist', 'in', 'resources', 'analytics']",1,"['the', 'ultimate', 'plan', 'to', 'become', 'a', 'data', 'scientist', 'in', 'resource', 'analytics']","['ultimate', 'plan', 'become', 'data', 'scientist', 'resource', 'analytics']",ultimate plan become data scientist resource analytics,0.0,0.0,11,54,4.5,0,0,0,0,0,0,0,0
3597,can anyone help me to choose the correct path towards data scientist,Career,can anyone help me to choose the correct path towards data scientist,"['can', 'anyone', 'help', 'me', 'to', 'choose', 'the', 'correct', 'path', 'towards', 'data', 'scientist']",0,"['can', 'anyone', 'help', 'me', 'to', 'choose', 'the', 'correct', 'path', 'towards', 'data', 'scientist']","['anyone', 'help', 'choose', 'correct', 'path', 'towards', 'data', 'scientist']",anyone help choose correct path towards data scientist,0.0,0.0,12,54,4.153846153846154,0,0,0,0,0,0,0,0
3598,interpretation cumulative gain chart output,Techniques,interpretation cumulative gain chart output,"['interpretation', 'cumulative', 'gain', 'chart', 'output']",0,"['interpretation', 'cumulative', 'gain', 'chart', 'output']","['interpretation', 'cumulative', 'gain', 'chart', 'output']",interpretation cumulative gain chart output,0.0,0.0,5,43,7.166666666666667,0,0,0,0,0,0,0,0
3599,frequentist vs bayesian statistics,Techniques,frequentist vs bayesian statistics,"['frequentist', 'vs', 'bayesian', 'statistics']",0,"['frequentist', 'v', 'bayesian', 'statistic']","['frequentist', 'v', 'bayesian', 'statistic']",frequentist v bayesian statistic,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
3600,time series data for different categories,Techniques,time series data for different categories,"['time', 'series', 'data', 'for', 'different', 'categories']",0,"['time', 'series', 'data', 'for', 'different', 'category']","['time', 'series', 'data', 'different', 'category']",time series data different category,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
3601,rstudio error could not find function view,Tools,rstudio error could not find function view,"['rstudio', 'error', 'could', 'not', 'find', 'function', 'view']",0,"['rstudio', 'error', 'could', 'not', 'find', 'function', 'view']","['rstudio', 'error', 'could', 'find', 'function', 'view']",rstudio error could find function view,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
3602,lemmatizing dataframe using nltk,Techniques,lemmatizing dataframe using nltk,"['lemmatizing', 'dataframe', 'using', 'nltk']",0,"['lemmatizing', 'dataframe', 'using', 'nltk']","['lemmatizing', 'dataframe', 'using', 'nltk']",lemmatizing dataframe using nltk,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
3603,university of virginia data science,Career,university of virginia data science,"['university', 'of', 'virginia', 'data', 'science']",0,"['university', 'of', 'virginia', 'data', 'science']","['university', 'virginia', 'data', 'science']",university virginia data science,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
3604,top decile lift in repeated fold cross validation,Techniques,top decile lift in repeated fold cross validation,"['top', 'decile', 'lift', 'in', 'repeated', 'fold', 'cross', 'validation']",0,"['top', 'decile', 'lift', 'in', 'repeated', 'fold', 'cross', 'validation']","['top', 'decile', 'lift', 'repeated', 'fold', 'cross', 'validation']",top decile lift repeated fold cross validation,0.25,0.25,8,46,5.111111111111111,0,0,0,0,0,0,0,0
3605,how to create dummy variable for n categories in python,Tools,how to create dummy variable for n categories in python,"['how', 'to', 'create', 'dummy', 'variable', 'for', 'n', 'categories', 'in', 'python']",0,"['how', 'to', 'create', 'dummy', 'variable', 'for', 'n', 'category', 'in', 'python']","['create', 'dummy', 'variable', 'n', 'category', 'python']",create dummy variable n category python,0.0,0.0,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
3606,best algorithm for pricing intelligence query for an ecommerce venture,Techniques,best algorithm for pricing intelligence query for an ecommerce venture,"['best', 'algorithm', 'for', 'pricing', 'intelligence', 'query', 'for', 'an', 'ecommerce', 'venture']",0,"['best', 'algorithm', 'for', 'pricing', 'intelligence', 'query', 'for', 'an', 'ecommerce', 'venture']","['best', 'algorithm', 'pricing', 'intelligence', 'query', 'ecommerce', 'venture']",best algorithm pricing intelligence query ecommerce venture,1.0,1.0,10,59,5.363636363636363,0,0,0,0,0,0,0,0
3607,python library for creating neural networks and deep learning,Tools,python library for creating neural networks and deep learning,"['python', 'library', 'for', 'creating', 'neural', 'networks', 'and', 'deep', 'learning']",0,"['python', 'library', 'for', 'creating', 'neural', 'network', 'and', 'deep', 'learning']","['python', 'library', 'creating', 'neural', 'network', 'deep', 'learning']",python library creating neural network deep learning,0.0,0.0,9,52,5.2,0,0,0,0,0,0,0,0
3608,coordcartesian  command is not working r,Tools,coordcartesian  command is not working r,"['coordcartesian', 'command', 'is', 'not', 'working', 'r']",0,"['coordcartesian', 'command', 'is', 'not', 'working', 'r']","['coordcartesian', 'command', 'working', 'r']",coordcartesian command working r,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
3609,improper output of class probabilities in random forest classifier,Techniques,improper output of class probabilities in random forest classifier,"['improper', 'output', 'of', 'class', 'probabilities', 'in', 'random', 'forest', 'classifier']",0,"['improper', 'output', 'of', 'class', 'probability', 'in', 'random', 'forest', 'classifier']","['improper', 'output', 'class', 'probability', 'random', 'forest', 'classifier']",improper output class probability random forest classifier,-0.5,-0.5,9,58,5.8,0,0,0,0,0,0,0,0
3610,confusion in determining significance of categorical variable using glm function,Techniques,confusion in determining significance of categorical variable using glm function,"['confusion', 'in', 'determining', 'significance', 'of', 'categorical', 'variable', 'using', 'glm', 'function']",0,"['confusion', 'in', 'determining', 'significance', 'of', 'categorical', 'variable', 'using', 'glm', 'function']","['confusion', 'determining', 'significance', 'categorical', 'variable', 'using', 'glm', 'function']",confusion determining significance categorical variable using glm function,0.0,0.0,10,74,6.7272727272727275,0,0,0,0,0,0,0,0
3611,hypothesis while data modelling,Techniques,hypothesis while data modelling,"['hypothesis', 'while', 'data', 'modelling']",0,"['hypothesis', 'while', 'data', 'modelling']","['hypothesis', 'data', 'modelling']",hypothesis data modelling,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
3612,it operations defect prediction model,Techniques,it operations defect prediction model,"['it', 'operations', 'defect', 'prediction', 'model']",0,"['it', 'operation', 'defect', 'prediction', 'model']","['operation', 'defect', 'prediction', 'model']",operation defect prediction model,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
3613,project experience from analytics vidya and kaggle,Career,project experience from analytics vidya and kaggle,"['project', 'experience', 'from', 'analytics', 'vidya', 'and', 'kaggle']",0,"['project', 'experience', 'from', 'analytics', 'vidya', 'and', 'kaggle']","['project', 'experience', 'analytics', 'vidya', 'kaggle']",project experience analytics vidya kaggle,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
3614,how to compare distribution of variables using box plot in sas,Tools,how to compare distribution of variables using box plot in sas,"['how', 'to', 'compare', 'distribution', 'of', 'variables', 'using', 'box', 'plot', 'in', 'sas']",0,"['how', 'to', 'compare', 'distribution', 'of', 'variable', 'using', 'box', 'plot', 'in', 'sa']","['compare', 'distribution', 'variable', 'using', 'box', 'plot', 'sa']",compare distribution variable using box plot sa,0.0,0.0,11,47,3.9166666666666665,0,0,0,0,0,0,0,0
3615,what does uniqueness specifies in factor analysis,Techniques,what does uniqueness specifies in factor analysis,"['what', 'does', 'uniqueness', 'specifies', 'in', 'factor', 'analysis']",0,"['what', 'doe', 'uniqueness', 'specifies', 'in', 'factor', 'analysis']","['doe', 'uniqueness', 'specifies', 'factor', 'analysis']",doe uniqueness specifies factor analysis,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
3616,replacing a particular integer by another integer in pandas dataframe,Techniques,replacing a particular integer by another integer in pandas dataframe,"['replacing', 'a', 'particular', 'integer', 'by', 'another', 'integer', 'in', 'pandas', 'dataframe']",0,"['replacing', 'a', 'particular', 'integer', 'by', 'another', 'integer', 'in', 'panda', 'dataframe']","['replacing', 'particular', 'integer', 'another', 'integer', 'panda', 'dataframe']",replacing particular integer another integer panda dataframe,0.1666666666666666,0.1666666666666666,10,60,5.454545454545454,0,0,0,0,0,0,0,0
3617,precampaign ab testing  ttest  anava,Techniques,precampaign ab testing  ttest  anava,"['precampaign', 'ab', 'testing', 'ttest', 'anava']",0,"['precampaign', 'ab', 'testing', 'ttest', 'anava']","['precampaign', 'ab', 'testing', 'ttest', 'anava']",precampaign ab testing ttest anava,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
3618,questions related to the article on multivariate vector auto regression using python,Techniques,questions related to the article on multivariate vector auto regression using python,"['questions', 'related', 'to', 'the', 'article', 'on', 'multivariate', 'vector', 'auto', 'regression', 'using', 'python']",0,"['question', 'related', 'to', 'the', 'article', 'on', 'multivariate', 'vector', 'auto', 'regression', 'using', 'python']","['question', 'related', 'article', 'multivariate', 'vector', 'auto', 'regression', 'using', 'python']",question related article multivariate vector auto regression using python,0.0,0.0,12,73,5.615384615384615,0,0,0,0,0,0,0,0
3619,mse as a performance metrics for random forest,Techniques,mse as a performance metrics for random forest,"['mse', 'as', 'a', 'performance', 'metrics', 'for', 'random', 'forest']",0,"['mse', 'a', 'a', 'performance', 'metric', 'for', 'random', 'forest']","['mse', 'performance', 'metric', 'random', 'forest']",mse performance metric random forest,-0.5,-0.5,8,36,4.0,0,0,0,0,0,0,0,0
3620,how to automate r scripts in rstudio,Tools,how to automate r scripts in rstudio,"['how', 'to', 'automate', 'r', 'scripts', 'in', 'rstudio']",0,"['how', 'to', 'automate', 'r', 'script', 'in', 'rstudio']","['automate', 'r', 'script', 'rstudio']",automate r script rstudio,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
3621,typeerror docbow expects an array of unicode tokens on input not a single string,Techniques,typeerror docbow expects an array of unicode tokens on input not a single string,"['typeerror', 'docbow', 'expects', 'an', 'array', 'of', 'unicode', 'tokens', 'on', 'input', 'not', 'a', 'single', 'string']",0,"['typeerror', 'docbow', 'expects', 'an', 'array', 'of', 'unicode', 'token', 'on', 'input', 'not', 'a', 'single', 'string']","['typeerror', 'docbow', 'expects', 'array', 'unicode', 'token', 'input', 'single', 'string']",typeerror docbow expects array unicode token input single string,0.0357142857142857,-0.0714285714285714,14,64,4.266666666666667,0,0,0,0,0,0,0,0
3622,how to use setseed,Techniques,how to use setseed,"['how', 'to', 'use', 'setseed']",0,"['how', 'to', 'use', 'setseed']","['use', 'setseed']",use setseed,0.0,0.0,4,11,2.2,0,0,0,0,0,0,0,0
3623,student verification,Other,student verification,"['student', 'verification']",0,"['student', 'verification']","['student', 'verification']",student verification,0.0,0.0,2,20,6.666666666666667,0,0,0,0,0,0,0,0
3624,prediction of  output variables,Techniques,prediction of  output variables,"['prediction', 'of', 'output', 'variables']",1,"['prediction', 'of', 'output', 'variable']","['prediction', 'output', 'variable']",prediction output variable,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
3625,low r value in my regression problem,Techniques,low r value in my regression problem,"['low', 'r', 'value', 'in', 'my', 'regression', 'problem']",0,"['low', 'r', 'value', 'in', 'my', 'regression', 'problem']","['low', 'r', 'value', 'regression', 'problem']",low r value regression problem,0.0,0.0,7,30,3.75,0,0,0,0,0,0,0,0
3626,discussion about analytics program,Career,discussion about analytics program,"['discussion', 'about', 'analytics', 'program']",0,"['discussion', 'about', 'analytics', 'program']","['discussion', 'analytics', 'program']",discussion analytics program,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
3627,how to convert image data in matrix form into vector in r,Tools,how to convert image data in matrix form into vector in r,"['how', 'to', 'convert', 'image', 'data', 'in', 'matrix', 'form', 'into', 'vector', 'in', 'r']",0,"['how', 'to', 'convert', 'image', 'data', 'in', 'matrix', 'form', 'into', 'vector', 'in', 'r']","['convert', 'image', 'data', 'matrix', 'form', 'vector', 'r']",convert image data matrix form vector r,0.0,0.0,12,39,3.0,0,0,0,0,0,0,0,0
3628,what are thestateofart techniques used for stock price and return prediction,Techniques,what are thestateofart techniques used for stock price and return prediction,"['what', 'are', 'thestateofart', 'techniques', 'used', 'for', 'stock', 'price', 'and', 'return', 'prediction']",0,"['what', 'are', 'thestateofart', 'technique', 'used', 'for', 'stock', 'price', 'and', 'return', 'prediction']","['thestateofart', 'technique', 'used', 'stock', 'price', 'return', 'prediction']",thestateofart technique used stock price return prediction,0.0,0.0,11,58,4.833333333333333,0,0,0,0,0,0,0,0
3629,using sas studio university edition for loan prediction problem,Hackathons,using sas studio university edition for loan prediction problem,"['using', 'sas', 'studio', 'university', 'edition', 'for', 'loan', 'prediction', 'problem']",0,"['using', 'sa', 'studio', 'university', 'edition', 'for', 'loan', 'prediction', 'problem']","['using', 'sa', 'studio', 'university', 'edition', 'loan', 'prediction', 'problem']",using sa studio university edition loan prediction problem,0.0,0.0,9,58,5.8,0,0,0,0,0,0,0,0
3630,what are the best methods to find relationship between categorical variables,Techniques,what are the best methods to find relationship between categorical variables,"['what', 'are', 'the', 'best', 'methods', 'to', 'find', 'relationship', 'between', 'categorical', 'variables']",0,"['what', 'are', 'the', 'best', 'method', 'to', 'find', 'relationship', 'between', 'categorical', 'variable']","['best', 'method', 'find', 'relationship', 'categorical', 'variable']",best method find relationship categorical variable,1.0,1.0,11,50,4.166666666666667,0,0,0,0,0,0,0,0
3631,what is the function of the formula used in ldalinear discriminant analysis in r,Tools,what is the function of the formula used in ldalinear discriminant analysis in r,"['what', 'is', 'the', 'function', 'of', 'the', 'formula', 'used', 'in', 'ldalinear', 'discriminant', 'analysis', 'in', 'r']",0,"['what', 'is', 'the', 'function', 'of', 'the', 'formula', 'used', 'in', 'ldalinear', 'discriminant', 'analysis', 'in', 'r']","['function', 'formula', 'used', 'ldalinear', 'discriminant', 'analysis', 'r']",function formula used ldalinear discriminant analysis r,0.0,0.0,14,55,3.6666666666666665,0,0,0,0,0,0,0,0
3632,how to plot the proportions in mosaic plot in r,Tools,how to plot the proportions in mosaic plot in r,"['how', 'to', 'plot', 'the', 'proportions', 'in', 'mosaic', 'plot', 'in', 'r']",0,"['how', 'to', 'plot', 'the', 'proportion', 'in', 'mosaic', 'plot', 'in', 'r']","['plot', 'proportion', 'mosaic', 'plot', 'r']",plot proportion mosaic plot r,0.0,0.0,10,29,2.6363636363636362,0,0,0,0,0,0,0,0
3633,data hackathon  th  th august   register here,Hackathons,data hackathon  th  th august   register here,"['data', 'hackathon', 'th', 'th', 'august', 'register', 'here']",2,"['data', 'hackathon', 'th', 'th', 'august', 'register', 'here']","['data', 'hackathon', 'th', 'th', 'august', 'register']",data hackathon th th august register,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
3634,how to get the data from data frame in python,Tools,how to get the data from data frame in python,"['how', 'to', 'get', 'the', 'data', 'from', 'data', 'frame', 'in', 'python']",0,"['how', 'to', 'get', 'the', 'data', 'from', 'data', 'frame', 'in', 'python']","['get', 'data', 'data', 'frame', 'python']",get data data frame python,0.0,0.0,10,26,2.3636363636363638,0,0,0,0,0,0,0,0
3635,how do you score equities based on multiple recommendations and target prices,Other,how do you score equities based on multiple recommendations and target prices,"['how', 'do', 'you', 'score', 'equities', 'based', 'on', 'multiple', 'recommendations', 'and', 'target', 'prices']",0,"['how', 'do', 'you', 'score', 'equity', 'based', 'on', 'multiple', 'recommendation', 'and', 'target', 'price']","['score', 'equity', 'based', 'multiple', 'recommendation', 'target', 'price']",score equity based multiple recommendation target price,0.0,0.0,12,55,4.230769230769231,0,0,0,0,0,0,0,0
3636,reading a wide dataset in r,Tools,reading a wide dataset in r,"['reading', 'a', 'wide', 'dataset', 'in', 'r']",0,"['reading', 'a', 'wide', 'dataset', 'in', 'r']","['reading', 'wide', 'dataset', 'r']",reading wide dataset r,-0.1,-0.1,6,22,3.142857142857143,0,0,0,0,0,0,0,0
3637,how to take model and implement data pipeline and customer facing dashboard,Tools,how to take model and implement data pipeline and customer facing dashboard,"['how', 'to', 'take', 'model', 'and', 'implement', 'data', 'pipeline', 'and', 'customer', 'facing', 'dashboard']",0,"['how', 'to', 'take', 'model', 'and', 'implement', 'data', 'pipeline', 'and', 'customer', 'facing', 'dashboard']","['take', 'model', 'implement', 'data', 'pipeline', 'customer', 'facing', 'dashboard']",take model implement data pipeline customer facing dashboard,0.0,0.0,12,60,4.615384615384615,0,0,0,0,0,0,0,0
3638,for r users download cheat sheet on data exploration  steps,Resources,for r users download cheat sheet on data exploration  steps,"['for', 'r', 'users', 'download', 'cheat', 'sheet', 'on', 'data', 'exploration', 'steps']",1,"['for', 'r', 'user', 'download', 'cheat', 'sheet', 'on', 'data', 'exploration', 'step']","['r', 'user', 'download', 'cheat', 'sheet', 'data', 'exploration', 'step']",r user download cheat sheet data exploration step,0.0,0.0,10,49,4.454545454545454,0,0,0,0,0,0,0,0
3639,shiny package in r,Tools,shiny package in r,"['shiny', 'package', 'in', 'r']",0,"['shiny', 'package', 'in', 'r']","['shiny', 'package', 'r']",shiny package r,0.0,0.0,4,15,3.0,0,0,0,0,0,0,0,0
3640,how to apply an ensemble of random forests in r,Tools,how to apply an ensemble of random forests in r,"['how', 'to', 'apply', 'an', 'ensemble', 'of', 'random', 'forests', 'in', 'r']",0,"['how', 'to', 'apply', 'an', 'ensemble', 'of', 'random', 'forest', 'in', 'r']","['apply', 'ensemble', 'random', 'forest', 'r']",apply ensemble random forest r,-0.5,-0.5,10,30,2.727272727272727,0,0,0,0,0,0,0,0
3641,what are some intersting techniques skills or tips you use to solve regressionclassification problems,Techniques,what are some intersting techniques skills or tips you use to solve regressionclassification problems,"['what', 'are', 'some', 'intersting', 'techniques', 'skills', 'or', 'tips', 'you', 'use', 'to', 'solve', 'regressionclassification', 'problems']",0,"['what', 'are', 'some', 'intersting', 'technique', 'skill', 'or', 'tip', 'you', 'use', 'to', 'solve', 'regressionclassification', 'problem']","['intersting', 'technique', 'skill', 'tip', 'use', 'solve', 'regressionclassification', 'problem']",intersting technique skill tip use solve regressionclassification problem,0.0,0.0,14,73,4.866666666666666,0,0,0,0,0,0,0,0
3642,whether to learn r or python,Career,whether to learn r or python,"['whether', 'to', 'learn', 'r', 'or', 'python']",0,"['whether', 'to', 'learn', 'r', 'or', 'python']","['whether', 'learn', 'r', 'python']",whether learn r python,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
3643,download hiring path to get yourself hired as a data scientist,Resources,download hiring path to get yourself hired as a data scientist,"['download', 'hiring', 'path', 'to', 'get', 'yourself', 'hired', 'as', 'a', 'data', 'scientist']",0,"['download', 'hiring', 'path', 'to', 'get', 'yourself', 'hired', 'a', 'a', 'data', 'scientist']","['download', 'hiring', 'path', 'get', 'hired', 'data', 'scientist']",download hiring path get hired data scientist,0.0,0.0,11,45,3.75,0,0,0,0,0,0,0,0
3644,pca how many variables needs to be considered,Techniques,pca how many variables needs to be considered,"['pca', 'how', 'many', 'variables', 'needs', 'to', 'be', 'considered']",0,"['pca', 'how', 'many', 'variable', 'need', 'to', 'be', 'considered']","['pca', 'many', 'variable', 'need', 'considered']",pca many variable need considered,0.5,0.5,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
3645,missing value imputation in a very large dataset,Techniques,missing value imputation in a very large dataset,"['missing', 'value', 'imputation', 'in', 'a', 'very', 'large', 'dataset']",0,"['missing', 'value', 'imputation', 'in', 'a', 'very', 'large', 'dataset']","['missing', 'value', 'imputation', 'large', 'dataset']",missing value imputation large dataset,0.0392857142857142,0.0071428571428571,8,38,4.222222222222222,0,0,0,0,0,0,0,0
3646,machine learning by andrew ng on coursera vs learning from data on edx,Techniques,machine learning by andrew ng on coursera vs learning from data on edx,"['machine', 'learning', 'by', 'andrew', 'ng', 'on', 'coursera', 'vs', 'learning', 'from', 'data', 'on', 'edx']",0,"['machine', 'learning', 'by', 'andrew', 'ng', 'on', 'coursera', 'v', 'learning', 'from', 'data', 'on', 'edx']","['machine', 'learning', 'andrew', 'ng', 'coursera', 'v', 'learning', 'data', 'edx']",machine learning andrew ng coursera v learning data edx,0.0,0.0,13,55,3.9285714285714284,0,0,0,0,0,0,0,0
3647,web scraping using r,Techniques,web scraping using r,"['web', 'scraping', 'using', 'r']",0,"['web', 'scraping', 'using', 'r']","['web', 'scraping', 'using', 'r']",web scraping using r,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
3648,implementation of k nearest neighbor from scratch,Resources,implementation of k nearest neighbor from scratch,"['implementation', 'of', 'k', 'nearest', 'neighbor', 'from', 'scratch']",0,"['implementation', 'of', 'k', 'nearest', 'neighbor', 'from', 'scratch']","['implementation', 'k', 'nearest', 'neighbor', 'scratch']",implementation k nearest neighbor scratch,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
3649,car pricing case study,Techniques,car pricing case study,"['car', 'pricing', 'case', 'study']",0,"['car', 'pricing', 'case', 'study']","['car', 'pricing', 'case', 'study']",car pricing case study,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
3650,social media analytics,Techniques,social media analytics,"['social', 'media', 'analytics']",0,"['social', 'medium', 'analytics']","['social', 'medium', 'analytics']",social medium analytics,0.0333333333333333,0.0333333333333333,3,23,5.75,0,0,0,0,0,0,0,0
3651,which sas course is best for a data analyst,Career,which sas course is best for a data analyst,"['which', 'sas', 'course', 'is', 'best', 'for', 'a', 'data', 'analyst']",0,"['which', 'sa', 'course', 'is', 'best', 'for', 'a', 'data', 'analyst']","['sa', 'course', 'best', 'data', 'analyst']",sa course best data analyst,1.0,1.0,9,27,2.7,0,0,0,0,0,0,0,0
3652,model monitoring,Techniques,model monitoring,"['model', 'monitoring']",0,"['model', 'monitoring']","['model', 'monitoring']",model monitoring,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
3653,error in knntrain  iristrain test  iristest c  iristraintarget  unused argument c  iristraintarget,Techniques,error in knntrain  iristrain test  iristest c  iristraintarget  unused argument c  iristraintarget,"['error', 'in', 'knntrain', 'iristrain', 'test', 'iristest', 'c', 'iristraintarget', 'unused', 'argument', 'c', 'iristraintarget']",0,"['error', 'in', 'knntrain', 'iristrain', 'test', 'iristest', 'c', 'iristraintarget', 'unused', 'argument', 'c', 'iristraintarget']","['error', 'knntrain', 'iristrain', 'test', 'iristest', 'c', 'iristraintarget', 'unused', 'argument', 'c', 'iristraintarget']",error knntrain iristrain test iristest c iristraintarget unused argument c iristraintarget,0.0,0.0,12,90,6.923076923076923,0,0,0,0,0,0,0,0
3654,how to calculate mode of votes in an ensemble in r,Techniques,how to calculate mode of votes in an ensemble in r,"['how', 'to', 'calculate', 'mode', 'of', 'votes', 'in', 'an', 'ensemble', 'in', 'r']",0,"['how', 'to', 'calculate', 'mode', 'of', 'vote', 'in', 'an', 'ensemble', 'in', 'r']","['calculate', 'mode', 'vote', 'ensemble', 'r']",calculate mode vote ensemble r,0.0,0.0,11,30,2.5,0,0,0,0,0,0,0,0
3655,how to mock large volume of data,Tools,how to mock large volume of data,"['how', 'to', 'mock', 'large', 'volume', 'of', 'data']",0,"['how', 'to', 'mock', 'large', 'volume', 'of', 'data']","['mock', 'large', 'volume', 'data']",mock large volume data,0.2142857142857142,0.2142857142857142,7,22,2.75,0,0,0,0,0,0,0,0
3656,only  vertical line in histogram,Techniques,only  vertical line in histogram,"['only', 'vertical', 'line', 'in', 'histogram']",1,"['only', 'vertical', 'line', 'in', 'histogram']","['vertical', 'line', 'histogram']",vertical line histogram,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
3657,scala ide for data science applications like rstudio  spyder  rodeo,Techniques,scala ide for data science applications like rstudio  spyder  rodeo,"['scala', 'ide', 'for', 'data', 'science', 'applications', 'like', 'rstudio', 'spyder', 'rodeo']",0,"['scala', 'ide', 'for', 'data', 'science', 'application', 'like', 'rstudio', 'spyder', 'rodeo']","['scala', 'ide', 'data', 'science', 'application', 'like', 'rstudio', 'spyder', 'rodeo']",scala ide data science application like rstudio spyder rodeo,0.0,0.0,10,60,5.454545454545454,0,0,0,0,0,0,0,0
3658,market research by data science,Other,market research by data science,"['market', 'research', 'by', 'data', 'science']",0,"['market', 'research', 'by', 'data', 'science']","['market', 'research', 'data', 'science']",market research data science,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
3659,weight of evidence transformation,Techniques,weight of evidence transformation,"['weight', 'of', 'evidence', 'transformation']",0,"['weight', 'of', 'evidence', 'transformation']","['weight', 'evidence', 'transformation']",weight evidence transformation,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
3660,how to find the number of cluster in kmeans algorithm,Techniques,how to find the number of cluster in kmeans algorithm,"['how', 'to', 'find', 'the', 'number', 'of', 'cluster', 'in', 'kmeans', 'algorithm']",0,"['how', 'to', 'find', 'the', 'number', 'of', 'cluster', 'in', 'kmeans', 'algorithm']","['find', 'number', 'cluster', 'kmeans', 'algorithm']",find number cluster kmeans algorithm,0.0,0.0,10,36,3.272727272727273,0,0,0,0,0,0,0,0
3661,is statistics degree necessary to be a data scientist,Career,is statistics degree necessary to be a data scientist,"['is', 'statistics', 'degree', 'necessary', 'to', 'be', 'a', 'data', 'scientist']",0,"['is', 'statistic', 'degree', 'necessary', 'to', 'be', 'a', 'data', 'scientist']","['statistic', 'degree', 'necessary', 'data', 'scientist']",statistic degree necessary data scientist,0.0,0.0,9,41,4.1,0,0,0,0,0,0,0,0
3662,how to delete a library in sas,Techniques,how to delete a library in sas,"['how', 'to', 'delete', 'a', 'library', 'in', 'sas']",0,"['how', 'to', 'delete', 'a', 'library', 'in', 'sa']","['delete', 'library', 'sa']",delete library sa,0.0,0.0,7,17,2.125,0,0,0,0,0,0,0,0
3663,how to normalize the skewed multivariate data in r,Techniques,how to normalize the skewed multivariate data in r,"['how', 'to', 'normalize', 'the', 'skewed', 'multivariate', 'data', 'in', 'r']",0,"['how', 'to', 'normalize', 'the', 'skewed', 'multivariate', 'data', 'in', 'r']","['normalize', 'skewed', 'multivariate', 'data', 'r']",normalize skewed multivariate data r,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
3664,datalake for sql server and log files,Resources,datalake for sql server and log files,"['datalake', 'for', 'sql', 'server', 'and', 'log', 'files']",0,"['datalake', 'for', 'sql', 'server', 'and', 'log', 'file']","['datalake', 'sql', 'server', 'log', 'file']",datalake sql server log file,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
3665,speech recognition  audio data analysis post doubts mfccs,Techniques,speech recognition  audio data analysis post doubts mfccs,"['speech', 'recognition', 'audio', 'data', 'analysis', 'post', 'doubts', 'mfccs']",0,"['speech', 'recognition', 'audio', 'data', 'analysis', 'post', 'doubt', 'mfccs']","['speech', 'recognition', 'audio', 'data', 'analysis', 'post', 'doubt', 'mfccs']",speech recognition audio data analysis post doubt mfccs,0.0,0.0,8,55,6.111111111111111,0,0,0,0,0,0,0,0
3666,missing data and cart,Techniques,missing data and cart,"['missing', 'data', 'and', 'cart']",0,"['missing', 'data', 'and', 'cart']","['missing', 'data', 'cart']",missing data cart,-0.2,-0.2,4,17,3.4,0,0,0,0,0,0,0,0
3667,how to reshape a dataset in r,Tools,how to reshape a dataset in r,"['how', 'to', 'reshape', 'a', 'dataset', 'in', 'r']",0,"['how', 'to', 'reshape', 'a', 'dataset', 'in', 'r']","['reshape', 'dataset', 'r']",reshape dataset r,0.0,0.0,7,17,2.125,0,0,0,0,0,0,0,0
3668,develop a machine learning model based on the features availability,Techniques,develop a machine learning model based on the features availability,"['develop', 'a', 'machine', 'learning', 'model', 'based', 'on', 'the', 'features', 'availability']",0,"['develop', 'a', 'machine', 'learning', 'model', 'based', 'on', 'the', 'feature', 'availability']","['develop', 'machine', 'learning', 'model', 'based', 'feature', 'availability']",develop machine learning model based feature availability,0.0,0.0,10,57,5.181818181818182,0,0,0,0,0,0,0,0
3669,learning one tool at a time or taking multiple trainings at a time,Career,learning one tool at a time or taking multiple trainings at a time,"['learning', 'one', 'tool', 'at', 'a', 'time', 'or', 'taking', 'multiple', 'trainings', 'at', 'a', 'time']",0,"['learning', 'one', 'tool', 'at', 'a', 'time', 'or', 'taking', 'multiple', 'training', 'at', 'a', 'time']","['learning', 'one', 'tool', 'time', 'taking', 'multiple', 'training', 'time']",learning one tool time taking multiple training time,0.0,0.0,13,52,3.7142857142857144,0,0,0,0,0,0,0,0
3670,when we use binomial distribution and poisson distributions,Techniques,when we use binomial distribution and poisson distributions,"['when', 'we', 'use', 'binomial', 'distribution', 'and', 'poisson', 'distributions']",0,"['when', 'we', 'use', 'binomial', 'distribution', 'and', 'poisson', 'distribution']","['use', 'binomial', 'distribution', 'poisson', 'distribution']",use binomial distribution poisson distribution,0.0,0.0,8,46,5.111111111111111,0,0,0,0,0,0,0,0
3671,document classification,Techniques,document classification,"['document', 'classification']",0,"['document', 'classification']","['document', 'classification']",document classification,0.0,0.0,2,23,7.666666666666667,0,0,0,0,0,0,0,0
3672,freshers oppurtunities,Career,freshers oppurtunities,"['freshers', 'oppurtunities']",0,"['fresher', 'oppurtunities']","['fresher', 'oppurtunities']",fresher oppurtunities,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
3673,imbalanced dataset and scaling variables,Techniques,imbalanced dataset and scaling variables,"['imbalanced', 'dataset', 'and', 'scaling', 'variables']",0,"['imbalanced', 'dataset', 'and', 'scaling', 'variable']","['imbalanced', 'dataset', 'scaling', 'variable']",imbalanced dataset scaling variable,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
3674,pursuing a career in business analytics after research,Career,pursuing a career in business analytics after research,"['pursuing', 'a', 'career', 'in', 'business', 'analytics', 'after', 'research']",0,"['pursuing', 'a', 'career', 'in', 'business', 'analytics', 'after', 'research']","['pursuing', 'career', 'business', 'analytics', 'research']",pursuing career business analytics research,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
3675,use of analytics to tackle data privacy and governance,Misc,use of analytics to tackle data privacy and governance,"['use', 'of', 'analytics', 'to', 'tackle', 'data', 'privacy', 'and', 'governance']",0,"['use', 'of', 'analytics', 'to', 'tackle', 'data', 'privacy', 'and', 'governance']","['use', 'analytics', 'tackle', 'data', 'privacy', 'governance']",use analytics tackle data privacy governance,0.0,0.0,9,44,4.4,0,0,0,0,0,0,0,0
3676,deep learning medical image attention mechanism,Resources,deep learning medical image attention mechanism,"['deep', 'learning', 'medical', 'image', 'attention', 'mechanism']",0,"['deep', 'learning', 'medical', 'image', 'attention', 'mechanism']","['deep', 'learning', 'medical', 'image', 'attention', 'mechanism']",deep learning medical image attention mechanism,0.0,0.0,6,47,6.714285714285714,0,0,0,0,0,0,0,0
3677,outlier detection for one dimensional price return series fro stocks,Techniques,outlier detection for one dimensional price return series fro stocks,"['outlier', 'detection', 'for', 'one', 'dimensional', 'price', 'return', 'series', 'fro', 'stocks']",0,"['outlier', 'detection', 'for', 'one', 'dimensional', 'price', 'return', 'series', 'fro', 'stock']","['outlier', 'detection', 'one', 'dimensional', 'price', 'return', 'series', 'fro', 'stock']",outlier detection one dimensional price return series fro stock,0.0,0.0,10,63,5.7272727272727275,0,0,0,0,0,0,0,0
3678,which algorithm is best for sales forecasting and why,Techniques,which algorithm is best for sales forecasting and why,"['which', 'algorithm', 'is', 'best', 'for', 'sales', 'forecasting', 'and', 'why']",0,"['which', 'algorithm', 'is', 'best', 'for', 'sale', 'forecasting', 'and', 'why']","['algorithm', 'best', 'sale', 'forecasting']",algorithm best sale forecasting,1.0,1.0,9,31,3.1,0,0,0,0,0,0,0,0
3679,decision tree and random forest in r,Techniques,decision tree and random forest in r,"['decision', 'tree', 'and', 'random', 'forest', 'in', 'r']",0,"['decision', 'tree', 'and', 'random', 'forest', 'in', 'r']","['decision', 'tree', 'random', 'forest', 'r']",decision tree random forest r,-0.5,-0.5,7,29,3.625,0,0,0,0,0,0,0,0
3680,python vs python,Tools,python vs python,"['python', 'vs', 'python']",0,"['python', 'v', 'python']","['python', 'v', 'python']",python v python,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
3681,career shift from business development to data science,Career,career shift from business development to data science,"['career', 'shift', 'from', 'business', 'development', 'to', 'data', 'science']",0,"['career', 'shift', 'from', 'business', 'development', 'to', 'data', 'science']","['career', 'shift', 'business', 'development', 'data', 'science']",career shift business development data science,0.0,0.0,8,46,5.111111111111111,0,0,0,0,0,0,0,0
3682,regarding profiling of products using unsupervised learning,Techniques,regarding profiling of products using unsupervised learning,"['regarding', 'profiling', 'of', 'products', 'using', 'unsupervised', 'learning']",0,"['regarding', 'profiling', 'of', 'product', 'using', 'unsupervised', 'learning']","['regarding', 'profiling', 'product', 'using', 'unsupervised', 'learning']",regarding profiling product using unsupervised learning,0.0,0.0,7,55,6.875,0,0,0,0,0,0,0,0
3683,hierarchical hidden markov model with kmeans algorithm,Techniques,hierarchical hidden markov model with kmeans algorithm,"['hierarchical', 'hidden', 'markov', 'model', 'with', 'kmeans', 'algorithm']",0,"['hierarchical', 'hidden', 'markov', 'model', 'with', 'kmeans', 'algorithm']","['hierarchical', 'hidden', 'markov', 'model', 'kmeans', 'algorithm']",hierarchical hidden markov model kmeans algorithm,-0.1666666666666666,-0.1666666666666666,7,49,6.125,0,0,0,0,0,0,0,0
3684,mandatory submission of the code file,Hackathons,mandatory submission of the code file,"['mandatory', 'submission', 'of', 'the', 'code', 'file']",0,"['mandatory', 'submission', 'of', 'the', 'code', 'file']","['mandatory', 'submission', 'code', 'file']",mandatory submission code file,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
3685,need trainingassistance in one or two case studies modelling using r,Career,need trainingassistance in one or two case studies modelling using r,"['need', 'trainingassistance', 'in', 'one', 'or', 'two', 'case', 'studies', 'modelling', 'using', 'r']",0,"['need', 'trainingassistance', 'in', 'one', 'or', 'two', 'case', 'study', 'modelling', 'using', 'r']","['need', 'trainingassistance', 'one', 'two', 'case', 'study', 'modelling', 'using', 'r']",need trainingassistance one two case study modelling using r,0.0,0.0,11,60,5.0,0,0,0,0,0,0,0,0
3686,text mining how to remove shortcut words,Techniques,text mining how to remove shortcut words,"['text', 'mining', 'how', 'to', 'remove', 'shortcut', 'words']",0,"['text', 'mining', 'how', 'to', 'remove', 'shortcut', 'word']","['text', 'mining', 'remove', 'shortcut', 'word']",text mining remove shortcut word,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
3687,what does it mean if test and train accuracy is oscillating too much for cnn model in tensorflow,Techniques,what does it mean if test and train accuracy is oscillating too much for cnn model in tensorflow,"['what', 'does', 'it', 'mean', 'if', 'test', 'and', 'train', 'accuracy', 'is', 'oscillating', 'too', 'much', 'for', 'cnn', 'model', 'in', 'tensorflow']",0,"['what', 'doe', 'it', 'mean', 'if', 'test', 'and', 'train', 'accuracy', 'is', 'oscillating', 'too', 'much', 'for', 'cnn', 'model', 'in', 'tensorflow']","['doe', 'mean', 'test', 'train', 'accuracy', 'oscillating', 'much', 'cnn', 'model', 'tensorflow']",doe mean test train accuracy oscillating much cnn model tensorflow,-0.0562499999999999,-0.0562499999999999,18,66,3.473684210526316,0,0,0,0,0,0,0,0
3688,skills required to be a analytics consultant,Career,skills required to be a analytics consultant,"['skills', 'required', 'to', 'be', 'a', 'analytics', 'consultant']",0,"['skill', 'required', 'to', 'be', 'a', 'analytics', 'consultant']","['skill', 'required', 'analytics', 'consultant']",skill required analytics consultant,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
3689,what are some of the data science modelling techniques used in risk analytics,Techniques,what are some of the data science modelling techniques used in risk analytics,"['what', 'are', 'some', 'of', 'the', 'data', 'science', 'modelling', 'techniques', 'used', 'in', 'risk', 'analytics']",0,"['what', 'are', 'some', 'of', 'the', 'data', 'science', 'modelling', 'technique', 'used', 'in', 'risk', 'analytics']","['data', 'science', 'modelling', 'technique', 'used', 'risk', 'analytics']",data science modelling technique used risk analytics,0.0,0.0,13,52,3.7142857142857144,0,0,0,0,0,0,0,0
3690,find difference in contents of  pdf,Tools,find difference in contents of  pdf,"['find', 'difference', 'in', 'contents', 'of', 'pdf']",1,"['find', 'difference', 'in', 'content', 'of', 'pdf']","['find', 'difference', 'content', 'pdf']",find difference content pdf,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
3691,how to extract columns with repeating values in a data frame in r,Tools,how to extract columns with repeating values in a data frame in r,"['how', 'to', 'extract', 'columns', 'with', 'repeating', 'values', 'in', 'a', 'data', 'frame', 'in', 'r']",0,"['how', 'to', 'extract', 'column', 'with', 'repeating', 'value', 'in', 'a', 'data', 'frame', 'in', 'r']","['extract', 'column', 'repeating', 'value', 'data', 'frame', 'r']",extract column repeating value data frame r,0.0,0.0,13,43,3.0714285714285716,0,0,0,0,0,0,0,0
3692,multicollinearity technique for any regression model,Techniques,multicollinearity technique for any regression model,"['multicollinearity', 'technique', 'for', 'any', 'regression', 'model']",0,"['multicollinearity', 'technique', 'for', 'any', 'regression', 'model']","['multicollinearity', 'technique', 'regression', 'model']",multicollinearity technique regression model,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
3693,ensemble models in r,Techniques,ensemble models in r,"['ensemble', 'models', 'in', 'r']",0,"['ensemble', 'model', 'in', 'r']","['ensemble', 'model', 'r']",ensemble model r,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
3694,what is the best book for predictive analytics for ecommerce industry,Techniques,what is the best book for predictive analytics for ecommerce industry,"['what', 'is', 'the', 'best', 'book', 'for', 'predictive', 'analytics', 'for', 'ecommerce', 'industry']",0,"['what', 'is', 'the', 'best', 'book', 'for', 'predictive', 'analytics', 'for', 'ecommerce', 'industry']","['best', 'book', 'predictive', 'analytics', 'ecommerce', 'industry']",best book predictive analytics ecommerce industry,1.0,1.0,11,49,4.083333333333333,0,0,0,0,0,0,0,0
3695,what are the various uses of proc format in sas,Tools,what are the various uses of proc format in sas,"['what', 'are', 'the', 'various', 'uses', 'of', 'proc', 'format', 'in', 'sas']",0,"['what', 'are', 'the', 'various', 'us', 'of', 'proc', 'format', 'in', 'sa']","['various', 'us', 'proc', 'format', 'sa']",various us proc format sa,0.0,0.0,10,25,2.272727272727273,0,0,0,0,0,0,0,0
3696,merging rows data such that the column which has different string values combines multiple cells into one separated by comma,Techniques,merging rows data such that the column which has different string values combines multiple cells into one separated by comma,"['merging', 'rows', 'data', 'such', 'that', 'the', 'column', 'which', 'has', 'different', 'string', 'values', 'combines', 'multiple', 'cells', 'into', 'one', 'separated', 'by', 'comma']",0,"['merging', 'row', 'data', 'such', 'that', 'the', 'column', 'which', 'ha', 'different', 'string', 'value', 'combine', 'multiple', 'cell', 'into', 'one', 'separated', 'by', 'comma']","['merging', 'row', 'data', 'column', 'ha', 'different', 'string', 'value', 'combine', 'multiple', 'cell', 'one', 'separated', 'comma']",merging row data column ha different string value combine multiple cell one separated comma,0.0,0.0,20,91,4.333333333333333,0,0,0,0,0,0,0,0
3697,data preprocessing for decision trees,Techniques,data preprocessing for decision trees,"['data', 'preprocessing', 'for', 'decision', 'trees']",0,"['data', 'preprocessing', 'for', 'decision', 'tree']","['data', 'preprocessing', 'decision', 'tree']",data preprocessing decision tree,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
3698,pandas custom function,Techniques,pandas custom function,"['pandas', 'custom', 'function']",0,"['panda', 'custom', 'function']","['panda', 'custom', 'function']",panda custom function,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
3699,beautiful charts in google sheets and microsoft excel  office ,Other,beautiful charts in google sheets and microsoft excel  office ,"['beautiful', 'charts', 'in', 'google', 'sheets', 'and', 'microsoft', 'excel', 'office']",1,"['beautiful', 'chart', 'in', 'google', 'sheet', 'and', 'microsoft', 'excel', 'office']","['beautiful', 'chart', 'google', 'sheet', 'microsoft', 'excel', 'office']",beautiful chart google sheet microsoft excel office,0.85,0.85,9,51,5.1,0,0,0,0,0,0,0,0
3700,need career advice,Career,need career advice,"['need', 'career', 'advice']",0,"['need', 'career', 'advice']","['need', 'career', 'advice']",need career advice,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
3701,doubt about the div in crosstab,Hackathons,doubt about the div in crosstab,"['doubt', 'about', 'the', 'div', 'in', 'crosstab']",0,"['doubt', 'about', 'the', 'div', 'in', 'crosstab']","['doubt', 'div', 'crosstab']",doubt div crosstab,0.0,0.0,6,18,2.5714285714285716,0,0,0,0,0,0,0,0
3702,how is the score calculated for any submission,Hackathons,how is the score calculated for any submission,"['how', 'is', 'the', 'score', 'calculated', 'for', 'any', 'submission']",0,"['how', 'is', 'the', 'score', 'calculated', 'for', 'any', 'submission']","['score', 'calculated', 'submission']",score calculated submission,0.0,0.0,8,27,3.0,0,0,0,0,0,0,0,0
3703,twitter sentiment analysis,Hackathons,twitter sentiment analysis,"['twitter', 'sentiment', 'analysis']",0,"['twitter', 'sentiment', 'analysis']","['twitter', 'sentiment', 'analysis']",twitter sentiment analysis,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
3704,clarity needed regarding scaling standardizing a normalization,Techniques,clarity needed regarding scaling standardizing a normalization,"['clarity', 'needed', 'regarding', 'scaling', 'standardizing', 'a', 'normalization']",0,"['clarity', 'needed', 'regarding', 'scaling', 'standardizing', 'a', 'normalization']","['clarity', 'needed', 'regarding', 'scaling', 'standardizing', 'normalization']",clarity needed regarding scaling standardizing normalization,0.0,0.0,7,60,7.5,0,0,0,0,0,0,0,0
3705,uploading solution file for a hackathon,Hackathons,uploading solution file for a hackathon,"['uploading', 'solution', 'file', 'for', 'a', 'hackathon']",0,"['uploading', 'solution', 'file', 'for', 'a', 'hackathon']","['uploading', 'solution', 'file', 'hackathon']",uploading solution file hackathon,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
3706,threshold for logistic regression,Techniques,threshold for logistic regression,"['threshold', 'for', 'logistic', 'regression']",0,"['threshold', 'for', 'logistic', 'regression']","['threshold', 'logistic', 'regression']",threshold logistic regression,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
3707,how to select optimal number of k in knn technique,Techniques,how to select optimal number of k in knn technique,"['how', 'to', 'select', 'optimal', 'number', 'of', 'k', 'in', 'knn', 'technique']",0,"['how', 'to', 'select', 'optimal', 'number', 'of', 'k', 'in', 'knn', 'technique']","['select', 'optimal', 'number', 'k', 'knn', 'technique']",select optimal number k knn technique,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
3708,error in operator in java ,Misc,error in operator in java ,"['error', 'in', 'operator', 'in', 'java']",1,"['error', 'in', 'operator', 'in', 'java']","['error', 'operator', 'java']",error operator java,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
3709,how to do feature selection for linear regression,Techniques,how to do feature selection for linear regression,"['how', 'to', 'do', 'feature', 'selection', 'for', 'linear', 'regression']",0,"['how', 'to', 'do', 'feature', 'selection', 'for', 'linear', 'regression']","['feature', 'selection', 'linear', 'regression']",feature selection linear regression,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
3710,why backward selection can not be used when np,Techniques,why backward selection can not be used when np,"['why', 'backward', 'selection', 'can', 'not', 'be', 'used', 'when', 'np']",0,"['why', 'backward', 'selection', 'can', 'not', 'be', 'used', 'when', 'np']","['backward', 'selection', 'used', 'np']",backward selection used np,0.0,0.0,9,26,2.6,0,0,0,0,0,0,0,0
3711,how to proceed with innoplexus competition,Hackathons,how to proceed with innoplexus competition,"['how', 'to', 'proceed', 'with', 'innoplexus', 'competition']",0,"['how', 'to', 'proceed', 'with', 'innoplexus', 'competition']","['proceed', 'innoplexus', 'competition']",proceed innoplexus competition,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
3712,chi square test,Tools,chi square test,"['chi', 'square', 'test']",0,"['chi', 'square', 'test']","['chi', 'square', 'test']",chi square test,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
3713,how to to use c decision tree for large data,Techniques,how to to use c decision tree for large data,"['how', 'to', 'to', 'use', 'c', 'decision', 'tree', 'for', 'large', 'data']",0,"['how', 'to', 'to', 'use', 'c', 'decision', 'tree', 'for', 'large', 'data']","['use', 'c', 'decision', 'tree', 'large', 'data']",use c decision tree large data,0.2142857142857142,0.2142857142857142,10,30,2.727272727272727,0,0,0,0,0,0,0,0
3714,multiclass multioutput machine learning or neural network problem in python,Techniques,multiclass multioutput machine learning or neural network problem in python,"['multiclass', 'multioutput', 'machine', 'learning', 'or', 'neural', 'network', 'problem', 'in', 'python']",0,"['multiclass', 'multioutput', 'machine', 'learning', 'or', 'neural', 'network', 'problem', 'in', 'python']","['multiclass', 'multioutput', 'machine', 'learning', 'neural', 'network', 'problem', 'python']",multiclass multioutput machine learning neural network problem python,0.0,0.0,10,69,6.2727272727272725,0,0,0,0,0,0,0,0
3715,are neural nets better than random forests given the increase in computation time,Techniques,are neural nets better than random forests given the increase in computation time,"['are', 'neural', 'nets', 'better', 'than', 'random', 'forests', 'given', 'the', 'increase', 'in', 'computation', 'time']",0,"['are', 'neural', 'net', 'better', 'than', 'random', 'forest', 'given', 'the', 'increase', 'in', 'computation', 'time']","['neural', 'net', 'better', 'random', 'forest', 'given', 'increase', 'computation', 'time']",neural net better random forest given increase computation time,0.0,0.0,13,63,4.5,0,0,0,0,0,0,0,0
3716,how to see the results of kknreg in r,Tools,how to see the results of kknreg in r,"['how', 'to', 'see', 'the', 'results', 'of', 'kknreg', 'in', 'r']",0,"['how', 'to', 'see', 'the', 'result', 'of', 'kknreg', 'in', 'r']","['see', 'result', 'kknreg', 'r']",see result kknreg r,0.0,0.0,9,19,1.9,0,0,0,0,0,0,0,0
3717,getting scores ,Techniques,getting scores ,"['getting', 'scores']",1,"['getting', 'score']","['getting', 'score']",getting score,0.0,0.0,2,13,4.333333333333333,0,0,0,0,0,0,0,0
3718,smooth inverse frequency,Techniques,smooth inverse frequency,"['smooth', 'inverse', 'frequency']",0,"['smooth', 'inverse', 'frequency']","['smooth', 'inverse', 'frequency']",smooth inverse frequency,0.4,0.4,3,24,6.0,0,0,0,0,0,0,0,0
3719,how do i draw a bar chart based on two groups in r,Tools,how do i draw a bar chart based on two groups in r,"['how', 'do', 'i', 'draw', 'a', 'bar', 'chart', 'based', 'on', 'two', 'groups', 'in', 'r']",0,"['how', 'do', 'i', 'draw', 'a', 'bar', 'chart', 'based', 'on', 'two', 'group', 'in', 'r']","['draw', 'bar', 'chart', 'based', 'two', 'group', 'r']",draw bar chart based two group r,0.0,0.0,13,32,2.2857142857142856,0,0,0,0,0,0,0,0
3720,what is difference between outlier and influential observation,Techniques,what is difference between outlier and influential observation,"['what', 'is', 'difference', 'between', 'outlier', 'and', 'influential', 'observation']",0,"['what', 'is', 'difference', 'between', 'outlier', 'and', 'influential', 'observation']","['difference', 'outlier', 'influential', 'observation']",difference outlier influential observation,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
3721,is it possible to work on both the software hadoop maprspark and the hardware fpga gpu multicore aspects of big data,Career,is it possible to work on both the software hadoop maprspark and the hardware fpga gpu multicore aspects of big data,"['is', 'it', 'possible', 'to', 'work', 'on', 'both', 'the', 'software', 'hadoop', 'maprspark', 'and', 'the', 'hardware', 'fpga', 'gpu', 'multicore', 'aspects', 'of', 'big', 'data']",0,"['is', 'it', 'possible', 'to', 'work', 'on', 'both', 'the', 'software', 'hadoop', 'maprspark', 'and', 'the', 'hardware', 'fpga', 'gpu', 'multicore', 'aspect', 'of', 'big', 'data']","['possible', 'work', 'software', 'hadoop', 'maprspark', 'hardware', 'fpga', 'gpu', 'multicore', 'aspect', 'big', 'data']",possible work software hadoop maprspark hardware fpga gpu multicore aspect big data,0.0,0.0,21,83,3.772727272727273,0,0,0,0,0,0,0,0
3722,how to retain objectsmodels of ho type in r if the ho cluster shuts down abruptly due to system issues,Techniques,how to retain objectsmodels of ho type in r if the ho cluster shuts down abruptly due to system issues,"['how', 'to', 'retain', 'objectsmodels', 'of', 'ho', 'type', 'in', 'r', 'if', 'the', 'ho', 'cluster', 'shuts', 'down', 'abruptly', 'due', 'to', 'system', 'issues']",0,"['how', 'to', 'retain', 'objectsmodels', 'of', 'ho', 'type', 'in', 'r', 'if', 'the', 'ho', 'cluster', 'shuts', 'down', 'abruptly', 'due', 'to', 'system', 'issue']","['retain', 'objectsmodels', 'ho', 'type', 'r', 'ho', 'cluster', 'shuts', 'abruptly', 'due', 'system', 'issue']",retain objectsmodels ho type r ho cluster shuts abruptly due system issue,-0.1402777777777777,-0.125,20,73,3.4761904761904763,0,0,0,0,0,0,0,0
3723,plots are not appearing in the spyder console,Tools,plots are not appearing in the spyder console,"['plots', 'are', 'not', 'appearing', 'in', 'the', 'spyder', 'console']",0,"['plot', 'are', 'not', 'appearing', 'in', 'the', 'spyder', 'console']","['plot', 'appearing', 'spyder', 'console']",plot appearing spyder console,0.0,0.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
3724,types of naive bayes classifier,Techniques,types of naive bayes classifier,"['types', 'of', 'naive', 'bayes', 'classifier']",0,"['type', 'of', 'naive', 'bayes', 'classifier']","['type', 'naive', 'bayes', 'classifier']",type naive bayes classifier,-0.3,-0.3,5,27,4.5,0,0,0,0,0,0,0,0
3725,what does autolag in adfuller methoddicky fuller test represent,Techniques,what does autolag in adfuller methoddicky fuller test represent,"['what', 'does', 'autolag', 'in', 'adfuller', 'methoddicky', 'fuller', 'test', 'represent']",0,"['what', 'doe', 'autolag', 'in', 'adfuller', 'methoddicky', 'fuller', 'test', 'represent']","['doe', 'autolag', 'adfuller', 'methoddicky', 'fuller', 'test', 'represent']",doe autolag adfuller methoddicky fuller test represent,0.0,0.0,9,54,5.4,0,0,0,0,0,0,0,0
3726,how to see the optimal cutoff in specificity vs sensitivity in gbm in r,Tools,how to see the optimal cutoff in specificity vs sensitivity in gbm in r,"['how', 'to', 'see', 'the', 'optimal', 'cutoff', 'in', 'specificity', 'vs', 'sensitivity', 'in', 'gbm', 'in', 'r']",0,"['how', 'to', 'see', 'the', 'optimal', 'cutoff', 'in', 'specificity', 'v', 'sensitivity', 'in', 'gbm', 'in', 'r']","['see', 'optimal', 'cutoff', 'specificity', 'v', 'sensitivity', 'gbm', 'r']",see optimal cutoff specificity v sensitivity gbm r,0.0,0.0,14,50,3.3333333333333335,0,0,0,0,0,0,0,0
3727,model selection in machine learning problem,Techniques,model selection in machine learning problem,"['model', 'selection', 'in', 'machine', 'learning', 'problem']",0,"['model', 'selection', 'in', 'machine', 'learning', 'problem']","['model', 'selection', 'machine', 'learning', 'problem']",model selection machine learning problem,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
3728,an excellent initiative by udacity,Resources,an excellent initiative by udacity,"['an', 'excellent', 'initiative', 'by', 'udacity']",0,"['an', 'excellent', 'initiative', 'by', 'udacity']","['excellent', 'initiative', 'udacity']",excellent initiative udacity,1.0,1.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
3729,a practical guide to object detection using the popular yolo framework,Techniques,a practical guide to object detection using the popular yolo framework,"['a', 'practical', 'guide', 'to', 'object', 'detection', 'using', 'the', 'popular', 'yolo', 'framework']",0,"['a', 'practical', 'guide', 'to', 'object', 'detection', 'using', 'the', 'popular', 'yolo', 'framework']","['practical', 'guide', 'object', 'detection', 'using', 'popular', 'yolo', 'framework']",practical guide object detection using popular yolo framework,0.6,0.6,11,61,5.083333333333333,0,0,0,0,0,0,0,0
3730,looking for parttime or full time projects of analytics,Career,looking for parttime or full time projects of analytics,"['looking', 'for', 'parttime', 'or', 'full', 'time', 'projects', 'of', 'analytics']",0,"['looking', 'for', 'parttime', 'or', 'full', 'time', 'project', 'of', 'analytics']","['looking', 'parttime', 'full', 'time', 'project', 'analytics']",looking parttime full time project analytics,0.35,0.35,9,44,4.4,0,0,0,0,0,0,0,0
3731,how family attribute affect the logistic model in r,Tools,how family attribute affect the logistic model in r,"['how', 'family', 'attribute', 'affect', 'the', 'logistic', 'model', 'in', 'r']",0,"['how', 'family', 'attribute', 'affect', 'the', 'logistic', 'model', 'in', 'r']","['family', 'attribute', 'affect', 'logistic', 'model', 'r']",family attribute affect logistic model r,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
3732,resources for sqlsql programming,Tools,resources for sqlsql programming,"['resources', 'for', 'sqlsql', 'programming']",0,"['resource', 'for', 'sqlsql', 'programming']","['resource', 'sqlsql', 'programming']",resource sqlsql programming,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
3733,comparative stock market analysis,Techniques,comparative stock market analysis,"['comparative', 'stock', 'market', 'analysis']",0,"['comparative', 'stock', 'market', 'analysis']","['comparative', 'stock', 'market', 'analysis']",comparative stock market analysis,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
3734,tutorial for spss modeler,Tools,tutorial for spss modeler,"['tutorial', 'for', 'spss', 'modeler']",0,"['tutorial', 'for', 'spss', 'modeler']","['tutorial', 'spss', 'modeler']",tutorial spss modeler,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
3735,how to fill the element of matrix row wise in r,Tools,how to fill the element of matrix row wise in r,"['how', 'to', 'fill', 'the', 'element', 'of', 'matrix', 'row', 'wise', 'in', 'r']",0,"['how', 'to', 'fill', 'the', 'element', 'of', 'matrix', 'row', 'wise', 'in', 'r']","['fill', 'element', 'matrix', 'row', 'wise', 'r']",fill element matrix row wise r,0.7,0.7,11,30,2.5,0,0,0,0,0,0,0,0
3736,why do we want to remove the outliers of a feature,Techniques,why do we want to remove the outliers of a feature,"['why', 'do', 'we', 'want', 'to', 'remove', 'the', 'outliers', 'of', 'a', 'feature']",0,"['why', 'do', 'we', 'want', 'to', 'remove', 'the', 'outlier', 'of', 'a', 'feature']","['want', 'remove', 'outlier', 'feature']",want remove outlier feature,0.0,0.0,11,27,2.25,0,0,0,0,0,0,0,0
3737,how to restrict users to change value of a dimension in qlikview dashboard,Tools,how to restrict users to change value of a dimension in qlikview dashboard,"['how', 'to', 'restrict', 'users', 'to', 'change', 'value', 'of', 'a', 'dimension', 'in', 'qlikview', 'dashboard']",0,"['how', 'to', 'restrict', 'user', 'to', 'change', 'value', 'of', 'a', 'dimension', 'in', 'qlikview', 'dashboard']","['restrict', 'user', 'change', 'value', 'dimension', 'qlikview', 'dashboard']",restrict user change value dimension qlikview dashboard,0.0,0.0,13,55,3.9285714285714284,0,0,0,0,0,0,0,0
3738,modelling rare event,Techniques,modelling rare event,"['modelling', 'rare', 'event']",0,"['modelling', 'rare', 'event']","['modelling', 'rare', 'event']",modelling rare event,0.3,0.3,3,20,5.0,0,0,0,0,0,0,0,0
3739,is data science program by manipal global worth it,Career,is data science program by manipal global worth it,"['is', 'data', 'science', 'program', 'by', 'manipal', 'global', 'worth', 'it']",0,"['is', 'data', 'science', 'program', 'by', 'manipal', 'global', 'worth', 'it']","['data', 'science', 'program', 'manipal', 'global', 'worth']",data science program manipal global worth,0.15,0.15,9,41,4.1,0,0,0,0,0,0,0,0
3740,outlier treatment,Techniques,outlier treatment,"['outlier', 'treatment']",0,"['outlier', 'treatment']","['outlier', 'treatment']",outlier treatment,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
3741,curse of dimentionality,Techniques,curse of dimentionality,"['curse', 'of', 'dimentionality']",0,"['curse', 'of', 'dimentionality']","['curse', 'dimentionality']",curse dimentionality,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
3742,how do i specify the number of nodes in voronoimosaic in r,Tools,how do i specify the number of nodes in voronoimosaic in r,"['how', 'do', 'i', 'specify', 'the', 'number', 'of', 'nodes', 'in', 'voronoimosaic', 'in', 'r']",0,"['how', 'do', 'i', 'specify', 'the', 'number', 'of', 'node', 'in', 'voronoimosaic', 'in', 'r']","['specify', 'number', 'node', 'voronoimosaic', 'r']",specify number node voronoimosaic r,0.0,0.0,12,35,2.6923076923076925,0,0,0,0,0,0,0,0
3743,which one is better method for dimensinality reduction pca forward elimination or backward elimination,Techniques,which one is better method for dimensinality reduction pca forward elimination or backward elimination,"['which', 'one', 'is', 'better', 'method', 'for', 'dimensinality', 'reduction', 'pca', 'forward', 'elimination', 'or', 'backward', 'elimination']",0,"['which', 'one', 'is', 'better', 'method', 'for', 'dimensinality', 'reduction', 'pca', 'forward', 'elimination', 'or', 'backward', 'elimination']","['one', 'better', 'method', 'dimensinality', 'reduction', 'pca', 'forward', 'elimination', 'backward', 'elimination']",one better method dimensinality reduction pca forward elimination backward elimination,0.5,0.5,14,86,5.733333333333333,0,0,0,0,0,0,0,0
3744,what happen when svm has to predict more than two class,Techniques,what happen when svm has to predict more than two class,"['what', 'happen', 'when', 'svm', 'has', 'to', 'predict', 'more', 'than', 'two', 'class']",0,"['what', 'happen', 'when', 'svm', 'ha', 'to', 'predict', 'more', 'than', 'two', 'class']","['happen', 'svm', 'ha', 'predict', 'two', 'class']",happen svm ha predict two class,0.5,0.0,11,31,2.5833333333333335,0,0,0,0,0,0,0,0
3745,stopword removal using nltk in python,Techniques,stopword removal using nltk in python,"['stopword', 'removal', 'using', 'nltk', 'in', 'python']",0,"['stopword', 'removal', 'using', 'nltk', 'in', 'python']","['stopword', 'removal', 'using', 'nltk', 'python']",stopword removal using nltk python,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
3746,regression analysis,Techniques,regression analysis,"['regression', 'analysis']",0,"['regression', 'analysis']","['regression', 'analysis']",regression analysis,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
3747,adding summary stat such as mean median mode on ggplot,Techniques,adding summary stat such as mean median mode on ggplot,"['adding', 'summary', 'stat', 'such', 'as', 'mean', 'median', 'mode', 'on', 'ggplot']",0,"['adding', 'summary', 'stat', 'such', 'a', 'mean', 'median', 'mode', 'on', 'ggplot']","['adding', 'summary', 'stat', 'mean', 'median', 'mode', 'ggplot']",adding summary stat mean median mode ggplot,-0.15625,-0.3125,10,43,3.909090909090909,0,0,0,0,0,0,0,0
3748,seeking help from experts in fraud predictive models,Misc,seeking help from experts in fraud predictive models,"['seeking', 'help', 'from', 'experts', 'in', 'fraud', 'predictive', 'models']",0,"['seeking', 'help', 'from', 'expert', 'in', 'fraud', 'predictive', 'model']","['seeking', 'help', 'expert', 'fraud', 'predictive', 'model']",seeking help expert fraud predictive model,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
3749,how to speed up the video in the course videos,Misc,how to speed up the video in the course videos,"['how', 'to', 'speed', 'up', 'the', 'video', 'in', 'the', 'course', 'videos']",0,"['how', 'to', 'speed', 'up', 'the', 'video', 'in', 'the', 'course', 'video']","['speed', 'video', 'course', 'video']",speed video course video,0.0,0.0,10,24,2.1818181818181817,0,0,0,0,0,0,0,0
3750,rstan package installation issue,Tools,rstan package installation issue,"['rstan', 'package', 'installation', 'issue']",0,"['rstan', 'package', 'installation', 'issue']","['rstan', 'package', 'installation', 'issue']",rstan package installation issue,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
3751,which python ide preferred by data scientists,Resources,which python ide preferred by data scientists,"['which', 'python', 'ide', 'preferred', 'by', 'data', 'scientists']",0,"['which', 'python', 'ide', 'preferred', 'by', 'data', 'scientist']","['python', 'ide', 'preferred', 'data', 'scientist']",python ide preferred data scientist,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
3752,evaluation matrix for text summerization done using lsa,Techniques,evaluation matrix for text summerization done using lsa,"['evaluation', 'matrix', 'for', 'text', 'summerization', 'done', 'using', 'lsa']",0,"['evaluation', 'matrix', 'for', 'text', 'summerization', 'done', 'using', 'lsa']","['evaluation', 'matrix', 'text', 'summerization', 'done', 'using', 'lsa']",evaluation matrix text summerization done using lsa,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
3753,what are some good resources to learn about ensemble learning,Techniques,what are some good resources to learn about ensemble learning,"['what', 'are', 'some', 'good', 'resources', 'to', 'learn', 'about', 'ensemble', 'learning']",0,"['what', 'are', 'some', 'good', 'resource', 'to', 'learn', 'about', 'ensemble', 'learning']","['good', 'resource', 'learn', 'ensemble', 'learning']",good resource learn ensemble learning,0.7,0.7,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
3754,requesting information  planning to do masters in business analytics from usa,Career,requesting information  planning to do masters in business analytics from usa,"['requesting', 'information', 'planning', 'to', 'do', 'masters', 'in', 'business', 'analytics', 'from', 'usa']",0,"['requesting', 'information', 'planning', 'to', 'do', 'master', 'in', 'business', 'analytics', 'from', 'usa']","['requesting', 'information', 'planning', 'master', 'business', 'analytics', 'usa']",requesting information planning master business analytics usa,0.0,0.0,11,61,5.083333333333333,0,0,0,0,0,0,0,0
3755,what are the things to learn,Career,what are the things to learn,"['what', 'are', 'the', 'things', 'to', 'learn']",0,"['what', 'are', 'the', 'thing', 'to', 'learn']","['thing', 'learn']",thing learn,0.0,0.0,6,11,1.5714285714285714,0,0,0,0,0,0,0,0
3756,please suggest a pathway to learn data analysis,Career,please suggest a pathway to learn data analysis,"['please', 'suggest', 'a', 'pathway', 'to', 'learn', 'data', 'analysis']",0,"['please', 'suggest', 'a', 'pathway', 'to', 'learn', 'data', 'analysis']","['please', 'suggest', 'pathway', 'learn', 'data', 'analysis']",please suggest pathway learn data analysis,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
3757,data fest   biggest data fest ever,Hackathons,data fest   biggest data fest ever,"['data', 'fest', 'biggest', 'data', 'fest', 'ever']",1,"['data', 'fest', 'biggest', 'data', 'fest', 'ever']","['data', 'fest', 'biggest', 'data', 'fest', 'ever']",data fest biggest data fest ever,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
3758,r packages for data manipulation,Tools,r packages for data manipulation,"['r', 'packages', 'for', 'data', 'manipulation']",0,"['r', 'package', 'for', 'data', 'manipulation']","['r', 'package', 'data', 'manipulation']",r package data manipulation,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
3759,data cleansing in pyspark,Techniques,data cleansing in pyspark,"['data', 'cleansing', 'in', 'pyspark']",0,"['data', 'cleansing', 'in', 'pyspark']","['data', 'cleansing', 'pyspark']",data cleansing pyspark,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
3760,how to build a career in algorithmic trading,Career,how to build a career in algorithmic trading,"['how', 'to', 'build', 'a', 'career', 'in', 'algorithmic', 'trading']",0,"['how', 'to', 'build', 'a', 'career', 'in', 'algorithmic', 'trading']","['build', 'career', 'algorithmic', 'trading']",build career algorithmic trading,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
3761,exploratory data analysis,Techniques,exploratory data analysis,"['exploratory', 'data', 'analysis']",0,"['exploratory', 'data', 'analysis']","['exploratory', 'data', 'analysis']",exploratory data analysis,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
3762,unable to check variable class in a data frame in r,Tools,unable to check variable class in a data frame in r,"['unable', 'to', 'check', 'variable', 'class', 'in', 'a', 'data', 'frame', 'in', 'r']",0,"['unable', 'to', 'check', 'variable', 'class', 'in', 'a', 'data', 'frame', 'in', 'r']","['unable', 'check', 'variable', 'class', 'data', 'frame', 'r']",unable check variable class data frame r,-0.5,-0.5,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
3763,kaggle score of  in titanic,Techniques,kaggle score of  in titanic,"['kaggle', 'score', 'of', 'in', 'titanic']",1,"['kaggle', 'score', 'of', 'in', 'titanic']","['kaggle', 'score', 'titanic']",kaggle score titanic,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
3764,r mlr methods for defining parameters,Tools,r mlr methods for defining parameters,"['r', 'mlr', 'methods', 'for', 'defining', 'parameters']",0,"['r', 'mlr', 'method', 'for', 'defining', 'parameter']","['r', 'mlr', 'method', 'defining', 'parameter']",r mlr method defining parameter,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
3765,how to create a wordcloud from a tdm in python,Techniques,how to create a wordcloud from a tdm in python,"['how', 'to', 'create', 'a', 'wordcloud', 'from', 'a', 'tdm', 'in', 'python']",0,"['how', 'to', 'create', 'a', 'wordcloud', 'from', 'a', 'tdm', 'in', 'python']","['create', 'wordcloud', 'tdm', 'python']",create wordcloud tdm python,0.0,0.0,10,27,2.4545454545454546,0,0,0,0,0,0,0,0
3766,how to plot the scree plot with line in r,Techniques,how to plot the scree plot with line in r,"['how', 'to', 'plot', 'the', 'scree', 'plot', 'with', 'line', 'in', 'r']",0,"['how', 'to', 'plot', 'the', 'scree', 'plot', 'with', 'line', 'in', 'r']","['plot', 'scree', 'plot', 'line', 'r']",plot scree plot line r,0.0,0.0,10,22,2.0,0,0,0,0,0,0,0,0
3767,what are the packages required to plot a fancy rpart plot in r,Tools,what are the packages required to plot a fancy rpart plot in r,"['what', 'are', 'the', 'packages', 'required', 'to', 'plot', 'a', 'fancy', 'rpart', 'plot', 'in', 'r']",0,"['what', 'are', 'the', 'package', 'required', 'to', 'plot', 'a', 'fancy', 'rpart', 'plot', 'in', 'r']","['package', 'required', 'plot', 'fancy', 'rpart', 'plot', 'r']",package required plot fancy rpart plot r,0.0,0.0,13,40,2.857142857142857,0,0,0,0,0,0,0,0
3768,how correctly encode categorical features avoiding data leakage,Techniques,how correctly encode categorical features avoiding data leakage,"['how', 'correctly', 'encode', 'categorical', 'features', 'avoiding', 'data', 'leakage']",0,"['how', 'correctly', 'encode', 'categorical', 'feature', 'avoiding', 'data', 'leakage']","['correctly', 'encode', 'categorical', 'feature', 'avoiding', 'data', 'leakage']",correctly encode categorical feature avoiding data leakage,0.0,0.0,8,58,6.444444444444445,0,0,0,0,0,0,0,0
3769,what is a good order to impute dataset having na in multiple feature without using package,Techniques,what is a good order to impute dataset having na in multiple feature without using package,"['what', 'is', 'a', 'good', 'order', 'to', 'impute', 'dataset', 'having', 'na', 'in', 'multiple', 'feature', 'without', 'using', 'package']",0,"['what', 'is', 'a', 'good', 'order', 'to', 'impute', 'dataset', 'having', 'na', 'in', 'multiple', 'feature', 'without', 'using', 'package']","['good', 'order', 'impute', 'dataset', 'na', 'multiple', 'feature', 'without', 'using', 'package']",good order impute dataset na multiple feature without using package,0.35,0.35,16,67,3.9411764705882355,0,0,0,0,0,0,0,0
3770,cross correlation and t test,Techniques,cross correlation and t test,"['cross', 'correlation', 'and', 't', 'test']",0,"['cross', 'correlation', 'and', 't', 'test']","['cross', 'correlation', 'test']",cross correlation test,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
3771,code to remove email addresses from corpus in r,Tools,code to remove email addresses from corpus in r,"['code', 'to', 'remove', 'email', 'addresses', 'from', 'corpus', 'in', 'r']",0,"['code', 'to', 'remove', 'email', 'address', 'from', 'corpus', 'in', 'r']","['code', 'remove', 'email', 'address', 'corpus', 'r']",code remove email address corpus r,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
3772,typeresponse in glm function in r,Techniques,typeresponse in glm function in r,"['typeresponse', 'in', 'glm', 'function', 'in', 'r']",0,"['typeresponse', 'in', 'glm', 'function', 'in', 'r']","['typeresponse', 'glm', 'function', 'r']",typeresponse glm function r,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
3773,what is bayesdb how can i use it in python,Other,what is bayesdb how can i use it in python,"['what', 'is', 'bayesdb', 'how', 'can', 'i', 'use', 'it', 'in', 'python']",0,"['what', 'is', 'bayesdb', 'how', 'can', 'i', 'use', 'it', 'in', 'python']","['bayesdb', 'use', 'python']",bayesdb use python,0.0,0.0,10,18,1.6363636363636365,0,0,0,0,0,0,0,0
3774,what is meant by double series in visualization,Techniques,what is meant by double series in visualization,"['what', 'is', 'meant', 'by', 'double', 'series', 'in', 'visualization']",0,"['what', 'is', 'meant', 'by', 'double', 'series', 'in', 'visualization']","['meant', 'double', 'series', 'visualization']",meant double series visualization,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
3775,text mining hack doubt,Techniques,text mining hack doubt,"['text', 'mining', 'hack', 'doubt']",0,"['text', 'mining', 'hack', 'doubt']","['text', 'mining', 'hack', 'doubt']",text mining hack doubt,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
3776,how to determine the optimal number of clusters in r,Tools,how to determine the optimal number of clusters in r,"['how', 'to', 'determine', 'the', 'optimal', 'number', 'of', 'clusters', 'in', 'r']",0,"['how', 'to', 'determine', 'the', 'optimal', 'number', 'of', 'cluster', 'in', 'r']","['determine', 'optimal', 'number', 'cluster', 'r']",determine optimal number cluster r,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
3777,getting mean of a numeric variable according to the categorical variable in r,Techniques,getting mean of a numeric variable according to the categorical variable in r,"['getting', 'mean', 'of', 'a', 'numeric', 'variable', 'according', 'to', 'the', 'categorical', 'variable', 'in', 'r']",0,"['getting', 'mean', 'of', 'a', 'numeric', 'variable', 'according', 'to', 'the', 'categorical', 'variable', 'in', 'r']","['getting', 'mean', 'numeric', 'variable', 'according', 'categorical', 'variable', 'r']",getting mean numeric variable according categorical variable r,-0.3125,-0.3125,13,62,4.428571428571429,0,0,0,0,0,0,0,0
3778,guidance to prepare and learn sql sas python r,Career,guidance to prepare and learn sql sas python r,"['guidance', 'to', 'prepare', 'and', 'learn', 'sql', 'sas', 'python', 'r']",0,"['guidance', 'to', 'prepare', 'and', 'learn', 'sql', 'sa', 'python', 'r']","['guidance', 'prepare', 'learn', 'sql', 'sa', 'python', 'r']",guidance prepare learn sql sa python r,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
3779,xgboost script for classifying text,Techniques,xgboost script for classifying text,"['xgboost', 'script', 'for', 'classifying', 'text']",0,"['xgboost', 'script', 'for', 'classifying', 'text']","['xgboost', 'script', 'classifying', 'text']",xgboost script classifying text,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
3780,jupyter notebooks on azureml platform,Tools,jupyter notebooks on azureml platform,"['jupyter', 'notebooks', 'on', 'azureml', 'platform']",0,"['jupyter', 'notebook', 'on', 'azureml', 'platform']","['jupyter', 'notebook', 'azureml', 'platform']",jupyter notebook azureml platform,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
3781,can i download test result for datahack,Hackathons,can i download test result for datahack,"['can', 'i', 'download', 'test', 'result', 'for', 'datahack']",0,"['can', 'i', 'download', 'test', 'result', 'for', 'datahack']","['download', 'test', 'result', 'datahack']",download test result datahack,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
3782,what are the various sas programming challenges websites,Tools,what are the various sas programming challenges websites,"['what', 'are', 'the', 'various', 'sas', 'programming', 'challenges', 'websites']",0,"['what', 'are', 'the', 'various', 'sa', 'programming', 'challenge', 'website']","['various', 'sa', 'programming', 'challenge', 'website']",various sa programming challenge website,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
3783,income group not present in testcsv,Other,income group not present in testcsv,"['income', 'group', 'not', 'present', 'in', 'testcsv']",0,"['income', 'group', 'not', 'present', 'in', 'testcsv']","['income', 'group', 'present', 'testcsv']",income group present testcsv,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
3784,ab testing vs test control analysis,Techniques,ab testing vs test control analysis,"['ab', 'testing', 'vs', 'test', 'control', 'analysis']",0,"['ab', 'testing', 'v', 'test', 'control', 'analysis']","['ab', 'testing', 'v', 'test', 'control', 'analysis']",ab testing v test control analysis,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
3785,ransac in outlier treatment,Techniques,ransac in outlier treatment,"['ransac', 'in', 'outlier', 'treatment']",0,"['ransac', 'in', 'outlier', 'treatment']","['ransac', 'outlier', 'treatment']",ransac outlier treatment,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
3786,determining the weights assigned to each model in gradient boosting,Techniques,determining the weights assigned to each model in gradient boosting,"['determining', 'the', 'weights', 'assigned', 'to', 'each', 'model', 'in', 'gradient', 'boosting']",0,"['determining', 'the', 'weight', 'assigned', 'to', 'each', 'model', 'in', 'gradient', 'boosting']","['determining', 'weight', 'assigned', 'model', 'gradient', 'boosting']",determining weight assigned model gradient boosting,0.0,0.0,10,51,4.636363636363637,0,0,0,0,0,0,0,0
3787,how to predict multiple target using linear regression,Techniques,how to predict multiple target using linear regression,"['how', 'to', 'predict', 'multiple', 'target', 'using', 'linear', 'regression']",0,"['how', 'to', 'predict', 'multiple', 'target', 'using', 'linear', 'regression']","['predict', 'multiple', 'target', 'using', 'linear', 'regression']",predict multiple target using linear regression,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
3788,which ml techniques to use for demand forecasting in a retail company,Techniques,which ml techniques to use for demand forecasting in a retail company,"['which', 'ml', 'techniques', 'to', 'use', 'for', 'demand', 'forecasting', 'in', 'a', 'retail', 'company']",0,"['which', 'ml', 'technique', 'to', 'use', 'for', 'demand', 'forecasting', 'in', 'a', 'retail', 'company']","['ml', 'technique', 'use', 'demand', 'forecasting', 'retail', 'company']",ml technique use demand forecasting retail company,0.0,0.0,12,50,3.8461538461538463,0,0,0,0,0,0,0,0
3789,eliminating homoscedasticity from the data set before linear regression,Techniques,eliminating homoscedasticity from the data set before linear regression,"['eliminating', 'homoscedasticity', 'from', 'the', 'data', 'set', 'before', 'linear', 'regression']",0,"['eliminating', 'homoscedasticity', 'from', 'the', 'data', 'set', 'before', 'linear', 'regression']","['eliminating', 'homoscedasticity', 'data', 'set', 'linear', 'regression']",eliminating homoscedasticity data set linear regression,0.0,0.0,9,55,5.5,0,0,0,0,0,0,0,0
3790,why is relu a good activation function,Techniques,why is relu a good activation function,"['why', 'is', 'relu', 'a', 'good', 'activation', 'function']",0,"['why', 'is', 'relu', 'a', 'good', 'activation', 'function']","['relu', 'good', 'activation', 'function']",relu good activation function,0.7,0.7,7,29,3.625,0,0,0,0,0,0,0,0
3791,dealing with categorical variables  looking for recommendations,Techniques,dealing with categorical variables  looking for recommendations,"['dealing', 'with', 'categorical', 'variables', 'looking', 'for', 'recommendations']",0,"['dealing', 'with', 'categorical', 'variable', 'looking', 'for', 'recommendation']","['dealing', 'categorical', 'variable', 'looking', 'recommendation']",dealing categorical variable looking recommendation,0.0,0.0,7,51,6.375,0,0,0,0,0,0,0,0
3792,how to increase accuracy of classification problem in r,Tools,how to increase accuracy of classification problem in r,"['how', 'to', 'increase', 'accuracy', 'of', 'classification', 'problem', 'in', 'r']",0,"['how', 'to', 'increase', 'accuracy', 'of', 'classification', 'problem', 'in', 'r']","['increase', 'accuracy', 'classification', 'problem', 'r']",increase accuracy classification problem r,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
3793,loanprediction   i dont understand the no of dependent variable,Hackathons,loanprediction   i dont understand the no of dependent variable,"['loanprediction', 'i', 'dont', 'understand', 'the', 'no', 'of', 'dependent', 'variable']",1,"['loanprediction', 'i', 'dont', 'understand', 'the', 'no', 'of', 'dependent', 'variable']","['loanprediction', 'dont', 'understand', 'dependent', 'variable']",loanprediction dont understand dependent variable,0.0,0.0,9,49,4.9,0,0,0,0,0,0,0,0
3794,python code to pyspark,Techniques,python code to pyspark,"['python', 'code', 'to', 'pyspark']",0,"['python', 'code', 'to', 'pyspark']","['python', 'code', 'pyspark']",python code pyspark,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
3795,image processing,Techniques,image processing,"['image', 'processing']",0,"['image', 'processing']","['image', 'processing']",image processing,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
3796,point of sales data required for an analytics project,Career,point of sales data required for an analytics project,"['point', 'of', 'sales', 'data', 'required', 'for', 'an', 'analytics', 'project']",0,"['point', 'of', 'sale', 'data', 'required', 'for', 'an', 'analytics', 'project']","['point', 'sale', 'data', 'required', 'analytics', 'project']",point sale data required analytics project,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
3797,how big can you go release of tb driving data by oxford robotics research group,Resources,how big can you go release of tb driving data by oxford robotics research group,"['how', 'big', 'can', 'you', 'go', 'release', 'of', 'tb', 'driving', 'data', 'by', 'oxford', 'robotics', 'research', 'group']",0,"['how', 'big', 'can', 'you', 'go', 'release', 'of', 'tb', 'driving', 'data', 'by', 'oxford', 'robotics', 'research', 'group']","['big', 'go', 'release', 'tb', 'driving', 'data', 'oxford', 'robotics', 'research', 'group']",big go release tb driving data oxford robotics research group,0.0,0.0,15,61,3.8125,0,0,0,0,0,0,0,0
3798,help random forest parameters,Techniques,help random forest parameters,"['help', 'random', 'forest', 'parameters']",0,"['help', 'random', 'forest', 'parameter']","['help', 'random', 'forest', 'parameter']",help random forest parameter,-0.5,-0.5,4,28,5.6,0,0,0,0,0,0,0,0
3799,faster rcnn algorithm for object detection part  labelling wrong,Techniques,faster rcnn algorithm for object detection part  labelling wrong,"['faster', 'rcnn', 'algorithm', 'for', 'object', 'detection', 'part', 'labelling', 'wrong']",1,"['faster', 'rcnn', 'algorithm', 'for', 'object', 'detection', 'part', 'labelling', 'wrong']","['faster', 'rcnn', 'algorithm', 'object', 'detection', 'part', 'labelling', 'wrong']",faster rcnn algorithm object detection part labelling wrong,-0.5,-0.5,9,59,5.9,0,0,0,0,0,0,0,0
3800,does multicollinearity effects in naïve bayes,Techniques,does multicollinearity effects in naïve bayes,"['does', 'multicollinearity', 'effects', 'in', 'naïve', 'bayes']",0,"['doe', 'multicollinearity', 'effect', 'in', 'naïve', 'bayes']","['doe', 'multicollinearity', 'effect', 'naïve', 'bayes']",doe multicollinearity effect naïve bayes,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
3801,welcome to practice problem  recommendation engine,Hackathons,welcome to practice problem  recommendation engine,"['welcome', 'to', 'practice', 'problem', 'recommendation', 'engine']",0,"['welcome', 'to', 'practice', 'problem', 'recommendation', 'engine']","['welcome', 'practice', 'problem', 'recommendation', 'engine']",welcome practice problem recommendation engine,0.8,0.8,6,46,6.571428571428571,0,0,0,0,0,0,0,0
3802,unable to update conda packages behind corporate firewall updated condarc file proxy settings still it is asking for proxy user name and password,Tools,unable to update conda packages behind corporate firewall updated condarc file proxy settings still it is asking for proxy user name and password,"['unable', 'to', 'update', 'conda', 'packages', 'behind', 'corporate', 'firewall', 'updated', 'condarc', 'file', 'proxy', 'settings', 'still', 'it', 'is', 'asking', 'for', 'proxy', 'user', 'name', 'and', 'password']",0,"['unable', 'to', 'update', 'conda', 'package', 'behind', 'corporate', 'firewall', 'updated', 'condarc', 'file', 'proxy', 'setting', 'still', 'it', 'is', 'asking', 'for', 'proxy', 'user', 'name', 'and', 'password']","['unable', 'update', 'conda', 'package', 'behind', 'corporate', 'firewall', 'updated', 'condarc', 'file', 'proxy', 'setting', 'still', 'asking', 'proxy', 'user', 'name', 'password']",unable update conda package behind corporate firewall updated condarc file proxy setting still asking proxy user name password,-0.3,-0.3,23,126,5.25,0,0,0,0,0,0,0,0
3803,how to find  of cases based on group by on multiple columns,Tools,how to find  of cases based on group by on multiple columns,"['how', 'to', 'find', 'of', 'cases', 'based', 'on', 'group', 'by', 'on', 'multiple', 'columns']",0,"['how', 'to', 'find', 'of', 'case', 'based', 'on', 'group', 'by', 'on', 'multiple', 'column']","['find', 'case', 'based', 'group', 'multiple', 'column']",find case based group multiple column,0.0,0.0,12,37,2.8461538461538463,0,0,0,0,0,0,0,0
3804,bridge school of management,Career,bridge school of management,"['bridge', 'school', 'of', 'management']",0,"['bridge', 'school', 'of', 'management']","['bridge', 'school', 'management']",bridge school management,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
3805,d coordinated visualization,Techniques,d coordinated visualization,"['d', 'coordinated', 'visualization']",0,"['d', 'coordinated', 'visualization']","['coordinated', 'visualization']",coordinated visualization,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
3806,how to improve score,Hackathons,how to improve score,"['how', 'to', 'improve', 'score']",0,"['how', 'to', 'improve', 'score']","['improve', 'score']",improve score,0.0,0.0,4,13,2.6,0,0,0,0,0,0,0,0
3807,dealing with negative values,Techniques,dealing with negative values,"['dealing', 'with', 'negative', 'values']",0,"['dealing', 'with', 'negative', 'value']","['dealing', 'negative', 'value']",dealing negative value,-0.3,-0.3,4,22,4.4,0,0,0,0,0,0,0,0
3808,how to forecast loan prepayment,Other,how to forecast loan prepayment,"['how', 'to', 'forecast', 'loan', 'prepayment']",0,"['how', 'to', 'forecast', 'loan', 'prepayment']","['forecast', 'loan', 'prepayment']",forecast loan prepayment,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
3809,efficient merging with proc format in sas,Tools,efficient merging with proc format in sas,"['efficient', 'merging', 'with', 'proc', 'format', 'in', 'sas']",0,"['efficient', 'merging', 'with', 'proc', 'format', 'in', 'sa']","['efficient', 'merging', 'proc', 'format', 'sa']",efficient merging proc format sa,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
3810,why did abc stopped doing hiring hack,Career,why did abc stopped doing hiring hack,"['why', 'did', 'abc', 'stopped', 'doing', 'hiring', 'hack']",0,"['why', 'did', 'abc', 'stopped', 'doing', 'hiring', 'hack']","['abc', 'stopped', 'hiring', 'hack']",abc stopped hiring hack,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
3811,how to create more than one level using split function in r,Tools,how to create more than one level using split function in r,"['how', 'to', 'create', 'more', 'than', 'one', 'level', 'using', 'split', 'function', 'in', 'r']",0,"['how', 'to', 'create', 'more', 'than', 'one', 'level', 'using', 'split', 'function', 'in', 'r']","['create', 'one', 'level', 'using', 'split', 'function', 'r']",create one level using split function r,0.5,0.0,12,39,3.0,0,0,0,0,0,0,0,0
3812,cross validation import error,Hackathons,cross validation import error,"['cross', 'validation', 'import', 'error']",0,"['cross', 'validation', 'import', 'error']","['cross', 'validation', 'import', 'error']",cross validation import error,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
3813,how ggplot is different from basic plotting function in r,Techniques,how ggplot is different from basic plotting function in r,"['how', 'ggplot', 'is', 'different', 'from', 'basic', 'plotting', 'function', 'in', 'r']",0,"['how', 'ggplot', 'is', 'different', 'from', 'basic', 'plotting', 'function', 'in', 'r']","['ggplot', 'different', 'basic', 'plotting', 'function', 'r']",ggplot different basic plotting function r,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
3814,what is a dummy variable,Techniques,what is a dummy variable,"['what', 'is', 'a', 'dummy', 'variable']",0,"['what', 'is', 'a', 'dummy', 'variable']","['dummy', 'variable']",dummy variable,0.0,0.0,5,14,2.3333333333333335,0,0,0,0,0,0,0,0
3815,is there any data set which have duplicate documents and in categorized form,Techniques,is there any data set which have duplicate documents and in categorized form,"['is', 'there', 'any', 'data', 'set', 'which', 'have', 'duplicate', 'documents', 'and', 'in', 'categorized', 'form']",0,"['is', 'there', 'any', 'data', 'set', 'which', 'have', 'duplicate', 'document', 'and', 'in', 'categorized', 'form']","['data', 'set', 'duplicate', 'document', 'categorized', 'form']",data set duplicate document categorized form,0.0,0.0,13,44,3.142857142857143,0,0,0,0,0,0,0,0
3816,machine learning algorithms linear vs non linear,Techniques,machine learning algorithms linear vs non linear,"['machine', 'learning', 'algorithms', 'linear', 'vs', 'non', 'linear']",0,"['machine', 'learning', 'algorithm', 'linear', 'v', 'non', 'linear']","['machine', 'learning', 'algorithm', 'linear', 'v', 'non', 'linear']",machine learning algorithm linear v non linear,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
3817,real estate ml use cases,Techniques,real estate ml use cases,"['real', 'estate', 'ml', 'use', 'cases']",0,"['real', 'estate', 'ml', 'use', 'case']","['real', 'estate', 'ml', 'use', 'case']",real estate ml use case,0.2,0.2,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
3818,how to verify error independence for ensembles in r,Techniques,how to verify error independence for ensembles in r,"['how', 'to', 'verify', 'error', 'independence', 'for', 'ensembles', 'in', 'r']",0,"['how', 'to', 'verify', 'error', 'independence', 'for', 'ensemble', 'in', 'r']","['verify', 'error', 'independence', 'ensemble', 'r']",verify error independence ensemble r,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
3819,ipl top  batsman dashboard,Hackathons,ipl top  batsman dashboard,"['ipl', 'top', 'batsman', 'dashboard']",1,"['ipl', 'top', 'batsman', 'dashboard']","['ipl', 'top', 'batsman', 'dashboard']",ipl top batsman dashboard,0.5,0.5,4,25,5.0,0,0,0,0,0,0,0,0
3820,how to find first non numeric character in the string using excel,Tools,how to find first non numeric character in the string using excel,"['how', 'to', 'find', 'first', 'non', 'numeric', 'character', 'in', 'the', 'string', 'using', 'excel']",0,"['how', 'to', 'find', 'first', 'non', 'numeric', 'character', 'in', 'the', 'string', 'using', 'excel']","['find', 'first', 'non', 'numeric', 'character', 'string', 'using', 'excel']",find first non numeric character string using excel,0.25,0.25,12,51,3.923076923076923,0,0,0,0,0,0,0,0
3821,undersampling is not improving precision for binary classification,Techniques,undersampling is not improving precision for binary classification,"['undersampling', 'is', 'not', 'improving', 'precision', 'for', 'binary', 'classification']",0,"['undersampling', 'is', 'not', 'improving', 'precision', 'for', 'binary', 'classification']","['undersampling', 'improving', 'precision', 'binary', 'classification']",undersampling improving precision binary classification,0.0,0.0,8,55,6.111111111111111,0,0,0,0,0,0,0,0
3822,seers accuracy can any one share your approach towards the problem,Techniques,seers accuracy can any one share your approach towards the problem,"['seers', 'accuracy', 'can', 'any', 'one', 'share', 'your', 'approach', 'towards', 'the', 'problem']",0,"['seer', 'accuracy', 'can', 'any', 'one', 'share', 'your', 'approach', 'towards', 'the', 'problem']","['seer', 'accuracy', 'one', 'share', 'approach', 'towards', 'problem']",seer accuracy one share approach towards problem,0.0,0.0,11,48,4.0,0,0,0,0,0,0,0,0
3823,anyone applying to any analyticsbig data programs,Career,anyone applying to any analyticsbig data programs,"['anyone', 'applying', 'to', 'any', 'analyticsbig', 'data', 'programs']",0,"['anyone', 'applying', 'to', 'any', 'analyticsbig', 'data', 'program']","['anyone', 'applying', 'analyticsbig', 'data', 'program']",anyone applying analyticsbig data program,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
3824,how to used dataset in time series forecasting,Techniques,how to used dataset in time series forecasting,"['how', 'to', 'used', 'dataset', 'in', 'time', 'series', 'forecasting']",0,"['how', 'to', 'used', 'dataset', 'in', 'time', 'series', 'forecasting']","['used', 'dataset', 'time', 'series', 'forecasting']",used dataset time series forecasting,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
3825,pgdba course iitk iim isi,Career,pgdba course iitk iim isi,"['pgdba', 'course', 'iitk', 'iim', 'isi']",0,"['pgdba', 'course', 'iitk', 'iim', 'isi']","['pgdba', 'course', 'iitk', 'iim', 'isi']",pgdba course iitk iim isi,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
3826,what is the best open source data analytics tool right now,Tools,what is the best open source data analytics tool right now,"['what', 'is', 'the', 'best', 'open', 'source', 'data', 'analytics', 'tool', 'right', 'now']",0,"['what', 'is', 'the', 'best', 'open', 'source', 'data', 'analytics', 'tool', 'right', 'now']","['best', 'open', 'source', 'data', 'analytics', 'tool', 'right']",best open source data analytics tool right,0.4285714285714285,0.4285714285714285,11,42,3.5,0,0,0,0,0,0,0,0
3827,imputting missing values with ,Techniques,imputting missing values with ,"['imputting', 'missing', 'values', 'with']",1,"['imputting', 'missing', 'value', 'with']","['imputting', 'missing', 'value']",imputting missing value,-0.2,-0.2,4,23,4.6,0,0,0,0,0,0,0,0
3828,the strategic saviour event  suggestion for future,Other,the strategic saviour event  suggestion for future,"['the', 'strategic', 'saviour', 'event', 'suggestion', 'for', 'future']",0,"['the', 'strategic', 'saviour', 'event', 'suggestion', 'for', 'future']","['strategic', 'saviour', 'event', 'suggestion', 'future']",strategic saviour event suggestion future,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
3829,gradientdescentoptimizer,Techniques,gradientdescentoptimizer,['gradientdescentoptimizer'],0,['gradientdescentoptimizer'],['gradientdescentoptimizer'],gradientdescentoptimizer,0.0,0.0,1,24,12.0,0,0,0,0,0,0,0,0
3831,machine unlearning,Techniques,machine unlearning,"['machine', 'unlearning']",0,"['machine', 'unlearning']","['machine', 'unlearning']",machine unlearning,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
3832,course material,Resources,course material,"['course', 'material']",0,"['course', 'material']","['course', 'material']",course material,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
3833,sas certification help required,Career,sas certification help required,"['sas', 'certification', 'help', 'required']",0,"['sa', 'certification', 'help', 'required']","['sa', 'certification', 'help', 'required']",sa certification help required,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
3834,how to add text to individual curves on a plot in r,Tools,how to add text to individual curves on a plot in r,"['how', 'to', 'add', 'text', 'to', 'individual', 'curves', 'on', 'a', 'plot', 'in', 'r']",0,"['how', 'to', 'add', 'text', 'to', 'individual', 'curve', 'on', 'a', 'plot', 'in', 'r']","['add', 'text', 'individual', 'curve', 'plot', 'r']",add text individual curve plot r,0.0,0.0,12,32,2.4615384615384617,0,0,0,0,0,0,0,0
3835,how to scrape data using xpath in scrapy,Techniques,how to scrape data using xpath in scrapy,"['how', 'to', 'scrape', 'data', 'using', 'xpath', 'in', 'scrapy']",0,"['how', 'to', 'scrape', 'data', 'using', 'xpath', 'in', 'scrapy']","['scrape', 'data', 'using', 'xpath', 'scrapy']",scrape data using xpath scrapy,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
3836,what is the difference between cluster sampling and clustering,Techniques,what is the difference between cluster sampling and clustering,"['what', 'is', 'the', 'difference', 'between', 'cluster', 'sampling', 'and', 'clustering']",0,"['what', 'is', 'the', 'difference', 'between', 'cluster', 'sampling', 'and', 'clustering']","['difference', 'cluster', 'sampling', 'clustering']",difference cluster sampling clustering,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
3837,clustering of large volume of string data,Techniques,clustering of large volume of string data,"['clustering', 'of', 'large', 'volume', 'of', 'string', 'data']",0,"['clustering', 'of', 'large', 'volume', 'of', 'string', 'data']","['clustering', 'large', 'volume', 'string', 'data']",clustering large volume string data,0.2142857142857142,0.2142857142857142,7,35,4.375,0,0,0,0,0,0,0,0
3838,multi collinearity and unnecessary features removing using regularization,Techniques,multi collinearity and unnecessary features removing using regularization,"['multi', 'collinearity', 'and', 'unnecessary', 'features', 'removing', 'using', 'regularization']",0,"['multi', 'collinearity', 'and', 'unnecessary', 'feature', 'removing', 'using', 'regularization']","['multi', 'collinearity', 'unnecessary', 'feature', 'removing', 'using', 'regularization']",multi collinearity unnecessary feature removing using regularization,-0.4,-0.4,8,68,7.555555555555555,0,0,0,0,0,0,0,0
3839,elaborate on the difference in career options between data science and machine learning,Career,elaborate on the difference in career options between data science and machine learning,"['elaborate', 'on', 'the', 'difference', 'in', 'career', 'options', 'between', 'data', 'science', 'and', 'machine', 'learning']",0,"['elaborate', 'on', 'the', 'difference', 'in', 'career', 'option', 'between', 'data', 'science', 'and', 'machine', 'learning']","['elaborate', 'difference', 'career', 'option', 'data', 'science', 'machine', 'learning']",elaborate difference career option data science machine learning,0.5,0.5,13,64,4.571428571428571,0,0,0,0,0,0,0,0
3840,create a d  histogram using latitudes and longitudes in r,Tools,create a d  histogram using latitudes and longitudes in r,"['create', 'a', 'd', 'histogram', 'using', 'latitudes', 'and', 'longitudes', 'in', 'r']",0,"['create', 'a', 'd', 'histogram', 'using', 'latitude', 'and', 'longitude', 'in', 'r']","['create', 'histogram', 'using', 'latitude', 'longitude', 'r']",create histogram using latitude longitude r,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
3841,where to find practice problems for linear regression,Resources,where to find practice problems for linear regression,"['where', 'to', 'find', 'practice', 'problems', 'for', 'linear', 'regression']",0,"['where', 'to', 'find', 'practice', 'problem', 'for', 'linear', 'regression']","['find', 'practice', 'problem', 'linear', 'regression']",find practice problem linear regression,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
3842,running java code on the gpu with aparapi,Tools,running java code on the gpu with aparapi,"['running', 'java', 'code', 'on', 'the', 'gpu', 'with', 'aparapi']",0,"['running', 'java', 'code', 'on', 'the', 'gpu', 'with', 'aparapi']","['running', 'java', 'code', 'gpu', 'aparapi']",running java code gpu aparapi,0.0,0.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
3843,rpython script needed to assign cluster id to each po records based on multiple conditions across columns,Tools,rpython script needed to assign cluster id to each po records based on multiple conditions across columns,"['rpython', 'script', 'needed', 'to', 'assign', 'cluster', 'id', 'to', 'each', 'po', 'records', 'based', 'on', 'multiple', 'conditions', 'across', 'columns']",0,"['rpython', 'script', 'needed', 'to', 'assign', 'cluster', 'id', 'to', 'each', 'po', 'record', 'based', 'on', 'multiple', 'condition', 'across', 'column']","['rpython', 'script', 'needed', 'assign', 'cluster', 'id', 'po', 'record', 'based', 'multiple', 'condition', 'across', 'column']",rpython script needed assign cluster id po record based multiple condition across column,0.0,0.0,17,88,4.888888888888889,0,0,0,0,0,0,0,0
3844,separate a column into two column,Techniques,separate a column into two column,"['separate', 'a', 'column', 'into', 'two', 'column']",0,"['separate', 'a', 'column', 'into', 'two', 'column']","['separate', 'column', 'two', 'column']",separate column two column,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
3845,clustering and segmentation,Techniques,clustering and segmentation,"['clustering', 'and', 'segmentation']",0,"['clustering', 'and', 'segmentation']","['clustering', 'segmentation']",clustering segmentation,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
