ID,Title,original_title,text_words,text_digit_cnt,clean_text_lem,clean_text_wrds,clean_text,title_polarity,text_polarity,ttl_wrds,char_count,word_density,punctuation_count,title_word_count,upper_case_word_count,noun_count,verb_count,adj_count,adv_count,pron_count
3846,spark cheatsheet,spark cheatsheet,"['spark', 'cheatsheet']",0,"['spark', 'cheatsheet']","['spark', 'cheatsheet']",spark cheatsheet,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
3847,review of random forest code in python,review of random forest code in python,"['review', 'of', 'random', 'forest', 'code', 'in', 'python']",0,"['review', 'of', 'random', 'forest', 'code', 'in', 'python']","['review', 'random', 'forest', 'code', 'python']",review random forest code python,-0.5,-0.5,7,32,4.0,0,0,0,0,0,0,0,0
3848,chisq test for numeric variables,chisq test for numeric variables,"['chisq', 'test', 'for', 'numeric', 'variables']",0,"['chisq', 'test', 'for', 'numeric', 'variable']","['chisq', 'test', 'numeric', 'variable']",chisq test numeric variable,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
3849,prediction from loaded pickled file for single instance of input,prediction from loaded pickled file for single instance of input,"['prediction', 'from', 'loaded', 'pickled', 'file', 'for', 'single', 'instance', 'of', 'input']",0,"['prediction', 'from', 'loaded', 'pickled', 'file', 'for', 'single', 'instance', 'of', 'input']","['prediction', 'loaded', 'pickled', 'file', 'single', 'instance', 'input']",prediction loaded pickled file single instance input,-0.0714285714285714,-0.0714285714285714,10,52,4.7272727272727275,0,0,0,0,0,0,0,0
3850,even after installing anaconda on my pc i am unable to access jupyter notebook on my command prompt,even after installing anaconda on my pc i am unable to access jupyter notebook on my command prompt,"['even', 'after', 'installing', 'anaconda', 'on', 'my', 'pc', 'i', 'am', 'unable', 'to', 'access', 'jupyter', 'notebook', 'on', 'my', 'command', 'prompt']",0,"['even', 'after', 'installing', 'anaconda', 'on', 'my', 'pc', 'i', 'am', 'unable', 'to', 'access', 'jupyter', 'notebook', 'on', 'my', 'command', 'prompt']","['even', 'installing', 'anaconda', 'pc', 'unable', 'access', 'jupyter', 'notebook', 'command', 'prompt']",even installing anaconda pc unable access jupyter notebook command prompt,-0.5,-0.5,18,73,3.8421052631578947,0,0,0,0,0,0,0,0
3851,unhide multiple sheets together in excel,unhide multiple sheets together in excel,"['unhide', 'multiple', 'sheets', 'together', 'in', 'excel']",0,"['unhide', 'multiple', 'sheet', 'together', 'in', 'excel']","['unhide', 'multiple', 'sheet', 'together', 'excel']",unhide multiple sheet together excel,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
3852,relation between hypothesis testing and null hypothesis,relation between hypothesis testing and null hypothesis,"['relation', 'between', 'hypothesis', 'testing', 'and', 'null', 'hypothesis']",0,"['relation', 'between', 'hypothesis', 'testing', 'and', 'null', 'hypothesis']","['relation', 'hypothesis', 'testing', 'null', 'hypothesis']",relation hypothesis testing null hypothesis,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
3853,how to plot two yaxis data in r using ggplot,how to plot two yaxis data in r using ggplot,"['how', 'to', 'plot', 'two', 'yaxis', 'data', 'in', 'r', 'using', 'ggplot']",0,"['how', 'to', 'plot', 'two', 'yaxis', 'data', 'in', 'r', 'using', 'ggplot']","['plot', 'two', 'yaxis', 'data', 'r', 'using', 'ggplot']",plot two yaxis data r using ggplot,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
3854,how to create target encoding or mean encoding in r,how to create target encoding or mean encoding in r,"['how', 'to', 'create', 'target', 'encoding', 'or', 'mean', 'encoding', 'in', 'r']",0,"['how', 'to', 'create', 'target', 'encoding', 'or', 'mean', 'encoding', 'in', 'r']","['create', 'target', 'encoding', 'mean', 'encoding', 'r']",create target encoding mean encoding r,-0.3125,-0.3125,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
3855,example for using xgboost to perform regression in r,example for using xgboost to perform regression in r,"['example', 'for', 'using', 'xgboost', 'to', 'perform', 'regression', 'in', 'r']",0,"['example', 'for', 'using', 'xgboost', 'to', 'perform', 'regression', 'in', 'r']","['example', 'using', 'xgboost', 'perform', 'regression', 'r']",example using xgboost perform regression r,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
3856,problem in running http server python,problem in running http server python,"['problem', 'in', 'running', 'http', 'server', 'python']",0,"['problem', 'in', 'running', 'http', 'server', 'python']","['problem', 'running', 'http', 'server', 'python']",problem running http server python,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
3857,error while using the function hoinit,error while using the function hoinit,"['error', 'while', 'using', 'the', 'function', 'hoinit']",0,"['error', 'while', 'using', 'the', 'function', 'hoinit']","['error', 'using', 'function', 'hoinit']",error using function hoinit,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
3858,adding subtitles andor bookmarks for reference,adding subtitles andor bookmarks for reference,"['adding', 'subtitles', 'andor', 'bookmarks', 'for', 'reference']",0,"['adding', 'subtitle', 'andor', 'bookmark', 'for', 'reference']","['adding', 'subtitle', 'andor', 'bookmark', 'reference']",adding subtitle andor bookmark reference,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
3859,how to remove variable from work space in r,how to remove variable from work space in r,"['how', 'to', 'remove', 'variable', 'from', 'work', 'space', 'in', 'r']",0,"['how', 'to', 'remove', 'variable', 'from', 'work', 'space', 'in', 'r']","['remove', 'variable', 'work', 'space', 'r']",remove variable work space r,0.0,0.0,9,28,2.8,0,0,0,0,0,0,0,0
3860,my  words  an attempt to be better at blogging,my  words  an attempt to be better at blogging,"['my', 'words', 'an', 'attempt', 'to', 'be', 'better', 'at', 'blogging']",1,"['my', 'word', 'an', 'attempt', 'to', 'be', 'better', 'at', 'blogging']","['word', 'attempt', 'better', 'blogging']",word attempt better blogging,0.5,0.5,9,28,2.8,0,0,0,0,0,0,0,0
3861,analytics in sales,analytics in sales,"['analytics', 'in', 'sales']",0,"['analytics', 'in', 'sale']","['analytics', 'sale']",analytics sale,0.0,0.0,3,14,3.5,0,0,0,0,0,0,0,0
3862,how to authenticate the twitter credentials object in r,how to authenticate the twitter credentials object in r,"['how', 'to', 'authenticate', 'the', 'twitter', 'credentials', 'object', 'in', 'r']",0,"['how', 'to', 'authenticate', 'the', 'twitter', 'credential', 'object', 'in', 'r']","['authenticate', 'twitter', 'credential', 'object', 'r']",authenticate twitter credential object r,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
3863,bayesian probability analysis using openbugs,bayesian probability analysis using openbugs,"['bayesian', 'probability', 'analysis', 'using', 'openbugs']",0,"['bayesian', 'probability', 'analysis', 'using', 'openbugs']","['bayesian', 'probability', 'analysis', 'using', 'openbugs']",bayesian probability analysis using openbugs,0.0,0.0,5,44,7.333333333333333,0,0,0,0,0,0,0,0
3864,how to integrate ldap with rshiny dashboard application,how to integrate ldap with rshiny dashboard application,"['how', 'to', 'integrate', 'ldap', 'with', 'rshiny', 'dashboard', 'application']",0,"['how', 'to', 'integrate', 'ldap', 'with', 'rshiny', 'dashboard', 'application']","['integrate', 'ldap', 'rshiny', 'dashboard', 'application']",integrate ldap rshiny dashboard application,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
3865,anomaly detection on large time series dataset,anomaly detection on large time series dataset,"['anomaly', 'detection', 'on', 'large', 'time', 'series', 'dataset']",0,"['anomaly', 'detection', 'on', 'large', 'time', 'series', 'dataset']","['anomaly', 'detection', 'large', 'time', 'series', 'dataset']",anomaly detection large time series dataset,0.2142857142857142,0.2142857142857142,7,43,5.375,0,0,0,0,0,0,0,0
3866,help me to transform my career into data science,help me to transform my career into data science,"['help', 'me', 'to', 'transform', 'my', 'career', 'into', 'data', 'science']",0,"['help', 'me', 'to', 'transform', 'my', 'career', 'into', 'data', 'science']","['help', 'transform', 'career', 'data', 'science']",help transform career data science,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
3867,discussion badges not showing up on my profile,discussion badges not showing up on my profile,"['discussion', 'badges', 'not', 'showing', 'up', 'on', 'my', 'profile']",0,"['discussion', 'badge', 'not', 'showing', 'up', 'on', 'my', 'profile']","['discussion', 'badge', 'showing', 'profile']",discussion badge showing profile,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
3868,logistic regression not giving categorical output,logistic regression not giving categorical output,"['logistic', 'regression', 'not', 'giving', 'categorical', 'output']",0,"['logistic', 'regression', 'not', 'giving', 'categorical', 'output']","['logistic', 'regression', 'giving', 'categorical', 'output']",logistic regression giving categorical output,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
3869,how to manipulate best package nosql data format in r,how to manipulate best package nosql data format in r,"['how', 'to', 'manipulate', 'best', 'package', 'nosql', 'data', 'format', 'in', 'r']",0,"['how', 'to', 'manipulate', 'best', 'package', 'nosql', 'data', 'format', 'in', 'r']","['manipulate', 'best', 'package', 'nosql', 'data', 'format', 'r']",manipulate best package nosql data format r,1.0,1.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
3870,rstudio importing problem,rstudio importing problem,"['rstudio', 'importing', 'problem']",0,"['rstudio', 'importing', 'problem']","['rstudio', 'importing', 'problem']",rstudio importing problem,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
3871,when is normalization of data required,when is normalization of data required,"['when', 'is', 'normalization', 'of', 'data', 'required']",0,"['when', 'is', 'normalization', 'of', 'data', 'required']","['normalization', 'data', 'required']",normalization data required,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
3872,keep only the rows with latest dates in dataframe,keep only the rows with latest dates in dataframe,"['keep', 'only', 'the', 'rows', 'with', 'latest', 'dates', 'in', 'dataframe']",0,"['keep', 'only', 'the', 'row', 'with', 'latest', 'date', 'in', 'dataframe']","['keep', 'row', 'latest', 'date', 'dataframe']",keep row latest date dataframe,0.25,0.5,9,30,3.0,0,0,0,0,0,0,0,0
3873,change in career path,change in career path,"['change', 'in', 'career', 'path']",0,"['change', 'in', 'career', 'path']","['change', 'career', 'path']",change career path,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
3874,how to handle multi collinearity in data efficiently,how to handle multi collinearity in data efficiently,"['how', 'to', 'handle', 'multi', 'collinearity', 'in', 'data', 'efficiently']",0,"['how', 'to', 'handle', 'multi', 'collinearity', 'in', 'data', 'efficiently']","['handle', 'multi', 'collinearity', 'data', 'efficiently']",handle multi collinearity data efficiently,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
3875,mapping postal codes on country map using r,mapping postal codes on country map using r,"['mapping', 'postal', 'codes', 'on', 'country', 'map', 'using', 'r']",0,"['mapping', 'postal', 'code', 'on', 'country', 'map', 'using', 'r']","['mapping', 'postal', 'code', 'country', 'map', 'using', 'r']",mapping postal code country map using r,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
3876,what insights can we derive from the mean of squared residuals and  variance explained terms in a randomforest model,what insights can we derive from the mean of squared residuals and  variance explained terms in a randomforest model,"['what', 'insights', 'can', 'we', 'derive', 'from', 'the', 'mean', 'of', 'squared', 'residuals', 'and', 'variance', 'explained', 'terms', 'in', 'a', 'randomforest', 'model']",0,"['what', 'insight', 'can', 'we', 'derive', 'from', 'the', 'mean', 'of', 'squared', 'residual', 'and', 'variance', 'explained', 'term', 'in', 'a', 'randomforest', 'model']","['insight', 'derive', 'mean', 'squared', 'residual', 'variance', 'explained', 'term', 'randomforest', 'model']",insight derive mean squared residual variance explained term randomforest model,-0.3125,-0.3125,19,79,3.95,0,0,0,0,0,0,0,0
3877,merging two excel files of different size into one,merging two excel files of different size into one,"['merging', 'two', 'excel', 'files', 'of', 'different', 'size', 'into', 'one']",0,"['merging', 'two', 'excel', 'file', 'of', 'different', 'size', 'into', 'one']","['merging', 'two', 'excel', 'file', 'different', 'size', 'one']",merging two excel file different size one,0.0,0.0,9,41,4.1,0,0,0,0,0,0,0,0
3878,how to take subset or matching one row of first dataframe with respect to second dataframe columns in pandas,how to take subset or matching one row of first dataframe with respect to second dataframe columns in pandas,"['how', 'to', 'take', 'subset', 'or', 'matching', 'one', 'row', 'of', 'first', 'dataframe', 'with', 'respect', 'to', 'second', 'dataframe', 'columns', 'in', 'pandas']",0,"['how', 'to', 'take', 'subset', 'or', 'matching', 'one', 'row', 'of', 'first', 'dataframe', 'with', 'respect', 'to', 'second', 'dataframe', 'column', 'in', 'panda']","['take', 'subset', 'matching', 'one', 'row', 'first', 'dataframe', 'respect', 'second', 'dataframe', 'column', 'panda']",take subset matching one row first dataframe respect second dataframe column panda,0.125,0.125,19,82,4.1,0,0,0,0,0,0,0,0
3879,what exactly does xgboost gblinearreglinear do,what exactly does xgboost gblinearreglinear do,"['what', 'exactly', 'does', 'xgboost', 'gblinearreglinear', 'do']",0,"['what', 'exactly', 'doe', 'xgboost', 'gblinearreglinear', 'do']","['exactly', 'doe', 'xgboost', 'gblinearreglinear']",exactly doe xgboost gblinearreglinear,0.25,0.25,6,37,5.285714285714286,0,0,0,0,0,0,0,0
3880,data analysis and interpretation,data analysis and interpretation,"['data', 'analysis', 'and', 'interpretation']",0,"['data', 'analysis', 'and', 'interpretation']","['data', 'analysis', 'interpretation']",data analysis interpretation,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
3881,what is your new year learning resolution,what is your new year learning resolution,"['what', 'is', 'your', 'new', 'year', 'learning', 'resolution']",0,"['what', 'is', 'your', 'new', 'year', 'learning', 'resolution']","['new', 'year', 'learning', 'resolution']",new year learning resolution,0.1363636363636363,0.1363636363636363,7,28,3.5,0,0,0,0,0,0,0,0
3882,applying grm package,applying grm package,"['applying', 'grm', 'package']",0,"['applying', 'grm', 'package']","['applying', 'grm', 'package']",applying grm package,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
3883,r htmltreeparse and xml library giving empty list during webscraping attempt,r htmltreeparse and xml library giving empty list during webscraping attempt,"['r', 'htmltreeparse', 'and', 'xml', 'library', 'giving', 'empty', 'list', 'during', 'webscraping', 'attempt']",0,"['r', 'htmltreeparse', 'and', 'xml', 'library', 'giving', 'empty', 'list', 'during', 'webscraping', 'attempt']","['r', 'htmltreeparse', 'xml', 'library', 'giving', 'empty', 'list', 'webscraping', 'attempt']",r htmltreeparse xml library giving empty list webscraping attempt,-0.1,-0.1,11,65,5.416666666666667,0,0,0,0,0,0,0,0
3884,what is inductive bias,what is inductive bias,"['what', 'is', 'inductive', 'bias']",0,"['what', 'is', 'inductive', 'bias']","['inductive', 'bias']",inductive bias,0.0,0.0,4,14,2.8,0,0,0,0,0,0,0,0
3885,how to predict next value using only one variable in linear regression,how to predict next value using only one variable in linear regression,"['how', 'to', 'predict', 'next', 'value', 'using', 'only', 'one', 'variable', 'in', 'linear', 'regression']",0,"['how', 'to', 'predict', 'next', 'value', 'using', 'only', 'one', 'variable', 'in', 'linear', 'regression']","['predict', 'next', 'value', 'using', 'one', 'variable', 'linear', 'regression']",predict next value using one variable linear regression,0.0,0.0,12,55,4.230769230769231,0,0,0,0,0,0,0,0
3886,decision tree rules,decision tree rules,"['decision', 'tree', 'rules']",0,"['decision', 'tree', 'rule']","['decision', 'tree', 'rule']",decision tree rule,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
3887,please suggest a faster methodpackage for parameter tuning in r,please suggest a faster methodpackage for parameter tuning in r,"['please', 'suggest', 'a', 'faster', 'methodpackage', 'for', 'parameter', 'tuning', 'in', 'r']",0,"['please', 'suggest', 'a', 'faster', 'methodpackage', 'for', 'parameter', 'tuning', 'in', 'r']","['please', 'suggest', 'faster', 'methodpackage', 'parameter', 'tuning', 'r']",please suggest faster methodpackage parameter tuning r,0.0,0.0,10,54,4.909090909090909,0,0,0,0,0,0,0,0
3888,is anyone of this called supervised learning and is this a correct way to solve to problem,is anyone of this called supervised learning and is this a correct way to solve to problem,"['is', 'anyone', 'of', 'this', 'called', 'supervised', 'learning', 'and', 'is', 'this', 'a', 'correct', 'way', 'to', 'solve', 'to', 'problem']",0,"['is', 'anyone', 'of', 'this', 'called', 'supervised', 'learning', 'and', 'is', 'this', 'a', 'correct', 'way', 'to', 'solve', 'to', 'problem']","['anyone', 'called', 'supervised', 'learning', 'correct', 'way', 'solve', 'problem']",anyone called supervised learning correct way solve problem,0.0,0.0,17,59,3.2777777777777777,0,0,0,0,0,0,0,0
3889,viaregiondatajson file not found error while it is there in train and test dataset,viaregiondatajson file not found error while it is there in train and test dataset,"['viaregiondatajson', 'file', 'not', 'found', 'error', 'while', 'it', 'is', 'there', 'in', 'train', 'and', 'test', 'dataset']",0,"['viaregiondatajson', 'file', 'not', 'found', 'error', 'while', 'it', 'is', 'there', 'in', 'train', 'and', 'test', 'dataset']","['viaregiondatajson', 'file', 'found', 'error', 'train', 'test', 'dataset']",viaregiondatajson file found error train test dataset,0.0,0.0,14,53,3.533333333333333,0,0,0,0,0,0,0,0
3890,creating a new variable with multiple conditions in python,creating a new variable with multiple conditions in python,"['creating', 'a', 'new', 'variable', 'with', 'multiple', 'conditions', 'in', 'python']",0,"['creating', 'a', 'new', 'variable', 'with', 'multiple', 'condition', 'in', 'python']","['creating', 'new', 'variable', 'multiple', 'condition', 'python']",creating new variable multiple condition python,0.0681818181818181,0.0681818181818181,9,47,4.7,0,0,0,0,0,0,0,0
3891,does kmeans clustering algorithm really finds the global minimum or not,does kmeans clustering algorithm really finds the global minimum or not,"['does', 'kmeans', 'clustering', 'algorithm', 'really', 'finds', 'the', 'global', 'minimum', 'or', 'not']",0,"['doe', 'kmeans', 'clustering', 'algorithm', 'really', 'find', 'the', 'global', 'minimum', 'or', 'not']","['doe', 'kmeans', 'clustering', 'algorithm', 'really', 'find', 'global', 'minimum']",doe kmeans clustering algorithm really find global minimum,0.1,0.1,11,58,4.833333333333333,0,0,0,0,0,0,0,0
3892,which classification algorithm could be used for sentiment analysis,which classification algorithm could be used for sentiment analysis,"['which', 'classification', 'algorithm', 'could', 'be', 'used', 'for', 'sentiment', 'analysis']",0,"['which', 'classification', 'algorithm', 'could', 'be', 'used', 'for', 'sentiment', 'analysis']","['classification', 'algorithm', 'could', 'used', 'sentiment', 'analysis']",classification algorithm could used sentiment analysis,0.0,0.0,9,54,5.4,0,0,0,0,0,0,0,0
3893,not able to download data of bigbuck challenge,not able to download data of bigbuck challenge,"['not', 'able', 'to', 'download', 'data', 'of', 'bigbuck', 'challenge']",0,"['not', 'able', 'to', 'download', 'data', 'of', 'bigbuck', 'challenge']","['able', 'download', 'data', 'bigbuck', 'challenge']",able download data bigbuck challenge,-0.25,0.5,8,36,4.0,0,0,0,0,0,0,0,0
3894,curve fitting of three curves to single equation,curve fitting of three curves to single equation,"['curve', 'fitting', 'of', 'three', 'curves', 'to', 'single', 'equation']",0,"['curve', 'fitting', 'of', 'three', 'curve', 'to', 'single', 'equation']","['curve', 'fitting', 'three', 'curve', 'single', 'equation']",curve fitting three curve single equation,0.2142857142857143,0.2142857142857143,8,41,4.555555555555555,0,0,0,0,0,0,0,0
3895,computer vision using deep learning,computer vision using deep learning,"['computer', 'vision', 'using', 'deep', 'learning']",0,"['computer', 'vision', 'using', 'deep', 'learning']","['computer', 'vision', 'using', 'deep', 'learning']",computer vision using deep learning,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
3896,how to implement semantic search in python or r,how to implement semantic search in python or r,"['how', 'to', 'implement', 'semantic', 'search', 'in', 'python', 'or', 'r']",0,"['how', 'to', 'implement', 'semantic', 'search', 'in', 'python', 'or', 'r']","['implement', 'semantic', 'search', 'python', 'r']",implement semantic search python r,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
3897,tips for handling big data efficiently in python,tips for handling big data efficiently in python,"['tips', 'for', 'handling', 'big', 'data', 'efficiently', 'in', 'python']",0,"['tip', 'for', 'handling', 'big', 'data', 'efficiently', 'in', 'python']","['tip', 'handling', 'big', 'data', 'efficiently', 'python']",tip handling big data efficiently python,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
3898,knocktober   gap between public score and private score,knocktober   gap between public score and private score,"['knocktober', 'gap', 'between', 'public', 'score', 'and', 'private', 'score']",1,"['knocktober', 'gap', 'between', 'public', 'score', 'and', 'private', 'score']","['knocktober', 'gap', 'public', 'score', 'private', 'score']",knocktober gap public score private score,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
3899,how analytics in bank is differ from role of data scientist,how analytics in bank is differ from role of data scientist,"['how', 'analytics', 'in', 'bank', 'is', 'differ', 'from', 'role', 'of', 'data', 'scientist']",0,"['how', 'analytics', 'in', 'bank', 'is', 'differ', 'from', 'role', 'of', 'data', 'scientist']","['analytics', 'bank', 'differ', 'role', 'data', 'scientist']",analytics bank differ role data scientist,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
3900,error nonnumeric argument to binary operator,error nonnumeric argument to binary operator,"['error', 'nonnumeric', 'argument', 'to', 'binary', 'operator']",0,"['error', 'nonnumeric', 'argument', 'to', 'binary', 'operator']","['error', 'nonnumeric', 'argument', 'binary', 'operator']",error nonnumeric argument binary operator,0.0,0.0,6,41,5.857142857142857,0,0,0,0,0,0,0,0
3901,for people having work ex in different domain learn the skill of transitioning your career in data science,for people having work ex in different domain learn the skill of transitioning your career in data science,"['for', 'people', 'having', 'work', 'ex', 'in', 'different', 'domain', 'learn', 'the', 'skill', 'of', 'transitioning', 'your', 'career', 'in', 'data', 'science']",0,"['for', 'people', 'having', 'work', 'ex', 'in', 'different', 'domain', 'learn', 'the', 'skill', 'of', 'transitioning', 'your', 'career', 'in', 'data', 'science']","['people', 'work', 'ex', 'different', 'domain', 'learn', 'skill', 'transitioning', 'career', 'data', 'science']",people work ex different domain learn skill transitioning career data science,0.0,0.0,18,77,4.052631578947368,0,0,0,0,0,0,0,0
3902,help credit approval model in python,help credit approval model in python,"['help', 'credit', 'approval', 'model', 'in', 'python']",0,"['help', 'credit', 'approval', 'model', 'in', 'python']","['help', 'credit', 'approval', 'model', 'python']",help credit approval model python,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
3903,cheat sheet  sql,cheat sheet  sql,"['cheat', 'sheet', 'sql']",0,"['cheat', 'sheet', 'sql']","['cheat', 'sheet', 'sql']",cheat sheet sql,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
3904,microsoft tools in analytics,microsoft tools in analytics,"['microsoft', 'tools', 'in', 'analytics']",0,"['microsoft', 'tool', 'in', 'analytics']","['microsoft', 'tool', 'analytics']",microsoft tool analytics,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
3905,how to sort the matrix in a specific dimension in ipython,how to sort the matrix in a specific dimension in ipython,"['how', 'to', 'sort', 'the', 'matrix', 'in', 'a', 'specific', 'dimension', 'in', 'ipython']",0,"['how', 'to', 'sort', 'the', 'matrix', 'in', 'a', 'specific', 'dimension', 'in', 'ipython']","['sort', 'matrix', 'specific', 'dimension', 'ipython']",sort matrix specific dimension ipython,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
3906,unrelated features with common target issue,unrelated features with common target issue,"['unrelated', 'features', 'with', 'common', 'target', 'issue']",0,"['unrelated', 'feature', 'with', 'common', 'target', 'issue']","['unrelated', 'feature', 'common', 'target', 'issue']",unrelated feature common target issue,-0.3,-0.3,6,37,5.285714285714286,0,0,0,0,0,0,0,0
3907,how to sort a data frame rowcolumn wise according to alphanumeric values in r,how to sort a data frame rowcolumn wise according to alphanumeric values in r,"['how', 'to', 'sort', 'a', 'data', 'frame', 'rowcolumn', 'wise', 'according', 'to', 'alphanumeric', 'values', 'in', 'r']",0,"['how', 'to', 'sort', 'a', 'data', 'frame', 'rowcolumn', 'wise', 'according', 'to', 'alphanumeric', 'value', 'in', 'r']","['sort', 'data', 'frame', 'rowcolumn', 'wise', 'according', 'alphanumeric', 'value', 'r']",sort data frame rowcolumn wise according alphanumeric value r,0.7,0.7,14,61,4.066666666666666,0,0,0,0,0,0,0,0
3908,methods to improve time series forecast including arima holts winter,methods to improve time series forecast including arima holts winter,"['methods', 'to', 'improve', 'time', 'series', 'forecast', 'including', 'arima', 'holts', 'winter']",0,"['method', 'to', 'improve', 'time', 'series', 'forecast', 'including', 'arima', 'holts', 'winter']","['method', 'improve', 'time', 'series', 'forecast', 'including', 'arima', 'holts', 'winter']",method improve time series forecast including arima holts winter,0.0,0.0,10,64,5.818181818181818,0,0,0,0,0,0,0,0
3909,how does r calculate the probabilities in naive bayes,how does r calculate the probabilities in naive bayes,"['how', 'does', 'r', 'calculate', 'the', 'probabilities', 'in', 'naive', 'bayes']",0,"['how', 'doe', 'r', 'calculate', 'the', 'probability', 'in', 'naive', 'bayes']","['doe', 'r', 'calculate', 'probability', 'naive', 'bayes']",doe r calculate probability naive bayes,-0.3,-0.3,9,39,3.9,0,0,0,0,0,0,0,0
3910,regularization with linear regression,regularization with linear regression,"['regularization', 'with', 'linear', 'regression']",0,"['regularization', 'with', 'linear', 'regression']","['regularization', 'linear', 'regression']",regularization linear regression,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
3911,q how to convert different level to same level in r,q how to convert different level to same level in r,"['q', 'how', 'to', 'convert', 'different', 'level', 'to', 'same', 'level', 'in', 'r']",0,"['q', 'how', 'to', 'convert', 'different', 'level', 'to', 'same', 'level', 'in', 'r']","['q', 'convert', 'different', 'level', 'level', 'r']",q convert different level level r,0.0,0.0,11,33,2.75,0,0,0,0,0,0,0,0
3912,request for the test set for problem set ,request for the test set for problem set ,"['request', 'for', 'the', 'test', 'set', 'for', 'problem', 'set']",1,"['request', 'for', 'the', 'test', 'set', 'for', 'problem', 'set']","['request', 'test', 'set', 'problem', 'set']",request test set problem set,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
3913,importing html values to r,importing html values to r,"['importing', 'html', 'values', 'to', 'r']",0,"['importing', 'html', 'value', 'to', 'r']","['importing', 'html', 'value', 'r']",importing html value r,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
3914,please help on sas basic error,please help on sas basic error,"['please', 'help', 'on', 'sas', 'basic', 'error']",0,"['please', 'help', 'on', 'sa', 'basic', 'error']","['please', 'help', 'sa', 'basic', 'error']",please help sa basic error,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
3915,comapare the values of same column name of two different dataframes,comapare the values of same column name of two different dataframes,"['comapare', 'the', 'values', 'of', 'same', 'column', 'name', 'of', 'two', 'different', 'dataframes']",0,"['comapare', 'the', 'value', 'of', 'same', 'column', 'name', 'of', 'two', 'different', 'dataframes']","['comapare', 'value', 'column', 'name', 'two', 'different', 'dataframes']",comapare value column name two different dataframes,0.0,0.0,11,51,4.25,0,0,0,0,0,0,0,0
3916,does anybody knows how we can generate pdf includes user imported image ie not r generated chartsmaps from jupyter notebook for r,does anybody knows how we can generate pdf includes user imported image ie not r generated chartsmaps from jupyter notebook for r,"['does', 'anybody', 'knows', 'how', 'we', 'can', 'generate', 'pdf', 'includes', 'user', 'imported', 'image', 'ie', 'not', 'r', 'generated', 'chartsmaps', 'from', 'jupyter', 'notebook', 'for', 'r']",0,"['doe', 'anybody', 'know', 'how', 'we', 'can', 'generate', 'pdf', 'includes', 'user', 'imported', 'image', 'ie', 'not', 'r', 'generated', 'chartsmaps', 'from', 'jupyter', 'notebook', 'for', 'r']","['doe', 'anybody', 'know', 'generate', 'pdf', 'includes', 'user', 'imported', 'image', 'ie', 'r', 'generated', 'chartsmaps', 'jupyter', 'notebook', 'r']",doe anybody know generate pdf includes user imported image ie r generated chartsmaps jupyter notebook r,0.0,0.0,22,103,4.478260869565218,0,0,0,0,0,0,0,0
3917,how to skip missing values between two delimiters in sas,how to skip missing values between two delimiters in sas,"['how', 'to', 'skip', 'missing', 'values', 'between', 'two', 'delimiters', 'in', 'sas']",0,"['how', 'to', 'skip', 'missing', 'value', 'between', 'two', 'delimiters', 'in', 'sa']","['skip', 'missing', 'value', 'two', 'delimiters', 'sa']",skip missing value two delimiters sa,-0.2,-0.2,10,36,3.272727272727273,0,0,0,0,0,0,0,0
3918,need help improving accuracy of model,need help improving accuracy of model,"['need', 'help', 'improving', 'accuracy', 'of', 'model']",0,"['need', 'help', 'improving', 'accuracy', 'of', 'model']","['need', 'help', 'improving', 'accuracy', 'model']",need help improving accuracy model,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
3919,how can we plot d scatter plot in python,how can we plot d scatter plot in python,"['how', 'can', 'we', 'plot', 'd', 'scatter', 'plot', 'in', 'python']",0,"['how', 'can', 'we', 'plot', 'd', 'scatter', 'plot', 'in', 'python']","['plot', 'scatter', 'plot', 'python']",plot scatter plot python,0.0,0.0,9,24,2.4,0,0,0,0,0,0,0,0
3920,multi class classification using xgbclassifier,multi class classification using xgbclassifier,"['multi', 'class', 'classification', 'using', 'xgbclassifier']",0,"['multi', 'class', 'classification', 'using', 'xgbclassifier']","['multi', 'class', 'classification', 'using', 'xgbclassifier']",multi class classification using xgbclassifier,0.0,0.0,5,46,7.666666666666667,0,0,0,0,0,0,0,0
3921,i keep getting an error unnamed  is seen in your code when i want to submit my solution,i keep getting an error unnamed  is seen in your code when i want to submit my solution,"['i', 'keep', 'getting', 'an', 'error', 'unnamed', 'is', 'seen', 'in', 'your', 'code', 'when', 'i', 'want', 'to', 'submit', 'my', 'solution']",1,"['i', 'keep', 'getting', 'an', 'error', 'unnamed', 'is', 'seen', 'in', 'your', 'code', 'when', 'i', 'want', 'to', 'submit', 'my', 'solution']","['keep', 'getting', 'error', 'unnamed', 'seen', 'code', 'want', 'submit', 'solution']",keep getting error unnamed seen code want submit solution,0.0,0.0,18,57,3.0,0,0,0,0,0,0,0,0
3922,error in xycoordsx y xlabel ylabel log  x is a list but does not have components x and y while trying to implement kmeans algorithm in r,error in xycoordsx y xlabel ylabel log  x is a list but does not have components x and y while trying to implement kmeans algorithm in r,"['error', 'in', 'xycoordsx', 'y', 'xlabel', 'ylabel', 'log', 'x', 'is', 'a', 'list', 'but', 'does', 'not', 'have', 'components', 'x', 'and', 'y', 'while', 'trying', 'to', 'implement', 'kmeans', 'algorithm', 'in', 'r']",0,"['error', 'in', 'xycoordsx', 'y', 'xlabel', 'ylabel', 'log', 'x', 'is', 'a', 'list', 'but', 'doe', 'not', 'have', 'component', 'x', 'and', 'y', 'while', 'trying', 'to', 'implement', 'kmeans', 'algorithm', 'in', 'r']","['error', 'xycoordsx', 'xlabel', 'ylabel', 'log', 'x', 'list', 'doe', 'component', 'x', 'trying', 'implement', 'kmeans', 'algorithm', 'r']",error xycoordsx xlabel ylabel log x list doe component x trying implement kmeans algorithm r,0.0,0.0,27,92,3.2857142857142856,0,0,0,0,0,0,0,0
3923,most common qlikview interview question,most common qlikview interview question,"['most', 'common', 'qlikview', 'interview', 'question']",0,"['most', 'common', 'qlikview', 'interview', 'question']","['common', 'qlikview', 'interview', 'question']",common qlikview interview question,0.1,-0.3,5,34,5.666666666666667,0,0,0,0,0,0,0,0
3924,what is the difference between matrix and asmatrix functions in r,what is the difference between matrix and asmatrix functions in r,"['what', 'is', 'the', 'difference', 'between', 'matrix', 'and', 'asmatrix', 'functions', 'in', 'r']",0,"['what', 'is', 'the', 'difference', 'between', 'matrix', 'and', 'asmatrix', 'function', 'in', 'r']","['difference', 'matrix', 'asmatrix', 'function', 'r']",difference matrix asmatrix function r,0.0,0.0,11,37,3.0833333333333335,0,0,0,0,0,0,0,0
3925,regression  dtreerandom forest  boosting,regression  dtreerandom forest  boosting,"['regression', 'dtreerandom', 'forest', 'boosting']",0,"['regression', 'dtreerandom', 'forest', 'boosting']","['regression', 'dtreerandom', 'forest', 'boosting']",regression dtreerandom forest boosting,0.0,0.0,4,38,7.6,0,0,0,0,0,0,0,0
3926,cloning required for mask r cnn,cloning required for mask r cnn,"['cloning', 'required', 'for', 'mask', 'r', 'cnn']",0,"['cloning', 'required', 'for', 'mask', 'r', 'cnn']","['cloning', 'required', 'mask', 'r', 'cnn']",cloning required mask r cnn,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
3927,error with accessing the public api,error with accessing the public api,"['error', 'with', 'accessing', 'the', 'public', 'api']",0,"['error', 'with', 'accessing', 'the', 'public', 'api']","['error', 'accessing', 'public', 'api']",error accessing public api,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
3928,how to convert string to date in pandas dataframe using python,how to convert string to date in pandas dataframe using python,"['how', 'to', 'convert', 'string', 'to', 'date', 'in', 'pandas', 'dataframe', 'using', 'python']",0,"['how', 'to', 'convert', 'string', 'to', 'date', 'in', 'panda', 'dataframe', 'using', 'python']","['convert', 'string', 'date', 'panda', 'dataframe', 'using', 'python']",convert string date panda dataframe using python,0.0,0.0,11,48,4.0,0,0,0,0,0,0,0,0
3929,how the value of mfinal effect in boosting,how the value of mfinal effect in boosting,"['how', 'the', 'value', 'of', 'mfinal', 'effect', 'in', 'boosting']",0,"['how', 'the', 'value', 'of', 'mfinal', 'effect', 'in', 'boosting']","['value', 'mfinal', 'effect', 'boosting']",value mfinal effect boosting,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
3930,why is it required to do anova before doing tukeys hsd,why is it required to do anova before doing tukeys hsd,"['why', 'is', 'it', 'required', 'to', 'do', 'anova', 'before', 'doing', 'tukeys', 'hsd']",0,"['why', 'is', 'it', 'required', 'to', 'do', 'anova', 'before', 'doing', 'tukeys', 'hsd']","['required', 'anova', 'tukeys', 'hsd']",required anova tukeys hsd,0.0,0.0,11,25,2.0833333333333335,0,0,0,0,0,0,0,0
3931,how to manually removeadd a node in decision tree in r,how to manually removeadd a node in decision tree in r,"['how', 'to', 'manually', 'removeadd', 'a', 'node', 'in', 'decision', 'tree', 'in', 'r']",0,"['how', 'to', 'manually', 'removeadd', 'a', 'node', 'in', 'decision', 'tree', 'in', 'r']","['manually', 'removeadd', 'node', 'decision', 'tree', 'r']",manually removeadd node decision tree r,0.0,0.0,11,39,3.25,0,0,0,0,0,0,0,0
3932,data prediction using svm,data prediction using svm,"['data', 'prediction', 'using', 'svm']",0,"['data', 'prediction', 'using', 'svm']","['data', 'prediction', 'using', 'svm']",data prediction using svm,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
3933,glmfit fitted probabilities numerically  or  occurred warning message when i run logistic regression,glmfit fitted probabilities numerically  or  occurred warning message when i run logistic regression,"['glmfit', 'fitted', 'probabilities', 'numerically', 'or', 'occurred', 'warning', 'message', 'when', 'i', 'run', 'logistic', 'regression']",2,"['glmfit', 'fitted', 'probability', 'numerically', 'or', 'occurred', 'warning', 'message', 'when', 'i', 'run', 'logistic', 'regression']","['glmfit', 'fitted', 'probability', 'numerically', 'occurred', 'warning', 'message', 'run', 'logistic', 'regression']",glmfit fitted probability numerically occurred warning message run logistic regression,0.0,0.0,13,86,6.142857142857143,0,0,0,0,0,0,0,0
3934,predicting future events,predicting future events,"['predicting', 'future', 'events']",0,"['predicting', 'future', 'event']","['predicting', 'future', 'event']",predicting future event,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
3935,question regarding skilltest,question regarding skilltest,"['question', 'regarding', 'skilltest']",0,"['question', 'regarding', 'skilltest']","['question', 'regarding', 'skilltest']",question regarding skilltest,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
3936,memory error digits recognition in python av article   trainx  npstacktemp and in testx  npstacktemp,memory error digits recognition in python av article   trainx  npstacktemp and in testx  npstacktemp,"['memory', 'error', 'digits', 'recognition', 'in', 'python', 'av', 'article', 'trainx', 'npstacktemp', 'and', 'in', 'testx', 'npstacktemp']",0,"['memory', 'error', 'digit', 'recognition', 'in', 'python', 'av', 'article', 'trainx', 'npstacktemp', 'and', 'in', 'testx', 'npstacktemp']","['memory', 'error', 'digit', 'recognition', 'python', 'av', 'article', 'trainx', 'npstacktemp', 'testx', 'npstacktemp']",memory error digit recognition python av article trainx npstacktemp testx npstacktemp,0.0,0.0,14,85,5.666666666666667,0,0,0,0,0,0,0,0
3937,knn quiz query  loocv in knn,knn quiz query  loocv in knn,"['knn', 'quiz', 'query', 'loocv', 'in', 'knn']",0,"['knn', 'quiz', 'query', 'loocv', 'in', 'knn']","['knn', 'quiz', 'query', 'loocv', 'knn']",knn quiz query loocv knn,0.0,0.0,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
3938,drop multiple variables of similar name in sas,drop multiple variables of similar name in sas,"['drop', 'multiple', 'variables', 'of', 'similar', 'name', 'in', 'sas']",0,"['drop', 'multiple', 'variable', 'of', 'similar', 'name', 'in', 'sa']","['drop', 'multiple', 'variable', 'similar', 'name', 'sa']",drop multiple variable similar name sa,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
3939,how to select the inner matrix of a multiple index series in python,how to select the inner matrix of a multiple index series in python,"['how', 'to', 'select', 'the', 'inner', 'matrix', 'of', 'a', 'multiple', 'index', 'series', 'in', 'python']",0,"['how', 'to', 'select', 'the', 'inner', 'matrix', 'of', 'a', 'multiple', 'index', 'series', 'in', 'python']","['select', 'inner', 'matrix', 'multiple', 'index', 'series', 'python']",select inner matrix multiple index series python,0.0,0.0,13,48,3.4285714285714284,0,0,0,0,0,0,0,0
3940,is it worth learning aws for data engineer,is it worth learning aws for data engineer,"['is', 'it', 'worth', 'learning', 'aws', 'for', 'data', 'engineer']",0,"['is', 'it', 'worth', 'learning', 'aws', 'for', 'data', 'engineer']","['worth', 'learning', 'aws', 'data', 'engineer']",worth learning aws data engineer,0.3,0.3,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
3941,what should be the allowed percentage of missing values,what should be the allowed percentage of missing values,"['what', 'should', 'be', 'the', 'allowed', 'percentage', 'of', 'missing', 'values']",0,"['what', 'should', 'be', 'the', 'allowed', 'percentage', 'of', 'missing', 'value']","['allowed', 'percentage', 'missing', 'value']",allowed percentage missing value,-0.2,-0.2,9,32,3.2,0,0,0,0,0,0,0,0
3942,time series forecasting,time series forecasting,"['time', 'series', 'forecasting']",0,"['time', 'series', 'forecasting']","['time', 'series', 'forecasting']",time series forecasting,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
3943,analytics course part time vs full time,analytics course part time vs full time,"['analytics', 'course', 'part', 'time', 'vs', 'full', 'time']",0,"['analytics', 'course', 'part', 'time', 'v', 'full', 'time']","['analytics', 'course', 'part', 'time', 'v', 'full', 'time']",analytics course part time v full time,0.35,0.35,7,38,4.75,0,0,0,0,0,0,0,0
3944,writing ann in excel vba,writing ann in excel vba,"['writing', 'ann', 'in', 'excel', 'vba']",0,"['writing', 'ann', 'in', 'excel', 'vba']","['writing', 'ann', 'excel', 'vba']",writing ann excel vba,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
3945,why do we use the tstatistic to find out the significance of the predictors while we use the zstatistic to compute the confidence interval of the predictor coefficients,why do we use the tstatistic to find out the significance of the predictors while we use the zstatistic to compute the confidence interval of the predictor coefficients,"['why', 'do', 'we', 'use', 'the', 'tstatistic', 'to', 'find', 'out', 'the', 'significance', 'of', 'the', 'predictors', 'while', 'we', 'use', 'the', 'zstatistic', 'to', 'compute', 'the', 'confidence', 'interval', 'of', 'the', 'predictor', 'coefficients']",0,"['why', 'do', 'we', 'use', 'the', 'tstatistic', 'to', 'find', 'out', 'the', 'significance', 'of', 'the', 'predictor', 'while', 'we', 'use', 'the', 'zstatistic', 'to', 'compute', 'the', 'confidence', 'interval', 'of', 'the', 'predictor', 'coefficient']","['use', 'tstatistic', 'find', 'significance', 'predictor', 'use', 'zstatistic', 'compute', 'confidence', 'interval', 'predictor', 'coefficient']",use tstatistic find significance predictor use zstatistic compute confidence interval predictor coefficient,0.0,0.0,28,107,3.689655172413793,0,0,0,0,0,0,0,0
3946,multiple categorical iv single continuous dv,multiple categorical iv single continuous dv,"['multiple', 'categorical', 'iv', 'single', 'continuous', 'dv']",0,"['multiple', 'categorical', 'iv', 'single', 'continuous', 'dv']","['multiple', 'categorical', 'iv', 'single', 'continuous', 'dv']",multiple categorical iv single continuous dv,-0.0357142857142857,-0.0357142857142857,6,44,6.285714285714286,0,0,0,0,0,0,0,0
3947,training object detection algorithm,training object detection algorithm,"['training', 'object', 'detection', 'algorithm']",0,"['training', 'object', 'detection', 'algorithm']","['training', 'object', 'detection', 'algorithm']",training object detection algorithm,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
3948,how to subset the array using boolean array in ipython,how to subset the array using boolean array in ipython,"['how', 'to', 'subset', 'the', 'array', 'using', 'boolean', 'array', 'in', 'ipython']",0,"['how', 'to', 'subset', 'the', 'array', 'using', 'boolean', 'array', 'in', 'ipython']","['subset', 'array', 'using', 'boolean', 'array', 'ipython']",subset array using boolean array ipython,0.0,0.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
3949,catboost missing value handling,catboost missing value handling,"['catboost', 'missing', 'value', 'handling']",0,"['catboost', 'missing', 'value', 'handling']","['catboost', 'missing', 'value', 'handling']",catboost missing value handling,-0.2,-0.2,4,31,6.2,0,0,0,0,0,0,0,0
3950,finding average of features generated to create template for prediction of class of object,finding average of features generated to create template for prediction of class of object,"['finding', 'average', 'of', 'features', 'generated', 'to', 'create', 'template', 'for', 'prediction', 'of', 'class', 'of', 'object']",0,"['finding', 'average', 'of', 'feature', 'generated', 'to', 'create', 'template', 'for', 'prediction', 'of', 'class', 'of', 'object']","['finding', 'average', 'feature', 'generated', 'create', 'template', 'prediction', 'class', 'object']",finding average feature generated create template prediction class object,-0.15,-0.15,14,73,4.866666666666666,0,0,0,0,0,0,0,0
3951,can r and sas be simultaneously learnt  time constraint,can r and sas be simultaneously learnt  time constraint,"['can', 'r', 'and', 'sas', 'be', 'simultaneously', 'learnt', 'time', 'constraint']",0,"['can', 'r', 'and', 'sa', 'be', 'simultaneously', 'learnt', 'time', 'constraint']","['r', 'sa', 'simultaneously', 'learnt', 'time', 'constraint']",r sa simultaneously learnt time constraint,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
3952,how to check the level of each variable in data,how to check the level of each variable in data,"['how', 'to', 'check', 'the', 'level', 'of', 'each', 'variable', 'in', 'data']",0,"['how', 'to', 'check', 'the', 'level', 'of', 'each', 'variable', 'in', 'data']","['check', 'level', 'variable', 'data']",check level variable data,0.0,0.0,10,25,2.272727272727273,0,0,0,0,0,0,0,0
3953,how to import multiple files from a specific folder in sas,how to import multiple files from a specific folder in sas,"['how', 'to', 'import', 'multiple', 'files', 'from', 'a', 'specific', 'folder', 'in', 'sas']",0,"['how', 'to', 'import', 'multiple', 'file', 'from', 'a', 'specific', 'folder', 'in', 'sa']","['import', 'multiple', 'file', 'specific', 'folder', 'sa']",import multiple file specific folder sa,0.0,0.0,11,39,3.25,0,0,0,0,0,0,0,0
3954,kaggle competitions,kaggle competitions,"['kaggle', 'competitions']",0,"['kaggle', 'competition']","['kaggle', 'competition']",kaggle competition,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
3955,hansa cequity hiring hack  download data set here,hansa cequity hiring hack  download data set here,"['hansa', 'cequity', 'hiring', 'hack', 'download', 'data', 'set', 'here']",0,"['hansa', 'cequity', 'hiring', 'hack', 'download', 'data', 'set', 'here']","['hansa', 'cequity', 'hiring', 'hack', 'download', 'data', 'set']",hansa cequity hiring hack download data set,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
3956,panel data regression analysis  whether to use panel structure,panel data regression analysis  whether to use panel structure,"['panel', 'data', 'regression', 'analysis', 'whether', 'to', 'use', 'panel', 'structure']",0,"['panel', 'data', 'regression', 'analysis', 'whether', 'to', 'use', 'panel', 'structure']","['panel', 'data', 'regression', 'analysis', 'whether', 'use', 'panel', 'structure']",panel data regression analysis whether use panel structure,0.0,0.0,9,58,5.8,0,0,0,0,0,0,0,0
3957,should i learn julia to perform statistical modeling,should i learn julia to perform statistical modeling,"['should', 'i', 'learn', 'julia', 'to', 'perform', 'statistical', 'modeling']",0,"['should', 'i', 'learn', 'julia', 'to', 'perform', 'statistical', 'modeling']","['learn', 'julia', 'perform', 'statistical', 'modeling']",learn julia perform statistical modeling,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
3958,terminology distributions,terminology distributions,"['terminology', 'distributions']",0,"['terminology', 'distribution']","['terminology', 'distribution']",terminology distribution,0.0,0.0,2,24,8.0,0,0,0,0,0,0,0,0
3959,error while performing gridsearch in r,error while performing gridsearch in r,"['error', 'while', 'performing', 'gridsearch', 'in', 'r']",0,"['error', 'while', 'performing', 'gridsearch', 'in', 'r']","['error', 'performing', 'gridsearch', 'r']",error performing gridsearch r,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
3960,typeerror when finding mode for each outlettype,typeerror when finding mode for each outlettype,"['typeerror', 'when', 'finding', 'mode', 'for', 'each', 'outlettype']",0,"['typeerror', 'when', 'finding', 'mode', 'for', 'each', 'outlettype']","['typeerror', 'finding', 'mode', 'outlettype']",typeerror finding mode outlettype,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
3961,is learning sap important to be an analyst or would sas and r suffice,is learning sap important to be an analyst or would sas and r suffice,"['is', 'learning', 'sap', 'important', 'to', 'be', 'an', 'analyst', 'or', 'would', 'sas', 'and', 'r', 'suffice']",0,"['is', 'learning', 'sap', 'important', 'to', 'be', 'an', 'analyst', 'or', 'would', 'sa', 'and', 'r', 'suffice']","['learning', 'sap', 'important', 'analyst', 'would', 'sa', 'r', 'suffice']",learning sap important analyst would sa r suffice,0.4,0.4,14,49,3.2666666666666666,0,0,0,0,0,0,0,0
3962,light gradient boosting,light gradient boosting,"['light', 'gradient', 'boosting']",0,"['light', 'gradient', 'boosting']","['light', 'gradient', 'boosting']",light gradient boosting,0.4,0.4,3,23,5.75,0,0,0,0,0,0,0,0
3963,which statistical analysis method to use nominal data,which statistical analysis method to use nominal data,"['which', 'statistical', 'analysis', 'method', 'to', 'use', 'nominal', 'data']",0,"['which', 'statistical', 'analysis', 'method', 'to', 'use', 'nominal', 'data']","['statistical', 'analysis', 'method', 'use', 'nominal', 'data']",statistical analysis method use nominal data,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
3964,how to build a chatbot,how to build a chatbot,"['how', 'to', 'build', 'a', 'chatbot']",0,"['how', 'to', 'build', 'a', 'chatbot']","['build', 'chatbot']",build chatbot,0.0,0.0,5,13,2.1666666666666665,0,0,0,0,0,0,0,0
3965,why is the validation error coming to be nan in boosting in r,why is the validation error coming to be nan in boosting in r,"['why', 'is', 'the', 'validation', 'error', 'coming', 'to', 'be', 'nan', 'in', 'boosting', 'in', 'r']",0,"['why', 'is', 'the', 'validation', 'error', 'coming', 'to', 'be', 'nan', 'in', 'boosting', 'in', 'r']","['validation', 'error', 'coming', 'nan', 'boosting', 'r']",validation error coming nan boosting r,0.0,0.0,13,38,2.7142857142857144,0,0,0,0,0,0,0,0
3966,help create ids of an igraph graph using internal ids,help create ids of an igraph graph using internal ids,"['help', 'create', 'ids', 'of', 'an', 'igraph', 'graph', 'using', '', 'internal', '', 'ids']",0,"['help', 'create', 'id', 'of', 'an', 'igraph', 'graph', 'using', '', 'internal', '', 'id']","['help', 'create', 'id', 'igraph', 'graph', 'using', '', 'internal', '', 'id']",help create id igraph graph using  internal  id,0.0,0.0,12,49,3.769230769230769,0,0,0,0,0,0,0,0
3967,how to resolve not enough distinct predictions to compute area under the roc curve error in gbm,how to resolve not enough distinct predictions to compute area under the roc curve error in gbm,"['how', 'to', 'resolve', 'not', 'enough', 'distinct', 'predictions', 'to', 'compute', 'area', 'under', 'the', 'roc', 'curve', 'error', 'in', 'gbm']",0,"['how', 'to', 'resolve', 'not', 'enough', 'distinct', 'prediction', 'to', 'compute', 'area', 'under', 'the', 'roc', 'curve', 'error', 'in', 'gbm']","['resolve', 'enough', 'distinct', 'prediction', 'compute', 'area', 'roc', 'curve', 'error', 'gbm']",resolve enough distinct prediction compute area roc curve error gbm,0.15,0.15,17,67,3.7222222222222223,0,0,0,0,0,0,0,0
3968,error metrics regression,error metrics regression,"['error', 'metrics', 'regression']",0,"['error', 'metric', 'regression']","['error', 'metric', 'regression']",error metric regression,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
3969,how to calculate confidence interval ,how to calculate confidence interval ,"['how', 'to', 'calculate', 'confidence', 'interval']",0,"['how', 'to', 'calculate', 'confidence', 'interval']","['calculate', 'confidence', 'interval']",calculate confidence interval,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
3970,regcareer shift to analytics after  yr exp in it nd  yr of break after that,regcareer shift to analytics after  yr exp in it nd  yr of break after that,"['regcareer', 'shift', 'to', 'analytics', 'after', 'yr', 'exp', 'in', 'it', 'nd', 'yr', 'of', 'break', 'after', 'that']",2,"['regcareer', 'shift', 'to', 'analytics', 'after', 'yr', 'exp', 'in', 'it', 'nd', 'yr', 'of', 'break', 'after', 'that']","['regcareer', 'shift', 'analytics', 'yr', 'exp', 'nd', 'yr', 'break']",regcareer shift analytics yr exp nd yr break,0.0,0.0,15,44,2.75,0,0,0,0,0,0,0,0
3971,what are some good resources for text analytics in r,what are some good resources for text analytics in r,"['what', 'are', 'some', 'good', 'resources', 'for', 'text', 'analytics', 'in', 'r']",0,"['what', 'are', 'some', 'good', 'resource', 'for', 'text', 'analytics', 'in', 'r']","['good', 'resource', 'text', 'analytics', 'r']",good resource text analytics r,0.7,0.7,10,30,2.727272727272727,0,0,0,0,0,0,0,0
3972,use of pdmerge for merging two databases,use of pdmerge for merging two databases,"['use', 'of', 'pdmerge', 'for', 'merging', 'two', 'databases']",0,"['use', 'of', 'pdmerge', 'for', 'merging', 'two', 'database']","['use', 'pdmerge', 'merging', 'two', 'database']",use pdmerge merging two database,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
3973,video recomendation,video recomendation,"['video', 'recomendation']",0,"['video', 'recomendation']","['video', 'recomendation']",video recomendation,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
3974,chi square test for independence of  categorical variables,chi square test for independence of  categorical variables,"['chi', 'square', 'test', 'for', 'independence', 'of', 'categorical', 'variables']",1,"['chi', 'square', 'test', 'for', 'independence', 'of', 'categorical', 'variable']","['chi', 'square', 'test', 'independence', 'categorical', 'variable']",chi square test independence categorical variable,0.0,0.0,8,49,5.444444444444445,0,0,0,0,0,0,0,0
3975,massive open online courses,massive open online courses,"['massive', 'open', 'online', 'courses']",0,"['massive', 'open', 'online', 'course']","['massive', 'open', 'online', 'course']",massive open online course,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
3976,how to calculate the performance of boosting model at each iteration,how to calculate the performance of boosting model at each iteration,"['how', 'to', 'calculate', 'the', 'performance', 'of', 'boosting', 'model', 'at', 'each', 'iteration']",0,"['how', 'to', 'calculate', 'the', 'performance', 'of', 'boosting', 'model', 'at', 'each', 'iteration']","['calculate', 'performance', 'boosting', 'model', 'iteration']",calculate performance boosting model iteration,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
3977,combining two classifications for ensemble learning in r,combining two classifications for ensemble learning in r,"['combining', 'two', 'classifications', 'for', 'ensemble', 'learning', 'in', 'r']",0,"['combining', 'two', 'classification', 'for', 'ensemble', 'learning', 'in', 'r']","['combining', 'two', 'classification', 'ensemble', 'learning', 'r']",combining two classification ensemble learning r,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
3978,how to use the predict function of arima,how to use the predict function of arima,"['how', 'to', 'use', 'the', 'predict', 'function', 'of', 'arima']",0,"['how', 'to', 'use', 'the', 'predict', 'function', 'of', 'arima']","['use', 'predict', 'function', 'arima']",use predict function arima,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
3979,why are degrees of freedom calculated while calculating the residual standard error in linear regression,why are degrees of freedom calculated while calculating the residual standard error in linear regression,"['why', 'are', 'degrees', 'of', 'freedom', 'calculated', 'while', 'calculating', 'the', 'residual', 'standard', 'error', 'in', 'linear', 'regression']",0,"['why', 'are', 'degree', 'of', 'freedom', 'calculated', 'while', 'calculating', 'the', 'residual', 'standard', 'error', 'in', 'linear', 'regression']","['degree', 'freedom', 'calculated', 'calculating', 'residual', 'standard', 'error', 'linear', 'regression']",degree freedom calculated calculating residual standard error linear regression,0.0,0.0,15,79,4.9375,0,0,0,0,0,0,0,0
3980,error while converting a vector of text strings to a corpus in r,error while converting a vector of text strings to a corpus in r,"['error', 'while', 'converting', 'a', 'vector', 'of', 'text', 'strings', 'to', 'a', 'corpus', 'in', 'r']",0,"['error', 'while', 'converting', 'a', 'vector', 'of', 'text', 'string', 'to', 'a', 'corpus', 'in', 'r']","['error', 'converting', 'vector', 'text', 'string', 'corpus', 'r']",error converting vector text string corpus r,0.0,0.0,13,44,3.142857142857143,0,0,0,0,0,0,0,0
3981,forecast scores of students,forecast scores of students,"['forecast', 'scores', 'of', 'students']",0,"['forecast', 'score', 'of', 'student']","['forecast', 'score', 'student']",forecast score student,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
3982,how to send image in email via sas ods,how to send image in email via sas ods,"['how', 'to', 'send', 'image', 'in', 'email', 'via', 'sas', 'ods']",0,"['how', 'to', 'send', 'image', 'in', 'email', 'via', 'sa', 'od']","['send', 'image', 'email', 'via', 'sa', 'od']",send image email via sa od,0.0,0.0,9,26,2.6,0,0,0,0,0,0,0,0
3983,normalisation of target varible,normalisation of target varible,"['normalisation', 'of', 'target', 'varible']",0,"['normalisation', 'of', 'target', 'varible']","['normalisation', 'target', 'varible']",normalisation target varible,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
3984,machine learning project ideas,machine learning project ideas,"['machine', 'learning', 'project', 'ideas']",0,"['machine', 'learning', 'project', 'idea']","['machine', 'learning', 'project', 'idea']",machine learning project idea,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
3985,predicting new product performance,predicting new product performance,"['predicting', 'new', 'product', 'performance']",0,"['predicting', 'new', 'product', 'performance']","['predicting', 'new', 'product', 'performance']",predicting new product performance,0.1363636363636363,0.1363636363636363,4,34,6.8,0,0,0,0,0,0,0,0
3986,finding frequently occuring items,finding frequently occuring items,"['finding', 'frequently', 'occuring', 'items']",0,"['finding', 'frequently', 'occuring', 'item']","['finding', 'frequently', 'occuring', 'item']",finding frequently occuring item,0.1,0.1,4,32,6.4,0,0,0,0,0,0,0,0
3987,r text classificaton bayesian network,r text classificaton bayesian network,"['r', 'text', 'classificaton', 'bayesian', 'network']",0,"['r', 'text', 'classificaton', 'bayesian', 'network']","['r', 'text', 'classificaton', 'bayesian', 'network']",r text classificaton bayesian network,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
3988,iv categorical variable for logistic regression,iv categorical variable for logistic regression,"['iv', 'categorical', 'variable', 'for', 'logistic', 'regression']",0,"['iv', 'categorical', 'variable', 'for', 'logistic', 'regression']","['iv', 'categorical', 'variable', 'logistic', 'regression']",iv categorical variable logistic regression,0.0,0.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
3989,variable selection,variable selection,"['variable', 'selection']",0,"['variable', 'selection']","['variable', 'selection']",variable selection,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
3990,how to build loan default forecasting model,how to build loan default forecasting model,"['how', 'to', 'build', 'loan', 'default', 'forecasting', 'model']",0,"['how', 'to', 'build', 'loan', 'default', 'forecasting', 'model']","['build', 'loan', 'default', 'forecasting', 'model']",build loan default forecasting model,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
3991,how can i do hands on pratice on python,how can i do hands on pratice on python,"['how', 'can', 'i', 'do', 'hands', 'on', 'pratice', 'on', 'python']",0,"['how', 'can', 'i', 'do', 'hand', 'on', 'pratice', 'on', 'python']","['hand', 'pratice', 'python']",hand pratice python,0.0,0.0,9,19,1.9,0,0,0,0,0,0,0,0
3992,data availability after hackathon ends,data availability after hackathon ends,"['data', 'availability', 'after', 'hackathon', 'ends']",0,"['data', 'availability', 'after', 'hackathon', 'end']","['data', 'availability', 'hackathon', 'end']",data availability hackathon end,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
3993,multilabel classification in r,multilabel classification in r,"['multilabel', 'classification', 'in', 'r']",0,"['multilabel', 'classification', 'in', 'r']","['multilabel', 'classification', 'r']",multilabel classification r,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
3994,combining output deciles or risk score of  or more logistic regression based model into one single output score,combining output deciles or risk score of  or more logistic regression based model into one single output score,"['combining', 'output', 'deciles', 'or', 'risk', 'score', 'of', 'or', 'more', 'logistic', 'regression', 'based', 'model', 'into', 'one', 'single', 'output', 'score']",1,"['combining', 'output', 'decile', 'or', 'risk', 'score', 'of', 'or', 'more', 'logistic', 'regression', 'based', 'model', 'into', 'one', 'single', 'output', 'score']","['combining', 'output', 'decile', 'risk', 'score', 'logistic', 'regression', 'based', 'model', 'one', 'single', 'output', 'score']",combining output decile risk score logistic regression based model one single output score,0.2142857142857143,-0.0714285714285714,18,90,4.7368421052631575,0,0,0,0,0,0,0,0
3995,gradient descent confusion,gradient descent confusion,"['gradient', 'descent', 'confusion']",0,"['gradient', 'descent', 'confusion']","['gradient', 'descent', 'confusion']",gradient descent confusion,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
3996,best practices used while building models,best practices used while building models,"['best', 'practices', 'used', 'while', 'building', 'models']",0,"['best', 'practice', 'used', 'while', 'building', 'model']","['best', 'practice', 'used', 'building', 'model']",best practice used building model,1.0,1.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
3997,digital marketing in finacial industry,digital marketing in finacial industry,"['digital', 'marketing', 'in', 'finacial', 'industry']",0,"['digital', 'marketing', 'in', 'finacial', 'industry']","['digital', 'marketing', 'finacial', 'industry']",digital marketing finacial industry,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
3998,how to practice tableau are they any competitions held to get handson,how to practice tableau are they any competitions held to get handson,"['how', 'to', 'practice', 'tableau', 'are', 'they', 'any', 'competitions', 'held', 'to', 'get', 'handson']",0,"['how', 'to', 'practice', 'tableau', 'are', 'they', 'any', 'competition', 'held', 'to', 'get', 'handson']","['practice', 'tableau', 'competition', 'held', 'get', 'handson']",practice tableau competition held get handson,0.0,0.0,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
3999,how to join two different graphs together side by side in r,how to join two different graphs together side by side in r,"['how', 'to', 'join', 'two', 'different', 'graphs', 'together', 'side', 'by', 'side', 'in', 'r']",0,"['how', 'to', 'join', 'two', 'different', 'graph', 'together', 'side', 'by', 'side', 'in', 'r']","['join', 'two', 'different', 'graph', 'together', 'side', 'side', 'r']",join two different graph together side side r,0.0,0.0,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
4000,help me to understand backpropagation in neural network,help me to understand backpropagation in neural network,"['help', 'me', 'to', 'understand', 'backpropagation', 'in', 'neural', 'network']",0,"['help', 'me', 'to', 'understand', 'backpropagation', 'in', 'neural', 'network']","['help', 'understand', 'backpropagation', 'neural', 'network']",help understand backpropagation neural network,0.0,0.0,8,46,5.111111111111111,0,0,0,0,0,0,0,0
4001,how do understand anonymized data data without column names,how do understand anonymized data data without column names,"['how', 'do', 'understand', 'anonymized', 'data', 'data', 'without', 'column', 'names']",0,"['how', 'do', 'understand', 'anonymized', 'data', 'data', 'without', 'column', 'name']","['understand', 'anonymized', 'data', 'data', 'without', 'column', 'name']",understand anonymized data data without column name,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
4002,output of the sapply function in r,output of the sapply function in r,"['output', 'of', 'the', 'sapply', 'function', 'in', 'r']",0,"['output', 'of', 'the', 'sapply', 'function', 'in', 'r']","['output', 'sapply', 'function', 'r']",output sapply function r,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
4003,data analytics in portfolio or investment management,data analytics in portfolio or investment management,"['data', 'analytics', 'in', 'portfolio', 'or', 'investment', 'management']",0,"['data', 'analytics', 'in', 'portfolio', 'or', 'investment', 'management']","['data', 'analytics', 'portfolio', 'investment', 'management']",data analytics portfolio investment management,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
4004,image type for data set,image type for data set,"['image', 'type', 'for', 'data', 'set']",0,"['image', 'type', 'for', 'data', 'set']","['image', 'type', 'data', 'set']",image type data set,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
4005,how to make sure my data is ready before choosing any algorithm for modelling and analysis,how to make sure my data is ready before choosing any algorithm for modelling and analysis,"['how', 'to', 'make', 'sure', 'my', 'data', 'is', 'ready', 'before', 'choosing', 'any', 'algorithm', 'for', 'modelling', 'and', 'analysis']",0,"['how', 'to', 'make', 'sure', 'my', 'data', 'is', 'ready', 'before', 'choosing', 'any', 'algorithm', 'for', 'modelling', 'and', 'analysis']","['make', 'sure', 'data', 'ready', 'choosing', 'algorithm', 'modelling', 'analysis']",make sure data ready choosing algorithm modelling analysis,0.35,0.35,16,58,3.411764705882353,0,0,0,0,0,0,0,0
4006,how do you backprop in cnn pooling layer,how do you backprop in cnn pooling layer,"['how', 'do', 'you', 'backprop', 'in', 'cnn', 'pooling', 'layer']",0,"['how', 'do', 'you', 'backprop', 'in', 'cnn', 'pooling', 'layer']","['backprop', 'cnn', 'pooling', 'layer']",backprop cnn pooling layer,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
4007,feature selection and model tuning in r,feature selection and model tuning in r,"['feature', 'selection', 'and', 'model', 'tuning', 'in', 'r']",0,"['feature', 'selection', 'and', 'model', 'tuning', 'in', 'r']","['feature', 'selection', 'model', 'tuning', 'r']",feature selection model tuning r,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
4008,databsesneurological,databsesneurological,['databsesneurological'],0,['databsesneurological'],['databsesneurological'],databsesneurological,0.0,0.0,1,20,10.0,0,0,0,0,0,0,0,0
4009,uses of the  operator in r,uses of the  operator in r,"['uses', 'of', 'the', 'operator', 'in', 'r']",0,"['us', 'of', 'the', 'operator', 'in', 'r']","['us', 'operator', 'r']",us operator r,0.0,0.0,6,13,1.8571428571428572,0,0,0,0,0,0,0,0
4010,methods for computing coefficients in linear regression,methods for computing coefficients in linear regression,"['methods', 'for', 'computing', 'coefficients', 'in', 'linear', 'regression']",0,"['method', 'for', 'computing', 'coefficient', 'in', 'linear', 'regression']","['method', 'computing', 'coefficient', 'linear', 'regression']",method computing coefficient linear regression,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
4011,research topics in data science dealing with real life problems,research topics in data science dealing with real life problems,"['research', 'topics', 'in', 'data', 'science', 'dealing', 'with', 'real', 'life', 'problems']",0,"['research', 'topic', 'in', 'data', 'science', 'dealing', 'with', 'real', 'life', 'problem']","['research', 'topic', 'data', 'science', 'dealing', 'real', 'life', 'problem']",research topic data science dealing real life problem,0.2,0.2,10,53,4.818181818181818,0,0,0,0,0,0,0,0
4012,want to enter the field of analytics,want to enter the field of analytics,"['want', 'to', 'enter', 'the', 'field', 'of', 'analytics']",0,"['want', 'to', 'enter', 'the', 'field', 'of', 'analytics']","['want', 'enter', 'field', 'analytics']",want enter field analytics,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
4013,words with multiple meanings  nlp,words with multiple meanings  nlp,"['words', 'with', 'multiple', 'meanings', 'nlp']",0,"['word', 'with', 'multiple', 'meaning', 'nlp']","['word', 'multiple', 'meaning', 'nlp']",word multiple meaning nlp,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
4014,best ways to pick up deep learning skills,best ways to pick up deep learning skills,"['best', 'ways', 'to', 'pick', 'up', 'deep', 'learning', 'skills']",0,"['best', 'way', 'to', 'pick', 'up', 'deep', 'learning', 'skill']","['best', 'way', 'pick', 'deep', 'learning', 'skill']",best way pick deep learning skill,0.5,0.5,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
4015,how to rescale features in r,how to rescale features in r,"['how', 'to', 'rescale', 'features', 'in', 'r']",0,"['how', 'to', 'rescale', 'feature', 'in', 'r']","['rescale', 'feature', 'r']",rescale feature r,0.0,0.0,6,17,2.4285714285714284,0,0,0,0,0,0,0,0
4016,anova and regression,anova and regression,"['anova', 'and', 'regression']",0,"['anova', 'and', 'regression']","['anova', 'regression']",anova regression,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
4017,job prospects after completing pgcertification in ba,job prospects after completing pgcertification in ba,"['job', 'prospects', 'after', 'completing', 'pgcertification', 'in', 'ba']",0,"['job', 'prospect', 'after', 'completing', 'pgcertification', 'in', 'ba']","['job', 'prospect', 'completing', 'pgcertification', 'ba']",job prospect completing pgcertification ba,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
4018,how to add a column to a dataframe in r,how to add a column to a dataframe in r,"['how', 'to', 'add', 'a', 'column', 'to', 'a', 'dataframe', 'in', 'r']",0,"['how', 'to', 'add', 'a', 'column', 'to', 'a', 'dataframe', 'in', 'r']","['add', 'column', 'dataframe', 'r']",add column dataframe r,0.0,0.0,10,22,2.0,0,0,0,0,0,0,0,0
4019,replacing for loop in pandas python search and replace,replacing for loop in pandas python search and replace,"['replacing', 'for', 'loop', 'in', 'pandas', 'python', 'search', 'and', 'replace']",0,"['replacing', 'for', 'loop', 'in', 'panda', 'python', 'search', 'and', 'replace']","['replacing', 'loop', 'panda', 'python', 'search', 'replace']",replacing loop panda python search replace,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
4020,logistic regression for categorical variables,logistic regression for categorical variables,"['logistic', 'regression', 'for', 'categorical', 'variables']",0,"['logistic', 'regression', 'for', 'categorical', 'variable']","['logistic', 'regression', 'categorical', 'variable']",logistic regression categorical variable,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
4021,create a new variable based on values frequency of existing variable in python,create a new variable based on values frequency of existing variable in python,"['create', 'a', 'new', 'variable', 'based', 'on', 'values', 'frequency', 'of', 'existing', 'variable', 'in', 'python']",0,"['create', 'a', 'new', 'variable', 'based', 'on', 'value', 'frequency', 'of', 'existing', 'variable', 'in', 'python']","['create', 'new', 'variable', 'based', 'value', 'frequency', 'existing', 'variable', 'python']",create new variable based value frequency existing variable python,0.1363636363636363,0.1363636363636363,13,66,4.714285714285714,0,0,0,0,0,0,0,0
4022,multinomial logistic regression from scratch,multinomial logistic regression from scratch,"['multinomial', 'logistic', 'regression', 'from', 'scratch']",0,"['multinomial', 'logistic', 'regression', 'from', 'scratch']","['multinomial', 'logistic', 'regression', 'scratch']",multinomial logistic regression scratch,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
4023,significance of degree of freedom,significance of degree of freedom,"['significance', 'of', 'degree', 'of', 'freedom']",0,"['significance', 'of', 'degree', 'of', 'freedom']","['significance', 'degree', 'freedom']",significance degree freedom,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
4024,what should be height of tree in random forest,what should be height of tree in random forest,"['what', 'should', 'be', 'height', 'of', 'tree', 'in', 'random', 'forest']",0,"['what', 'should', 'be', 'height', 'of', 'tree', 'in', 'random', 'forest']","['height', 'tree', 'random', 'forest']",height tree random forest,-0.5,-0.5,9,25,2.5,0,0,0,0,0,0,0,0
4025,problem with logistic regression  classification problem,problem with logistic regression  classification problem,"['problem', 'with', 'logistic', 'regression', 'classification', 'problem']",0,"['problem', 'with', 'logistic', 'regression', 'classification', 'problem']","['problem', 'logistic', 'regression', 'classification', 'problem']",problem logistic regression classification problem,0.0,0.0,6,50,7.142857142857143,0,0,0,0,0,0,0,0
4026,regarding online vs full time course of data science,regarding online vs full time course of data science,"['regarding', 'online', 'vs', 'full', 'time', 'course', 'of', 'data', 'science']",0,"['regarding', 'online', 'v', 'full', 'time', 'course', 'of', 'data', 'science']","['regarding', 'online', 'v', 'full', 'time', 'course', 'data', 'science']",regarding online v full time course data science,0.35,0.35,9,48,4.8,0,0,0,0,0,0,0,0
4027,error with readhtml peer certificate cannot be authenticated,error with readhtml peer certificate cannot be authenticated,"['error', 'with', 'readhtml', 'peer', 'certificate', 'can', 'not', 'be', 'authenticated']",0,"['error', 'with', 'readhtml', 'peer', 'certificate', 'can', 'not', 'be', 'authenticated']","['error', 'readhtml', 'peer', 'certificate', 'authenticated']",error readhtml peer certificate authenticated,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
4028,classification of watermarked and nonwatermarked images,classification of watermarked and nonwatermarked images,"['classification', 'of', 'watermarked', 'and', 'nonwatermarked', 'images']",0,"['classification', 'of', 'watermarked', 'and', 'nonwatermarked', 'image']","['classification', 'watermarked', 'nonwatermarked', 'image']",classification watermarked nonwatermarked image,0.0,0.0,6,47,6.714285714285714,0,0,0,0,0,0,0,0
4029,solutions for stategic thinking,solutions for stategic thinking,"['solutions', 'for', 'stategic', 'thinking']",0,"['solution', 'for', 'stategic', 'thinking']","['solution', 'stategic', 'thinking']",solution stategic thinking,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
4030,goodness of fit for binary logistic regression,goodness of fit for binary logistic regression,"['goodness', 'of', 'fit', 'for', 'binary', 'logistic', 'regression']",0,"['goodness', 'of', 'fit', 'for', 'binary', 'logistic', 'regression']","['goodness', 'fit', 'binary', 'logistic', 'regression']",goodness fit binary logistic regression,0.4,0.4,7,39,4.875,0,0,0,0,0,0,0,0
4031,what is the difference between forecasting vs prediction,what is the difference between forecasting vs prediction,"['what', 'is', 'the', 'difference', 'between', 'forecasting', 'vs', 'prediction']",0,"['what', 'is', 'the', 'difference', 'between', 'forecasting', 'v', 'prediction']","['difference', 'forecasting', 'v', 'prediction']",difference forecasting v prediction,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
4032,benford law  fraud prediction,benford law  fraud prediction,"['benford', 'law', 'fraud', 'prediction']",0,"['benford', 'law', 'fraud', 'prediction']","['benford', 'law', 'fraud', 'prediction']",benford law fraud prediction,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
4033,replace missing value with average in sas,replace missing value with average in sas,"['replace', 'missing', 'value', 'with', 'average', 'in', 'sas']",0,"['replace', 'missing', 'value', 'with', 'average', 'in', 'sa']","['replace', 'missing', 'value', 'average', 'sa']",replace missing value average sa,-0.175,-0.175,7,32,4.0,0,0,0,0,0,0,0,0
4034,how to improve the faster rcnn model performance,how to improve the faster rcnn model performance,"['how', 'to', 'improve', 'the', 'faster', 'rcnn', 'model', 'performance']",0,"['how', 'to', 'improve', 'the', 'faster', 'rcnn', 'model', 'performance']","['improve', 'faster', 'rcnn', 'model', 'performance']",improve faster rcnn model performance,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
4035,hypothesis testing  type l and ii errors,hypothesis testing  type l and ii errors,"['hypothesis', 'testing', 'type', 'l', 'and', 'ii', 'errors']",0,"['hypothesis', 'testing', 'type', 'l', 'and', 'ii', 'error']","['hypothesis', 'testing', 'type', 'l', 'ii', 'error']",hypothesis testing type l ii error,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
4036,identify lookalike customers,identify lookalike customers,"['identify', 'lookalike', 'customers']",0,"['identify', 'lookalike', 'customer']","['identify', 'lookalike', 'customer']",identify lookalike customer,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
4037,handling missing categorical data,handling missing categorical data,"['handling', 'missing', 'categorical', 'data']",0,"['handling', 'missing', 'categorical', 'data']","['handling', 'missing', 'categorical', 'data']",handling missing categorical data,-0.2,-0.2,4,33,6.6,0,0,0,0,0,0,0,0
4038,machine learning pattern recognition and data mining,machine learning pattern recognition and data mining,"['machine', 'learning', 'pattern', 'recognition', 'and', 'data', 'mining']",0,"['machine', 'learning', 'pattern', 'recognition', 'and', 'data', 'mining']","['machine', 'learning', 'pattern', 'recognition', 'data', 'mining']",machine learning pattern recognition data mining,0.0,0.0,7,48,6.0,0,0,0,0,0,0,0,0
4039,kaggle scripts execution of single line,kaggle scripts execution of single line,"['kaggle', 'scripts', 'execution', 'of', 'single', 'line']",0,"['kaggle', 'script', 'execution', 'of', 'single', 'line']","['kaggle', 'script', 'execution', 'single', 'line']",kaggle script execution single line,-0.0714285714285714,-0.0714285714285714,6,35,5.0,0,0,0,0,0,0,0,0
4040,text mining in r,text mining in r,"['text', 'mining', 'in', 'r']",0,"['text', 'mining', 'in', 'r']","['text', 'mining', 'r']",text mining r,0.0,0.0,4,13,2.6,0,0,0,0,0,0,0,0
4041,how does bayesian voting work in ensemble mthods,how does bayesian voting work in ensemble mthods,"['how', 'does', 'bayesian', 'voting', 'work', 'in', 'ensemble', 'mthods']",0,"['how', 'doe', 'bayesian', 'voting', 'work', 'in', 'ensemble', 'mthods']","['doe', 'bayesian', 'voting', 'work', 'ensemble', 'mthods']",doe bayesian voting work ensemble mthods,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
4042,converting nested dictionary into dataframe  but one key has multiple values,converting nested dictionary into dataframe  but one key has multiple values,"['converting', 'nested', 'dictionary', 'into', 'dataframe', 'but', 'one', 'key', 'has', 'multiple', 'values']",0,"['converting', 'nested', 'dictionary', 'into', 'dataframe', 'but', 'one', 'key', 'ha', 'multiple', 'value']","['converting', 'nested', 'dictionary', 'dataframe', 'one', 'key', 'ha', 'multiple', 'value']",converting nested dictionary dataframe one key ha multiple value,0.0,0.0,11,64,5.333333333333333,0,0,0,0,0,0,0,0
4043,gate statistics,gate statistics,"['gate', 'statistics']",0,"['gate', 'statistic']","['gate', 'statistic']",gate statistic,0.0,0.0,2,14,4.666666666666667,0,0,0,0,0,0,0,0
4044,how to check the missing values in ipython notebook,how to check the missing values in ipython notebook,"['how', 'to', 'check', 'the', 'missing', 'values', 'in', 'ipython', 'notebook']",0,"['how', 'to', 'check', 'the', 'missing', 'value', 'in', 'ipython', 'notebook']","['check', 'missing', 'value', 'ipython', 'notebook']",check missing value ipython notebook,-0.2,-0.2,9,36,3.6,0,0,0,0,0,0,0,0
4045,understanding machine learning in a minute,understanding machine learning in a minute,"['understanding', 'machine', 'learning', 'in', 'a', 'minute']",0,"['understanding', 'machine', 'learning', 'in', 'a', 'minute']","['understanding', 'machine', 'learning', 'minute']",understanding machine learning minute,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
4046,how can i stack one featureengineering based model and another one nonfeature engineering based model in python,how can i stack one featureengineering based model and another one nonfeature engineering based model in python,"['how', 'can', 'i', 'stack', 'one', 'featureengineering', 'based', 'model', 'and', 'another', 'one', 'nonfeature', 'engineering', 'based', 'model', 'in', 'python']",0,"['how', 'can', 'i', 'stack', 'one', 'featureengineering', 'based', 'model', 'and', 'another', 'one', 'nonfeature', 'engineering', 'based', 'model', 'in', 'python']","['stack', 'one', 'featureengineering', 'based', 'model', 'another', 'one', 'nonfeature', 'engineering', 'based', 'model', 'python']",stack one featureengineering based model another one nonfeature engineering based model python,0.0,0.0,17,94,5.222222222222222,0,0,0,0,0,0,0,0
4047,variable reduction using decision tress,variable reduction using decision tress,"['variable', 'reduction', 'using', 'decision', 'tress']",0,"['variable', 'reduction', 'using', 'decision', 'tress']","['variable', 'reduction', 'using', 'decision', 'tress']",variable reduction using decision tress,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
4048,how to plot horizontal line inside a graph in r,how to plot horizontal line inside a graph in r,"['how', 'to', 'plot', 'horizontal', 'line', 'inside', 'a', 'graph', 'in', 'r']",0,"['how', 'to', 'plot', 'horizontal', 'line', 'inside', 'a', 'graph', 'in', 'r']","['plot', 'horizontal', 'line', 'inside', 'graph', 'r']",plot horizontal line inside graph r,0.0,0.0,10,35,3.1818181818181817,0,0,0,0,0,0,0,0
4049,what is the solution for time series analysis dataset,what is the solution for time series analysis dataset,"['what', 'is', 'the', 'solution', 'for', 'time', 'series', 'analysis', 'dataset']",0,"['what', 'is', 'the', 'solution', 'for', 'time', 'series', 'analysis', 'dataset']","['solution', 'time', 'series', 'analysis', 'dataset']",solution time series analysis dataset,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
4050,seeking methods to compare the techniques used in outlier treatment,seeking methods to compare the techniques used in outlier treatment,"['seeking', 'methods', 'to', 'compare', 'the', 'techniques', 'used', 'in', 'outlier', 'treatment']",0,"['seeking', 'method', 'to', 'compare', 'the', 'technique', 'used', 'in', 'outlier', 'treatment']","['seeking', 'method', 'compare', 'technique', 'used', 'outlier', 'treatment']",seeking method compare technique used outlier treatment,0.0,0.0,10,55,5.0,0,0,0,0,0,0,0,0
4051,how is haversine distance used for weight optimization across trips in r,how is haversine distance used for weight optimization across trips in r,"['how', 'is', 'haversine', 'distance', 'used', 'for', 'weight', 'optimization', 'across', 'trips', 'in', 'r']",0,"['how', 'is', 'haversine', 'distance', 'used', 'for', 'weight', 'optimization', 'across', 'trip', 'in', 'r']","['haversine', 'distance', 'used', 'weight', 'optimization', 'across', 'trip', 'r']",haversine distance used weight optimization across trip r,0.0,0.0,12,57,4.384615384615385,0,0,0,0,0,0,0,0
4052,superset vs plot ly,superset vs plot ly,"['superset', 'vs', 'plot', 'ly']",0,"['superset', 'v', 'plot', 'ly']","['superset', 'v', 'plot', 'ly']",superset v plot ly,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
4053,suggestions for quicker kind of company on analytics,suggestions for quicker kind of company on analytics,"['suggestions', 'for', 'quicker', 'kind', 'of', 'company', 'on', 'analytics']",0,"['suggestion', 'for', 'quicker', 'kind', 'of', 'company', 'on', 'analytics']","['suggestion', 'quicker', 'kind', 'company', 'analytics']",suggestion quicker kind company analytics,0.6,0.6,8,41,4.555555555555555,0,0,0,0,0,0,0,0
4054,best places to read about clustering and classification topics of machine learning,best places to read about clustering and classification topics of machine learning,"['best', 'places', 'to', 'read', 'about', 'clustering', 'and', 'classification', 'topics', 'of', 'machine', 'learning']",0,"['best', 'place', 'to', 'read', 'about', 'clustering', 'and', 'classification', 'topic', 'of', 'machine', 'learning']","['best', 'place', 'read', 'clustering', 'classification', 'topic', 'machine', 'learning']",best place read clustering classification topic machine learning,1.0,1.0,12,64,4.923076923076923,0,0,0,0,0,0,0,0
4055,how to perform element wise functioning in a data frame of a python,how to perform element wise functioning in a data frame of a python,"['how', 'to', 'perform', 'element', 'wise', 'functioning', 'in', 'a', 'data', 'frame', 'of', 'a', 'python']",0,"['how', 'to', 'perform', 'element', 'wise', 'functioning', 'in', 'a', 'data', 'frame', 'of', 'a', 'python']","['perform', 'element', 'wise', 'functioning', 'data', 'frame', 'python']",perform element wise functioning data frame python,0.7,0.7,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
4056,simpsons paradox in regression  solution,simpsons paradox in regression  solution,"['simpsons', 'paradox', 'in', 'regression', 'solution']",0,"['simpson', 'paradox', 'in', 'regression', 'solution']","['simpson', 'paradox', 'regression', 'solution']",simpson paradox regression solution,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
4057,what is the maximum dataset size for xgboost,what is the maximum dataset size for xgboost,"['what', 'is', 'the', 'maximum', 'dataset', 'size', 'for', 'xgboost']",0,"['what', 'is', 'the', 'maximum', 'dataset', 'size', 'for', 'xgboost']","['maximum', 'dataset', 'size', 'xgboost']",maximum dataset size xgboost,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
4058,data manipulation in rcluster analysis,data manipulation in rcluster analysis,"['data', 'manipulation', 'in', 'rcluster', 'analysis']",0,"['data', 'manipulation', 'in', 'rcluster', 'analysis']","['data', 'manipulation', 'rcluster', 'analysis']",data manipulation rcluster analysis,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
4059,online machine learning,online machine learning,"['online', 'machine', 'learning']",0,"['online', 'machine', 'learning']","['online', 'machine', 'learning']",online machine learning,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
4060,book crossing dataset in ml,book crossing dataset in ml,"['book', 'crossing', 'dataset', 'in', 'ml']",0,"['book', 'crossing', 'dataset', 'in', 'ml']","['book', 'crossing', 'dataset', 'ml']",book crossing dataset ml,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
4061,can you suggest any good materials for markov chains,can you suggest any good materials for markov chains,"['can', 'you', 'suggest', 'any', 'good', 'materials', 'for', 'markov', 'chains']",0,"['can', 'you', 'suggest', 'any', 'good', 'material', 'for', 'markov', 'chain']","['suggest', 'good', 'material', 'markov', 'chain']",suggest good material markov chain,0.7,0.7,9,34,3.4,0,0,0,0,0,0,0,0
4062,how to resolve error while importing modules in python,how to resolve error while importing modules in python,"['how', 'to', 'resolve', 'error', 'while', 'importing', 'modules', 'in', 'python']",0,"['how', 'to', 'resolve', 'error', 'while', 'importing', 'module', 'in', 'python']","['resolve', 'error', 'importing', 'module', 'python']",resolve error importing module python,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
4063,how do i set up a corpus of documents using the tm package in r,how do i set up a corpus of documents using the tm package in r,"['how', 'do', 'i', 'set', 'up', 'a', 'corpus', 'of', 'documents', 'using', 'the', 'tm', 'package', 'in', 'r']",0,"['how', 'do', 'i', 'set', 'up', 'a', 'corpus', 'of', 'document', 'using', 'the', 'tm', 'package', 'in', 'r']","['set', 'corpus', 'document', 'using', 'tm', 'package', 'r']",set corpus document using tm package r,0.0,0.0,15,38,2.375,0,0,0,0,0,0,0,0
4064,interpreting the poisson regression output when the input dataset is normalized,interpreting the poisson regression output when the input dataset is normalized,"['interpreting', 'the', 'poisson', 'regression', 'output', 'when', 'the', 'input', 'dataset', 'is', 'normalized']",0,"['interpreting', 'the', 'poisson', 'regression', 'output', 'when', 'the', 'input', 'dataset', 'is', 'normalized']","['interpreting', 'poisson', 'regression', 'output', 'input', 'dataset', 'normalized']",interpreting poisson regression output input dataset normalized,0.0,0.0,11,63,5.25,0,0,0,0,0,0,0,0
4065,interpreting and forecasting using arima or arima models,interpreting and forecasting using arima or arima models,"['interpreting', 'and', 'forecasting', 'using', 'arima', 'or', 'arima', 'models']",0,"['interpreting', 'and', 'forecasting', 'using', 'arima', 'or', 'arima', 'model']","['interpreting', 'forecasting', 'using', 'arima', 'arima', 'model']",interpreting forecasting using arima arima model,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
4066,hackathon check accuracy of your solutions,hackathon check accuracy of your solutions,"['hackathon', 'check', 'accuracy', 'of', 'your', 'solutions']",0,"['hackathon', 'check', 'accuracy', 'of', 'your', 'solution']","['hackathon', 'check', 'accuracy', 'solution']",hackathon check accuracy solution,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
4067,how to shuffle rows in a data frame in r,how to shuffle rows in a data frame in r,"['how', 'to', 'shuffle', 'rows', 'in', 'a', 'data', 'frame', 'in', 'r']",0,"['how', 'to', 'shuffle', 'row', 'in', 'a', 'data', 'frame', 'in', 'r']","['shuffle', 'row', 'data', 'frame', 'r']",shuffle row data frame r,0.0,0.0,10,24,2.1818181818181817,0,0,0,0,0,0,0,0
4068,how to make sense of notes made by executives  text mining or sentimental analysis,how to make sense of notes made by executives  text mining or sentimental analysis,"['how', 'to', 'make', 'sense', 'of', 'notes', 'made', 'by', 'executives', 'text', 'mining', 'or', 'sentimental', 'analysis']",0,"['how', 'to', 'make', 'sense', 'of', 'note', 'made', 'by', 'executive', 'text', 'mining', 'or', 'sentimental', 'analysis']","['make', 'sense', 'note', 'made', 'executive', 'text', 'mining', 'sentimental', 'analysis']",make sense note made executive text mining sentimental analysis,-0.25,-0.25,14,63,4.2,0,0,0,0,0,0,0,0
4069,is it mandatory to have industry knowledge to shift your career,is it mandatory to have industry knowledge to shift your career,"['is', 'it', 'mandatory', 'to', 'have', 'industry', 'knowledge', 'to', 'shift', 'your', 'career']",0,"['is', 'it', 'mandatory', 'to', 'have', 'industry', 'knowledge', 'to', 'shift', 'your', 'career']","['mandatory', 'industry', 'knowledge', 'shift', 'career']",mandatory industry knowledge shift career,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
4070,how to simulate multivariate dataset on random basis,how to simulate multivariate dataset on random basis,"['how', 'to', 'simulate', 'multivariate', 'dataset', 'on', 'random', 'basis']",0,"['how', 'to', 'simulate', 'multivariate', 'dataset', 'on', 'random', 'basis']","['simulate', 'multivariate', 'dataset', 'random', 'basis']",simulate multivariate dataset random basis,-0.5,-0.5,8,42,4.666666666666667,0,0,0,0,0,0,0,0
4071,how to perform multivariate multiclass text classification,how to perform multivariate multiclass text classification,"['how', 'to', 'perform', 'multivariate', 'multiclass', 'text', 'classification']",0,"['how', 'to', 'perform', 'multivariate', 'multiclass', 'text', 'classification']","['perform', 'multivariate', 'multiclass', 'text', 'classification']",perform multivariate multiclass text classification,0.0,0.0,7,51,6.375,0,0,0,0,0,0,0,0
4072,finding percentage of movies rated above ,finding percentage of movies rated above ,"['finding', 'percentage', 'of', 'movies', 'rated', 'above']",1,"['finding', 'percentage', 'of', 'movie', 'rated', 'above']","['finding', 'percentage', 'movie', 'rated']",finding percentage movie rated,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
4073,how to start and get going in ml,how to start and get going in ml,"['how', 'to', 'start', 'and', 'get', 'going', 'in', 'ml']",0,"['how', 'to', 'start', 'and', 'get', 'going', 'in', 'ml']","['start', 'get', 'going', 'ml']",start get going ml,0.0,0.0,8,18,2.0,0,0,0,0,0,0,0,0
4074,applying naive bayes model created in r outside of r,applying naive bayes model created in r outside of r,"['applying', 'naive', 'bayes', 'model', 'created', 'in', 'r', 'outside', 'of', 'r']",0,"['applying', 'naive', 'bayes', 'model', 'created', 'in', 'r', 'outside', 'of', 'r']","['applying', 'naive', 'bayes', 'model', 'created', 'r', 'outside', 'r']",applying naive bayes model created r outside r,-0.15,-0.15,10,46,4.181818181818182,0,0,0,0,0,0,0,0
4075,how to implement gradient boosting,how to implement gradient boosting,"['how', 'to', 'implement', 'gradient', 'boosting']",0,"['how', 'to', 'implement', 'gradient', 'boosting']","['implement', 'gradient', 'boosting']",implement gradient boosting,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
4076,creating a dimension which has only week and month named as period,creating a dimension which has only week and month named as period,"['creating', 'a', 'dimension', 'which', 'has', 'only', 'week', 'and', 'month', 'named', 'as', 'period']",0,"['creating', 'a', 'dimension', 'which', 'ha', 'only', 'week', 'and', 'month', 'named', 'a', 'period']","['creating', 'dimension', 'ha', 'week', 'month', 'named', 'period']",creating dimension ha week month named period,0.0,0.0,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
4077,need help with garch analysis on r,need help with garch analysis on r,"['need', 'help', 'with', 'garch', 'analysis', 'on', 'r']",0,"['need', 'help', 'with', 'garch', 'analysis', 'on', 'r']","['need', 'help', 'garch', 'analysis', 'r']",need help garch analysis r,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
4078,unable to print loop values in r,unable to print loop values in r,"['unable', 'to', 'print', 'loop', 'values', 'in', 'r']",0,"['unable', 'to', 'print', 'loop', 'value', 'in', 'r']","['unable', 'print', 'loop', 'value', 'r']",unable print loop value r,-0.5,-0.5,7,25,3.125,0,0,0,0,0,0,0,0
4079,which is best performance evaluation metric for classification problems  accuracy or aucroc,which is best performance evaluation metric for classification problems  accuracy or aucroc,"['which', 'is', 'best', 'performance', 'evaluation', 'metric', 'for', 'classification', 'problems', 'accuracy', 'or', 'aucroc']",0,"['which', 'is', 'best', 'performance', 'evaluation', 'metric', 'for', 'classification', 'problem', 'accuracy', 'or', 'aucroc']","['best', 'performance', 'evaluation', 'metric', 'classification', 'problem', 'accuracy', 'aucroc']",best performance evaluation metric classification problem accuracy aucroc,1.0,1.0,12,73,5.615384615384615,0,0,0,0,0,0,0,0
4080,cheat sheet  regular expressions,cheat sheet  regular expressions,"['cheat', 'sheet', 'regular', 'expressions']",0,"['cheat', 'sheet', 'regular', 'expression']","['cheat', 'sheet', 'regular', 'expression']",cheat sheet regular expression,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
4081,regardingjobs and career advice in data science,regardingjobs and career advice in data science,"['regardingjobs', 'and', 'career', 'advice', 'in', 'data', 'science']",0,"['regardingjobs', 'and', 'career', 'advice', 'in', 'data', 'science']","['regardingjobs', 'career', 'advice', 'data', 'science']",regardingjobs career advice data science,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
4082,what are the paste and paste functions in r used for,what are the paste and paste functions in r used for,"['what', 'are', 'the', 'paste', 'and', 'paste', 'functions', 'in', 'r', 'used', 'for']",0,"['what', 'are', 'the', 'paste', 'and', 'paste', 'function', 'in', 'r', 'used', 'for']","['paste', 'paste', 'function', 'r', 'used']",paste paste function r used,0.0,0.0,11,27,2.25,0,0,0,0,0,0,0,0
4083,how to impute missing values in time series by moving average in r,how to impute missing values in time series by moving average in r,"['how', 'to', 'impute', 'missing', 'values', 'in', 'time', 'series', 'by', 'moving', 'average', 'in', 'r']",0,"['how', 'to', 'impute', 'missing', 'value', 'in', 'time', 'series', 'by', 'moving', 'average', 'in', 'r']","['impute', 'missing', 'value', 'time', 'series', 'moving', 'average', 'r']",impute missing value time series moving average r,-0.175,-0.175,13,49,3.5,0,0,0,0,0,0,0,0
4084,sp jain or aegis school  which is best for a fresher,sp jain or aegis school  which is best for a fresher,"['sp', 'jain', 'or', 'aegis', 'school', 'which', 'is', 'best', 'for', 'a', 'fresher']",0,"['sp', 'jain', 'or', 'aegis', 'school', 'which', 'is', 'best', 'for', 'a', 'fresher']","['sp', 'jain', 'aegis', 'school', 'best', 'fresher']",sp jain aegis school best fresher,1.0,1.0,11,33,2.75,0,0,0,0,0,0,0,0
4085,random model lorenz curve of uplift curve,random model lorenz curve of uplift curve,"['random', 'model', 'lorenz', 'curve', 'of', 'uplift', 'curve']",0,"['random', 'model', 'lorenz', 'curve', 'of', 'uplift', 'curve']","['random', 'model', 'lorenz', 'curve', 'uplift', 'curve']",random model lorenz curve uplift curve,-0.5,-0.5,7,38,4.75,0,0,0,0,0,0,0,0
4086,text summarization  text summarization using deep learning,text summarization  text summarization using deep learning,"['text', 'summarization', 'text', 'summarization', 'using', 'deep', 'learning']",0,"['text', 'summarization', 'text', 'summarization', 'using', 'deep', 'learning']","['text', 'summarization', 'text', 'summarization', 'using', 'deep', 'learning']",text summarization text summarization using deep learning,0.0,0.0,7,57,7.125,0,0,0,0,0,0,0,0
4087,difference between  and  operators in r,difference between  and  operators in r,"['difference', 'between', 'and', 'operators', 'in', 'r']",0,"['difference', 'between', 'and', 'operator', 'in', 'r']","['difference', 'operator', 'r']",difference operator r,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
4088,retail business understanding,retail business understanding,"['retail', 'business', 'understanding']",0,"['retail', 'business', 'understanding']","['retail', 'business', 'understanding']",retail business understanding,0.0,0.0,3,29,7.25,0,0,0,0,0,0,0,0
4089,errors in logistic regression,errors in logistic regression,"['errors', 'in', 'logistic', 'regression']",0,"['error', 'in', 'logistic', 'regression']","['error', 'logistic', 'regression']",error logistic regression,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
4090,spatial clustering with profiling variablesweights,spatial clustering with profiling variablesweights,"['spatial', 'clustering', 'with', 'profiling', 'variablesweights']",0,"['spatial', 'clustering', 'with', 'profiling', 'variablesweights']","['spatial', 'clustering', 'profiling', 'variablesweights']",spatial clustering profiling variablesweights,0.0,0.0,5,45,7.5,0,0,0,0,0,0,0,0
4091,stepbystep deep learning tutorial to build your own video classification model,stepbystep deep learning tutorial to build your own video classification model,"['stepbystep', 'deep', 'learning', 'tutorial', 'to', 'build', 'your', 'own', 'video', 'classification', 'model']",0,"['stepbystep', 'deep', 'learning', 'tutorial', 'to', 'build', 'your', 'own', 'video', 'classification', 'model']","['stepbystep', 'deep', 'learning', 'tutorial', 'build', 'video', 'classification', 'model']",stepbystep deep learning tutorial build video classification model,0.3,0.0,11,66,5.5,0,0,0,0,0,0,0,0
4092,good read how convolutional neural networks work,good read how convolutional neural networks work,"['good', 'read', 'how', 'convolutional', 'neural', 'networks', 'work']",0,"['good', 'read', 'how', 'convolutional', 'neural', 'network', 'work']","['good', 'read', 'convolutional', 'neural', 'network', 'work']",good read convolutional neural network work,0.7,0.7,7,43,5.375,0,0,0,0,0,0,0,0
4093,how to read and convert xml data into r,how to read and convert xml data into r,"['how', 'to', 'read', 'and', 'convert', 'xml', 'data', 'into', 'r']",0,"['how', 'to', 'read', 'and', 'convert', 'xml', 'data', 'into', 'r']","['read', 'convert', 'xml', 'data', 'r']",read convert xml data r,0.0,0.0,9,23,2.3,0,0,0,0,0,0,0,0
4094,how to get number of rows of subplots in python,how to get number of rows of subplots in python,"['how', 'to', 'get', 'number', 'of', 'rows', 'of', 'subplots', 'in', 'python']",0,"['how', 'to', 'get', 'number', 'of', 'row', 'of', 'subplots', 'in', 'python']","['get', 'number', 'row', 'subplots', 'python']",get number row subplots python,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
4095,statsmodels in python,statsmodels in python,"['statsmodels', 'in', 'python']",0,"['statsmodels', 'in', 'python']","['statsmodels', 'python']",statsmodels python,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
4096,help required to choose processing architecture,help required to choose processing architecture,"['help', 'required', 'to', 'choose', 'processing', 'architecture']",0,"['help', 'required', 'to', 'choose', 'processing', 'architecture']","['help', 'required', 'choose', 'processing', 'architecture']",help required choose processing architecture,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
4097,how can i read first  records of excel file in python,how can i read first  records of excel file in python,"['how', 'can', 'i', 'read', 'first', 'records', 'of', 'excel', 'file', 'in', 'python']",1,"['how', 'can', 'i', 'read', 'first', 'record', 'of', 'excel', 'file', 'in', 'python']","['read', 'first', 'record', 'excel', 'file', 'python']",read first record excel file python,0.25,0.25,11,35,2.9166666666666665,0,0,0,0,0,0,0,0
4098,how to join two data tables in r,how to join two data tables in r,"['how', 'to', 'join', 'two', 'data', 'tables', 'in', 'r']",0,"['how', 'to', 'join', 'two', 'data', 'table', 'in', 'r']","['join', 'two', 'data', 'table', 'r']",join two data table r,0.0,0.0,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
4099,how improved intelligence can push the education sector forward,how improved intelligence can push the education sector forward,"['how', 'improved', 'intelligence', 'can', 'push', 'the', 'education', 'sector', 'forward']",0,"['how', 'improved', 'intelligence', 'can', 'push', 'the', 'education', 'sector', 'forward']","['improved', 'intelligence', 'push', 'education', 'sector', 'forward']",improved intelligence push education sector forward,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
4100,masters in management specializing in business analytics from iiscbangalore,masters in management specializing in business analytics from iiscbangalore,"['masters', 'in', 'management', 'specializing', 'in', 'business', 'analytics', 'from', 'iiscbangalore']",0,"['master', 'in', 'management', 'specializing', 'in', 'business', 'analytics', 'from', 'iiscbangalore']","['master', 'management', 'specializing', 'business', 'analytics', 'iiscbangalore']",master management specializing business analytics iiscbangalore,0.0,0.0,9,63,6.3,0,0,0,0,0,0,0,0
4101,where can i find prelabeled dataset of tweets for sentimental analysis using neural networks,where can i find prelabeled dataset of tweets for sentimental analysis using neural networks,"['where', 'can', 'i', 'find', 'prelabeled', 'dataset', 'of', 'tweets', 'for', 'sentimental', 'analysis', 'using', 'neural', 'networks']",0,"['where', 'can', 'i', 'find', 'prelabeled', 'dataset', 'of', 'tweet', 'for', 'sentimental', 'analysis', 'using', 'neural', 'network']","['find', 'prelabeled', 'dataset', 'tweet', 'sentimental', 'analysis', 'using', 'neural', 'network']",find prelabeled dataset tweet sentimental analysis using neural network,-0.25,-0.25,14,71,4.733333333333333,0,0,0,0,0,0,0,0
4102,incorrect mime type for reading from google drive,incorrect mime type for reading from google drive,"['incorrect', 'mime', 'type', 'for', 'reading', 'from', 'google', 'drive']",0,"['incorrect', 'mime', 'type', 'for', 'reading', 'from', 'google', 'drive']","['incorrect', 'mime', 'type', 'reading', 'google', 'drive']",incorrect mime type reading google drive,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
4103,overfitting on a model,overfitting on a model,"['overfitting', 'on', 'a', 'model']",0,"['overfitting', 'on', 'a', 'model']","['overfitting', 'model']",overfitting model,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
4104,pg diploma in data analytics from iiit bangalore,pg diploma in data analytics from iiit bangalore,"['pg', 'diploma', 'in', 'data', 'analytics', 'from', 'iiit', 'bangalore']",0,"['pg', 'diploma', 'in', 'data', 'analytics', 'from', 'iiit', 'bangalore']","['pg', 'diploma', 'data', 'analytics', 'iiit', 'bangalore']",pg diploma data analytics iiit bangalore,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
4105,suggest online resources for hadoop practice,suggest online resources for hadoop practice,"['suggest', 'online', 'resources', 'for', 'hadoop', 'practice']",0,"['suggest', 'online', 'resource', 'for', 'hadoop', 'practice']","['suggest', 'online', 'resource', 'hadoop', 'practice']",suggest online resource hadoop practice,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
4106,how to simulate matrix rotations for svd in r,how to simulate matrix rotations for svd in r,"['how', 'to', 'simulate', 'matrix', 'rotations', 'for', 'svd', 'in', 'r']",0,"['how', 'to', 'simulate', 'matrix', 'rotation', 'for', 'svd', 'in', 'r']","['simulate', 'matrix', 'rotation', 'svd', 'r']",simulate matrix rotation svd r,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
4107,views on executive program on data mining  analytics from iit roorkee  talentedge,views on executive program on data mining  analytics from iit roorkee  talentedge,"['views', 'on', 'executive', 'program', 'on', 'data', 'mining', 'analytics', 'from', 'iit', 'roorkee', 'talentedge']",0,"['view', 'on', 'executive', 'program', 'on', 'data', 'mining', 'analytics', 'from', 'iit', 'roorkee', 'talentedge']","['view', 'executive', 'program', 'data', 'mining', 'analytics', 'iit', 'roorkee', 'talentedge']",view executive program data mining analytics iit roorkee talentedge,0.0,0.0,12,67,5.153846153846154,0,0,0,0,0,0,0,0
4108,how can i use a cross validation with logistic regression in r,how can i use a cross validation with logistic regression in r,"['how', 'can', 'i', 'use', 'a', 'cross', 'validation', 'with', 'logistic', 'regression', 'in', 'r']",0,"['how', 'can', 'i', 'use', 'a', 'cross', 'validation', 'with', 'logistic', 'regression', 'in', 'r']","['use', 'cross', 'validation', 'logistic', 'regression', 'r']",use cross validation logistic regression r,0.0,0.0,12,42,3.230769230769231,0,0,0,0,0,0,0,0
4109,seeking ideas for data preparation for unique dataset,seeking ideas for data preparation for unique dataset,"['seeking', 'ideas', 'for', 'data', 'preparation', 'for', 'unique', 'dataset']",0,"['seeking', 'idea', 'for', 'data', 'preparation', 'for', 'unique', 'dataset']","['seeking', 'idea', 'data', 'preparation', 'unique', 'dataset']",seeking idea data preparation unique dataset,0.375,0.375,8,44,4.888888888888889,0,0,0,0,0,0,0,0
4110,what are your favourite r hacks and why,what are your favourite r hacks and why,"['what', 'are', 'your', 'favourite', 'r', 'hacks', 'and', 'why']",0,"['what', 'are', 'your', 'favourite', 'r', 'hack', 'and', 'why']","['favourite', 'r', 'hack']",favourite r hack,0.0,0.0,8,16,1.7777777777777777,0,0,0,0,0,0,0,0
4111, common mistakes amateur data scientists make and how to avoid them, common mistakes amateur data scientists make and how to avoid them,"['common', 'mistakes', 'amateur', 'data', 'scientists', 'make', 'and', 'how', 'to', 'avoid', 'them']",1,"['common', 'mistake', 'amateur', 'data', 'scientist', 'make', 'and', 'how', 'to', 'avoid', 'them']","['common', 'mistake', 'amateur', 'data', 'scientist', 'make', 'avoid']",common mistake amateur data scientist make avoid,-0.275,-0.275,11,48,4.0,0,0,0,0,0,0,0,0
4112,interview que  related to what analysis to be used,interview que  related to what analysis to be used,"['interview', 'que', 'related', 'to', 'what', 'analysis', 'to', 'be', 'used']",0,"['interview', 'que', 'related', 'to', 'what', 'analysis', 'to', 'be', 'used']","['interview', 'que', 'related', 'analysis', 'used']",interview que related analysis used,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
4113,model comparision,model comparision,"['model', 'comparision']",0,"['model', 'comparision']","['model', 'comparision']",model comparision,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
4114,i need source code and data set for stock market prediction,i need source code and data set for stock market prediction,"['i', 'need', 'source', 'code', 'and', 'data', 'set', 'for', 'stock', 'market', 'prediction']",0,"['i', 'need', 'source', 'code', 'and', 'data', 'set', 'for', 'stock', 'market', 'prediction']","['need', 'source', 'code', 'data', 'set', 'stock', 'market', 'prediction']",need source code data set stock market prediction,0.0,0.0,11,49,4.083333333333333,0,0,0,0,0,0,0,0
4115,linear regression assumptions testing in r,linear regression assumptions testing in r,"['linear', 'regression', 'assumptions', 'testing', 'in', 'r']",0,"['linear', 'regression', 'assumption', 'testing', 'in', 'r']","['linear', 'regression', 'assumption', 'testing', 'r']",linear regression assumption testing r,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
4116,how to calculate the error in an ensemble technique,how to calculate the error in an ensemble technique,"['how', 'to', 'calculate', 'the', 'error', 'in', 'an', 'ensemble', 'technique']",0,"['how', 'to', 'calculate', 'the', 'error', 'in', 'an', 'ensemble', 'technique']","['calculate', 'error', 'ensemble', 'technique']",calculate error ensemble technique,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
4117,error while converting into date format in r,error while converting into date format in r,"['error', 'while', 'converting', 'into', 'date', 'format', 'in', 'r']",0,"['error', 'while', 'converting', 'into', 'date', 'format', 'in', 'r']","['error', 'converting', 'date', 'format', 'r']",error converting date format r,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
4118,how to substract in r studio,how to substract in r studio,"['how', 'to', 'substract', 'in', 'r', 'studio']",0,"['how', 'to', 'substract', 'in', 'r', 'studio']","['substract', 'r', 'studio']",substract r studio,0.0,0.0,6,18,2.5714285714285716,0,0,0,0,0,0,0,0
4119,how to interpret the result of ranking a series in python,how to interpret the result of ranking a series in python,"['how', 'to', 'interpret', 'the', 'result', 'of', 'ranking', 'a', 'series', 'in', 'python']",0,"['how', 'to', 'interpret', 'the', 'result', 'of', 'ranking', 'a', 'series', 'in', 'python']","['interpret', 'result', 'ranking', 'series', 'python']",interpret result ranking series python,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
4120,seeking guidance to detect create knowledge base for chatbot using ml,seeking guidance to detect create knowledge base for chatbot using ml,"['seeking', 'guidance', 'to', 'detect', 'create', 'knowledge', 'base', 'for', 'chatbot', 'using', 'ml']",0,"['seeking', 'guidance', 'to', 'detect', 'create', 'knowledge', 'base', 'for', 'chatbot', 'using', 'ml']","['seeking', 'guidance', 'detect', 'create', 'knowledge', 'base', 'chatbot', 'using', 'ml']",seeking guidance detect create knowledge base chatbot using ml,-0.8,-0.8,11,62,5.166666666666667,0,0,0,0,0,0,0,0
4121,how to replace missing observation while modeling,how to replace missing observation while modeling,"['how', 'to', 'replace', 'missing', 'observation', 'while', 'modeling']",0,"['how', 'to', 'replace', 'missing', 'observation', 'while', 'modeling']","['replace', 'missing', 'observation', 'modeling']",replace missing observation modeling,-0.2,-0.2,7,36,4.5,0,0,0,0,0,0,0,0
4122,what does the value of votes and prob signifies in bagging,what does the value of votes and prob signifies in bagging,"['what', 'does', 'the', 'value', 'of', 'votes', 'and', 'prob', 'signifies', 'in', 'bagging']",0,"['what', 'doe', 'the', 'value', 'of', 'vote', 'and', 'prob', 'signifies', 'in', 'bagging']","['doe', 'value', 'vote', 'prob', 'signifies', 'bagging']",doe value vote prob signifies bagging,0.0,0.0,11,37,3.0833333333333335,0,0,0,0,0,0,0,0
4123,what would be the expected salary for data science fresher with  years experience,what would be the expected salary for data science fresher with  years experience,"['what', 'would', 'be', 'the', 'expected', 'salary', 'for', 'data', 'science', 'fresher', 'with', 'years', 'experience']",1,"['what', 'would', 'be', 'the', 'expected', 'salary', 'for', 'data', 'science', 'fresher', 'with', 'year', 'experience']","['would', 'expected', 'salary', 'data', 'science', 'fresher', 'year', 'experience']",would expected salary data science fresher year experience,-0.1,-0.1,13,58,4.142857142857143,0,0,0,0,0,0,0,0
4124,variable clustering,variable clustering,"['variable', 'clustering']",0,"['variable', 'clustering']","['variable', 'clustering']",variable clustering,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
4125,merge progress in gantt chart,merge progress in gantt chart,"['merge', 'progress', 'in', 'gantt', 'chart']",0,"['merge', 'progress', 'in', 'gantt', 'chart']","['merge', 'progress', 'gantt', 'chart']",merge progress gantt chart,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
4126,review of nus singapore msba programme ms in business analytics,review of nus singapore msba programme ms in business analytics,"['review', 'of', 'nus', 'singapore', 'msba', 'programme', 'ms', 'in', 'business', 'analytics']",0,"['review', 'of', 'nu', 'singapore', 'msba', 'programme', 'm', 'in', 'business', 'analytics']","['review', 'nu', 'singapore', 'msba', 'programme', 'business', 'analytics']",review nu singapore msba programme business analytics,0.0,0.0,10,53,4.818181818181818,0,0,0,0,0,0,0,0
4127,final step to missing value imputation in r,final step to missing value imputation in r,"['final', 'step', 'to', 'missing', 'value', 'imputation', 'in', 'r']",0,"['final', 'step', 'to', 'missing', 'value', 'imputation', 'in', 'r']","['final', 'step', 'missing', 'value', 'imputation', 'r']",final step missing value imputation r,-0.1,-0.1,8,37,4.111111111111111,0,0,0,0,0,0,0,0
4128,how to calculate number of months between two dates in qlikview,how to calculate number of months between two dates in qlikview,"['how', 'to', 'calculate', 'number', 'of', 'months', 'between', 'two', 'dates', 'in', 'qlikview']",0,"['how', 'to', 'calculate', 'number', 'of', 'month', 'between', 'two', 'date', 'in', 'qlikview']","['calculate', 'number', 'month', 'two', 'date', 'qlikview']",calculate number month two date qlikview,0.0,0.0,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
4129,please help me in joining the datafest online from us,please help me in joining the datafest online from us,"['please', 'help', 'me', 'in', 'joining', 'the', 'datafest', 'online', 'from', 'us']",0,"['please', 'help', 'me', 'in', 'joining', 'the', 'datafest', 'online', 'from', 'u']","['please', 'help', 'joining', 'datafest', 'online', 'u']",please help joining datafest online u,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
4130,parameters tuning random forest,parameters tuning random forest,"['parameters', 'tuning', 'random', 'forest']",0,"['parameter', 'tuning', 'random', 'forest']","['parameter', 'tuning', 'random', 'forest']",parameter tuning random forest,-0.5,-0.5,4,30,6.0,0,0,0,0,0,0,0,0
4131,predictive maintenance for machines,predictive maintenance for machines,"['predictive', 'maintenance', 'for', 'machines']",0,"['predictive', 'maintenance', 'for', 'machine']","['predictive', 'maintenance', 'machine']",predictive maintenance machine,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
4132,r how to relate datasets with multiple predictor values to a single target value for prediction,r how to relate datasets with multiple predictor values to a single target value for prediction,"['r', 'how', 'to', 'relate', 'datasets', 'with', 'multiple', 'predictor', 'values', 'to', 'a', 'single', 'target', 'value', 'for', 'prediction']",0,"['r', 'how', 'to', 'relate', 'datasets', 'with', 'multiple', 'predictor', 'value', 'to', 'a', 'single', 'target', 'value', 'for', 'prediction']","['r', 'relate', 'datasets', 'multiple', 'predictor', 'value', 'single', 'target', 'value', 'prediction']",r relate datasets multiple predictor value single target value prediction,-0.0357142857142857,-0.0357142857142857,16,73,4.294117647058823,0,0,0,0,0,0,0,0
4133,certification in big data vs r for new entrant into analytics,certification in big data vs r for new entrant into analytics,"['certification', 'in', 'big', 'data', 'vs', 'r', 'for', 'new', 'entrant', 'into', 'analytics']",0,"['certification', 'in', 'big', 'data', 'v', 'r', 'for', 'new', 'entrant', 'into', 'analytics']","['certification', 'big', 'data', 'v', 'r', 'new', 'entrant', 'analytics']",certification big data v r new entrant analytics,0.0681818181818181,0.0681818181818181,11,48,4.0,0,0,0,0,0,0,0,0
4134,looking for theoreticalmathematical basis for vector auto regression materials,looking for theoreticalmathematical basis for vector auto regression materials,"['looking', 'for', 'theoreticalmathematical', 'basis', 'for', 'vector', 'auto', 'regression', 'materials']",0,"['looking', 'for', 'theoreticalmathematical', 'basis', 'for', 'vector', 'auto', 'regression', 'material']","['looking', 'theoreticalmathematical', 'basis', 'vector', 'auto', 'regression', 'material']",looking theoreticalmathematical basis vector auto regression material,0.0,0.0,9,69,6.9,0,0,0,0,0,0,0,0
4135,msc business analytics bits pilani,msc business analytics bits pilani,"['msc', 'business', 'analytics', 'bits', 'pilani']",0,"['msc', 'business', 'analytics', 'bit', 'pilani']","['msc', 'business', 'analytics', 'bit', 'pilani']",msc business analytics bit pilani,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
4136,should i learn python first or statistics,should i learn python first or statistics,"['should', 'i', 'learn', 'python', 'first', 'or', 'statistics']",0,"['should', 'i', 'learn', 'python', 'first', 'or', 'statistic']","['learn', 'python', 'first', 'statistic']",learn python first statistic,0.25,0.25,7,28,3.5,0,0,0,0,0,0,0,0
4137,career change from sales to analytics,career change from sales to analytics,"['career', 'change', 'from', 'sales', 'to', 'analytics']",0,"['career', 'change', 'from', 'sale', 'to', 'analytics']","['career', 'change', 'sale', 'analytics']",career change sale analytics,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
4138,resource for beginners in data science,resource for beginners in data science,"['resource', 'for', 'beginners', 'in', 'data', 'science']",0,"['resource', 'for', 'beginner', 'in', 'data', 'science']","['resource', 'beginner', 'data', 'science']",resource beginner data science,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
4139,how to use plot function in ipython notebook,how to use plot function in ipython notebook,"['how', 'to', 'use', 'plot', 'function', 'in', 'ipython', 'notebook']",0,"['how', 'to', 'use', 'plot', 'function', 'in', 'ipython', 'notebook']","['use', 'plot', 'function', 'ipython', 'notebook']",use plot function ipython notebook,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
4140,doubt in conditional subsetting in pandas,doubt in conditional subsetting in pandas,"['doubt', 'in', 'conditional', 'subsetting', 'in', 'pandas']",0,"['doubt', 'in', 'conditional', 'subsetting', 'in', 'panda']","['doubt', 'conditional', 'subsetting', 'panda']",doubt conditional subsetting panda,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
4141,learning  hands on recommendation engines,learning  hands on recommendation engines,"['learning', 'hands', 'on', 'recommendation', 'engines']",0,"['learning', 'hand', 'on', 'recommendation', 'engine']","['learning', 'hand', 'recommendation', 'engine']",learning hand recommendation engine,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
4142,multicollinearity  should this always be avoided,multicollinearity  should this always be avoided,"['multicollinearity', 'should', 'this', 'always', 'be', 'avoided']",0,"['multicollinearity', 'should', 'this', 'always', 'be', 'avoided']","['multicollinearity', 'always', 'avoided']",multicollinearity always avoided,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
4143,using either mean median or mode to describe central tendency of any data,using either mean median or mode to describe central tendency of any data,"['using', 'either', 'mean', 'median', 'or', 'mode', 'to', 'describe', 'central', 'tendency', 'of', 'any', 'data']",0,"['using', 'either', 'mean', 'median', 'or', 'mode', 'to', 'describe', 'central', 'tendency', 'of', 'any', 'data']","['using', 'either', 'mean', 'median', 'mode', 'describe', 'central', 'tendency', 'data']",using either mean median mode describe central tendency data,-0.15625,-0.15625,13,60,4.285714285714286,0,0,0,0,0,0,0,0
4144,cant access the video content in introduction to data science course,cant access the video content in introduction to data science course,"['cant', 'access', 'the', 'video', 'content', 'in', 'introduction', 'to', 'data', 'science', 'course']",0,"['cant', 'access', 'the', 'video', 'content', 'in', 'introduction', 'to', 'data', 'science', 'course']","['cant', 'access', 'video', 'content', 'introduction', 'data', 'science', 'course']",cant access video content introduction data science course,0.0,0.0,11,58,4.833333333333333,0,0,0,0,0,0,0,0
4145,what is the difference between parameter and statistic,what is the difference between parameter and statistic,"['what', 'is', 'the', 'difference', 'between', 'parameter', 'and', 'statistic']",0,"['what', 'is', 'the', 'difference', 'between', 'parameter', 'and', 'statistic']","['difference', 'parameter', 'statistic']",difference parameter statistic,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
4146,what are the techniques to improve the performance of a linearlogistic model,what are the techniques to improve the performance of a linearlogistic model,"['what', 'are', 'the', 'techniques', 'to', 'improve', 'the', 'performance', 'of', 'a', 'linearlogistic', 'model']",0,"['what', 'are', 'the', 'technique', 'to', 'improve', 'the', 'performance', 'of', 'a', 'linearlogistic', 'model']","['technique', 'improve', 'performance', 'linearlogistic', 'model']",technique improve performance linearlogistic model,0.0,0.0,12,50,3.8461538461538463,0,0,0,0,0,0,0,0
4147,hackathon private leaderboard score,hackathon private leaderboard score,"['hackathon', 'private', 'leaderboard', 'score']",0,"['hackathon', 'private', 'leaderboard', 'score']","['hackathon', 'private', 'leaderboard', 'score']",hackathon private leaderboard score,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
4148,can we combine two data frames with similar column names but different order directly in r,can we combine two data frames with similar column names but different order directly in r,"['can', 'we', 'combine', 'two', 'data', 'frames', 'with', 'similar', 'column', 'names', 'but', 'different', 'order', 'directly', 'in', 'r']",0,"['can', 'we', 'combine', 'two', 'data', 'frame', 'with', 'similar', 'column', 'name', 'but', 'different', 'order', 'directly', 'in', 'r']","['combine', 'two', 'data', 'frame', 'similar', 'column', 'name', 'different', 'order', 'directly', 'r']",combine two data frame similar column name different order directly r,0.0333333333333333,0.0333333333333333,16,69,4.0588235294117645,0,0,0,0,0,0,0,0
4149,identify the most isolated locations location id,identify the most isolated locations location id,"['identify', 'the', 'most', 'isolated', 'location', '', 's', 'location', 'id']",0,"['identify', 'the', 'most', 'isolated', 'location', '', 's', 'location', 'id']","['identify', 'isolated', 'location', '', 'location', 'id']",identify isolated location  location id,0.5,0.0,9,40,4.0,0,0,0,0,0,0,0,0
4150,how does gradient boosting deal with class imbalance problem,how does gradient boosting deal with class imbalance problem,"['how', 'does', 'gradient', 'boosting', 'deal', 'with', 'class', 'imbalance', 'problem']",0,"['how', 'doe', 'gradient', 'boosting', 'deal', 'with', 'class', 'imbalance', 'problem']","['doe', 'gradient', 'boosting', 'deal', 'class', 'imbalance', 'problem']",doe gradient boosting deal class imbalance problem,0.0,0.0,9,50,5.0,0,0,0,0,0,0,0,0
4151,what is dimensionality reduction degrees of freedom,what is dimensionality reduction degrees of freedom,"['what', 'is', 'dimensionality', 'reduction', 'degrees', 'of', 'freedom']",0,"['what', 'is', 'dimensionality', 'reduction', 'degree', 'of', 'freedom']","['dimensionality', 'reduction', 'degree', 'freedom']",dimensionality reduction degree freedom,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
4152,sas line chart and graph,sas line chart and graph,"['sas', 'line', 'chart', 'and', 'graph']",0,"['sa', 'line', 'chart', 'and', 'graph']","['sa', 'line', 'chart', 'graph']",sa line chart graph,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
4153,attributeerror module xgboost has no attribute xgbregressor,attributeerror module xgboost has no attribute xgbregressor,"['attributeerror', 'module', 'xgboost', 'has', 'no', 'attribute', 'xgbregressor']",0,"['attributeerror', 'module', 'xgboost', 'ha', 'no', 'attribute', 'xgbregressor']","['attributeerror', 'module', 'xgboost', 'ha', 'attribute', 'xgbregressor']",attributeerror module xgboost ha attribute xgbregressor,0.0,0.0,7,55,6.875,0,0,0,0,0,0,0,0
4154,roc curve in sas without macros,roc curve in sas without macros,"['roc', 'curve', 'in', 'sas', 'without', 'macros']",0,"['roc', 'curve', 'in', 'sa', 'without', 'macro']","['roc', 'curve', 'sa', 'without', 'macro']",roc curve sa without macro,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
4155,join a very large table with a small table  efficient way,join a very large table with a small table  efficient way,"['join', 'a', 'very', 'large', 'table', 'with', 'a', 'small', 'table', 'efficient', 'way']",0,"['join', 'a', 'very', 'large', 'table', 'with', 'a', 'small', 'table', 'efficient', 'way']","['join', 'large', 'table', 'small', 'table', 'efficient', 'way']",join large table small table efficient way,0.0142857142857142,-0.0178571428571428,11,42,3.5,0,0,0,0,0,0,0,0
4156,outlier treatment for predictive modeling,outlier treatment for predictive modeling,"['outlier', 'treatment', 'for', 'predictive', 'modeling']",0,"['outlier', 'treatment', 'for', 'predictive', 'modeling']","['outlier', 'treatment', 'predictive', 'modeling']",outlier treatment predictive modeling,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
4157,maximum levels that can be predicted by naive bayes,maximum levels that can be predicted by naive bayes,"['maximum', 'levels', 'that', 'can', 'be', 'predicted', 'by', 'naive', 'bayes']",0,"['maximum', 'level', 'that', 'can', 'be', 'predicted', 'by', 'naive', 'bayes']","['maximum', 'level', 'predicted', 'naive', 'bayes']",maximum level predicted naive bayes,-0.3,-0.3,9,35,3.5,0,0,0,0,0,0,0,0
4158,how to deal with variables with too many level,how to deal with variables with too many level,"['how', 'to', 'deal', 'with', 'variables', 'with', 'too', 'many', 'level']",0,"['how', 'to', 'deal', 'with', 'variable', 'with', 'too', 'many', 'level']","['deal', 'variable', 'many', 'level']",deal variable many level,0.5,0.5,9,24,2.4,0,0,0,0,0,0,0,0
4159,dataset optimizer sentiment analysis,dataset optimizer sentiment analysis,"['dataset', 'optimizer', 'sentiment', 'analysis']",0,"['dataset', 'optimizer', 'sentiment', 'analysis']","['dataset', 'optimizer', 'sentiment', 'analysis']",dataset optimizer sentiment analysis,0.0,0.0,4,36,7.2,0,0,0,0,0,0,0,0
4160,spark dataframes how to work with dense vectors and sparse vectors,spark dataframes how to work with dense vectors and sparse vectors,"['spark', 'dataframes', 'how', 'to', 'work', 'with', 'dense', 'vectors', 'and', 'sparse', 'vectors']",0,"['spark', 'dataframes', 'how', 'to', 'work', 'with', 'dense', 'vector', 'and', 'sparse', 'vector']","['spark', 'dataframes', 'work', 'dense', 'vector', 'sparse', 'vector']",spark dataframes work dense vector sparse vector,0.0,0.0,11,48,4.0,0,0,0,0,0,0,0,0
4161,how to pass dataframe element in function,how to pass dataframe element in function,"['how', 'to', 'pass', 'dataframe', 'element', 'in', 'function']",0,"['how', 'to', 'pas', 'dataframe', 'element', 'in', 'function']","['pas', 'dataframe', 'element', 'function']",pas dataframe element function,0.0,0.0,7,30,3.75,0,0,0,0,0,0,0,0
4162,determining significance of predictors in r,determining significance of predictors in r,"['determining', 'significance', 'of', 'predictors', 'in', 'r']",0,"['determining', 'significance', 'of', 'predictor', 'in', 'r']","['determining', 'significance', 'predictor', 'r']",determining significance predictor r,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
4163,how does decision tree decides split value for continuous vaiable,how does decision tree decides split value for continuous vaiable,"['how', 'does', 'decision', 'tree', 'decides', 'split', 'value', 'for', 'continuous', 'vaiable']",0,"['how', 'doe', 'decision', 'tree', 'decides', 'split', 'value', 'for', 'continuous', 'vaiable']","['doe', 'decision', 'tree', 'decides', 'split', 'value', 'continuous', 'vaiable']",doe decision tree decides split value continuous vaiable,0.0,0.0,10,56,5.090909090909091,0,0,0,0,0,0,0,0
4164,detection of helix shapedcorkscrew shaped structures nano sized propellers from an image using image processingcomputer vision,detection of helix shapedcorkscrew shaped structures nano sized propellers from an image using image processingcomputer vision,"['detection', 'of', 'helix', 'shapedcorkscrew', 'shaped', 'structures', 'nano', 'sized', 'propellers', 'from', 'an', 'image', 'using', 'image', 'processingcomputer', 'vision']",0,"['detection', 'of', 'helix', 'shapedcorkscrew', 'shaped', 'structure', 'nano', 'sized', 'propeller', 'from', 'an', 'image', 'using', 'image', 'processingcomputer', 'vision']","['detection', 'helix', 'shapedcorkscrew', 'shaped', 'structure', 'nano', 'sized', 'propeller', 'image', 'using', 'image', 'processingcomputer', 'vision']",detection helix shapedcorkscrew shaped structure nano sized propeller image using image processingcomputer vision,0.0,0.0,16,113,6.647058823529412,0,0,0,0,0,0,0,0
4165,how to impute values rowwise in a dataframe,how to impute values rowwise in a dataframe,"['how', 'to', 'impute', 'values', 'rowwise', 'in', 'a', 'dataframe']",0,"['how', 'to', 'impute', 'value', 'rowwise', 'in', 'a', 'dataframe']","['impute', 'value', 'rowwise', 'dataframe']",impute value rowwise dataframe,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
4166,time forecasting,time forecasting,"['time', 'forecasting']",0,"['time', 'forecasting']","['time', 'forecasting']",time forecasting,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
4167,getting typeerror  not supported between instances of float and str,getting typeerror  not supported between instances of float and str,"['getting', 'typeerror', 'not', 'supported', 'between', 'instances', 'of', 'float', 'and', 'str']",0,"['getting', 'typeerror', 'not', 'supported', 'between', 'instance', 'of', 'float', 'and', 'str']","['getting', 'typeerror', 'supported', 'instance', 'float', 'str']",getting typeerror supported instance float str,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
4168,you tube video data extraction,you tube video data extraction,"['you', 'tube', 'video', 'data', 'extraction']",0,"['you', 'tube', 'video', 'data', 'extraction']","['tube', 'video', 'data', 'extraction']",tube video data extraction,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
4169,what is the attribute type signify in naive bayes model,what is the attribute type signify in naive bayes model,"['what', 'is', 'the', 'attribute', 'type', 'signify', 'in', 'naive', 'bayes', 'model']",0,"['what', 'is', 'the', 'attribute', 'type', 'signify', 'in', 'naive', 'bayes', 'model']","['attribute', 'type', 'signify', 'naive', 'bayes', 'model']",attribute type signify naive bayes model,-0.3,-0.3,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
4170,ner or text extraction in nlp,ner or text extraction in nlp,"['ner', 'or', 'text', 'extraction', 'in', 'nlp']",0,"['ner', 'or', 'text', 'extraction', 'in', 'nlp']","['ner', 'text', 'extraction', 'nlp']",ner text extraction nlp,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
4171,a very good data science course in python by harvard,a very good data science course in python by harvard,"['a', 'very', 'good', 'data', 'science', 'course', 'in', 'python', 'by', 'harvard']",0,"['a', 'very', 'good', 'data', 'science', 'course', 'in', 'python', 'by', 'harvard']","['good', 'data', 'science', 'course', 'python', 'harvard']",good data science course python harvard,0.91,0.7,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
4172,error in plotnew  figure margins too large in r,error in plotnew  figure margins too large in r,"['error', 'in', 'plotnew', 'figure', 'margins', 'too', 'large', 'in', 'r']",0,"['error', 'in', 'plotnew', 'figure', 'margin', 'too', 'large', 'in', 'r']","['error', 'plotnew', 'figure', 'margin', 'large', 'r']",error plotnew figure margin large r,0.2142857142857142,0.2142857142857142,9,35,3.5,0,0,0,0,0,0,0,0
4173,how to resolve r error  nonnumeric argument to binary operator,how to resolve r error  nonnumeric argument to binary operator,"['how', 'to', 'resolve', 'r', 'error', 'nonnumeric', 'argument', 'to', 'binary', 'operator']",0,"['how', 'to', 'resolve', 'r', 'error', 'nonnumeric', 'argument', 'to', 'binary', 'operator']","['resolve', 'r', 'error', 'nonnumeric', 'argument', 'binary', 'operator']",resolve r error nonnumeric argument binary operator,0.0,0.0,10,51,4.636363636363637,0,0,0,0,0,0,0,0
4174,cant we comment a block of code at once in r,cant we comment a block of code at once in r,"['cant', 'we', 'comment', 'a', 'block', 'of', 'code', 'at', 'once', 'in', 'r']",0,"['cant', 'we', 'comment', 'a', 'block', 'of', 'code', 'at', 'once', 'in', 'r']","['cant', 'comment', 'block', 'code', 'r']",cant comment block code r,0.0,0.0,11,25,2.0833333333333335,0,0,0,0,0,0,0,0
4175,how to remove redundant rules from rules generated by apriori algorithm,how to remove redundant rules from rules generated by apriori algorithm,"['how', 'to', 'remove', 'redundant', 'rules', 'from', 'rules', 'generated', 'by', 'apriori', 'algorithm']",0,"['how', 'to', 'remove', 'redundant', 'rule', 'from', 'rule', 'generated', 'by', 'apriori', 'algorithm']","['remove', 'redundant', 'rule', 'rule', 'generated', 'apriori', 'algorithm']",remove redundant rule rule generated apriori algorithm,-0.2,-0.2,11,54,4.5,0,0,0,0,0,0,0,0
4176,dealing with special values in prediction problem,dealing with special values in prediction problem,"['dealing', 'with', 'special', 'values', 'in', 'prediction', 'problem']",0,"['dealing', 'with', 'special', 'value', 'in', 'prediction', 'problem']","['dealing', 'special', 'value', 'prediction', 'problem']",dealing special value prediction problem,0.3571428571428571,0.3571428571428571,7,40,5.0,0,0,0,0,0,0,0,0
4177,how to solve nonnumeric argument to binary operator error in ggplot,how to solve nonnumeric argument to binary operator error in ggplot,"['how', 'to', 'solve', 'nonnumeric', 'argument', 'to', 'binary', 'operator', 'error', 'in', 'ggplot']",0,"['how', 'to', 'solve', 'nonnumeric', 'argument', 'to', 'binary', 'operator', 'error', 'in', 'ggplot']","['solve', 'nonnumeric', 'argument', 'binary', 'operator', 'error', 'ggplot']",solve nonnumeric argument binary operator error ggplot,0.0,0.0,11,54,4.5,0,0,0,0,0,0,0,0
4178,python with hadoop,python with hadoop,"['python', 'with', 'hadoop']",0,"['python', 'with', 'hadoop']","['python', 'hadoop']",python hadoop,0.0,0.0,3,13,3.25,0,0,0,0,0,0,0,0
4179,seers accuracy data hack  approach,seers accuracy data hack  approach,"['seers', 'accuracy', 'data', 'hack', 'approach']",0,"['seer', 'accuracy', 'data', 'hack', 'approach']","['seer', 'accuracy', 'data', 'hack', 'approach']",seer accuracy data hack approach,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
4180,pattern matching with clustering,pattern matching with clustering,"['pattern', 'matching', 'with', 'clustering']",0,"['pattern', 'matching', 'with', 'clustering']","['pattern', 'matching', 'clustering']",pattern matching clustering,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
4181,if the linear regression coefficient of a predictor is  then what does it mean,if the linear regression coefficient of a predictor is  then what does it mean,"['if', 'the', 'linear', 'regression', 'coefficient', 'of', 'a', 'predictor', 'is', 'then', 'what', 'does', 'it', 'mean']",1,"['if', 'the', 'linear', 'regression', 'coefficient', 'of', 'a', 'predictor', 'is', 'then', 'what', 'doe', 'it', 'mean']","['linear', 'regression', 'coefficient', 'predictor', 'doe', 'mean']",linear regression coefficient predictor doe mean,-0.3125,-0.3125,14,48,3.2,0,0,0,0,0,0,0,0
4182,statistical modelling in r,statistical modelling in r,"['statistical', 'modelling', 'in', 'r']",0,"['statistical', 'modelling', 'in', 'r']","['statistical', 'modelling', 'r']",statistical modelling r,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
4183,how to extract a single word from text in r,how to extract a single word from text in r,"['how', 'to', 'extract', 'a', 'single', 'word', 'from', 'text', 'in', 'r']",0,"['how', 'to', 'extract', 'a', 'single', 'word', 'from', 'text', 'in', 'r']","['extract', 'single', 'word', 'text', 'r']",extract single word text r,-0.0714285714285714,-0.0714285714285714,10,26,2.3636363636363638,0,0,0,0,0,0,0,0
4184,pgdba from iit  iim c  isi vs praxis business school pgpba,pgdba from iit  iim c  isi vs praxis business school pgpba,"['pgdba', 'from', 'iit', 'iim', 'c', 'isi', 'vs', 'praxis', 'business', 'school', 'pgpba']",0,"['pgdba', 'from', 'iit', 'iim', 'c', 'isi', 'v', 'praxis', 'business', 'school', 'pgpba']","['pgdba', 'iit', 'iim', 'c', 'isi', 'v', 'praxis', 'business', 'school', 'pgpba']",pgdba iit iim c isi v praxis business school pgpba,0.0,0.0,11,50,4.166666666666667,0,0,0,0,0,0,0,0
4185,sales prediction for fashion retail data,sales prediction for fashion retail data,"['sales', 'prediction', 'for', 'fashion', 'retail', 'data']",0,"['sale', 'prediction', 'for', 'fashion', 'retail', 'data']","['sale', 'prediction', 'fashion', 'retail', 'data']",sale prediction fashion retail data,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
4186,data visualization using ggplot,data visualization using ggplot,"['data', 'visualization', 'using', 'ggplot']",0,"['data', 'visualization', 'using', 'ggplot']","['data', 'visualization', 'using', 'ggplot']",data visualization using ggplot,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
4187,use of pretrained language model in lord of the machines hackathon,use of pretrained language model in lord of the machines hackathon,"['use', 'of', 'pretrained', 'language', 'model', 'in', 'lord', 'of', 'the', 'machines', 'hackathon']",0,"['use', 'of', 'pretrained', 'language', 'model', 'in', 'lord', 'of', 'the', 'machine', 'hackathon']","['use', 'pretrained', 'language', 'model', 'lord', 'machine', 'hackathon']",use pretrained language model lord machine hackathon,0.0,0.0,11,52,4.333333333333333,0,0,0,0,0,0,0,0
4188,how to create groups of variable by deciles in sas,how to create groups of variable by deciles in sas,"['how', 'to', 'create', 'groups', 'of', 'variable', 'by', 'deciles', 'in', 'sas']",0,"['how', 'to', 'create', 'group', 'of', 'variable', 'by', 'decile', 'in', 'sa']","['create', 'group', 'variable', 'decile', 'sa']",create group variable decile sa,0.0,0.0,10,31,2.8181818181818183,0,0,0,0,0,0,0,0
4189,matt whiteny u test vs t test,matt whiteny u test vs t test,"['matt', 'whiteny', 'u', 'test', 'vs', 't', 'test']",0,"['matt', 'whiteny', 'u', 'test', 'v', 't', 'test']","['matt', 'whiteny', 'u', 'test', 'v', 'test']",matt whiteny u test v test,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
4190,how is the prob matrix generated in markov chain  cat and mouse problem,how is the prob matrix generated in markov chain  cat and mouse problem,"['how', 'is', 'the', 'prob', 'matrix', 'generated', 'in', 'markov', 'chain', 'cat', 'and', 'mouse', 'problem']",0,"['how', 'is', 'the', 'prob', 'matrix', 'generated', 'in', 'markov', 'chain', 'cat', 'and', 'mouse', 'problem']","['prob', 'matrix', 'generated', 'markov', 'chain', 'cat', 'mouse', 'problem']",prob matrix generated markov chain cat mouse problem,0.0,0.0,13,52,3.7142857142857144,0,0,0,0,0,0,0,0
4191,analytics life cycle methodology,analytics life cycle methodology,"['analytics', 'life', 'cycle', 'methodology']",0,"['analytics', 'life', 'cycle', 'methodology']","['analytics', 'life', 'cycle', 'methodology']",analytics life cycle methodology,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
4192,explain what is confusion matrix and how it is used to validate classification models,explain what is confusion matrix and how it is used to validate classification models,"['explain', 'what', 'is', 'confusion', 'matrix', 'and', 'how', 'it', 'is', 'used', 'to', 'validate', 'classification', 'models']",0,"['explain', 'what', 'is', 'confusion', 'matrix', 'and', 'how', 'it', 'is', 'used', 'to', 'validate', 'classification', 'model']","['explain', 'confusion', 'matrix', 'used', 'validate', 'classification', 'model']",explain confusion matrix used validate classification model,0.0,0.0,14,60,4.0,0,0,0,0,0,0,0,0
4193,chrun model  survival time analysis,chrun model  survival time analysis,"['chrun', 'model', 'survival', 'time', 'analysis']",0,"['chrun', 'model', 'survival', 'time', 'analysis']","['chrun', 'model', 'survival', 'time', 'analysis']",chrun model survival time analysis,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
4194,how to map values of a category to other category in the same variable,how to map values of a category to other category in the same variable,"['how', 'to', 'map', 'values', 'of', 'a', 'category', 'to', 'other', 'category', 'in', 'the', 'same', 'variable']",0,"['how', 'to', 'map', 'value', 'of', 'a', 'category', 'to', 'other', 'category', 'in', 'the', 'same', 'variable']","['map', 'value', 'category', 'category', 'variable']",map value category category variable,-0.0625,0.0,14,36,2.4,0,0,0,0,0,0,0,0
4195,creating confusion mattrix on loan prediction dataset,creating confusion mattrix on loan prediction dataset,"['creating', 'confusion', 'mattrix', 'on', 'loan', 'prediction', 'dataset']",0,"['creating', 'confusion', 'mattrix', 'on', 'loan', 'prediction', 'dataset']","['creating', 'confusion', 'mattrix', 'loan', 'prediction', 'dataset']",creating confusion mattrix loan prediction dataset,0.0,0.0,7,50,6.25,0,0,0,0,0,0,0,0
4196,data anonymization in r,data anonymization in r,"['data', 'anonymization', 'in', 'r']",0,"['data', 'anonymization', 'in', 'r']","['data', 'anonymization', 'r']",data anonymization r,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
4197,autospearman feature selection r,autospearman feature selection r,"['autospearman', 'feature', 'selection', 'r']",0,"['autospearman', 'feature', 'selection', 'r']","['autospearman', 'feature', 'selection', 'r']",autospearman feature selection r,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
4198,can we use continuous variables as an input for logistic regression,can we use continuous variables as an input for logistic regression,"['can', 'we', 'use', 'continuous', 'variables', 'as', 'an', 'input', 'for', 'logistic', 'regression']",0,"['can', 'we', 'use', 'continuous', 'variable', 'a', 'an', 'input', 'for', 'logistic', 'regression']","['use', 'continuous', 'variable', 'input', 'logistic', 'regression']",use continuous variable input logistic regression,0.0,0.0,11,49,4.083333333333333,0,0,0,0,0,0,0,0
4199,how to practice tableau,how to practice tableau,"['how', 'to', 'practice', 'tableau']",0,"['how', 'to', 'practice', 'tableau']","['practice', 'tableau']",practice tableau,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
4200,full life cycle data project,full life cycle data project,"['full', 'life', 'cycle', 'data', 'project']",0,"['full', 'life', 'cycle', 'data', 'project']","['full', 'life', 'cycle', 'data', 'project']",full life cycle data project,0.35,0.35,5,28,4.666666666666667,0,0,0,0,0,0,0,0
4201,theseersaccuracy hackthon dataset,theseersaccuracy hackthon dataset,"['theseersaccuracy', 'hackthon', 'dataset']",0,"['theseersaccuracy', 'hackthon', 'dataset']","['theseersaccuracy', 'hackthon', 'dataset']",theseersaccuracy hackthon dataset,0.0,0.0,3,33,8.25,0,0,0,0,0,0,0,0
4202,missing values imputation,missing values imputation,"['missing', 'values', 'imputation']",0,"['missing', 'value', 'imputation']","['missing', 'value', 'imputation']",missing value imputation,-0.2,-0.2,3,24,6.0,0,0,0,0,0,0,0,0
4203,introducing nonlinear transformations of independent variables into a logistic model to improve accuracy,introducing nonlinear transformations of independent variables into a logistic model to improve accuracy,"['introducing', 'nonlinear', 'transformations', 'of', 'independent', 'variables', 'into', 'a', 'logistic', 'model', 'to', 'improve', 'accuracy']",0,"['introducing', 'nonlinear', 'transformation', 'of', 'independent', 'variable', 'into', 'a', 'logistic', 'model', 'to', 'improve', 'accuracy']","['introducing', 'nonlinear', 'transformation', 'independent', 'variable', 'logistic', 'model', 'improve', 'accuracy']",introducing nonlinear transformation independent variable logistic model improve accuracy,0.0,0.0,13,89,6.357142857142857,0,0,0,0,0,0,0,0
4204,lemon fruits detection,lemon fruits detection,"['lemon', 'fruits', 'detection']",0,"['lemon', 'fruit', 'detection']","['lemon', 'fruit', 'detection']",lemon fruit detection,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
4205,data hackathon x problem statement and description,data hackathon x problem statement and description,"['data', 'hackathon', 'x', 'problem', 'statement', 'and', 'description']",0,"['data', 'hackathon', 'x', 'problem', 'statement', 'and', 'description']","['data', 'hackathon', 'x', 'problem', 'statement', 'description']",data hackathon x problem statement description,0.0,0.0,7,46,5.75,0,0,0,0,0,0,0,0
4206,hikeathon  minimum system requirements,hikeathon  minimum system requirements,"['hikeathon', 'minimum', 'system', 'requirements']",0,"['hikeathon', 'minimum', 'system', 'requirement']","['hikeathon', 'minimum', 'system', 'requirement']",hikeathon minimum system requirement,0.0,0.0,4,36,7.2,0,0,0,0,0,0,0,0
4207,how to create a stacked bar plot,how to create a stacked bar plot,"['how', 'to', 'create', 'a', 'stacked', 'bar', 'plot']",0,"['how', 'to', 'create', 'a', 'stacked', 'bar', 'plot']","['create', 'stacked', 'bar', 'plot']",create stacked bar plot,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
4208,data submission problem  seers accuracy,data submission problem  seers accuracy,"['data', 'submission', 'problem', 'seers', 'accuracy']",0,"['data', 'submission', 'problem', 'seer', 'accuracy']","['data', 'submission', 'problem', 'seer', 'accuracy']",data submission problem seer accuracy,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
4209,explaining choosing and arranging objects in simple english,explaining choosing and arranging objects in simple english,"['explaining', 'choosing', 'and', 'arranging', 'objects', 'in', 'simple', 'english']",0,"['explaining', 'choosing', 'and', 'arranging', 'object', 'in', 'simple', 'english']","['explaining', 'choosing', 'arranging', 'object', 'simple', 'english']",explaining choosing arranging object simple english,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
4210,how can nlp be used in finance,how can nlp be used in finance,"['how', 'can', 'nlp', 'be', 'used', 'in', 'finance']",0,"['how', 'can', 'nlp', 'be', 'used', 'in', 'finance']","['nlp', 'used', 'finance']",nlp used finance,0.0,0.0,7,16,2.0,0,0,0,0,0,0,0,0
4211,overfitting with r xgboost,overfitting with r xgboost,"['overfitting', 'with', 'r', 'xgboost']",0,"['overfitting', 'with', 'r', 'xgboost']","['overfitting', 'r', 'xgboost']",overfitting r xgboost,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
4212,last man standing  reveal your approach,last man standing  reveal your approach,"['last', 'man', 'standing', 'reveal', 'your', 'approach']",0,"['last', 'man', 'standing', 'reveal', 'your', 'approach']","['last', 'man', 'standing', 'reveal', 'approach']",last man standing reveal approach,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
4213,understanding reliability diagram for classification,understanding reliability diagram for classification,"['understanding', 'reliability', 'diagram', 'for', 'classification']",0,"['understanding', 'reliability', 'diagram', 'for', 'classification']","['understanding', 'reliability', 'diagram', 'classification']",understanding reliability diagram classification,0.0,0.0,5,48,8.0,0,0,0,0,0,0,0,0
4214,keras faster rcnn on custom dataset no output on test images,keras faster rcnn on custom dataset no output on test images,"['keras', 'faster', 'rcnn', 'on', 'custom', 'dataset', 'no', 'output', 'on', 'test', 'images']",0,"['kera', 'faster', 'rcnn', 'on', 'custom', 'dataset', 'no', 'output', 'on', 'test', 'image']","['kera', 'faster', 'rcnn', 'custom', 'dataset', 'output', 'test', 'image']",kera faster rcnn custom dataset output test image,0.0,0.0,11,49,4.083333333333333,0,0,0,0,0,0,0,0
4215,need basics of statistics,need basics of statistics,"['need', 'basics', 'of', 'statistics']",0,"['need', 'basic', 'of', 'statistic']","['need', 'basic', 'statistic']",need basic statistic,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
4216,what is difference between single bracket and double bracket in r,what is difference between single bracket and double bracket in r,"['what', 'is', 'difference', 'between', 'single', 'bracket', 'and', 'double', 'bracket', 'in', 'r']",0,"['what', 'is', 'difference', 'between', 'single', 'bracket', 'and', 'double', 'bracket', 'in', 'r']","['difference', 'single', 'bracket', 'double', 'bracket', 'r']",difference single bracket double bracket r,-0.0357142857142857,-0.0357142857142857,11,42,3.5,0,0,0,0,0,0,0,0
4217,how to get rows of false positive in python,how to get rows of false positive in python,"['how', 'to', 'get', 'rows', 'of', 'false', 'positive', 'in', 'python']",0,"['how', 'to', 'get', 'row', 'of', 'false', 'positive', 'in', 'python']","['get', 'row', 'false', 'positive', 'python']",get row false positive python,-0.0863636363636364,-0.0863636363636364,9,29,2.9,0,0,0,0,0,0,0,0
4218,how to merge  dataframes by id in r,how to merge  dataframes by id in r,"['how', 'to', 'merge', 'dataframes', 'by', 'id', 'in', 'r']",1,"['how', 'to', 'merge', 'dataframes', 'by', 'id', 'in', 'r']","['merge', 'dataframes', 'id', 'r']",merge dataframes id r,0.0,0.0,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
4219,choosing the programming language beginner data scientist,choosing the programming language beginner data scientist,"['choosing', 'the', 'programming', 'language', 'beginner', 'data', 'scientist']",0,"['choosing', 'the', 'programming', 'language', 'beginner', 'data', 'scientist']","['choosing', 'programming', 'language', 'beginner', 'data', 'scientist']",choosing programming language beginner data scientist,0.0,0.0,7,53,6.625,0,0,0,0,0,0,0,0
4220,need help in resolving error during installation of spark rerror in sparkrinitmaster  local  jvm is not ready after  seconds,need help in resolving error during installation of spark rerror in sparkrinitmaster  local  jvm is not ready after  seconds,"['need', 'help', 'in', 'resolving', 'error', 'during', 'installation', 'of', 'spark', 'rerror', 'in', 'sparkrinitmaster', 'local', 'jvm', 'is', 'not', 'ready', 'after', 'seconds']",1,"['need', 'help', 'in', 'resolving', 'error', 'during', 'installation', 'of', 'spark', 'rerror', 'in', 'sparkrinitmaster', 'local', 'jvm', 'is', 'not', 'ready', 'after', 'second']","['need', 'help', 'resolving', 'error', 'installation', 'spark', 'rerror', 'sparkrinitmaster', 'local', 'jvm', 'ready', 'second']",need help resolving error installation spark rerror sparkrinitmaster local jvm ready second,-0.05,0.0666666666666666,19,91,4.55,0,0,0,0,0,0,0,0
4221,list of libraries in python for text mining,list of libraries in python for text mining,"['list', 'of', 'libraries', 'in', 'python', 'for', 'text', 'mining']",0,"['list', 'of', 'library', 'in', 'python', 'for', 'text', 'mining']","['list', 'library', 'python', 'text', 'mining']",list library python text mining,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
4222,which language should i learn after i have learnt python,which language should i learn after i have learnt python,"['which', 'language', 'should', 'i', 'learn', 'after', 'i', 'have', 'learnt', 'python']",0,"['which', 'language', 'should', 'i', 'learn', 'after', 'i', 'have', 'learnt', 'python']","['language', 'learn', 'learnt', 'python']",language learn learnt python,0.0,0.0,10,28,2.5454545454545454,0,0,0,0,0,0,0,0
4223,how to normalize the dataset with many missing values,how to normalize the dataset with many missing values,"['how', 'to', 'normalize', 'the', 'dataset', 'with', 'many', 'missing', 'values']",0,"['how', 'to', 'normalize', 'the', 'dataset', 'with', 'many', 'missing', 'value']","['normalize', 'dataset', 'many', 'missing', 'value']",normalize dataset many missing value,0.15,0.15,9,36,3.6,0,0,0,0,0,0,0,0
4224,are pca eigenvalues equivalent to semipartial correlation coefficients in linear regression,are pca eigenvalues equivalent to semipartial correlation coefficients in linear regression,"['are', 'pca', 'eigenvalues', 'equivalent', 'to', 'semipartial', 'correlation', 'coefficients', 'in', 'linear', 'regression']",0,"['are', 'pca', 'eigenvalue', 'equivalent', 'to', 'semipartial', 'correlation', 'coefficient', 'in', 'linear', 'regression']","['pca', 'eigenvalue', 'equivalent', 'semipartial', 'correlation', 'coefficient', 'linear', 'regression']",pca eigenvalue equivalent semipartial correlation coefficient linear regression,0.0,0.0,11,79,6.583333333333333,0,0,0,0,0,0,0,0
4225,syntax error in machine learning code,syntax error in machine learning code,"['syntax', 'error', 'in', 'machine', 'learning', 'code']",0,"['syntax', 'error', 'in', 'machine', 'learning', 'code']","['syntax', 'error', 'machine', 'learning', 'code']",syntax error machine learning code,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
4226,how to resolve error while predicting using xgboost in r,how to resolve error while predicting using xgboost in r,"['how', 'to', 'resolve', 'error', 'while', 'predicting', 'using', 'xgboost', 'in', 'r']",0,"['how', 'to', 'resolve', 'error', 'while', 'predicting', 'using', 'xgboost', 'in', 'r']","['resolve', 'error', 'predicting', 'using', 'xgboost', 'r']",resolve error predicting using xgboost r,0.0,0.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
4227,parameters in rpart,parameters in rpart,"['parameters', 'in', 'rpart']",0,"['parameter', 'in', 'rpart']","['parameter', 'rpart']",parameter rpart,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
4228,list of companies  organizations using analytics in india,list of companies  organizations using analytics in india,"['list', 'of', 'companies', 'organizations', 'using', 'analytics', 'in', 'india']",0,"['list', 'of', 'company', 'organization', 'using', 'analytics', 'in', 'india']","['list', 'company', 'organization', 'using', 'analytics', 'india']",list company organization using analytics india,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
4229,please explain principal component analysis pcasvd algorithm in artificial intelligence,please explain principal component analysis pcasvd algorithm in artificial intelligence,"['please', 'explain', 'principal', 'component', 'analysis', 'pcasvd', 'algorithm', 'in', 'artificial', 'intelligence']",0,"['please', 'explain', 'principal', 'component', 'analysis', 'pcasvd', 'algorithm', 'in', 'artificial', 'intelligence']","['please', 'explain', 'principal', 'component', 'analysis', 'pcasvd', 'algorithm', 'artificial', 'intelligence']",please explain principal component analysis pcasvd algorithm artificial intelligence,-0.6,-0.6,10,84,7.636363636363637,0,0,0,0,0,0,0,0
4230,pattern matching text mining,pattern matching text mining,"['pattern', 'matching', 'text', 'mining']",0,"['pattern', 'matching', 'text', 'mining']","['pattern', 'matching', 'text', 'mining']",pattern matching text mining,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
4231,extract an image features in r,extract an image features in r,"['extract', 'an', 'image', 'features', 'in', 'r']",0,"['extract', 'an', 'image', 'feature', 'in', 'r']","['extract', 'image', 'feature', 'r']",extract image feature r,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
4232,confusion in replacing aggfunc by npmedian or npmean while using pivot table for loanamount,confusion in replacing aggfunc by npmedian or npmean while using pivot table for loanamount,"['confusion', 'in', 'replacing', 'aggfunc', 'by', 'npmedian', 'or', 'npmean', 'while', 'using', 'pivot', 'table', 'for', 'loanamount']",0,"['confusion', 'in', 'replacing', 'aggfunc', 'by', 'npmedian', 'or', 'npmean', 'while', 'using', 'pivot', 'table', 'for', 'loanamount']","['confusion', 'replacing', 'aggfunc', 'npmedian', 'npmean', 'using', 'pivot', 'table', 'loanamount']",confusion replacing aggfunc npmedian npmean using pivot table loanamount,0.0,0.0,14,72,4.8,0,0,0,0,0,0,0,0
4233,how can i download closed event dataset,how can i download closed event dataset,"['how', 'can', 'i', 'download', 'closed', 'event', 'dataset']",0,"['how', 'can', 'i', 'download', 'closed', 'event', 'dataset']","['download', 'closed', 'event', 'dataset']",download closed event dataset,-0.1,-0.1,7,29,3.625,0,0,0,0,0,0,0,0
4234,resampling code for different sampling techniques,resampling code for different sampling techniques,"['resampling', 'code', 'for', 'different', 'sampling', 'techniques']",0,"['resampling', 'code', 'for', 'different', 'sampling', 'technique']","['resampling', 'code', 'different', 'sampling', 'technique']",resampling code different sampling technique,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
4235,extracting coefficients of a linear model fitted to a ggplot using geomsmooth  in r,extracting coefficients of a linear model fitted to a ggplot using geomsmooth  in r,"['extracting', 'coefficients', 'of', 'a', 'linear', 'model', 'fitted', 'to', 'a', 'ggplot', 'using', 'geomsmooth', 'in', 'r']",0,"['extracting', 'coefficient', 'of', 'a', 'linear', 'model', 'fitted', 'to', 'a', 'ggplot', 'using', 'geomsmooth', 'in', 'r']","['extracting', 'coefficient', 'linear', 'model', 'fitted', 'ggplot', 'using', 'geomsmooth', 'r']",extracting coefficient linear model fitted ggplot using geomsmooth r,0.0,0.0,14,68,4.533333333333333,0,0,0,0,0,0,0,0
4236,case studies using eda in r,case studies using eda in r,"['case', 'studies', 'using', 'eda', 'in', 'r']",0,"['case', 'study', 'using', 'eda', 'in', 'r']","['case', 'study', 'using', 'eda', 'r']",case study using eda r,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
4237,what are some examples where false positive is preferred over false negative,what are some examples where false positive is preferred over false negative,"['what', 'are', 'some', 'examples', 'where', 'false', 'positive', 'is', 'preferred', 'over', 'false', 'negative']",0,"['what', 'are', 'some', 'example', 'where', 'false', 'positive', 'is', 'preferred', 'over', 'false', 'negative']","['example', 'false', 'positive', 'preferred', 'false', 'negative']",example false positive preferred false negative,-0.2181818181818182,-0.2181818181818182,12,47,3.6153846153846154,0,0,0,0,0,0,0,0
4238,calculating just a single row of dissimilaritydistance matrix,calculating just a single row of dissimilaritydistance matrix,"['calculating', 'just', 'a', 'single', 'row', 'of', 'dissimilaritydistance', 'matrix']",0,"['calculating', 'just', 'a', 'single', 'row', 'of', 'dissimilaritydistance', 'matrix']","['calculating', 'single', 'row', 'dissimilaritydistance', 'matrix']",calculating single row dissimilaritydistance matrix,-0.0714285714285714,-0.0714285714285714,8,51,5.666666666666667,0,0,0,0,0,0,0,0
4239,time series forecasting  for aggregated measure and sub variables,time series forecasting  for aggregated measure and sub variables,"['time', 'series', 'forecasting', 'for', 'aggregated', 'measure', 'and', 'sub', 'variables']",0,"['time', 'series', 'forecasting', 'for', 'aggregated', 'measure', 'and', 'sub', 'variable']","['time', 'series', 'forecasting', 'aggregated', 'measure', 'sub', 'variable']",time series forecasting aggregated measure sub variable,0.0,0.0,9,55,5.5,0,0,0,0,0,0,0,0
4240,news article success score formula,news article success score formula,"['news', 'article', 'success', 'score', 'formula']",0,"['news', 'article', 'success', 'score', 'formula']","['news', 'article', 'success', 'score', 'formula']",news article success score formula,0.3,0.3,5,34,5.666666666666667,0,0,0,0,0,0,0,0
4241,how to predict which users will purchase given the users activities,how to predict which users will purchase given the users activities,"['how', 'to', 'predict', 'which', 'users', 'will', 'purchase', 'given', 'the', 'users', 'activities']",0,"['how', 'to', 'predict', 'which', 'user', 'will', 'purchase', 'given', 'the', 'user', 'activity']","['predict', 'user', 'purchase', 'given', 'user', 'activity']",predict user purchase given user activity,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
4242,a request for feedback resource sharing,a request for feedback resource sharing,"['a', 'request', 'for', 'feedback', 'resource', 'sharing']",0,"['a', 'request', 'for', 'feedback', 'resource', 'sharing']","['request', 'feedback', 'resource', 'sharing']",request feedback resource sharing,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
4243,switching career to data science from research in mathematics,switching career to data science from research in mathematics,"['switching', 'career', 'to', 'data', 'science', 'from', 'research', 'in', 'mathematics']",0,"['switching', 'career', 'to', 'data', 'science', 'from', 'research', 'in', 'mathematics']","['switching', 'career', 'data', 'science', 'research', 'mathematics']",switching career data science research mathematics,0.0,0.0,9,50,5.0,0,0,0,0,0,0,0,0
4244,good book for predictive analytics in insurance,good book for predictive analytics in insurance,"['good', 'book', 'for', 'predictive', 'analytics', 'in', 'insurance']",0,"['good', 'book', 'for', 'predictive', 'analytics', 'in', 'insurance']","['good', 'book', 'predictive', 'analytics', 'insurance']",good book predictive analytics insurance,0.7,0.7,7,40,5.0,0,0,0,0,0,0,0,0
4245,better way of creating a dataframe in pandas,better way of creating a dataframe in pandas,"['better', 'way', 'of', 'creating', 'a', 'dataframe', 'in', 'pandas']",0,"['better', 'way', 'of', 'creating', 'a', 'dataframe', 'in', 'panda']","['better', 'way', 'creating', 'dataframe', 'panda']",better way creating dataframe panda,0.5,0.5,8,35,3.888888888888889,0,0,0,0,0,0,0,0
4246,keras binary classification i am getting same prediction class for all images,keras binary classification i am getting same prediction class for all images,"['keras', 'binary', 'classification', 'i', 'am', 'getting', 'same', 'prediction', 'class', 'for', 'all', 'images']",0,"['kera', 'binary', 'classification', 'i', 'am', 'getting', 'same', 'prediction', 'class', 'for', 'all', 'image']","['kera', 'binary', 'classification', 'getting', 'prediction', 'class', 'image']",kera binary classification getting prediction class image,0.0,0.0,12,57,4.384615384615385,0,0,0,0,0,0,0,0
4247,churn model using survival analysis,churn model using survival analysis,"['churn', 'model', 'using', 'survival', 'analysis']",0,"['churn', 'model', 'using', 'survival', 'analysis']","['churn', 'model', 'using', 'survival', 'analysis']",churn model using survival analysis,0.0,0.0,5,35,5.833333333333333,0,0,0,0,0,0,0,0
4248,isb cba vs glim  opportunities post course completion,isb cba vs glim  opportunities post course completion,"['isb', 'cba', 'vs', 'glim', 'opportunities', 'post', 'course', 'completion']",0,"['isb', 'cba', 'v', 'glim', 'opportunity', 'post', 'course', 'completion']","['isb', 'cba', 'v', 'glim', 'opportunity', 'post', 'course', 'completion']",isb cba v glim opportunity post course completion,0.0,0.0,8,49,5.444444444444445,0,0,0,0,0,0,0,0
4249,warning message glmfit algorithm did not converge,warning message glmfit algorithm did not converge,"['warning', 'message', 'glmfit', 'algorithm', 'did', 'not', 'converge']",0,"['warning', 'message', 'glmfit', 'algorithm', 'did', 'not', 'converge']","['warning', 'message', 'glmfit', 'algorithm', 'converge']",warning message glmfit algorithm converge,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
4250,conditional probability in r,conditional probability in r,"['conditional', 'probability', 'in', 'r']",0,"['conditional', 'probability', 'in', 'r']","['conditional', 'probability', 'r']",conditional probability r,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
4251,zero inflated reponse with random forest and gradient boosting regressors,zero inflated reponse with random forest and gradient boosting regressors,"['zero', 'inflated', 'reponse', 'with', 'random', 'forest', 'and', 'gradient', 'boosting', 'regressors']",0,"['zero', 'inflated', 'reponse', 'with', 'random', 'forest', 'and', 'gradient', 'boosting', 'regressors']","['zero', 'inflated', 'reponse', 'random', 'forest', 'gradient', 'boosting', 'regressors']",zero inflated reponse random forest gradient boosting regressors,-0.5,-0.5,10,64,5.818181818181818,0,0,0,0,0,0,0,0
4252,method for calculating the distance,method for calculating the distance,"['method', 'for', 'calculating', 'the', 'distance']",0,"['method', 'for', 'calculating', 'the', 'distance']","['method', 'calculating', 'distance']",method calculating distance,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
4253,how to run different lstm models on different data parallely,how to run different lstm models on different data parallely,"['how', 'to', 'run', 'different', 'lstm', 'models', 'on', 'different', 'data', 'parallely']",0,"['how', 'to', 'run', 'different', 'lstm', 'model', 'on', 'different', 'data', 'parallely']","['run', 'different', 'lstm', 'model', 'different', 'data', 'parallely']",run different lstm model different data parallely,0.0,0.0,10,49,4.454545454545454,0,0,0,0,0,0,0,0
4254,what does the parameter of svm signify,what does the parameter of svm signify,"['what', 'does', 'the', 'parameter', 'of', 'svm', 'signify']",0,"['what', 'doe', 'the', 'parameter', 'of', 'svm', 'signify']","['doe', 'parameter', 'svm', 'signify']",doe parameter svm signify,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
4255,r parallel processing code is taking time in server,r parallel processing code is taking time in server,"['r', 'parallel', 'processing', 'code', 'is', 'taking', 'time', 'in', 'server']",0,"['r', 'parallel', 'processing', 'code', 'is', 'taking', 'time', 'in', 'server']","['r', 'parallel', 'processing', 'code', 'taking', 'time', 'server']",r parallel processing code taking time server,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
4256,masters in big data  hadoop,masters in big data  hadoop,"['masters', 'in', 'big', 'data', 'hadoop']",0,"['master', 'in', 'big', 'data', 'hadoop']","['master', 'big', 'data', 'hadoop']",master big data hadoop,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
4257,seers accuracy slack live chat button,seers accuracy slack live chat button,"['seers', 'accuracy', 'slack', 'live', 'chat', 'button']",0,"['seer', 'accuracy', 'slack', 'live', 'chat', 'button']","['seer', 'accuracy', 'slack', 'live', 'chat', 'button']",seer accuracy slack live chat button,0.1363636363636363,0.1363636363636363,6,36,5.142857142857143,0,0,0,0,0,0,0,0
4258,is there any whatsapp contacts list for analytics and data science learningdiscussions,is there any whatsapp contacts list for analytics and data science learningdiscussions,"['is', 'there', 'any', 'whatsapp', 'contacts', 'list', 'for', 'analytics', 'and', 'data', 'science', 'learningdiscussions']",0,"['is', 'there', 'any', 'whatsapp', 'contact', 'list', 'for', 'analytics', 'and', 'data', 'science', 'learningdiscussions']","['whatsapp', 'contact', 'list', 'analytics', 'data', 'science', 'learningdiscussions']",whatsapp contact list analytics data science learningdiscussions,0.0,0.0,12,64,4.923076923076923,0,0,0,0,0,0,0,0
4259,how to calculate clv value,how to calculate clv value,"['how', 'to', 'calculate', 'clv', 'value']",0,"['how', 'to', 'calculate', 'clv', 'value']","['calculate', 'clv', 'value']",calculate clv value,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
4260,using spatial data for prediction,using spatial data for prediction,"['using', 'spatial', 'data', 'for', 'prediction']",0,"['using', 'spatial', 'data', 'for', 'prediction']","['using', 'spatial', 'data', 'prediction']",using spatial data prediction,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
4261,forecasting of election ,forecasting of election ,"['forecasting', 'of', 'election']",1,"['forecasting', 'of', 'election']","['forecasting', 'election']",forecasting election,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
4262,analyticsdata science opportunities using r in hyderabad,analyticsdata science opportunities using r in hyderabad,"['analyticsdata', 'science', 'opportunities', 'using', 'r', 'in', 'hyderabad']",0,"['analyticsdata', 'science', 'opportunity', 'using', 'r', 'in', 'hyderabad']","['analyticsdata', 'science', 'opportunity', 'using', 'r', 'hyderabad']",analyticsdata science opportunity using r hyderabad,0.0,0.0,7,51,6.375,0,0,0,0,0,0,0,0
4263,mean quantile and other way to analyze a variable in python,mean quantile and other way to analyze a variable in python,"['mean', 'quantile', 'and', 'other', 'way', 'to', 'analyze', 'a', 'variable', 'in', 'python']",0,"['mean', 'quantile', 'and', 'other', 'way', 'to', 'analyze', 'a', 'variable', 'in', 'python']","['mean', 'quantile', 'way', 'analyze', 'variable', 'python']",mean quantile way analyze variable python,-0.21875,-0.3125,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
4264,need guidance for an nit grad,need guidance for an nit grad,"['need', 'guidance', 'for', 'an', 'nit', 'grad']",0,"['need', 'guidance', 'for', 'an', 'nit', 'grad']","['need', 'guidance', 'nit', 'grad']",need guidance nit grad,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
4265,showing error in categorical missing value treatment,showing error in categorical missing value treatment,"['showing', 'error', 'in', 'categorical', 'missing', 'value', 'treatment']",0,"['showing', 'error', 'in', 'categorical', 'missing', 'value', 'treatment']","['showing', 'error', 'categorical', 'missing', 'value', 'treatment']",showing error categorical missing value treatment,-0.2,-0.2,7,49,6.125,0,0,0,0,0,0,0,0
4266,how should we place the clusters in a kmeans clustering implementation,how should we place the clusters in a kmeans clustering implementation,"['how', 'should', 'we', 'place', 'the', 'clusters', 'in', 'a', 'kmeans', 'clustering', 'implementation']",0,"['how', 'should', 'we', 'place', 'the', 'cluster', 'in', 'a', 'kmeans', 'clustering', 'implementation']","['place', 'cluster', 'kmeans', 'clustering', 'implementation']",place cluster kmeans clustering implementation,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
4267,what is difference between unsupervised learning supervised learning and semisupervised learning,what is difference between unsupervised learning supervised learning and semisupervised learning,"['what', 'is', 'difference', 'between', 'unsupervised', 'learning', 'supervised', 'learning', 'and', 'semisupervised', 'learning']",0,"['what', 'is', 'difference', 'between', 'unsupervised', 'learning', 'supervised', 'learning', 'and', 'semisupervised', 'learning']","['difference', 'unsupervised', 'learning', 'supervised', 'learning', 'semisupervised', 'learning']",difference unsupervised learning supervised learning semisupervised learning,0.0,0.0,11,76,6.333333333333333,0,0,0,0,0,0,0,0
4268,most suitable data science program,most suitable data science program,"['most', 'suitable', 'data', 'science', 'program']",0,"['most', 'suitable', 'data', 'science', 'program']","['suitable', 'data', 'science', 'program']",suitable data science program,0.525,0.55,5,29,4.833333333333333,0,0,0,0,0,0,0,0
4269,why nan acts like na in r,why nan acts like na in r,"['why', 'nan', 'acts', 'like', 'na', 'in', 'r']",0,"['why', 'nan', 'act', 'like', 'na', 'in', 'r']","['nan', 'act', 'like', 'na', 'r']",nan act like na r,0.0,0.0,7,17,2.125,0,0,0,0,0,0,0,0
4270,customize pivot table or chart,customize pivot table or chart,"['customize', 'pivot', 'table', 'or', 'chart']",0,"['customize', 'pivot', 'table', 'or', 'chart']","['customize', 'pivot', 'table', 'chart']",customize pivot table chart,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
4271,data modelling for agricultural data set,data modelling for agricultural data set,"['data', 'modelling', 'for', 'agricultural', 'data', 'set']",0,"['data', 'modelling', 'for', 'agricultural', 'data', 'set']","['data', 'modelling', 'agricultural', 'data', 'set']",data modelling agricultural data set,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
4272,missing value analysis,missing value analysis,"['missing', 'value', 'analysis']",0,"['missing', 'value', 'analysis']","['missing', 'value', 'analysis']",missing value analysis,-0.2,-0.2,3,22,5.5,0,0,0,0,0,0,0,0
4273,how can i post a new hackathon competition,how can i post a new hackathon competition,"['how', 'can', 'i', 'post', 'a', 'new', 'hackathon', 'competition']",0,"['how', 'can', 'i', 'post', 'a', 'new', 'hackathon', 'competition']","['post', 'new', 'hackathon', 'competition']",post new hackathon competition,0.1363636363636363,0.1363636363636363,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
4274,something is wrong all the accuracy metric values are missing,something is wrong all the accuracy metric values are missing,"['something', 'is', 'wrong', 'all', 'the', 'accuracy', 'metric', 'values', 'are', 'missing']",0,"['something', 'is', 'wrong', 'all', 'the', 'accuracy', 'metric', 'value', 'are', 'missing']","['something', 'wrong', 'accuracy', 'metric', 'value', 'missing']",something wrong accuracy metric value missing,-0.35,-0.35,10,45,4.090909090909091,0,0,0,0,0,0,0,0
4275,cross validation in data science life cycle,cross validation in data science life cycle,"['cross', 'validation', 'in', 'data', 'science', 'life', 'cycle']",0,"['cross', 'validation', 'in', 'data', 'science', 'life', 'cycle']","['cross', 'validation', 'data', 'science', 'life', 'cycle']",cross validation data science life cycle,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
4276,how to convert factor variable to a numeric vector in r,how to convert factor variable to a numeric vector in r,"['how', 'to', 'convert', 'factor', 'variable', 'to', 'a', 'numeric', 'vector', 'in', 'r']",0,"['how', 'to', 'convert', 'factor', 'variable', 'to', 'a', 'numeric', 'vector', 'in', 'r']","['convert', 'factor', 'variable', 'numeric', 'vector', 'r']",convert factor variable numeric vector r,0.0,0.0,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
4277,how can we share an excel file with multiple users,how can we share an excel file with multiple users,"['how', 'can', 'we', 'share', 'an', 'excel', 'file', 'with', 'multiple', 'users']",0,"['how', 'can', 'we', 'share', 'an', 'excel', 'file', 'with', 'multiple', 'user']","['share', 'excel', 'file', 'multiple', 'user']",share excel file multiple user,0.0,0.0,10,30,2.727272727272727,0,0,0,0,0,0,0,0
4278,learning path of r,learning path of r,"['learning', 'path', 'of', 'r']",0,"['learning', 'path', 'of', 'r']","['learning', 'path', 'r']",learning path r,0.0,0.0,4,15,3.0,0,0,0,0,0,0,0,0
4279,where to find the data set for python tutorial,where to find the data set for python tutorial,"['where', 'to', 'find', 'the', 'data', 'set', 'for', 'python', 'tutorial']",0,"['where', 'to', 'find', 'the', 'data', 'set', 'for', 'python', 'tutorial']","['find', 'data', 'set', 'python', 'tutorial']",find data set python tutorial,0.0,0.0,9,29,2.9,0,0,0,0,0,0,0,0
4280,tutorial to perform data exploration using elastic search  kibana python,tutorial to perform data exploration using elastic search  kibana python,"['tutorial', 'to', 'perform', 'data', 'exploration', 'using', 'elastic', 'search', 'kibana', 'python']",0,"['tutorial', 'to', 'perform', 'data', 'exploration', 'using', 'elastic', 'search', 'kibana', 'python']","['tutorial', 'perform', 'data', 'exploration', 'using', 'elastic', 'search', 'kibana', 'python']",tutorial perform data exploration using elastic search kibana python,0.0,0.0,10,68,6.181818181818182,0,0,0,0,0,0,0,0
4281,insofe good or not,insofe good or not,"['insofe', 'good', 'or', 'not']",0,"['insofe', 'good', 'or', 'not']","['insofe', 'good']",insofe good,0.7,0.7,4,11,2.2,0,0,0,0,0,0,0,0
4282,data set for central limit theorem,data set for central limit theorem,"['data', 'set', 'for', 'central', 'limit', 'theorem']",0,"['data', 'set', 'for', 'central', 'limit', 'theorem']","['data', 'set', 'central', 'limit', 'theorem']",data set central limit theorem,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
4283,where can i get the data set for the smart recruits,where can i get the data set for the smart recruits,"['where', 'can', 'i', 'get', 'the', 'data', 'set', 'for', 'the', 'smart', 'recruits']",0,"['where', 'can', 'i', 'get', 'the', 'data', 'set', 'for', 'the', 'smart', 'recruit']","['get', 'data', 'set', 'smart', 'recruit']",get data set smart recruit,0.2142857142857142,0.2142857142857142,11,26,2.1666666666666665,0,0,0,0,0,0,0,0
4284,factorization machines  how to recommend,factorization machines  how to recommend,"['factorization', 'machines', 'how', 'to', 'recommend']",0,"['factorization', 'machine', 'how', 'to', 'recommend']","['factorization', 'machine', 'recommend']",factorization machine recommend,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
4285,how dashboard software kpis and visualizations can optimize your business operations,how dashboard software kpis and visualizations can optimize your business operations,"['how', 'dashboard', 'software', 'kpis', 'and', 'visualizations', 'can', 'optimize', 'your', 'business', 'operations']",0,"['how', 'dashboard', 'software', 'kpis', 'and', 'visualization', 'can', 'optimize', 'your', 'business', 'operation']","['dashboard', 'software', 'kpis', 'visualization', 'optimize', 'business', 'operation']",dashboard software kpis visualization optimize business operation,0.0,0.0,11,65,5.416666666666667,0,0,0,0,0,0,0,0
4286,new leaderboard with  test verification,new leaderboard with  test verification,"['new', 'leaderboard', 'with', 'test', 'verification']",1,"['new', 'leaderboard', 'with', 'test', 'verification']","['new', 'leaderboard', 'test', 'verification']",new leaderboard test verification,0.1363636363636363,0.1363636363636363,5,33,5.5,0,0,0,0,0,0,0,0
4287,reverse analysis of a multiple regression problem,reverse analysis of a multiple regression problem,"['reverse', 'analysis', 'of', 'a', 'multiple', 'regression', 'problem']",0,"['reverse', 'analysis', 'of', 'a', 'multiple', 'regression', 'problem']","['reverse', 'analysis', 'multiple', 'regression', 'problem']",reverse analysis multiple regression problem,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
4288,what is the difference between regression and random forest where is random forest more effective,what is the difference between regression and random forest where is random forest more effective,"['what', 'is', 'the', 'difference', 'between', 'regression', 'and', 'random', 'forest', 'where', 'is', 'random', 'forest', 'more', 'effective']",0,"['what', 'is', 'the', 'difference', 'between', 'regression', 'and', 'random', 'forest', 'where', 'is', 'random', 'forest', 'more', 'effective']","['difference', 'regression', 'random', 'forest', 'random', 'forest', 'effective']",difference regression random forest random forest effective,0.0249999999999999,-0.1333333333333333,15,59,3.6875,0,0,0,0,0,0,0,0
4289,how to access large data sets on kaggle without downloading them to system,how to access large data sets on kaggle without downloading them to system,"['how', 'to', 'access', 'large', 'data', 'sets', 'on', 'kaggle', 'without', 'downloading', 'them', 'to', 'system']",0,"['how', 'to', 'access', 'large', 'data', 'set', 'on', 'kaggle', 'without', 'downloading', 'them', 'to', 'system']","['access', 'large', 'data', 'set', 'kaggle', 'without', 'downloading', 'system']",access large data set kaggle without downloading system,0.2142857142857142,0.2142857142857142,13,55,3.9285714285714284,0,0,0,0,0,0,0,0
4290,pattern matching,pattern matching,"['pattern', 'matching']",0,"['pattern', 'matching']","['pattern', 'matching']",pattern matching,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
4291,different outputs everytime the program is run while scraping web using beautiful soup,different outputs everytime the program is run while scraping web using beautiful soup,"['different', 'outputs', 'everytime', 'the', 'program', 'is', 'run', 'while', 'scraping', 'web', 'using', 'beautiful', 'soup']",0,"['different', 'output', 'everytime', 'the', 'program', 'is', 'run', 'while', 'scraping', 'web', 'using', 'beautiful', 'soup']","['different', 'output', 'everytime', 'program', 'run', 'scraping', 'web', 'using', 'beautiful', 'soup']",different output everytime program run scraping web using beautiful soup,0.425,0.425,13,72,5.142857142857143,0,0,0,0,0,0,0,0
4292,understanding transformers self attention calculation,understanding transformers self attention calculation,"['understanding', 'transformers', 'self', 'attention', 'calculation']",0,"['understanding', 'transformer', 'self', 'attention', 'calculation']","['understanding', 'transformer', 'self', 'attention', 'calculation']",understanding transformer self attention calculation,0.0,0.0,5,52,8.666666666666666,0,0,0,0,0,0,0,0
4293,download beginners guide to learn data science in python,download beginners guide to learn data science in python,"['download', 'beginners', 'guide', 'to', 'learn', 'data', 'science', 'in', 'python']",0,"['download', 'beginner', 'guide', 'to', 'learn', 'data', 'science', 'in', 'python']","['download', 'beginner', 'guide', 'learn', 'data', 'science', 'python']",download beginner guide learn data science python,0.0,0.0,9,49,4.9,0,0,0,0,0,0,0,0
4294,logistic regression,logistic regression,"['logistic', 'regression']",0,"['logistic', 'regression']","['logistic', 'regression']",logistic regression,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
4295,approach to time series problem xgboost,approach to time series problem xgboost,"['approach', 'to', 'time', 'series', 'problem', 'xgboost']",0,"['approach', 'to', 'time', 'series', 'problem', 'xgboost']","['approach', 'time', 'series', 'problem', 'xgboost']",approach time series problem xgboost,0.0,0.0,6,36,5.142857142857143,0,0,0,0,0,0,0,0
4296,switching to rsas from sap hana for better job prospects and the necessity of a masters degree for a nonengineer in analytics,switching to rsas from sap hana for better job prospects and the necessity of a masters degree for a nonengineer in analytics,"['switching', 'to', 'rsas', 'from', 'sap', 'hana', 'for', 'better', 'job', 'prospects', 'and', 'the', 'necessity', 'of', 'a', 'masters', 'degree', 'for', 'a', 'nonengineer', 'in', 'analytics']",0,"['switching', 'to', 'rsas', 'from', 'sap', 'hana', 'for', 'better', 'job', 'prospect', 'and', 'the', 'necessity', 'of', 'a', 'master', 'degree', 'for', 'a', 'nonengineer', 'in', 'analytics']","['switching', 'rsas', 'sap', 'hana', 'better', 'job', 'prospect', 'necessity', 'master', 'degree', 'nonengineer', 'analytics']",switching rsas sap hana better job prospect necessity master degree nonengineer analytics,0.5,0.5,22,89,3.869565217391304,0,0,0,0,0,0,0,0
4297,number of analytics professionals across the globe,number of analytics professionals across the globe,"['number', 'of', 'analytics', 'professionals', 'across', 'the', 'globe']",0,"['number', 'of', 'analytics', 'professional', 'across', 'the', 'globe']","['number', 'analytics', 'professional', 'across', 'globe']",number analytics professional across globe,0.0,0.1,7,42,5.25,0,0,0,0,0,0,0,0
4298,how to predict sale price in r,how to predict sale price in r,"['how', 'to', 'predict', 'sale', 'price', 'in', 'r']",0,"['how', 'to', 'predict', 'sale', 'price', 'in', 'r']","['predict', 'sale', 'price', 'r']",predict sale price r,0.0,0.0,7,20,2.5,0,0,0,0,0,0,0,0
4299,amazon ec instance for machine learning model,amazon ec instance for machine learning model,"['amazon', 'ec', 'instance', 'for', 'machine', 'learning', 'model']",0,"['amazon', 'ec', 'instance', 'for', 'machine', 'learning', 'model']","['amazon', 'ec', 'instance', 'machine', 'learning', 'model']",amazon ec instance machine learning model,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
4300,replacing  in the dataset in r,replacing  in the dataset in r,"['replacing', 'in', 'the', 'dataset', 'in', 'r']",0,"['replacing', 'in', 'the', 'dataset', 'in', 'r']","['replacing', 'dataset', 'r']",replacing dataset r,0.0,0.0,6,19,2.7142857142857144,0,0,0,0,0,0,0,0
4301,how to specify the index argument of series in ipython,how to specify the index argument of series in ipython,"['how', 'to', 'specify', 'the', 'index', 'argument', 'of', 'series', 'in', 'ipython']",0,"['how', 'to', 'specify', 'the', 'index', 'argument', 'of', 'series', 'in', 'ipython']","['specify', 'index', 'argument', 'series', 'ipython']",specify index argument series ipython,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
4302,how does c treat missing values internally,how does c treat missing values internally,"['how', 'does', 'c', 'treat', 'missing', 'values', 'internally']",0,"['how', 'doe', 'c', 'treat', 'missing', 'value', 'internally']","['doe', 'c', 'treat', 'missing', 'value', 'internally']",doe c treat missing value internally,-0.1,-0.1,7,36,4.5,0,0,0,0,0,0,0,0
4303,how to create a word cloud in r,how to create a word cloud in r,"['how', 'to', 'create', 'a', 'word', 'cloud', 'in', 'r']",0,"['how', 'to', 'create', 'a', 'word', 'cloud', 'in', 'r']","['create', 'word', 'cloud', 'r']",create word cloud r,0.0,0.0,8,19,2.111111111111111,0,0,0,0,0,0,0,0
4304,error in computing confusion matrix,error in computing confusion matrix,"['error', 'in', 'computing', 'confusion', 'matrix']",0,"['error', 'in', 'computing', 'confusion', 'matrix']","['error', 'computing', 'confusion', 'matrix']",error computing confusion matrix,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
4305,voice cloning with voice samples,voice cloning with voice samples,"['voice', 'cloning', 'with', 'voice', 'samples']",0,"['voice', 'cloning', 'with', 'voice', 'sample']","['voice', 'cloning', 'voice', 'sample']",voice cloning voice sample,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
4306,online deep learning course,online deep learning course,"['online', 'deep', 'learning', 'course']",0,"['online', 'deep', 'learning', 'course']","['online', 'deep', 'learning', 'course']",online deep learning course,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
4307,r studio proxy setting for windows,r studio proxy setting for windows,"['r', 'studio', 'proxy', 'setting', 'for', 'windows']",0,"['r', 'studio', 'proxy', 'setting', 'for', 'window']","['r', 'studio', 'proxy', 'setting', 'window']",r studio proxy setting window,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
4308,intime and outoftime validations,intime and outoftime validations,"['intime', 'and', 'outoftime', 'validations']",0,"['intime', 'and', 'outoftime', 'validation']","['intime', 'outoftime', 'validation']",intime outoftime validation,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
4309,extracting only  consecutive y values,extracting only  consecutive y values,"['extracting', 'only', 'consecutive', 'y', 'values']",1,"['extracting', 'only', 'consecutive', 'y', 'value']","['extracting', 'consecutive', 'value']",extracting consecutive value,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
4310,mini datahack  may solution,mini datahack  may solution,"['mini', 'datahack', 'may', 'solution']",1,"['mini', 'datahack', 'may', 'solution']","['mini', 'datahack', 'may', 'solution']",mini datahack may solution,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
4311,marketing analytics  predictive models,marketing analytics  predictive models,"['marketing', 'analytics', 'predictive', 'models']",0,"['marketing', 'analytics', 'predictive', 'model']","['marketing', 'analytics', 'predictive', 'model']",marketing analytics predictive model,0.0,0.0,4,36,7.2,0,0,0,0,0,0,0,0
4312,problem in storing output in image classification challenge,problem in storing output in image classification challenge,"['problem', 'in', 'storing', 'output', 'in', 'image', 'classification', 'challenge']",0,"['problem', 'in', 'storing', 'output', 'in', 'image', 'classification', 'challenge']","['problem', 'storing', 'output', 'image', 'classification', 'challenge']",problem storing output image classification challenge,0.0,0.0,8,53,5.888888888888889,0,0,0,0,0,0,0,0
4313,question on pca and factor analysisregression,question on pca and factor analysisregression,"['question', 'on', 'pca', 'and', 'factor', 'analysisregression']",0,"['question', 'on', 'pca', 'and', 'factor', 'analysisregression']","['question', 'pca', 'factor', 'analysisregression']",question pca factor analysisregression,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
4314,aggregation of discounts,aggregation of discounts,"['aggregation', 'of', 'discounts']",0,"['aggregation', 'of', 'discount']","['aggregation', 'discount']",aggregation discount,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
4315,customer health score,customer health score,"['customer', 'health', 'score']",0,"['customer', 'health', 'score']","['customer', 'health', 'score']",customer health score,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
4316,machine learning and ocr,machine learning and ocr,"['machine', 'learning', 'and', 'ocr']",0,"['machine', 'learning', 'and', 'ocr']","['machine', 'learning', 'ocr']",machine learning ocr,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
4317,time series forecasting with probabilitypython,time series forecasting with probabilitypython,"['time', 'series', 'forecasting', 'with', 'probabilitypython']",0,"['time', 'series', 'forecasting', 'with', 'probabilitypython']","['time', 'series', 'forecasting', 'probabilitypython']",time series forecasting probabilitypython,0.0,0.0,5,41,6.833333333333333,0,0,0,0,0,0,0,0
4318,do you know any open dataset,do you know any open dataset,"['do', 'you', 'know', 'any', 'open', 'dataset']",0,"['do', 'you', 'know', 'any', 'open', 'dataset']","['know', 'open', 'dataset']",know open dataset,0.0,0.0,6,17,2.4285714285714284,0,0,0,0,0,0,0,0
4319,how to install xgboost package on x bit windows for python,how to install xgboost package on x bit windows for python,"['how', 'to', 'install', 'xgboost', 'package', 'on', 'x', 'bit', 'windows', 'for', 'python']",0,"['how', 'to', 'install', 'xgboost', 'package', 'on', 'x', 'bit', 'window', 'for', 'python']","['install', 'xgboost', 'package', 'x', 'bit', 'window', 'python']",install xgboost package x bit window python,0.0,0.0,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
4320,how to calculate accuracy for the test data in python,how to calculate accuracy for the test data in python,"['how', 'to', 'calculate', 'accuracy', 'for', 'the', 'test', 'data', 'in', 'python']",0,"['how', 'to', 'calculate', 'accuracy', 'for', 'the', 'test', 'data', 'in', 'python']","['calculate', 'accuracy', 'test', 'data', 'python']",calculate accuracy test data python,0.0,0.0,10,35,3.1818181818181817,0,0,0,0,0,0,0,0
4321,data science interview guide,data science interview guide,"['data', 'science', 'interview', 'guide']",0,"['data', 'science', 'interview', 'guide']","['data', 'science', 'interview', 'guide']",data science interview guide,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
4322,maximum depth of a decision tree,maximum depth of a decision tree,"['maximum', 'depth', 'of', 'a', 'decision', 'tree']",0,"['maximum', 'depth', 'of', 'a', 'decision', 'tree']","['maximum', 'depth', 'decision', 'tree']",maximum depth decision tree,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
4323,how to load  gb data in r studio with  gb ram size,how to load  gb data in r studio with  gb ram size,"['how', 'to', 'load', 'gb', 'data', 'in', 'r', 'studio', 'with', 'gb', 'ram', 'size']",2,"['how', 'to', 'load', 'gb', 'data', 'in', 'r', 'studio', 'with', 'gb', 'ram', 'size']","['load', 'gb', 'data', 'r', 'studio', 'gb', 'ram', 'size']",load gb data r studio gb ram size,0.0,0.0,12,33,2.5384615384615383,0,0,0,0,0,0,0,0
4324,how multiple imputation helps in filling the missing value of a variable,how multiple imputation helps in filling the missing value of a variable,"['how', 'multiple', 'imputation', 'helps', 'in', 'filling', 'the', 'missing', 'value', 'of', 'a', 'variable']",0,"['how', 'multiple', 'imputation', 'help', 'in', 'filling', 'the', 'missing', 'value', 'of', 'a', 'variable']","['multiple', 'imputation', 'help', 'filling', 'missing', 'value', 'variable']",multiple imputation help filling missing value variable,-0.1,-0.1,12,55,4.230769230769231,0,0,0,0,0,0,0,0
4325,how to load googles pretrained wordvec model in python,how to load googles pretrained wordvec model in python,"['how', 'to', 'load', 'googles', 'pretrained', 'wordvec', 'model', 'in', 'python']",0,"['how', 'to', 'load', 'google', 'pretrained', 'wordvec', 'model', 'in', 'python']","['load', 'google', 'pretrained', 'wordvec', 'model', 'python']",load google pretrained wordvec model python,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
4326,error vs residual,error vs residual,"['error', 'vs', 'residual']",0,"['error', 'v', 'residual']","['error', 'v', 'residual']",error v residual,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
4327,what are the advantages of scipy over matlab,what are the advantages of scipy over matlab,"['what', 'are', 'the', 'advantages', 'of', 'scipy', 'over', 'matlab']",0,"['what', 'are', 'the', 'advantage', 'of', 'scipy', 'over', 'matlab']","['advantage', 'scipy', 'matlab']",advantage scipy matlab,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
4328,python how to use boxcox to transform right skewed data to normal distribution,python how to use boxcox to transform right skewed data to normal distribution,"['python', 'how', 'to', 'use', 'boxcox', 'to', 'transform', 'right', 'skewed', 'data', 'to', 'normal', 'distribution']",0,"['python', 'how', 'to', 'use', 'boxcox', 'to', 'transform', 'right', 'skewed', 'data', 'to', 'normal', 'distribution']","['python', 'use', 'boxcox', 'transform', 'right', 'skewed', 'data', 'normal', 'distribution']",python use boxcox transform right skewed data normal distribution,0.2178571428571428,0.2178571428571428,13,65,4.642857142857143,0,0,0,0,0,0,0,0
4329,python  how to fix a parameter while fitting,python  how to fix a parameter while fitting,"['python', 'how', 'to', 'fix', 'a', 'parameter', 'while', 'fitting']",0,"['python', 'how', 'to', 'fix', 'a', 'parameter', 'while', 'fitting']","['python', 'fix', 'parameter', 'fitting']",python fix parameter fitting,0.5,0.5,8,28,3.111111111111111,0,0,0,0,0,0,0,0
4330,tableau and power bi,tableau and power bi,"['tableau', 'and', 'power', 'bi']",0,"['tableau', 'and', 'power', 'bi']","['tableau', 'power', 'bi']",tableau power bi,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
4331,unbalanced data,unbalanced data,"['unbalanced', 'data']",0,"['unbalanced', 'data']","['unbalanced', 'data']",unbalanced data,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
4332,th place solution amexpert,th place solution amexpert,"['th', 'place', 'solution', 'amexpert']",0,"['th', 'place', 'solution', 'amexpert']","['th', 'place', 'solution', 'amexpert']",th place solution amexpert,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
4333,advance retail analytics course,advance retail analytics course,"['advance', 'retail', 'analytics', 'course']",0,"['advance', 'retail', 'analytics', 'course']","['advance', 'retail', 'analytics', 'course']",advance retail analytics course,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
4334,data analytics in pg,data analytics in pg,"['data', 'analytics', 'in', 'pg']",0,"['data', 'analytics', 'in', 'pg']","['data', 'analytics', 'pg']",data analytics pg,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
4335,retreving results after a keyword,retreving results after a keyword,"['retreving', 'results', 'after', 'a', 'keyword']",0,"['retreving', 'result', 'after', 'a', 'keyword']","['retreving', 'result', 'keyword']",retreving result keyword,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
4336,continually updated data science python notebooks spark hadoop mapreduce hdfs aws kaggle scikitlearn matplotlib pandas numpy and various command lines,continually updated data science python notebooks spark hadoop mapreduce hdfs aws kaggle scikitlearn matplotlib pandas numpy and various command lines,"['continually', 'updated', 'data', 'science', 'python', 'notebooks', 'spark', 'hadoop', 'mapreduce', 'hdfs', 'aws', 'kaggle', 'scikitlearn', 'matplotlib', 'pandas', 'numpy', 'and', 'various', 'command', 'lines']",0,"['continually', 'updated', 'data', 'science', 'python', 'notebook', 'spark', 'hadoop', 'mapreduce', 'hdfs', 'aws', 'kaggle', 'scikitlearn', 'matplotlib', 'panda', 'numpy', 'and', 'various', 'command', 'line']","['continually', 'updated', 'data', 'science', 'python', 'notebook', 'spark', 'hadoop', 'mapreduce', 'hdfs', 'aws', 'kaggle', 'scikitlearn', 'matplotlib', 'panda', 'numpy', 'various', 'command', 'line']",continually updated data science python notebook spark hadoop mapreduce hdfs aws kaggle scikitlearn matplotlib panda numpy various command line,0.0,0.0,20,143,6.809523809523809,0,0,0,0,0,0,0,0
4337,how to do proxy settings in rstudio in ubuntu ,how to do proxy settings in rstudio in ubuntu ,"['how', 'to', 'do', 'proxy', 'settings', 'in', 'rstudio', 'in', 'ubuntu']",1,"['how', 'to', 'do', 'proxy', 'setting', 'in', 'rstudio', 'in', 'ubuntu']","['proxy', 'setting', 'rstudio', 'ubuntu']",proxy setting rstudio ubuntu,0.0,0.0,9,28,2.8,0,0,0,0,0,0,0,0
4338,how to specify the number of trees in gradient boosting while using caret,how to specify the number of trees in gradient boosting while using caret,"['how', 'to', 'specify', 'the', 'number', 'of', 'trees', 'in', 'gradient', 'boosting', 'while', 'using', 'caret']",0,"['how', 'to', 'specify', 'the', 'number', 'of', 'tree', 'in', 'gradient', 'boosting', 'while', 'using', 'caret']","['specify', 'number', 'tree', 'gradient', 'boosting', 'using', 'caret']",specify number tree gradient boosting using caret,0.0,0.0,13,49,3.5,0,0,0,0,0,0,0,0
4339,is manipal prolearn data science full time course really worth it or should i go for praxis business school data science course,is manipal prolearn data science full time course really worth it or should i go for praxis business school data science course,"['is', 'manipal', 'prolearn', 'data', 'science', 'full', 'time', 'course', 'really', 'worth', 'it', 'or', 'should', 'i', 'go', 'for', 'praxis', 'business', 'school', 'data', 'science', 'course']",0,"['is', 'manipal', 'prolearn', 'data', 'science', 'full', 'time', 'course', 'really', 'worth', 'it', 'or', 'should', 'i', 'go', 'for', 'praxis', 'business', 'school', 'data', 'science', 'course']","['manipal', 'prolearn', 'data', 'science', 'full', 'time', 'course', 'really', 'worth', 'go', 'praxis', 'business', 'school', 'data', 'science', 'course']",manipal prolearn data science full time course really worth go praxis business school data science course,0.3249999999999999,0.3249999999999999,22,105,4.565217391304348,0,0,0,0,0,0,0,0
4340,what is time series analysis,what is time series analysis,"['what', 'is', 'time', 'series', 'analysis']",0,"['what', 'is', 'time', 'series', 'analysis']","['time', 'series', 'analysis']",time series analysis,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
4341,k means plotting in python,k means plotting in python,"['k', 'means', 'plotting', 'in', 'python']",0,"['k', 'mean', 'plotting', 'in', 'python']","['k', 'mean', 'plotting', 'python']",k mean plotting python,0.0,-0.3125,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
4342,linear regression assumptions not satisfied,linear regression assumptions not satisfied,"['linear', 'regression', 'assumptions', 'not', 'satisfied']",0,"['linear', 'regression', 'assumption', 'not', 'satisfied']","['linear', 'regression', 'assumption', 'satisfied']",linear regression assumption satisfied,-0.25,0.5,5,38,6.333333333333333,0,0,0,0,0,0,0,0
4343,iot analytics  time series,iot analytics  time series,"['iot', 'analytics', 'time', 'series']",0,"['iot', 'analytics', 'time', 'series']","['iot', 'analytics', 'time', 'series']",iot analytics time series,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
4344,imputing missing values in the smart recruits hackathon,imputing missing values in the smart recruits hackathon,"['imputing', 'missing', 'values', 'in', 'the', 'smart', 'recruits', 'hackathon']",0,"['imputing', 'missing', 'value', 'in', 'the', 'smart', 'recruit', 'hackathon']","['imputing', 'missing', 'value', 'smart', 'recruit', 'hackathon']",imputing missing value smart recruit hackathon,0.0071428571428571,0.0071428571428571,8,46,5.111111111111111,0,0,0,0,0,0,0,0
4345,what is repeated cv in caret,what is repeated cv in caret,"['what', 'is', 'repeated', 'cv', 'in', 'caret']",0,"['what', 'is', 'repeated', 'cv', 'in', 'caret']","['repeated', 'cv', 'caret']",repeated cv caret,0.0,0.0,6,17,2.4285714285714284,0,0,0,0,0,0,0,0
4346,how to shuffle the rows of the data set,how to shuffle the rows of the data set,"['how', 'to', 'shuffle', 'the', 'rows', 'of', 'the', 'data', 'set']",0,"['how', 'to', 'shuffle', 'the', 'row', 'of', 'the', 'data', 'set']","['shuffle', 'row', 'data', 'set']",shuffle row data set,0.0,0.0,9,20,2.0,0,0,0,0,0,0,0,0
4347,cox ph coefficients interpretation,cox ph coefficients interpretation,"['cox', 'ph', 'coefficients', 'interpretation']",0,"['cox', 'ph', 'coefficient', 'interpretation']","['cox', 'ph', 'coefficient', 'interpretation']",cox ph coefficient interpretation,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
4348,tuples vs lists in python,tuples vs lists in python,"['tuples', 'vs', 'lists', 'in', 'python']",0,"['tuples', 'v', 'list', 'in', 'python']","['tuples', 'v', 'list', 'python']",tuples v list python,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
4349,viewing the source code for a randomforest function,viewing the source code for a randomforest function,"['viewing', 'the', 'source', 'code', 'for', 'a', 'randomforest', 'function']",0,"['viewing', 'the', 'source', 'code', 'for', 'a', 'randomforest', 'function']","['viewing', 'source', 'code', 'randomforest', 'function']",viewing source code randomforest function,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
4350,what is centering of data,what is centering of data,"['what', 'is', 'centering', 'of', 'data']",0,"['what', 'is', 'centering', 'of', 'data']","['centering', 'data']",centering data,0.0,0.0,5,14,2.3333333333333335,0,0,0,0,0,0,0,0
4351,how to use sents method in spacy,how to use sents method in spacy,"['how', 'to', 'use', 'sents', 'method', 'in', 'spacy']",0,"['how', 'to', 'use', 'sent', 'method', 'in', 'spacy']","['use', 'sent', 'method', 'spacy']",use sent method spacy,0.0,0.0,7,21,2.625,0,0,0,0,0,0,0,0
4352,which tool should i choose to start studying analytics sas or r,which tool should i choose to start studying analytics sas or r,"['which', 'tool', 'should', 'i', 'choose', 'to', 'start', 'studying', 'analytics', 'sas', 'or', 'r']",0,"['which', 'tool', 'should', 'i', 'choose', 'to', 'start', 'studying', 'analytics', 'sa', 'or', 'r']","['tool', 'choose', 'start', 'studying', 'analytics', 'sa', 'r']",tool choose start studying analytics sa r,0.0,0.0,12,41,3.1538461538461537,0,0,0,0,0,0,0,0
4353,how to answer business understanding rounds in interviews,how to answer business understanding rounds in interviews,"['how', 'to', 'answer', 'business', 'understanding', 'rounds', 'in', 'interviews']",0,"['how', 'to', 'answer', 'business', 'understanding', 'round', 'in', 'interview']","['answer', 'business', 'understanding', 'round', 'interview']",answer business understanding round interview,0.0,-0.2,8,45,5.0,0,0,0,0,0,0,0,0
4354,what does the output of rotated components in r display,what does the output of rotated components in r display,"['what', 'does', 'the', 'output', 'of', 'rotated', 'components', 'in', 'r', 'display']",0,"['what', 'doe', 'the', 'output', 'of', 'rotated', 'component', 'in', 'r', 'display']","['doe', 'output', 'rotated', 'component', 'r', 'display']",doe output rotated component r display,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
4355,conversion of categorical var to numerical throws error with following code,conversion of categorical var to numerical throws error with following code,"['conversion', 'of', 'categorical', 'var', 'to', 'numerical', 'throws', 'error', 'with', 'following', 'code']",0,"['conversion', 'of', 'categorical', 'var', 'to', 'numerical', 'throw', 'error', 'with', 'following', 'code']","['conversion', 'categorical', 'var', 'numerical', 'throw', 'error', 'following', 'code']",conversion categorical var numerical throw error following code,0.0,0.0,11,63,5.25,0,0,0,0,0,0,0,0
4356,questions on time series tutorial,questions on time series tutorial,"['questions', 'on', 'time', 'series', 'tutorial']",0,"['question', 'on', 'time', 'series', 'tutorial']","['question', 'time', 'series', 'tutorial']",question time series tutorial,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
4357,a great resource for ensemble learning,a great resource for ensemble learning,"['a', 'great', 'resource', 'for', 'ensemble', 'learning']",0,"['a', 'great', 'resource', 'for', 'ensemble', 'learning']","['great', 'resource', 'ensemble', 'learning']",great resource ensemble learning,0.8,0.8,6,32,4.571428571428571,0,0,0,0,0,0,0,0
4358,typeerror string indices must be integers,typeerror string indices must be integers,"['typeerror', 'string', 'indices', 'must', 'be', 'integers']",0,"['typeerror', 'string', 'index', 'must', 'be', 'integer']","['typeerror', 'string', 'index', 'must', 'integer']",typeerror string index must integer,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
4359,is there anyway to see scipts from previous contests,is there anyway to see scipts from previous contests,"['is', 'there', 'anyway', 'to', 'see', 'scipts', 'from', 'previous', 'contests']",0,"['is', 'there', 'anyway', 'to', 'see', 'scipts', 'from', 'previous', 'contest']","['anyway', 'see', 'scipts', 'previous', 'contest']",anyway see scipts previous contest,-0.1666666666666666,-0.1666666666666666,9,34,3.4,0,0,0,0,0,0,0,0
4360,multi class classification,multi class classification,"['multi', 'class', 'classification']",0,"['multi', 'class', 'classification']","['multi', 'class', 'classification']",multi class classification,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
4361,how do i connect to a sql database using sas,how do i connect to a sql database using sas,"['how', 'do', 'i', 'connect', 'to', 'a', 'sql', 'database', 'using', 'sas']",0,"['how', 'do', 'i', 'connect', 'to', 'a', 'sql', 'database', 'using', 'sa']","['connect', 'sql', 'database', 'using', 'sa']",connect sql database using sa,0.0,0.0,10,29,2.6363636363636362,0,0,0,0,0,0,0,0
4362,welcome to practice problem big mart sales iii,welcome to practice problem big mart sales iii,"['welcome', 'to', 'practice', 'problem', 'big', 'mart', 'sales', 'iii']",0,"['welcome', 'to', 'practice', 'problem', 'big', 'mart', 'sale', 'iii']","['welcome', 'practice', 'problem', 'big', 'mart', 'sale', 'iii']",welcome practice problem big mart sale iii,0.4,0.4,8,42,4.666666666666667,0,0,0,0,0,0,0,0
4363,implementing var vector auto regression,implementing var vector auto regression,"['implementing', 'var', 'vector', 'auto', 'regression']",0,"['implementing', 'var', 'vector', 'auto', 'regression']","['implementing', 'var', 'vector', 'auto', 'regression']",implementing var vector auto regression,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
4364,clarification on employee absenteeism prediction kaggle dataset,clarification on employee absenteeism prediction kaggle dataset,"['clarification', 'on', 'employee', 'absenteeism', 'prediction', 'kaggle', 'dataset']",0,"['clarification', 'on', 'employee', 'absenteeism', 'prediction', 'kaggle', 'dataset']","['clarification', 'employee', 'absenteeism', 'prediction', 'kaggle', 'dataset']",clarification employee absenteeism prediction kaggle dataset,0.0,0.0,7,60,7.5,0,0,0,0,0,0,0,0
4365,resources for time series prediction using deep learning,resources for time series prediction using deep learning,"['resources', 'for', 'time', 'series', 'prediction', 'using', 'deep', 'learning']",0,"['resource', 'for', 'time', 'series', 'prediction', 'using', 'deep', 'learning']","['resource', 'time', 'series', 'prediction', 'using', 'deep', 'learning']",resource time series prediction using deep learning,0.0,0.0,8,51,5.666666666666667,0,0,0,0,0,0,0,0
4366,weightage of wiley wrox big data analytics certification in job market,weightage of wiley wrox big data analytics certification in job market,"['weightage', 'of', 'wiley', 'wrox', 'big', 'data', 'analytics', 'certification', 'in', 'job', 'market']",0,"['weightage', 'of', 'wiley', 'wrox', 'big', 'data', 'analytics', 'certification', 'in', 'job', 'market']","['weightage', 'wiley', 'wrox', 'big', 'data', 'analytics', 'certification', 'job', 'market']",weightage wiley wrox big data analytics certification job market,0.0,0.0,11,64,5.333333333333333,0,0,0,0,0,0,0,0
4367,adding dependent variable to test data set,adding dependent variable to test data set,"['adding', 'dependent', 'variable', 'to', 'test', 'data', 'set']",0,"['adding', 'dependent', 'variable', 'to', 'test', 'data', 'set']","['adding', 'dependent', 'variable', 'test', 'data', 'set']",adding dependent variable test data set,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
4368,best way to learn r  tableau,best way to learn r  tableau,"['best', 'way', 'to', 'learn', 'r', 'tableau']",0,"['best', 'way', 'to', 'learn', 'r', 'tableau']","['best', 'way', 'learn', 'r', 'tableau']",best way learn r tableau,1.0,1.0,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
4369,how to handle latlon features in a model,how to handle latlon features in a model,"['how', 'to', 'handle', 'latlon', 'features', 'in', 'a', 'model']",0,"['how', 'to', 'handle', 'latlon', 'feature', 'in', 'a', 'model']","['handle', 'latlon', 'feature', 'model']",handle latlon feature model,0.0,0.0,8,27,3.0,0,0,0,0,0,0,0,0
4370,sentiment analysis in python from scratch,sentiment analysis in python from scratch,"['sentiment', 'analysis', 'in', 'python', 'from', 'scratch']",0,"['sentiment', 'analysis', 'in', 'python', 'from', 'scratch']","['sentiment', 'analysis', 'python', 'scratch']",sentiment analysis python scratch,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
4371,how to deal with inputtext written by human  locode,how to deal with inputtext written by human  locode,"['how', 'to', 'deal', 'with', 'inputtext', 'written', 'by', 'human', 'locode']",0,"['how', 'to', 'deal', 'with', 'inputtext', 'written', 'by', 'human', 'locode']","['deal', 'inputtext', 'written', 'human', 'locode']",deal inputtext written human locode,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
4372,forecasting stock market and forex exchange,forecasting stock market and forex exchange,"['forecasting', 'stock', 'market', 'and', 'forex', 'exchange']",0,"['forecasting', 'stock', 'market', 'and', 'forex', 'exchange']","['forecasting', 'stock', 'market', 'forex', 'exchange']",forecasting stock market forex exchange,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
4373,reshaping data in r,reshaping data in r,"['reshaping', 'data', 'in', 'r']",0,"['reshaping', 'data', 'in', 'r']","['reshaping', 'data', 'r']",reshaping data r,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
4374,complete data scientist course package,complete data scientist course package,"['complete', 'data', 'scientist', 'course', 'package']",0,"['complete', 'data', 'scientist', 'course', 'package']","['complete', 'data', 'scientist', 'course', 'package']",complete data scientist course package,0.1,0.1,5,38,6.333333333333333,0,0,0,0,0,0,0,0
4375,trying to replicate loan prediction with sas but,trying to replicate loan prediction with sas but,"['trying', 'to', 'replicate', 'loan', 'prediction', 'with', 'sas', 'but']",0,"['trying', 'to', 'replicate', 'loan', 'prediction', 'with', 'sa', 'but']","['trying', 'replicate', 'loan', 'prediction', 'sa']",trying replicate loan prediction sa,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
4376,pwr functions in r,pwr functions in r,"['pwr', 'functions', 'in', 'r']",0,"['pwr', 'function', 'in', 'r']","['pwr', 'function', 'r']",pwr function r,0.0,0.0,4,14,2.8,0,0,0,0,0,0,0,0
4377,focus forecasting,focus forecasting,"['focus', 'forecasting']",0,"['focus', 'forecasting']","['focus', 'forecasting']",focus forecasting,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
4378,will an internship in clinical sas be good or bad for career in analytics,will an internship in clinical sas be good or bad for career in analytics,"['will', 'an', 'internship', 'in', 'clinical', 'sas', 'be', 'good', 'or', 'bad', 'for', 'career', 'in', 'analytics']",0,"['will', 'an', 'internship', 'in', 'clinical', 'sa', 'be', 'good', 'or', 'bad', 'for', 'career', 'in', 'analytics']","['internship', 'clinical', 'sa', 'good', 'bad', 'career', 'analytics']",internship clinical sa good bad career analytics,5.551115123125783e-17,5.551115123125783e-17,14,48,3.2,0,0,0,0,0,0,0,0
4379,bigmart sales using r,bigmart sales using r,"['bigmart', 'sales', 'using', 'r']",0,"['bigmart', 'sale', 'using', 'r']","['bigmart', 'sale', 'using', 'r']",bigmart sale using r,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
4380,training a neural network model on a simple windows  machine,training a neural network model on a simple windows  machine,"['training', 'a', 'neural', 'network', 'model', 'on', 'a', 'simple', 'windows', 'machine']",1,"['training', 'a', 'neural', 'network', 'model', 'on', 'a', 'simple', 'window', 'machine']","['training', 'neural', 'network', 'model', 'simple', 'window', 'machine']",training neural network model simple window machine,0.0,0.0,10,51,4.636363636363637,0,0,0,0,0,0,0,0
4381,how to do segmentation based on some filterseg traffic signals from live streaming data,how to do segmentation based on some filterseg traffic signals from live streaming data,"['how', 'to', 'do', 'segmentation', 'based', 'on', 'some', 'filterseg', 'traffic', 'signals', 'from', 'live', 'streaming', 'data']",0,"['how', 'to', 'do', 'segmentation', 'based', 'on', 'some', 'filterseg', 'traffic', 'signal', 'from', 'live', 'streaming', 'data']","['segmentation', 'based', 'filterseg', 'traffic', 'signal', 'live', 'streaming', 'data']",segmentation based filterseg traffic signal live streaming data,0.1363636363636363,0.1363636363636363,14,63,4.2,0,0,0,0,0,0,0,0
4382,analytics training info,analytics training info,"['analytics', 'training', 'info']",0,"['analytics', 'training', 'info']","['analytics', 'training', 'info']",analytics training info,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
4383,problem with weekday in sas gchart graphs,problem with weekday in sas gchart graphs,"['problem', 'with', 'weekday', 'in', 'sas', 'gchart', 'graphs']",0,"['problem', 'with', 'weekday', 'in', 'sa', 'gchart', 'graph']","['problem', 'weekday', 'sa', 'gchart', 'graph']",problem weekday sa gchart graph,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
4384,warning message when qplot function is used in r,warning message when qplot function is used in r,"['warning', 'message', 'when', 'qplot', 'function', 'is', 'used', 'in', 'r']",0,"['warning', 'message', 'when', 'qplot', 'function', 'is', 'used', 'in', 'r']","['warning', 'message', 'qplot', 'function', 'used', 'r']",warning message qplot function used r,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
4385,detecting outofdistribution datapoints via embeddings or predictions,detecting outofdistribution datapoints via embeddings or predictions,"['detecting', 'outofdistribution', 'datapoints', 'via', 'embeddings', 'or', 'predictions']",0,"['detecting', 'outofdistribution', 'datapoints', 'via', 'embeddings', 'or', 'prediction']","['detecting', 'outofdistribution', 'datapoints', 'via', 'embeddings', 'prediction']",detecting outofdistribution datapoints via embeddings prediction,0.0,0.0,7,64,8.0,0,0,0,0,0,0,0,0
4386,advances in data science and machine learning,advances in data science and machine learning,"['advances', 'in', 'data', 'science', 'and', 'machine', 'learning']",0,"['advance', 'in', 'data', 'science', 'and', 'machine', 'learning']","['advance', 'data', 'science', 'machine', 'learning']",advance data science machine learning,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
4387,resource material on time series,resource material on time series,"['resource', 'material', 'on', 'time', 'series']",0,"['resource', 'material', 'on', 'time', 'series']","['resource', 'material', 'time', 'series']",resource material time series,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
4388,logistic regression model building,logistic regression model building,"['logistic', 'regression', 'model', 'building']",0,"['logistic', 'regression', 'model', 'building']","['logistic', 'regression', 'model', 'building']",logistic regression model building,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
4389,converting date to weekday type in python,converting date to weekday type in python,"['converting', 'date', 'to', 'weekday', 'type', 'in', 'python']",0,"['converting', 'date', 'to', 'weekday', 'type', 'in', 'python']","['converting', 'date', 'weekday', 'type', 'python']",converting date weekday type python,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
4390,i want to switch from teaching career to data science in companies,i want to switch from teaching career to data science in companies,"['i', 'want', 'to', 'switch', 'from', 'teaching', 'career', 'to', 'data', 'science', 'in', 'companies']",0,"['i', 'want', 'to', 'switch', 'from', 'teaching', 'career', 'to', 'data', 'science', 'in', 'company']","['want', 'switch', 'teaching', 'career', 'data', 'science', 'company']",want switch teaching career data science company,0.0,0.0,12,48,3.6923076923076925,0,0,0,0,0,0,0,0
4391,statistics is basic skill for data scientist,statistics is basic skill for data scientist,"['statistics', 'is', 'basic', 'skill', 'for', 'data', 'scientist']",0,"['statistic', 'is', 'basic', 'skill', 'for', 'data', 'scientist']","['statistic', 'basic', 'skill', 'data', 'scientist']",statistic basic skill data scientist,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
4392,how to plot kernel density plot on a given histogram plot,how to plot kernel density plot on a given histogram plot,"['how', 'to', 'plot', 'kernel', 'density', 'plot', 'on', 'a', 'given', 'histogram', 'plot']",0,"['how', 'to', 'plot', 'kernel', 'density', 'plot', 'on', 'a', 'given', 'histogram', 'plot']","['plot', 'kernel', 'density', 'plot', 'given', 'histogram', 'plot']",plot kernel density plot given histogram plot,0.0,0.0,11,45,3.75,0,0,0,0,0,0,0,0
4393,r  how to calculate mean by decile in a svydesign object,r  how to calculate mean by decile in a svydesign object,"['r', 'how', 'to', 'calculate', 'mean', 'by', 'decile', 'in', 'a', 'svydesign', 'object']",0,"['r', 'how', 'to', 'calculate', 'mean', 'by', 'decile', 'in', 'a', 'svydesign', 'object']","['r', 'calculate', 'mean', 'decile', 'svydesign', 'object']",r calculate mean decile svydesign object,-0.3125,-0.3125,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
4394,what is difference between different probability distribution in r,what is difference between different probability distribution in r,"['what', 'is', 'difference', 'between', 'different', 'probability', 'distribution', 'in', 'r']",0,"['what', 'is', 'difference', 'between', 'different', 'probability', 'distribution', 'in', 'r']","['difference', 'different', 'probability', 'distribution', 'r']",difference different probability distribution r,0.0,0.0,9,47,4.7,0,0,0,0,0,0,0,0
4395,classification of  categories,classification of  categories,"['classification', 'of', 'categories']",1,"['classification', 'of', 'category']","['classification', 'category']",classification category,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
4396,will the shiny app work only if we keep the code running in background in rstudio,will the shiny app work only if we keep the code running in background in rstudio,"['will', 'the', 'shiny', 'app', 'work', 'only', 'if', 'we', 'keep', 'the', 'code', 'running', 'in', 'background', 'in', 'rstudio']",0,"['will', 'the', 'shiny', 'app', 'work', 'only', 'if', 'we', 'keep', 'the', 'code', 'running', 'in', 'background', 'in', 'rstudio']","['shiny', 'app', 'work', 'keep', 'code', 'running', 'background', 'rstudio']",shiny app work keep code running background rstudio,0.0,0.0,16,51,3.0,0,0,0,0,0,0,0,0
4397,intel scene classification challenge,intel scene classification challenge,"['intel', 'scene', 'classification', 'challenge']",0,"['intel', 'scene', 'classification', 'challenge']","['intel', 'scene', 'classification', 'challenge']",intel scene classification challenge,0.0,0.0,4,36,7.2,0,0,0,0,0,0,0,0
4398,migration to production in r,migration to production in r,"['migration', 'to', 'production', 'in', 'r']",0,"['migration', 'to', 'production', 'in', 'r']","['migration', 'production', 'r']",migration production r,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
4399,how to read a columnjson format from a data frame in r,how to read a columnjson format from a data frame in r,"['how', 'to', 'read', 'a', 'columnjson', 'format', 'from', 'a', 'data', 'frame', 'in', 'r']",0,"['how', 'to', 'read', 'a', 'columnjson', 'format', 'from', 'a', 'data', 'frame', 'in', 'r']","['read', 'columnjson', 'format', 'data', 'frame', 'r']",read columnjson format data frame r,0.0,0.0,12,35,2.6923076923076925,0,0,0,0,0,0,0,0
4400,share result for mini data hack  forecasting,share result for mini data hack  forecasting,"['share', 'result', 'for', 'mini', 'data', 'hack', 'forecasting']",0,"['share', 'result', 'for', 'mini', 'data', 'hack', 'forecasting']","['share', 'result', 'mini', 'data', 'hack', 'forecasting']",share result mini data hack forecasting,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
4401,memory allocation error in r text mining,memory allocation error in r text mining,"['memory', 'allocation', 'error', 'in', 'r', 'text', 'mining']",0,"['memory', 'allocation', 'error', 'in', 'r', 'text', 'mining']","['memory', 'allocation', 'error', 'r', 'text', 'mining']",memory allocation error r text mining,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
4402,fython fortran with python syntax,fython fortran with python syntax,"['fython', 'fortran', 'with', 'python', 'syntax']",0,"['fython', 'fortran', 'with', 'python', 'syntax']","['fython', 'fortran', 'python', 'syntax']",fython fortran python syntax,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
4403,statistics binomial distribution  how to calculate the probability of receiving number of calls,statistics binomial distribution  how to calculate the probability of receiving number of calls,"['statistics', 'binomial', 'distribution', 'how', 'to', 'calculate', 'the', 'probability', 'of', 'receiving', 'number', 'of', 'calls']",0,"['statistic', 'binomial', 'distribution', 'how', 'to', 'calculate', 'the', 'probability', 'of', 'receiving', 'number', 'of', 'call']","['statistic', 'binomial', 'distribution', 'calculate', 'probability', 'receiving', 'number', 'call']",statistic binomial distribution calculate probability receiving number call,0.0,0.0,13,75,5.357142857142857,0,0,0,0,0,0,0,0
4404,how do i develop a system to recommend a marketing channel using data science,how do i develop a system to recommend a marketing channel using data science,"['how', 'do', 'i', 'develop', 'a', 'system', 'to', 'recommend', 'a', 'marketing', 'channel', 'using', 'data', 'science']",0,"['how', 'do', 'i', 'develop', 'a', 'system', 'to', 'recommend', 'a', 'marketing', 'channel', 'using', 'data', 'science']","['develop', 'system', 'recommend', 'marketing', 'channel', 'using', 'data', 'science']",develop system recommend marketing channel using data science,0.0,0.0,14,61,4.066666666666666,0,0,0,0,0,0,0,0
4405,anyone having handson on scala with intellij,anyone having handson on scala with intellij,"['anyone', 'having', 'handson', 'on', 'scala', 'with', 'intellij']",0,"['anyone', 'having', 'handson', 'on', 'scala', 'with', 'intellij']","['anyone', 'handson', 'scala', 'intellij']",anyone handson scala intellij,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
4406,resources for recommendation engine,resources for recommendation engine,"['resources', 'for', 'recommendation', 'engine']",0,"['resource', 'for', 'recommendation', 'engine']","['resource', 'recommendation', 'engine']",resource recommendation engine,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
4407,decision tree gini impurity purity,decision tree gini impurity purity,"['decision', 'tree', 'gini', 'impurity', 'purity']",0,"['decision', 'tree', 'gini', 'impurity', 'purity']","['decision', 'tree', 'gini', 'impurity', 'purity']",decision tree gini impurity purity,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
4408,text mining and clustering,text mining and clustering,"['text', 'mining', 'and', 'clustering']",0,"['text', 'mining', 'and', 'clustering']","['text', 'mining', 'clustering']",text mining clustering,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
4409,johnson su distribution,johnson su distribution,"['johnson', 'su', 'distribution']",0,"['johnson', 'su', 'distribution']","['johnson', 'su', 'distribution']",johnson su distribution,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
4410,how can we randomly split time series data in r and python,how can we randomly split time series data in r and python,"['how', 'can', 'we', 'randomly', 'split', 'time', 'series', 'data', 'in', 'r', 'and', 'python']",0,"['how', 'can', 'we', 'randomly', 'split', 'time', 'series', 'data', 'in', 'r', 'and', 'python']","['randomly', 'split', 'time', 'series', 'data', 'r', 'python']",randomly split time series data r python,-0.5,-0.5,12,40,3.076923076923077,0,0,0,0,0,0,0,0
4411,which is the best place to learn big data,which is the best place to learn big data,"['which', 'is', 'the', 'best', 'place', 'to', 'learn', 'big', 'data']",0,"['which', 'is', 'the', 'best', 'place', 'to', 'learn', 'big', 'data']","['best', 'place', 'learn', 'big', 'data']",best place learn big data,0.5,0.5,9,25,2.5,0,0,0,0,0,0,0,0
4412,advantages of onehotcoding for gbm or xgboost,advantages of onehotcoding for gbm or xgboost,"['advantages', 'of', 'onehotcoding', 'for', 'gbm', 'or', 'xgboost']",0,"['advantage', 'of', 'onehotcoding', 'for', 'gbm', 'or', 'xgboost']","['advantage', 'onehotcoding', 'gbm', 'xgboost']",advantage onehotcoding gbm xgboost,0.0,0.0,7,34,4.25,0,0,0,0,0,0,0,0
4413,open  excel files and create a third file with values that are averaged in python,open  excel files and create a third file with values that are averaged in python,"['open', 'excel', 'files', 'and', 'create', 'a', 'third', 'file', 'with', 'values', 'that', 'are', 'averaged', 'in', 'python']",1,"['open', 'excel', 'file', 'and', 'create', 'a', 'third', 'file', 'with', 'value', 'that', 'are', 'averaged', 'in', 'python']","['open', 'excel', 'file', 'create', 'third', 'file', 'value', 'averaged', 'python']",open excel file create third file value averaged python,0.0,0.0,15,55,3.4375,0,0,0,0,0,0,0,0
4414,how long does it take for the community rankings to get updated after the hackathons end,how long does it take for the community rankings to get updated after the hackathons end,"['how', 'long', 'does', 'it', 'take', 'for', 'the', 'community', 'rankings', 'to', 'get', 'updated', 'after', 'the', 'hackathons', 'end']",0,"['how', 'long', 'doe', 'it', 'take', 'for', 'the', 'community', 'ranking', 'to', 'get', 'updated', 'after', 'the', 'hackathons', 'end']","['long', 'doe', 'take', 'community', 'ranking', 'get', 'updated', 'hackathons', 'end']",long doe take community ranking get updated hackathons end,-0.05,-0.05,16,58,3.411764705882353,0,0,0,0,0,0,0,0
4415,deep learning libraries by language,deep learning libraries by language,"['deep', 'learning', 'libraries', 'by', 'language']",0,"['deep', 'learning', 'library', 'by', 'language']","['deep', 'learning', 'library', 'language']",deep learning library language,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
4416,correlated variables in pca,correlated variables in pca,"['correlated', 'variables', 'in', 'pca']",0,"['correlated', 'variable', 'in', 'pca']","['correlated', 'variable', 'pca']",correlated variable pca,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
4417,want to pursue good course in analytics among sp jain  aegis  insofe etc,want to pursue good course in analytics among sp jain  aegis  insofe etc,"['want', 'to', 'pursue', 'good', 'course', 'in', 'analytics', 'among', 'sp', 'jain', 'aegis', 'insofe', 'etc']",0,"['want', 'to', 'pursue', 'good', 'course', 'in', 'analytics', 'among', 'sp', 'jain', 'aegis', 'insofe', 'etc']","['want', 'pursue', 'good', 'course', 'analytics', 'among', 'sp', 'jain', 'aegis', 'insofe', 'etc']",want pursue good course analytics among sp jain aegis insofe etc,0.7,0.7,13,64,4.571428571428571,0,0,0,0,0,0,0,0
4418,google open sources its ai engine tensor flow,google open sources its ai engine tensor flow,"['google', 'open', 'sources', 'its', 'ai', 'engine', 'tensor', 'flow']",0,"['google', 'open', 'source', 'it', 'ai', 'engine', 'tensor', 'flow']","['google', 'open', 'source', 'ai', 'engine', 'tensor', 'flow']",google open source ai engine tensor flow,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
4419,correlation in r,correlation in r,"['correlation', 'in', 'r']",0,"['correlation', 'in', 'r']","['correlation', 'r']",correlation r,0.0,0.0,3,13,3.25,0,0,0,0,0,0,0,0
4420,variable importance in random forest,variable importance in random forest,"['variable', 'importance', 'in', 'random', 'forest']",0,"['variable', 'importance', 'in', 'random', 'forest']","['variable', 'importance', 'random', 'forest']",variable importance random forest,-0.5,-0.5,5,33,5.5,0,0,0,0,0,0,0,0
4421,black friday hackathon,black friday hackathon,"['black', 'friday', 'hackathon']",0,"['black', 'friday', 'hackathon']","['black', 'friday', 'hackathon']",black friday hackathon,-0.1666666666666666,-0.1666666666666666,3,22,5.5,0,0,0,0,0,0,0,0
4422,big mart sales prediction data  no itemoutletsales in test data,big mart sales prediction data  no itemoutletsales in test data,"['big', 'mart', 'sales', 'prediction', 'data', 'no', 'itemoutletsales', 'in', 'test', 'data']",0,"['big', 'mart', 'sale', 'prediction', 'data', 'no', 'itemoutletsales', 'in', 'test', 'data']","['big', 'mart', 'sale', 'prediction', 'data', 'itemoutletsales', 'test', 'data']",big mart sale prediction data itemoutletsales test data,0.0,0.0,10,55,5.0,0,0,0,0,0,0,0,0
4423,cefficient of determination in r studio,cefficient of determination in r studio,"['cefficient', 'of', 'determination', 'in', 'r', 'studio']",0,"['cefficient', 'of', 'determination', 'in', 'r', 'studio']","['cefficient', 'determination', 'r', 'studio']",cefficient determination r studio,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
4424,error while copying from r to spark,error while copying from r to spark,"['error', 'while', 'copying', 'from', 'r', 'to', 'spark']",0,"['error', 'while', 'copying', 'from', 'r', 'to', 'spark']","['error', 'copying', 'r', 'spark']",error copying r spark,0.0,0.0,7,21,2.625,0,0,0,0,0,0,0,0
4425,big data analytics prespective,big data analytics prespective,"['big', 'data', 'analytics', 'prespective']",0,"['big', 'data', 'analytics', 'prespective']","['big', 'data', 'analytics', 'prespective']",big data analytics prespective,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
4426,should i consider a pg course from great lakes to enter data analytics,should i consider a pg course from great lakes to enter data analytics,"['should', 'i', 'consider', 'a', 'pg', 'course', 'from', 'great', 'lakes', 'to', 'enter', 'data', 'analytics']",0,"['should', 'i', 'consider', 'a', 'pg', 'course', 'from', 'great', 'lake', 'to', 'enter', 'data', 'analytics']","['consider', 'pg', 'course', 'great', 'lake', 'enter', 'data', 'analytics']",consider pg course great lake enter data analytics,0.8,0.8,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
4427,shifting career after  years of it experience,shifting career after  years of it experience,"['shifting', 'career', 'after', 'years', 'of', 'it', 'experience']",1,"['shifting', 'career', 'after', 'year', 'of', 'it', 'experience']","['shifting', 'career', 'year', 'experience']",shifting career year experience,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
4428,interpretation result of k means algorithm,interpretation result of k means algorithm,"['interpretation', 'result', 'of', 'k', 'means', 'algorithm']",0,"['interpretation', 'result', 'of', 'k', 'mean', 'algorithm']","['interpretation', 'result', 'k', 'mean', 'algorithm']",interpretation result k mean algorithm,0.0,-0.3125,6,38,5.428571428571429,0,0,0,0,0,0,0,0
4429,xgb model performance,xgb model performance,"['xgb', 'model', 'performance']",0,"['xgb', 'model', 'performance']","['xgb', 'model', 'performance']",xgb model performance,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
4430,bussiness analytics certification course in s p jain,bussiness analytics certification course in s p jain,"['bussiness', 'analytics', 'certification', 'course', 'in', 's', 'p', 'jain']",0,"['bussiness', 'analytics', 'certification', 'course', 'in', 's', 'p', 'jain']","['bussiness', 'analytics', 'certification', 'course', 'p', 'jain']",bussiness analytics certification course p jain,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
4431,email classification,email classification,"['email', 'classification']",0,"['email', 'classification']","['email', 'classification']",email classification,0.0,0.0,2,20,6.666666666666667,0,0,0,0,0,0,0,0
4432,dynamic reporting in qlikview,dynamic reporting in qlikview,"['dynamic', 'reporting', 'in', 'qlikview']",0,"['dynamic', 'reporting', 'in', 'qlikview']","['dynamic', 'reporting', 'qlikview']",dynamic reporting qlikview,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
4433,errorc models require a factor outcome,errorc models require a factor outcome,"['errorc', 'models', 'require', 'a', 'factor', 'outcome']",0,"['errorc', 'model', 'require', 'a', 'factor', 'outcome']","['errorc', 'model', 'require', 'factor', 'outcome']",errorc model require factor outcome,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
4434,generating additional dataset from the existing unlabeled dataset file,generating additional dataset from the existing unlabeled dataset file,"['generating', 'additional', 'dataset', 'from', 'the', 'existing', 'unlabeled', 'dataset', 'file']",0,"['generating', 'additional', 'dataset', 'from', 'the', 'existing', 'unlabeled', 'dataset', 'file']","['generating', 'additional', 'dataset', 'existing', 'unlabeled', 'dataset', 'file']",generating additional dataset existing unlabeled dataset file,0.0,0.0,9,61,6.1,0,0,0,0,0,0,0,0
4435,what are the ways to handle huge data in r,what are the ways to handle huge data in r,"['what', 'are', 'the', 'ways', 'to', 'handle', 'huge', 'data', 'in', 'r']",0,"['what', 'are', 'the', 'way', 'to', 'handle', 'huge', 'data', 'in', 'r']","['way', 'handle', 'huge', 'data', 'r']",way handle huge data r,0.4000000000000001,0.4000000000000001,10,22,2.0,0,0,0,0,0,0,0,0
4436,looking to team up,looking to team up,"['looking', 'to', 'team', 'up']",0,"['looking', 'to', 'team', 'up']","['looking', 'team']",looking team,0.0,0.0,4,12,2.4,0,0,0,0,0,0,0,0
4437,what does  operator indicate in r language,what does  operator indicate in r language,"['what', 'does', 'operator', 'indicate', 'in', 'r', 'language']",0,"['what', 'doe', 'operator', 'indicate', 'in', 'r', 'language']","['doe', 'operator', 'indicate', 'r', 'language']",doe operator indicate r language,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
4438,sas help rolling up information in sas data,sas help rolling up information in sas data,"['sas', 'help', 'rolling', 'up', 'information', 'in', 'sas', 'data']",0,"['sa', 'help', 'rolling', 'up', 'information', 'in', 'sa', 'data']","['sa', 'help', 'rolling', 'information', 'sa', 'data']",sa help rolling information sa data,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
4439,defining a machine learning problem,defining a machine learning problem,"['defining', 'a', 'machine', 'learning', 'problem']",0,"['defining', 'a', 'machine', 'learning', 'problem']","['defining', 'machine', 'learning', 'problem']",defining machine learning problem,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
4440,regarding clustering,regarding clustering,"['regarding', 'clustering']",0,"['regarding', 'clustering']","['regarding', 'clustering']",regarding clustering,0.0,0.0,2,20,6.666666666666667,0,0,0,0,0,0,0,0
4441,how to read json file in python,how to read json file in python,"['how', 'to', 'read', 'json', 'file', 'in', 'python']",0,"['how', 'to', 'read', 'json', 'file', 'in', 'python']","['read', 'json', 'file', 'python']",read json file python,0.0,0.0,7,21,2.625,0,0,0,0,0,0,0,0
4442,looking for mentor to guide in career change,looking for mentor to guide in career change,"['looking', 'for', 'mentor', 'to', 'guide', 'in', 'career', 'change']",0,"['looking', 'for', 'mentor', 'to', 'guide', 'in', 'career', 'change']","['looking', 'mentor', 'guide', 'career', 'change']",looking mentor guide career change,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
4443,error while using geomline in r,error while using geomline in r,"['error', 'while', 'using', 'geomline', 'in', 'r']",0,"['error', 'while', 'using', 'geomline', 'in', 'r']","['error', 'using', 'geomline', 'r']",error using geomline r,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
4444,venturing into data science from biologylife sciences research how good,venturing into data science from biologylife sciences research how good,"['venturing', 'into', 'data', 'science', 'from', 'biologylife', 'sciences', 'research', 'how', 'good']",0,"['venturing', 'into', 'data', 'science', 'from', 'biologylife', 'science', 'research', 'how', 'good']","['venturing', 'data', 'science', 'biologylife', 'science', 'research', 'good']",venturing data science biologylife science research good,0.7,0.7,10,56,5.090909090909091,0,0,0,0,0,0,0,0
4445,import csv file in python error,import csv file in python error,"['import', 'csv', 'file', 'in', 'python', 'error']",0,"['import', 'csv', 'file', 'in', 'python', 'error']","['import', 'csv', 'file', 'python', 'error']",import csv file python error,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
4446,error inheritsdoc textdocument is not true  while performing text analysis,error inheritsdoc textdocument is not true  while performing text analysis,"['error', 'inheritsdoc', 'textdocument', 'is', 'not', 'true', 'while', 'performing', 'text', 'analysis']",0,"['error', 'inheritsdoc', 'textdocument', 'is', 'not', 'true', 'while', 'performing', 'text', 'analysis']","['error', 'inheritsdoc', 'textdocument', 'true', 'performing', 'text', 'analysis']",error inheritsdoc textdocument true performing text analysis,-0.175,0.35,10,60,5.454545454545454,0,0,0,0,0,0,0,0
4447,non graphical corelated variables,non graphical corelated variables,"['non', 'graphical', 'corelated', 'variables']",0,"['non', 'graphical', 'corelated', 'variable']","['non', 'graphical', 'corelated', 'variable']",non graphical corelated variable,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
4448,how to interpret some of the outputs of pca like scoresrotation,how to interpret some of the outputs of pca like scoresrotation,"['how', 'to', 'interpret', 'some', 'of', 'the', 'outputs', 'of', 'pca', 'like', 'scoresrotation']",0,"['how', 'to', 'interpret', 'some', 'of', 'the', 'output', 'of', 'pca', 'like', 'scoresrotation']","['interpret', 'output', 'pca', 'like', 'scoresrotation']",interpret output pca like scoresrotation,0.0,0.0,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
4449,what is a p value and its significance in hypothesis testing,what is a p value and its significance in hypothesis testing,"['what', 'is', 'a', 'p', 'value', 'and', 'its', 'significance', 'in', 'hypothesis', 'testing']",0,"['what', 'is', 'a', 'p', 'value', 'and', 'it', 'significance', 'in', 'hypothesis', 'testing']","['p', 'value', 'significance', 'hypothesis', 'testing']",p value significance hypothesis testing,0.0,0.0,11,39,3.25,0,0,0,0,0,0,0,0
4450,outlierproblems,outlierproblems,['outlierproblems'],0,['outlierproblems'],['outlierproblems'],outlierproblems,0.0,0.0,1,15,7.5,0,0,0,0,0,0,0,0
4451,can i start a career in datascience after  years in marketingmarkeing analysis,can i start a career in datascience after  years in marketingmarkeing analysis,"['can', 'i', 'start', 'a', 'career', 'in', 'datascience', 'after', 'years', 'in', 'marketingmarkeing', 'analysis']",1,"['can', 'i', 'start', 'a', 'career', 'in', 'datascience', 'after', 'year', 'in', 'marketingmarkeing', 'analysis']","['start', 'career', 'datascience', 'year', 'marketingmarkeing', 'analysis']",start career datascience year marketingmarkeing analysis,0.0,0.0,12,56,4.3076923076923075,0,0,0,0,0,0,0,0
4452,level of difficulty,level of difficulty,"['level', 'of', 'difficulty']",0,"['level', 'of', 'difficulty']","['level', 'difficulty']",level difficulty,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
4453,what is the hypothesis definition for this case study,what is the hypothesis definition for this case study,"['what', 'is', 'the', 'hypothesis', 'definition', 'for', 'this', 'case', 'study']",0,"['what', 'is', 'the', 'hypothesis', 'definition', 'for', 'this', 'case', 'study']","['hypothesis', 'definition', 'case', 'study']",hypothesis definition case study,0.0,0.0,9,32,3.2,0,0,0,0,0,0,0,0
4454,download infographic must read books in data science  analytics,download infographic must read books in data science  analytics,"['download', 'infographic', 'must', 'read', 'books', 'in', 'data', 'science', 'analytics']",0,"['download', 'infographic', 'must', 'read', 'book', 'in', 'data', 'science', 'analytics']","['download', 'infographic', 'must', 'read', 'book', 'data', 'science', 'analytics']",download infographic must read book data science analytics,0.0,0.0,9,58,5.8,0,0,0,0,0,0,0,0
4455,understanding the data how to combine two files with different number of columns,understanding the data how to combine two files with different number of columns,"['understanding', 'the', 'data', 'how', 'to', 'combine', 'two', 'files', 'with', 'different', 'number', 'of', 'columns']",0,"['understanding', 'the', 'data', 'how', 'to', 'combine', 'two', 'file', 'with', 'different', 'number', 'of', 'column']","['understanding', 'data', 'combine', 'two', 'file', 'different', 'number', 'column']",understanding data combine two file different number column,0.0,0.0,13,59,4.214285714285714,0,0,0,0,0,0,0,0
4456,help with method to select right object in qlikview dashboard,help with method to select right object in qlikview dashboard,"['help', 'with', 'method', 'to', 'select', 'right', 'object', 'in', 'qlikview', 'dashboard']",0,"['help', 'with', 'method', 'to', 'select', 'right', 'object', 'in', 'qlikview', 'dashboard']","['help', 'method', 'select', 'right', 'object', 'qlikview', 'dashboard']",help method select right object qlikview dashboard,0.2857142857142857,0.2857142857142857,10,50,4.545454545454546,0,0,0,0,0,0,0,0
4457,research projects or work experience for ms in ai,research projects or work experience for ms in ai,"['research', 'projects', 'or', 'work', 'experience', 'for', 'ms', 'in', 'ai']",0,"['research', 'project', 'or', 'work', 'experience', 'for', 'm', 'in', 'ai']","['research', 'project', 'work', 'experience', 'ai']",research project work experience ai,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
4458,how to find best ratio for optimum profit for a dataset,how to find best ratio for optimum profit for a dataset,"['how', 'to', 'find', 'best', 'ratio', 'for', 'optimum', 'profit', 'for', 'a', 'dataset']",0,"['how', 'to', 'find', 'best', 'ratio', 'for', 'optimum', 'profit', 'for', 'a', 'dataset']","['find', 'best', 'ratio', 'optimum', 'profit', 'dataset']",find best ratio optimum profit dataset,0.85,0.85,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
4459,regarding adding bar labels on top of each bar in ggplot using geomtext,regarding adding bar labels on top of each bar in ggplot using geomtext,"['regarding', 'adding', 'bar', 'labels', 'on', 'top', 'of', 'each', 'bar', 'in', 'ggplot', 'using', 'geomtext']",0,"['regarding', 'adding', 'bar', 'label', 'on', 'top', 'of', 'each', 'bar', 'in', 'ggplot', 'using', 'geomtext']","['regarding', 'adding', 'bar', 'label', 'top', 'bar', 'ggplot', 'using', 'geomtext']",regarding adding bar label top bar ggplot using geomtext,0.5,0.5,13,56,4.0,0,0,0,0,0,0,0,0
4460,why in my module the videos are shown as unstarted red even after i have completed the video,why in my module the videos are shown as unstarted red even after i have completed the video,"['why', 'in', 'my', 'module', 'the', 'videos', 'are', 'shown', 'as', 'unstarted', 'red', 'even', 'after', 'i', 'have', 'completed', 'the', 'video']",0,"['why', 'in', 'my', 'module', 'the', 'video', 'are', 'shown', 'a', 'unstarted', 'red', 'even', 'after', 'i', 'have', 'completed', 'the', 'video']","['module', 'video', 'shown', 'unstarted', 'red', 'even', 'completed', 'video']",module video shown unstarted red even completed video,0.0,0.0,18,53,2.789473684210526,0,0,0,0,0,0,0,0
4461,explanation of gbm pseudocode,explanation of gbm pseudocode,"['explanation', 'of', 'gbm', 'pseudocode']",0,"['explanation', 'of', 'gbm', 'pseudocode']","['explanation', 'gbm', 'pseudocode']",explanation gbm pseudocode,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
4462,career transition from a mobility engineerblackberry administrator to aws engineer is it possible if so please let me know how to kick start,career transition from a mobility engineerblackberry administrator to aws engineer is it possible if so please let me know how to kick start,"['career', 'transition', 'from', 'a', 'mobility', 'engineerblackberry', 'administrator', 'to', 'aws', 'engineer', 'is', 'it', 'possible', 'if', 'so', 'please', 'let', 'me', 'know', 'how', 'to', 'kick', 'start']",0,"['career', 'transition', 'from', 'a', 'mobility', 'engineerblackberry', 'administrator', 'to', 'aws', 'engineer', 'is', 'it', 'possible', 'if', 'so', 'please', 'let', 'me', 'know', 'how', 'to', 'kick', 'start']","['career', 'transition', 'mobility', 'engineerblackberry', 'administrator', 'aws', 'engineer', 'possible', 'please', 'let', 'know', 'kick', 'start']",career transition mobility engineerblackberry administrator aws engineer possible please let know kick start,0.0,0.0,23,108,4.5,0,0,0,0,0,0,0,0
4463,random forest in r under classification,random forest in r under classification,"['random', 'forest', 'in', 'r', 'under', 'classification']",0,"['random', 'forest', 'in', 'r', 'under', 'classification']","['random', 'forest', 'r', 'classification']",random forest r classification,-0.5,-0.5,6,30,4.285714285714286,0,0,0,0,0,0,0,0
4464,getting different value in cooccurrence matrix,getting different value in cooccurrence matrix,"['getting', 'different', 'value', 'in', 'cooccurrence', 'matrix']",0,"['getting', 'different', 'value', 'in', 'cooccurrence', 'matrix']","['getting', 'different', 'value', 'cooccurrence', 'matrix']",getting different value cooccurrence matrix,0.0,0.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
4465,can we use high image resolution while training model,can we use high image resolution while training model,"['can', 'we', 'use', 'high', 'image', 'resolution', 'while', 'training', 'model']",0,"['can', 'we', 'use', 'high', 'image', 'resolution', 'while', 'training', 'model']","['use', 'high', 'image', 'resolution', 'training', 'model']",use high image resolution training model,0.16,0.16,9,40,4.0,0,0,0,0,0,0,0,0
4466,how to replace the data,how to replace the data,"['how', 'to', 'replace', 'the', 'data']",0,"['how', 'to', 'replace', 'the', 'data']","['replace', 'data']",replace data,0.0,0.0,5,12,2.0,0,0,0,0,0,0,0,0
4467,best institute in delhi for learning r  python,best institute in delhi for learning r  python,"['best', 'institute', 'in', 'delhi', 'for', 'learning', 'r', 'python']",0,"['best', 'institute', 'in', 'delhi', 'for', 'learning', 'r', 'python']","['best', 'institute', 'delhi', 'learning', 'r', 'python']",best institute delhi learning r python,1.0,1.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
4468,how can i append a listvector in python as a comma separated string of two values as each of its elements,how can i append a listvector in python as a comma separated string of two values as each of its elements,"['how', 'can', 'i', 'append', 'a', 'listvector', 'in', 'python', 'as', 'a', 'comma', 'separated', 'string', 'of', 'two', 'values', 'as', 'each', 'of', 'its', 'elements']",0,"['how', 'can', 'i', 'append', 'a', 'listvector', 'in', 'python', 'a', 'a', 'comma', 'separated', 'string', 'of', 'two', 'value', 'a', 'each', 'of', 'it', 'element']","['append', 'listvector', 'python', 'comma', 'separated', 'string', 'two', 'value', 'element']",append listvector python comma separated string two value element,0.0,0.0,21,65,2.9545454545454546,0,0,0,0,0,0,0,0
4469,dealing with singularities in a linear regression model,dealing with singularities in a linear regression model,"['dealing', 'with', 'singularities', 'in', 'a', 'linear', 'regression', 'model']",0,"['dealing', 'with', 'singularity', 'in', 'a', 'linear', 'regression', 'model']","['dealing', 'singularity', 'linear', 'regression', 'model']",dealing singularity linear regression model,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
4470,link prediction model,link prediction model,"['link', 'prediction', 'model']",0,"['link', 'prediction', 'model']","['link', 'prediction', 'model']",link prediction model,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
4471,how to update only missing values in r based on parameters,how to update only missing values in r based on parameters,"['how', 'to', 'update', 'only', 'missing', 'values', 'in', 'r', 'based', 'on', 'parameters']",0,"['how', 'to', 'update', 'only', 'missing', 'value', 'in', 'r', 'based', 'on', 'parameter']","['update', 'missing', 'value', 'r', 'based', 'parameter']",update missing value r based parameter,-0.1,-0.2,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
4472,functional looping in r,functional looping in r,"['functional', 'looping', 'in', 'r']",0,"['functional', 'looping', 'in', 'r']","['functional', 'looping', 'r']",functional looping r,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
4473,business analytics training institutes  ibat  coepd,business analytics training institutes  ibat  coepd,"['business', 'analytics', 'training', 'institutes', 'ibat', 'coepd']",0,"['business', 'analytics', 'training', 'institute', 'ibat', 'coepd']","['business', 'analytics', 'training', 'institute', 'ibat', 'coepd']",business analytics training institute ibat coepd,0.0,0.0,6,48,6.857142857142857,0,0,0,0,0,0,0,0
4474,need help in understanding the code,need help in understanding the code,"['need', 'help', 'in', 'understanding', 'the', 'code']",0,"['need', 'help', 'in', 'understanding', 'the', 'code']","['need', 'help', 'understanding', 'code']",need help understanding code,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
4475,what are some of the projects to do in a ecommerce area,what are some of the projects to do in a ecommerce area,"['what', 'are', 'some', 'of', 'the', 'projects', 'to', 'do', 'in', 'a', 'ecommerce', 'area']",0,"['what', 'are', 'some', 'of', 'the', 'project', 'to', 'do', 'in', 'a', 'ecommerce', 'area']","['project', 'ecommerce', 'area']",project ecommerce area,0.0,0.0,12,22,1.6923076923076923,0,0,0,0,0,0,0,0
4476,set analysis in qlikview,set analysis in qlikview,"['set', 'analysis', 'in', 'qlikview']",0,"['set', 'analysis', 'in', 'qlikview']","['set', 'analysis', 'qlikview']",set analysis qlikview,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
4477,is it possible to build text classification model  that depends on previous result of other model,is it possible to build text classification model  that depends on previous result of other model,"['is', 'it', 'possible', 'to', 'build', 'text', 'classification', 'model', 'that', 'depends', 'on', 'previous', 'result', 'of', 'other', 'model']",0,"['is', 'it', 'possible', 'to', 'build', 'text', 'classification', 'model', 'that', 'depends', 'on', 'previous', 'result', 'of', 'other', 'model']","['possible', 'build', 'text', 'classification', 'model', 'depends', 'previous', 'result', 'model']",possible build text classification model depends previous result model,-0.0972222222222222,-0.0833333333333333,16,70,4.117647058823529,0,0,0,0,0,0,0,0
4478,how to improve model performance in logistic regression in r,how to improve model performance in logistic regression in r,"['how', 'to', 'improve', 'model', 'performance', 'in', 'logistic', 'regression', 'in', 'r']",0,"['how', 'to', 'improve', 'model', 'performance', 'in', 'logistic', 'regression', 'in', 'r']","['improve', 'model', 'performance', 'logistic', 'regression', 'r']",improve model performance logistic regression r,0.0,0.0,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
4479,wherer the the data set for data and beyond competetion,wherer the the data set for data and beyond competetion,"['wherer', 'the', 'the', 'data', 'set', 'for', 'data', 'and', 'beyond', 'competetion']",0,"['wherer', 'the', 'the', 'data', 'set', 'for', 'data', 'and', 'beyond', 'competetion']","['wherer', 'data', 'set', 'data', 'beyond', 'competetion']",wherer data set data beyond competetion,0.0,0.0,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
4480,getting this error attempting model selection on an essentially perfect fit is nonsense,getting this error attempting model selection on an essentially perfect fit is nonsense,"['getting', 'this', 'error', 'attempting', 'model', 'selection', 'on', 'an', 'essentially', 'perfect', 'fit', 'is', 'nonsense']",0,"['getting', 'this', 'error', 'attempting', 'model', 'selection', 'on', 'an', 'essentially', 'perfect', 'fit', 'is', 'nonsense']","['getting', 'error', 'attempting', 'model', 'selection', 'essentially', 'perfect', 'fit', 'nonsense']",getting error attempting model selection essentially perfect fit nonsense,0.7,0.7,13,73,5.214285714285714,0,0,0,0,0,0,0,0
4481,name not showing in leaderboard,name not showing in leaderboard,"['name', 'not', 'showing', 'in', 'leaderboard']",0,"['name', 'not', 'showing', 'in', 'leaderboard']","['name', 'showing', 'leaderboard']",name showing leaderboard,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
4482,skill test timings,skill test timings,"['skill', 'test', 'timings']",0,"['skill', 'test', 'timing']","['skill', 'test', 'timing']",skill test timing,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
4483,regarding date variable in redate your data,regarding date variable in redate your data,"['regarding', 'date', 'variable', 'in', 'redate', 'your', 'data']",0,"['regarding', 'date', 'variable', 'in', 'redate', 'your', 'data']","['regarding', 'date', 'variable', 'redate', 'data']",regarding date variable redate data,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
4484,error while implementing randomforest in r,error while implementing randomforest in r,"['error', 'while', 'implementing', 'randomforest', 'in', 'r']",0,"['error', 'while', 'implementing', 'randomforest', 'in', 'r']","['error', 'implementing', 'randomforest', 'r']",error implementing randomforest r,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
4485,unsupervised data prediction,unsupervised data prediction,"['unsupervised', 'data', 'prediction']",0,"['unsupervised', 'data', 'prediction']","['unsupervised', 'data', 'prediction']",unsupervised data prediction,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
4486,error while submission of kaggle facial keypoint detection problem,error while submission of kaggle facial keypoint detection problem,"['error', 'while', 'submission', 'of', 'kaggle', 'facial', 'keypoint', 'detection', 'problem']",0,"['error', 'while', 'submission', 'of', 'kaggle', 'facial', 'keypoint', 'detection', 'problem']","['error', 'submission', 'kaggle', 'facial', 'keypoint', 'detection', 'problem']",error submission kaggle facial keypoint detection problem,0.0,0.0,9,57,5.7,0,0,0,0,0,0,0,0
4487,tableau dual axis,tableau dual axis,"['tableau', 'dual', 'axis']",0,"['tableau', 'dual', 'axis']","['tableau', 'dual', 'axis']",tableau dual axis,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
4488,look alike modelling,look alike modelling,"['look', 'alike', 'modelling']",0,"['look', 'alike', 'modelling']","['look', 'alike', 'modelling']",look alike modelling,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
4489,interview preparation for a career in analytics,interview preparation for a career in analytics,"['interview', 'preparation', 'for', 'a', 'career', 'in', 'analytics']",0,"['interview', 'preparation', 'for', 'a', 'career', 'in', 'analytics']","['interview', 'preparation', 'career', 'analytics']",interview preparation career analytics,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
4490,fine classing and coarse classing,fine classing and coarse classing,"['fine', 'classing', 'and', 'coarse', 'classing']",0,"['fine', 'classing', 'and', 'coarse', 'classing']","['fine', 'classing', 'coarse', 'classing']",fine classing coarse classing,0.2083333333333333,0.2083333333333333,5,29,4.833333333333333,0,0,0,0,0,0,0,0
4491,what is pruning and how to do pruning in decision trees,what is pruning and how to do pruning in decision trees,"['what', 'is', 'pruning', 'and', 'how', 'to', 'do', 'pruning', 'in', 'decision', 'trees']",0,"['what', 'is', 'pruning', 'and', 'how', 'to', 'do', 'pruning', 'in', 'decision', 'tree']","['pruning', 'pruning', 'decision', 'tree']",pruning pruning decision tree,0.0,0.0,11,29,2.4166666666666665,0,0,0,0,0,0,0,0
4492,uses of facetwrap and facetgrid,uses of facetwrap and facetgrid,"['uses', 'of', 'facetwrap', 'and', 'facetgrid']",0,"['us', 'of', 'facetwrap', 'and', 'facetgrid']","['us', 'facetwrap', 'facetgrid']",us facetwrap facetgrid,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
4493,aspect based sentiment analysis,aspect based sentiment analysis,"['aspect', 'based', 'sentiment', 'analysis']",0,"['aspect', 'based', 'sentiment', 'analysis']","['aspect', 'based', 'sentiment', 'analysis']",aspect based sentiment analysis,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
4494,what is the difference between star schema and snow flake schema in qlikview,what is the difference between star schema and snow flake schema in qlikview,"['what', 'is', 'the', 'difference', 'between', 'star', 'schema', 'and', 'snow', 'flake', 'schema', 'in', 'qlikview']",0,"['what', 'is', 'the', 'difference', 'between', 'star', 'schema', 'and', 'snow', 'flake', 'schema', 'in', 'qlikview']","['difference', 'star', 'schema', 'snow', 'flake', 'schema', 'qlikview']",difference star schema snow flake schema qlikview,0.0,0.0,13,49,3.5,0,0,0,0,0,0,0,0
4495,career change from vba developer to data scientist,career change from vba developer to data scientist,"['career', 'change', 'from', 'vba', 'developer', 'to', 'data', 'scientist']",0,"['career', 'change', 'from', 'vba', 'developer', 'to', 'data', 'scientist']","['career', 'change', 'vba', 'developer', 'data', 'scientist']",career change vba developer data scientist,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
4496,how are decision trees not sensitive to skewed distributions,how are decision trees not sensitive to skewed distributions,"['how', 'are', 'decision', 'trees', 'not', 'sensitive', 'to', 'skewed', 'distributions']",0,"['how', 'are', 'decision', 'tree', 'not', 'sensitive', 'to', 'skewed', 'distribution']","['decision', 'tree', 'sensitive', 'skewed', 'distribution']",decision tree sensitive skewed distribution,-0.05,0.1,9,43,4.3,0,0,0,0,0,0,0,0
4497,imputing missing values with mice in r,imputing missing values with mice in r,"['imputing', 'missing', 'values', 'with', 'mice', 'in', 'r']",0,"['imputing', 'missing', 'value', 'with', 'mouse', 'in', 'r']","['imputing', 'missing', 'value', 'mouse', 'r']",imputing missing value mouse r,-0.2,-0.2,7,30,3.75,0,0,0,0,0,0,0,0
4498,string comparison in python,string comparison in python,"['string', 'comparison', 'in', 'python']",0,"['string', 'comparison', 'in', 'python']","['string', 'comparison', 'python']",string comparison python,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
4499,how do i handle unbalanced text classification,how do i handle unbalanced text classification,"['how', 'do', 'i', 'handle', 'unbalanced', 'text', 'classification']",0,"['how', 'do', 'i', 'handle', 'unbalanced', 'text', 'classification']","['handle', 'unbalanced', 'text', 'classification']",handle unbalanced text classification,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
4500,the judgment of the balance of dataset,the judgment of the balance of dataset,"['the', 'judgment', 'of', 'the', 'balance', 'of', 'dataset']",0,"['the', 'judgment', 'of', 'the', 'balance', 'of', 'dataset']","['judgment', 'balance', 'dataset']",judgment balance dataset,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
4501,learning path for text analytics,learning path for text analytics,"['learning', 'path', 'for', 'text', 'analytics']",0,"['learning', 'path', 'for', 'text', 'analytics']","['learning', 'path', 'text', 'analytics']",learning path text analytics,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
4502,which analytics course i should opt,which analytics course i should opt,"['which', 'analytics', 'course', 'i', 'should', 'opt']",0,"['which', 'analytics', 'course', 'i', 'should', 'opt']","['analytics', 'course', 'opt']",analytics course opt,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
4503,memoryerror for creating a new numpy array,memoryerror for creating a new numpy array,"['memoryerror', 'for', 'creating', 'a', 'new', 'numpy', 'array']",0,"['memoryerror', 'for', 'creating', 'a', 'new', 'numpy', 'array']","['memoryerror', 'creating', 'new', 'numpy', 'array']",memoryerror creating new numpy array,0.1363636363636363,0.1363636363636363,7,36,4.5,0,0,0,0,0,0,0,0
4504,building a career in consumer  risk analytics  bi,building a career in consumer  risk analytics  bi,"['building', 'a', 'career', 'in', 'consumer', 'risk', 'analytics', 'bi']",0,"['building', 'a', 'career', 'in', 'consumer', 'risk', 'analytics', 'bi']","['building', 'career', 'consumer', 'risk', 'analytics', 'bi']",building career consumer risk analytics bi,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
4505,linear optimization  excel solver,linear optimization  excel solver,"['linear', 'optimization', 'excel', 'solver']",0,"['linear', 'optimization', 'excel', 'solver']","['linear', 'optimization', 'excel', 'solver']",linear optimization excel solver,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
4506,forecasting with random forest,forecasting with random forest,"['forecasting', 'with', 'random', 'forest']",0,"['forecasting', 'with', 'random', 'forest']","['forecasting', 'random', 'forest']",forecasting random forest,-0.5,-0.5,4,25,5.0,0,0,0,0,0,0,0,0
4507,can we hide sheet tabs conditionally in qlikview,can we hide sheet tabs conditionally in qlikview,"['can', 'we', 'hide', 'sheet', 'tabs', 'conditionally', 'in', 'qlikview']",0,"['can', 'we', 'hide', 'sheet', 'tab', 'conditionally', 'in', 'qlikview']","['hide', 'sheet', 'tab', 'conditionally', 'qlikview']",hide sheet tab conditionally qlikview,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
4508,how to start a career in data science,how to start a career in data science,"['how', 'to', 'start', 'a', 'career', 'in', 'data', 'science']",0,"['how', 'to', 'start', 'a', 'career', 'in', 'data', 'science']","['start', 'career', 'data', 'science']",start career data science,0.0,0.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
4509,deal with impute type of variables,deal with impute type of variables,"['deal', 'with', 'impute', 'type', 'of', 'variables']",0,"['deal', 'with', 'impute', 'type', 'of', 'variable']","['deal', 'impute', 'type', 'variable']",deal impute type variable,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
4510,why values are not changing using replacement function in r,why values are not changing using replacement function in r,"['why', 'values', 'are', 'not', 'changing', 'using', 'replacement', 'function', 'in', 'r']",0,"['why', 'value', 'are', 'not', 'changing', 'using', 'replacement', 'function', 'in', 'r']","['value', 'changing', 'using', 'replacement', 'function', 'r']",value changing using replacement function r,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
4511,no improvement using boosting,no improvement using boosting,"['no', 'improvement', 'using', 'boosting']",0,"['no', 'improvement', 'using', 'boosting']","['improvement', 'using', 'boosting']",improvement using boosting,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
4512,binary data comparison in excel,binary data comparison in excel,"['binary', 'data', 'comparison', 'in', 'excel']",0,"['binary', 'data', 'comparison', 'in', 'excel']","['binary', 'data', 'comparison', 'excel']",binary data comparison excel,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
4513,begineers guide to participate in hackthons,begineers guide to participate in hackthons,"['begineers', 'guide', 'to', 'participate', 'in', 'hackthons']",0,"['begineers', 'guide', 'to', 'participate', 'in', 'hackthons']","['begineers', 'guide', 'participate', 'hackthons']",begineers guide participate hackthons,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
4514,which parameter is best for measuring test error,which parameter is best for measuring test error,"['which', 'parameter', 'is', 'best', 'for', 'measuring', 'test', 'error']",0,"['which', 'parameter', 'is', 'best', 'for', 'measuring', 'test', 'error']","['parameter', 'best', 'measuring', 'test', 'error']",parameter best measuring test error,1.0,1.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
4515,why  or  for labeling categorical data,why  or  for labeling categorical data,"['why', 'or', 'for', 'labeling', 'categorical', 'data']",2,"['why', 'or', 'for', 'labeling', 'categorical', 'data']","['labeling', 'categorical', 'data']",labeling categorical data,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
4516,query around cut off probability in logistic regression techniques in r,query around cut off probability in logistic regression techniques in r,"['query', 'around', 'cut', 'off', 'probability', 'in', 'logistic', 'regression', 'techniques', 'in', 'r']",0,"['query', 'around', 'cut', 'off', 'probability', 'in', 'logistic', 'regression', 'technique', 'in', 'r']","['query', 'around', 'cut', 'probability', 'logistic', 'regression', 'technique', 'r']",query around cut probability logistic regression technique r,0.0,0.0,11,60,5.0,0,0,0,0,0,0,0,0
4517,how to import data from json file into r,how to import data from json file into r,"['how', 'to', 'import', 'data', 'from', 'json', 'file', 'into', 'r']",0,"['how', 'to', 'import', 'data', 'from', 'json', 'file', 'into', 'r']","['import', 'data', 'json', 'file', 'r']",import data json file r,0.0,0.0,9,23,2.3,0,0,0,0,0,0,0,0
4518,missing data values plot in r,missing data values plot in r,"['missing', 'data', 'values', 'plot', 'in', 'r']",0,"['missing', 'data', 'value', 'plot', 'in', 'r']","['missing', 'data', 'value', 'plot', 'r']",missing data value plot r,-0.2,-0.2,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
4519,not able to submit my solution file,not able to submit my solution file,"['not', 'able', 'to', 'submit', 'my', 'solution', 'file']",0,"['not', 'able', 'to', 'submit', 'my', 'solution', 'file']","['able', 'submit', 'solution', 'file']",able submit solution file,-0.25,0.5,7,25,3.125,0,0,0,0,0,0,0,0
4520,how to manually calculate textblobs naive bayes probclassify function,how to manually calculate textblobs naive bayes probclassify function,"['how', 'to', 'manually', 'calculate', 'textblobs', 'naive', 'bayes', 'probclassify', 'function']",0,"['how', 'to', 'manually', 'calculate', 'textblobs', 'naive', 'bayes', 'probclassify', 'function']","['manually', 'calculate', 'textblobs', 'naive', 'bayes', 'probclassify', 'function']",manually calculate textblobs naive bayes probclassify function,-0.3,-0.3,9,62,6.2,0,0,0,0,0,0,0,0
4521,how is a loss function equal to the negative log likelihood function of the outcome distribution,how is a loss function equal to the negative log likelihood function of the outcome distribution,"['how', 'is', 'a', 'loss', 'function', 'equal', 'to', 'the', 'negative', 'log', 'likelihood', 'function', 'of', 'the', 'outcome', 'distribution']",0,"['how', 'is', 'a', 'loss', 'function', 'equal', 'to', 'the', 'negative', 'log', 'likelihood', 'function', 'of', 'the', 'outcome', 'distribution']","['loss', 'function', 'equal', 'negative', 'log', 'likelihood', 'function', 'outcome', 'distribution']",loss function equal negative log likelihood function outcome distribution,-0.15,-0.15,16,73,4.294117647058823,0,0,0,0,0,0,0,0
4522,internship challenge round  images are not getting loaded from question ,internship challenge round  images are not getting loaded from question ,"['internship', 'challenge', 'round', 'images', 'are', 'not', 'getting', 'loaded', 'from', 'question']",2,"['internship', 'challenge', 'round', 'image', 'are', 'not', 'getting', 'loaded', 'from', 'question']","['internship', 'challenge', 'round', 'image', 'getting', 'loaded', 'question']",internship challenge round image getting loaded question,-0.2,-0.2,10,56,5.090909090909091,0,0,0,0,0,0,0,0
4523,suggestions about pgd in data analytics in iiitb and upgrad,suggestions about pgd in data analytics in iiitb and upgrad,"['suggestions', 'about', 'pgd', 'in', 'data', 'analytics', 'in', 'iiitb', 'and', 'upgrad']",0,"['suggestion', 'about', 'pgd', 'in', 'data', 'analytics', 'in', 'iiitb', 'and', 'upgrad']","['suggestion', 'pgd', 'data', 'analytics', 'iiitb', 'upgrad']",suggestion pgd data analytics iiitb upgrad,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
4524,how to find starting centroid and value of k in k means,how to find starting centroid and value of k in k means,"['how', 'to', 'find', 'starting', 'centroid', 'and', 'value', 'of', 'k', 'in', 'k', 'means']",0,"['how', 'to', 'find', 'starting', 'centroid', 'and', 'value', 'of', 'k', 'in', 'k', 'mean']","['find', 'starting', 'centroid', 'value', 'k', 'k', 'mean']",find starting centroid value k k mean,0.0,-0.15625,12,37,2.8461538461538463,0,0,0,0,0,0,0,0
4525,which sql db is used in data science,which sql db is used in data science,"['which', 'sql', 'db', 'is', 'used', 'in', 'data', 'science']",0,"['which', 'sql', 'db', 'is', 'used', 'in', 'data', 'science']","['sql', 'db', 'used', 'data', 'science']",sql db used data science,0.0,0.0,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
4526,suggestions about post graduate diploma in ba,suggestions about post graduate diploma in ba,"['suggestions', 'about', 'post', 'graduate', 'diploma', 'in', 'ba']",0,"['suggestion', 'about', 'post', 'graduate', 'diploma', 'in', 'ba']","['suggestion', 'post', 'graduate', 'diploma', 'ba']",suggestion post graduate diploma ba,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
4527,feature selection with pvalues,feature selection with pvalues,"['feature', 'selection', 'with', 'pvalues']",0,"['feature', 'selection', 'with', 'pvalues']","['feature', 'selection', 'pvalues']",feature selection pvalues,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
4528,document similarity in r,document similarity in r,"['document', 'similarity', 'in', 'r']",0,"['document', 'similarity', 'in', 'r']","['document', 'similarity', 'r']",document similarity r,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
4529,dummyvariable and and selection in factor analysis,dummyvariable and and selection in factor analysis,"['dummyvariable', 'and', 'and', 'selection', 'in', 'factor', 'analysis']",0,"['dummyvariable', 'and', 'and', 'selection', 'in', 'factor', 'analysis']","['dummyvariable', 'selection', 'factor', 'analysis']",dummyvariable selection factor analysis,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
4530,facing problem in data engineering,facing problem in data engineering,"['facing', 'problem', 'in', 'data', 'engineering']",0,"['facing', 'problem', 'in', 'data', 'engineering']","['facing', 'problem', 'data', 'engineering']",facing problem data engineering,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
4531,variance vs standard deviation,variance vs standard deviation,"['variance', 'vs', 'standard', 'deviation']",0,"['variance', 'v', 'standard', 'deviation']","['variance', 'v', 'standard', 'deviation']",variance v standard deviation,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
4532,abnormal score using random forest and svm,abnormal score using random forest and svm,"['abnormal', 'score', 'using', 'random', 'forest', 'and', 'svm']",0,"['abnormal', 'score', 'using', 'random', 'forest', 'and', 'svm']","['abnormal', 'score', 'using', 'random', 'forest', 'svm']",abnormal score using random forest svm,-0.5,-0.5,7,38,4.75,0,0,0,0,0,0,0,0
4533,lemmatization  stemming for bi and n grams,lemmatization  stemming for bi and n grams,"['lemmatization', 'stemming', 'for', 'bi', 'and', 'n', 'grams']",0,"['lemmatization', 'stemming', 'for', 'bi', 'and', 'n', 'gram']","['lemmatization', 'stemming', 'bi', 'n', 'gram']",lemmatization stemming bi n gram,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
4534,prediction test error,prediction test error,"['prediction', 'test', 'error']",0,"['prediction', 'test', 'error']","['prediction', 'test', 'error']",prediction test error,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
4535,getting  probabilities using predict proba,getting  probabilities using predict proba,"['getting', 'probabilities', 'using', 'predict', 'proba']",1,"['getting', 'probability', 'using', 'predict', 'proba']","['getting', 'probability', 'using', 'predict', 'proba']",getting probability using predict proba,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
4536,how to export r plots into tex files,how to export r plots into tex files,"['how', 'to', 'export', 'r', 'plots', 'into', 'tex', 'files']",0,"['how', 'to', 'export', 'r', 'plot', 'into', 'tex', 'file']","['export', 'r', 'plot', 'tex', 'file']",export r plot tex file,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
4537,download dataset for object detection yolo,download dataset for object detection yolo,"['download', 'dataset', 'for', 'object', 'detection', 'yolo']",0,"['download', 'dataset', 'for', 'object', 'detection', 'yolo']","['download', 'dataset', 'object', 'detection', 'yolo']",download dataset object detection yolo,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
4538,install and integrate plotly with r,install and integrate plotly with r,"['install', 'and', 'integrate', 'plotly', 'with', 'r']",0,"['install', 'and', 'integrate', 'plotly', 'with', 'r']","['install', 'integrate', 'plotly', 'r']",install integrate plotly r,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
4539,looking for career transition in data science  analytics,looking for career transition in data science  analytics,"['looking', 'for', 'career', 'transition', 'in', 'data', 'science', 'analytics']",0,"['looking', 'for', 'career', 'transition', 'in', 'data', 'science', 'analytics']","['looking', 'career', 'transition', 'data', 'science', 'analytics']",looking career transition data science analytics,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
4540,market basket analysis using sas,market basket analysis using sas,"['market', 'basket', 'analysis', 'using', 'sas']",0,"['market', 'basket', 'analysis', 'using', 'sa']","['market', 'basket', 'analysis', 'using', 'sa']",market basket analysis using sa,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
4541,getting an infinite p value while selecting best feature using selectkbest model,getting an infinite p value while selecting best feature using selectkbest model,"['getting', 'an', 'infinite', 'p', 'value', 'while', 'selecting', 'best', 'feature', 'using', 'selectkbest', 'model']",0,"['getting', 'an', 'infinite', 'p', 'value', 'while', 'selecting', 'best', 'feature', 'using', 'selectkbest', 'model']","['getting', 'infinite', 'p', 'value', 'selecting', 'best', 'feature', 'using', 'selectkbest', 'model']",getting infinite p value selecting best feature using selectkbest model,1.0,1.0,12,71,5.461538461538462,0,0,0,0,0,0,0,0
4542,can qlikview or tableau replace excel reporting,can qlikview or tableau replace excel reporting,"['can', 'qlikview', 'or', 'tableau', 'replace', 'excel', 'reporting']",0,"['can', 'qlikview', 'or', 'tableau', 'replace', 'excel', 'reporting']","['qlikview', 'tableau', 'replace', 'excel', 'reporting']",qlikview tableau replace excel reporting,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
4543,object detection of aircrafts helicopters,object detection of aircrafts helicopters,"['object', 'detection', 'of', 'aircrafts', 'helicopters']",0,"['object', 'detection', 'of', 'aircraft', 'helicopter']","['object', 'detection', 'aircraft', 'helicopter']",object detection aircraft helicopter,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
4544,logistic regression from scratch for loan prediction,logistic regression from scratch for loan prediction,"['logistic', 'regression', 'from', 'scratch', 'for', 'loan', 'prediction']",0,"['logistic', 'regression', 'from', 'scratch', 'for', 'loan', 'prediction']","['logistic', 'regression', 'scratch', 'loan', 'prediction']",logistic regression scratch loan prediction,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
4545,logistic regression fishers scoring,logistic regression fishers scoring,"['logistic', 'regression', 'fishers', 'scoring']",0,"['logistic', 'regression', 'fisher', 'scoring']","['logistic', 'regression', 'fisher', 'scoring']",logistic regression fisher scoring,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
4546,sas certification  palin technologies vs analytics lab vs jigsaw academy,sas certification  palin technologies vs analytics lab vs jigsaw academy,"['sas', 'certification', 'palin', 'technologies', 'vs', 'analytics', 'lab', 'vs', 'jigsaw', 'academy']",0,"['sa', 'certification', 'palin', 'technology', 'v', 'analytics', 'lab', 'v', 'jigsaw', 'academy']","['sa', 'certification', 'palin', 'technology', 'v', 'analytics', 'lab', 'v', 'jigsaw', 'academy']",sa certification palin technology v analytics lab v jigsaw academy,0.0,0.0,10,66,6.0,0,0,0,0,0,0,0,0
4547,how to calculate the number of features in a training data using python,how to calculate the number of features in a training data using python,"['how', 'to', 'calculate', 'the', 'number', 'of', 'features', 'in', 'a', 'training', 'data', 'using', 'python']",0,"['how', 'to', 'calculate', 'the', 'number', 'of', 'feature', 'in', 'a', 'training', 'data', 'using', 'python']","['calculate', 'number', 'feature', 'training', 'data', 'using', 'python']",calculate number feature training data using python,0.0,0.0,13,51,3.642857142857143,0,0,0,0,0,0,0,0
4548,question on new customers in rfm model,question on new customers in rfm model,"['question', 'on', 'new', 'customers', 'in', 'rfm', 'model']",0,"['question', 'on', 'new', 'customer', 'in', 'rfm', 'model']","['question', 'new', 'customer', 'rfm', 'model']",question new customer rfm model,0.1363636363636363,0.1363636363636363,7,31,3.875,0,0,0,0,0,0,0,0
4549,which platform windows or linux  is used by most r programmers for rstudio,which platform windows or linux  is used by most r programmers for rstudio,"['which', 'platform', 'windows', 'or', 'linux', 'is', 'used', 'by', 'most', 'r', 'programmers', 'for', 'rstudio']",0,"['which', 'platform', 'window', 'or', 'linux', 'is', 'used', 'by', 'most', 'r', 'programmer', 'for', 'rstudio']","['platform', 'window', 'linux', 'used', 'r', 'programmer', 'rstudio']",platform window linux used r programmer rstudio,0.5,0.0,13,47,3.357142857142857,0,0,0,0,0,0,0,0
4550,text classification algorithm selection,text classification algorithm selection,"['text', 'classification', 'algorithm', 'selection']",0,"['text', 'classification', 'algorithm', 'selection']","['text', 'classification', 'algorithm', 'selection']",text classification algorithm selection,0.0,0.0,4,39,7.8,0,0,0,0,0,0,0,0
4551,discussions for article a complete tutorial on time series modeling in r,discussions for article a complete tutorial on time series modeling in r,"['discussions', 'for', 'article', 'a', 'complete', 'tutorial', 'on', 'time', 'series', 'modeling', 'in', 'r']",0,"['discussion', 'for', 'article', 'a', 'complete', 'tutorial', 'on', 'time', 'series', 'modeling', 'in', 'r']","['discussion', 'article', 'complete', 'tutorial', 'time', 'series', 'modeling', 'r']",discussion article complete tutorial time series modeling r,0.1,0.1,12,59,4.538461538461538,0,0,0,0,0,0,0,0
4552,download cheat sheet for data visualization using r,download cheat sheet for data visualization using r,"['download', 'cheat', 'sheet', 'for', 'data', 'visualization', 'using', 'r']",0,"['download', 'cheat', 'sheet', 'for', 'data', 'visualization', 'using', 'r']","['download', 'cheat', 'sheet', 'data', 'visualization', 'using', 'r']",download cheat sheet data visualization using r,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
4553,choosing a sub domain in data science,choosing a sub domain in data science,"['choosing', 'a', 'sub', 'domain', 'in', 'data', 'science']",0,"['choosing', 'a', 'sub', 'domain', 'in', 'data', 'science']","['choosing', 'sub', 'domain', 'data', 'science']",choosing sub domain data science,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
4554,installing xgboost for python  for wndows,installing xgboost for python  for wndows,"['installing', 'xgboost', 'for', 'python', 'for', 'wndows']",1,"['installing', 'xgboost', 'for', 'python', 'for', 'wndows']","['installing', 'xgboost', 'python', 'wndows']",installing xgboost python wndows,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
4555,unorderable types str  float error in logistic regression,unorderable types str  float error in logistic regression,"['unorderable', 'types', 'str', 'float', 'error', 'in', 'logistic', 'regression']",0,"['unorderable', 'type', 'str', 'float', 'error', 'in', 'logistic', 'regression']","['unorderable', 'type', 'str', 'float', 'error', 'logistic', 'regression']",unorderable type str float error logistic regression,0.0,0.0,8,52,5.777777777777778,0,0,0,0,0,0,0,0
4556,skilltest  statistics for data science,skilltest  statistics for data science,"['skilltest', 'statistics', 'for', 'data', 'science']",0,"['skilltest', 'statistic', 'for', 'data', 'science']","['skilltest', 'statistic', 'data', 'science']",skilltest statistic data science,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
4557,nlptm  providing meaningful insights from the data,nlptm  providing meaningful insights from the data,"['nlptm', 'providing', 'meaningful', 'insights', 'from', 'the', 'data']",0,"['nlptm', 'providing', 'meaningful', 'insight', 'from', 'the', 'data']","['nlptm', 'providing', 'meaningful', 'insight', 'data']",nlptm providing meaningful insight data,0.5,0.5,7,39,4.875,0,0,0,0,0,0,0,0
4558,need sas software,need sas software,"['need', 'sas', 'software']",0,"['need', 'sa', 'software']","['need', 'sa', 'software']",need sa software,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
4559,iiim c apds vs iiit b data science course,iiim c apds vs iiit b data science course,"['iiim', 'c', 'apds', 'vs', 'iiit', 'b', 'data', 'science', 'course']",0,"['iiim', 'c', 'apds', 'v', 'iiit', 'b', 'data', 'science', 'course']","['iiim', 'c', 'apds', 'v', 'iiit', 'b', 'data', 'science', 'course']",iiim c apds v iiit b data science course,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
4560,stock prices prediction using machine learning and deep learning techniques,stock prices prediction using machine learning and deep learning techniques,"['stock', 'prices', 'prediction', 'using', 'machine', 'learning', 'and', 'deep', 'learning', 'techniques']",0,"['stock', 'price', 'prediction', 'using', 'machine', 'learning', 'and', 'deep', 'learning', 'technique']","['stock', 'price', 'prediction', 'using', 'machine', 'learning', 'deep', 'learning', 'technique']",stock price prediction using machine learning deep learning technique,0.0,0.0,10,69,6.2727272727272725,0,0,0,0,0,0,0,0
4561,how can i optmize the svr parameters using gwo,how can i optmize the svr parameters using gwo,"['how', 'can', 'i', 'optmize', 'the', 'svr', 'parameters', 'using', 'gwo']",0,"['how', 'can', 'i', 'optmize', 'the', 'svr', 'parameter', 'using', 'gwo']","['optmize', 'svr', 'parameter', 'using', 'gwo']",optmize svr parameter using gwo,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
4562,big data courses,big data courses,"['big', 'data', 'courses']",0,"['big', 'data', 'course']","['big', 'data', 'course']",big data course,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
4563,qlikview  tableau vs traditional bi systems  how are they different,qlikview  tableau vs traditional bi systems  how are they different,"['qlikview', 'tableau', 'vs', 'traditional', 'bi', 'systems', 'how', 'are', 'they', 'different']",0,"['qlikview', 'tableau', 'v', 'traditional', 'bi', 'system', 'how', 'are', 'they', 'different']","['qlikview', 'tableau', 'v', 'traditional', 'bi', 'system', 'different']",qlikview tableau v traditional bi system different,0.0,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
4564,histograms in the post kaggle bike sharing demand prediction  how to get in top  of competition,histograms in the post kaggle bike sharing demand prediction  how to get in top  of competition,"['histograms', 'in', 'the', 'post', 'kaggle', 'bike', 'sharing', 'demand', 'prediction', 'how', 'to', 'get', 'in', 'top', 'of', 'competition']",1,"['histogram', 'in', 'the', 'post', 'kaggle', 'bike', 'sharing', 'demand', 'prediction', 'how', 'to', 'get', 'in', 'top', 'of', 'competition']","['histogram', 'post', 'kaggle', 'bike', 'sharing', 'demand', 'prediction', 'get', 'top', 'competition']",histogram post kaggle bike sharing demand prediction get top competition,0.5,0.5,16,72,4.235294117647059,0,0,0,0,0,0,0,0
4565,should i use bar or line chart to show trend in qlikview,should i use bar or line chart to show trend in qlikview,"['should', 'i', 'use', 'bar', 'or', 'line', 'chart', 'to', 'show', 'trend', 'in', 'qlikview']",0,"['should', 'i', 'use', 'bar', 'or', 'line', 'chart', 'to', 'show', 'trend', 'in', 'qlikview']","['use', 'bar', 'line', 'chart', 'show', 'trend', 'qlikview']",use bar line chart show trend qlikview,0.0,0.0,12,38,2.923076923076923,0,0,0,0,0,0,0,0
4566,how to interpret the result of bagging,how to interpret the result of bagging,"['how', 'to', 'interpret', 'the', 'result', 'of', 'bagging']",0,"['how', 'to', 'interpret', 'the', 'result', 'of', 'bagging']","['interpret', 'result', 'bagging']",interpret result bagging,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
4567,analytics without business knowledge,analytics without business knowledge,"['analytics', 'without', 'business', 'knowledge']",0,"['analytics', 'without', 'business', 'knowledge']","['analytics', 'without', 'business', 'knowledge']",analytics without business knowledge,0.0,0.0,4,36,7.2,0,0,0,0,0,0,0,0
4568,deployment and implementation of predictive models into production,deployment and implementation of predictive models into production,"['deployment', 'and', 'implementation', 'of', 'predictive', 'models', 'into', 'production']",0,"['deployment', 'and', 'implementation', 'of', 'predictive', 'model', 'into', 'production']","['deployment', 'implementation', 'predictive', 'model', 'production']",deployment implementation predictive model production,0.0,0.0,8,53,5.888888888888889,0,0,0,0,0,0,0,0
4569,mysql server reporting services,mysql server reporting services,"['mysql', 'server', 'reporting', 'services']",0,"['mysql', 'server', 'reporting', 'service']","['mysql', 'server', 'reporting', 'service']",mysql server reporting service,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
4570,backtracking optimization,backtracking optimization,"['backtracking', 'optimization']",0,"['backtracking', 'optimization']","['backtracking', 'optimization']",backtracking optimization,0.0,0.0,2,25,8.333333333333334,0,0,0,0,0,0,0,0
4571,how to extract date time information from timestamps in r,how to extract date time information from timestamps in r,"['how', 'to', 'extract', 'date', 'time', 'information', 'from', 'timestamps', 'in', 'r']",0,"['how', 'to', 'extract', 'date', 'time', 'information', 'from', 'timestamps', 'in', 'r']","['extract', 'date', 'time', 'information', 'timestamps', 'r']",extract date time information timestamps r,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
4572,how can we use textual data variables for modeling,how can we use textual data variables for modeling,"['how', 'can', 'we', 'use', 'textual', 'data', 'variables', 'for', 'modeling']",0,"['how', 'can', 'we', 'use', 'textual', 'data', 'variable', 'for', 'modeling']","['use', 'textual', 'data', 'variable', 'modeling']",use textual data variable modeling,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
4573,knn skill test q,knn skill test q,"['knn', 'skill', 'test', 'q']",0,"['knn', 'skill', 'test', 'q']","['knn', 'skill', 'test', 'q']",knn skill test q,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
4574,career shift from net to analytics,career shift from net to analytics,"['career', 'shift', 'from', 'net', 'to', 'analytics']",0,"['career', 'shift', 'from', 'net', 'to', 'analytics']","['career', 'shift', 'net', 'analytics']",career shift net analytics,0.0,0.0,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
4575,sentencebert why docvec object doesnt have encode attribute and the associated solution,sentencebert why docvec object doesnt have encode attribute and the associated solution,"['sentencebert', 'why', 'docvec', 'object', 'doesnt', 'have', 'encode', 'attribute', 'and', 'the', 'associated', 'solution']",0,"['sentencebert', 'why', 'docvec', 'object', 'doesnt', 'have', 'encode', 'attribute', 'and', 'the', 'associated', 'solution']","['sentencebert', 'docvec', 'object', 'doesnt', 'encode', 'attribute', 'associated', 'solution']",sentencebert docvec object doesnt encode attribute associated solution,0.0,0.0,12,70,5.384615384615385,0,0,0,0,0,0,0,0
4576,difference in the ba courses offered by iitd  iimc,difference in the ba courses offered by iitd  iimc,"['difference', 'in', 'the', 'ba', 'courses', 'offered', 'by', 'iitd', 'iimc']",0,"['difference', 'in', 'the', 'ba', 'course', 'offered', 'by', 'iitd', 'iimc']","['difference', 'ba', 'course', 'offered', 'iitd', 'iimc']",difference ba course offered iitd iimc,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
4577,practice problem intel scene classification challenge,practice problem intel scene classification challenge,"['practice', 'problem', 'intel', 'scene', 'classification', 'challenge']",0,"['practice', 'problem', 'intel', 'scene', 'classification', 'challenge']","['practice', 'problem', 'intel', 'scene', 'classification', 'challenge']",practice problem intel scene classification challenge,0.0,0.0,6,53,7.571428571428571,0,0,0,0,0,0,0,0
4578,recommendation system evaluation,recommendation system evaluation,"['recommendation', 'system', 'evaluation']",0,"['recommendation', 'system', 'evaluation']","['recommendation', 'system', 'evaluation']",recommendation system evaluation,0.0,0.0,3,32,8.0,0,0,0,0,0,0,0,0
4579,hadoop basics and its commands,hadoop basics and its commands,"['hadoop', 'basics', 'and', 'its', 'commands']",0,"['hadoop', 'basic', 'and', 'it', 'command']","['hadoop', 'basic', 'command']",hadoop basic command,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
4580,data science for a data warehousing engineer  test analyst,data science for a data warehousing engineer  test analyst,"['data', 'science', 'for', 'a', 'data', 'warehousing', 'engineer', 'test', 'analyst']",0,"['data', 'science', 'for', 'a', 'data', 'warehousing', 'engineer', 'test', 'analyst']","['data', 'science', 'data', 'warehousing', 'engineer', 'test', 'analyst']",data science data warehousing engineer test analyst,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
4581,what are the packages in r to do dimensionality reduction,what are the packages in r to do dimensionality reduction,"['what', 'are', 'the', 'packages', 'in', 'r', 'to', 'do', 'dimensionality', 'reduction']",0,"['what', 'are', 'the', 'package', 'in', 'r', 'to', 'do', 'dimensionality', 'reduction']","['package', 'r', 'dimensionality', 'reduction']",package r dimensionality reduction,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
4582,what is the difference between collaborative and content based recommendation system,what is the difference between collaborative and content based recommendation system,"['what', 'is', 'the', 'difference', 'between', 'collaborative', 'and', 'content', 'based', 'recommendation', 'system']",0,"['what', 'is', 'the', 'difference', 'between', 'collaborative', 'and', 'content', 'based', 'recommendation', 'system']","['difference', 'collaborative', 'content', 'based', 'recommendation', 'system']",difference collaborative content based recommendation system,0.0,0.0,11,60,5.0,0,0,0,0,0,0,0,0
4583,scoring  text classification,scoring  text classification,"['scoring', 'text', 'classification']",0,"['scoring', 'text', 'classification']","['scoring', 'text', 'classification']",scoring text classification,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
4584,career switch from teaching to analytics,career switch from teaching to analytics,"['career', 'switch', 'from', 'teaching', 'to', 'analytics']",0,"['career', 'switch', 'from', 'teaching', 'to', 'analytics']","['career', 'switch', 'teaching', 'analytics']",career switch teaching analytics,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
4585,can i enroll in the new big data hackathon from sapient,can i enroll in the new big data hackathon from sapient,"['can', 'i', 'enroll', 'in', 'the', 'new', 'big', 'data', 'hackathon', 'from', 'sapient']",0,"['can', 'i', 'enroll', 'in', 'the', 'new', 'big', 'data', 'hackathon', 'from', 'sapient']","['enroll', 'new', 'big', 'data', 'hackathon', 'sapient']",enroll new big data hackathon sapient,0.0681818181818181,0.0681818181818181,11,37,3.0833333333333335,0,0,0,0,0,0,0,0
4586,questionstesttreebasedmodels,questionstesttreebasedmodels,['questionstesttreebasedmodels'],0,['questionstesttreebasedmodels'],['questionstesttreebasedmodels'],questionstesttreebasedmodels,0.0,0.0,1,28,14.0,0,0,0,0,0,0,0,0
4587,how to create a waterfall chart in tableau,how to create a waterfall chart in tableau,"['how', 'to', 'create', 'a', 'waterfall', 'chart', 'in', 'tableau']",0,"['how', 'to', 'create', 'a', 'waterfall', 'chart', 'in', 'tableau']","['create', 'waterfall', 'chart', 'tableau']",create waterfall chart tableau,0.0,0.0,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
4588,casino workshopexplanation to workshop problems,casino workshopexplanation to workshop problems,"['casino', 'workshopexplanation', 'to', 'workshop', 'problems']",0,"['casino', 'workshopexplanation', 'to', 'workshop', 'problem']","['casino', 'workshopexplanation', 'workshop', 'problem']",casino workshopexplanation workshop problem,0.0,0.0,5,43,7.166666666666667,0,0,0,0,0,0,0,0
4589,beginners guide on web scraping in r using rvest with handson example,beginners guide on web scraping in r using rvest with handson example,"['beginner', '', 's', 'guide', 'on', 'web', 'scraping', 'in', 'r', 'using', 'rvest', 'with', 'handson', 'example']",0,"['beginner', '', 's', 'guide', 'on', 'web', 'scraping', 'in', 'r', 'using', 'rvest', 'with', 'handson', 'example']","['beginner', '', 'guide', 'web', 'scraping', 'r', 'using', 'rvest', 'handson', 'example']",beginner  guide web scraping r using rvest handson example,0.0,0.0,14,59,3.933333333333333,0,0,0,0,0,0,0,0
4590,career growth of a business analyst and data scientist,career growth of a business analyst and data scientist,"['career', 'growth', 'of', 'a', 'business', 'analyst', 'and', 'data', 'scientist']",0,"['career', 'growth', 'of', 'a', 'business', 'analyst', 'and', 'data', 'scientist']","['career', 'growth', 'business', 'analyst', 'data', 'scientist']",career growth business analyst data scientist,0.0,0.0,9,45,4.5,0,0,0,0,0,0,0,0
4591,keyerror in the below attached code,keyerror in the below attached code,"['keyerror', 'in', 'the', 'below', 'attached', 'code']",0,"['keyerror', 'in', 'the', 'below', 'attached', 'code']","['keyerror', 'attached', 'code']",keyerror attached code,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
4592,what are the deliverables for a data scientist,what are the deliverables for a data scientist,"['what', 'are', 'the', 'deliverables', 'for', 'a', 'data', 'scientist']",0,"['what', 'are', 'the', 'deliverable', 'for', 'a', 'data', 'scientist']","['deliverable', 'data', 'scientist']",deliverable data scientist,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
4593,factor variables in random forest xgboost,factor variables in random forest xgboost,"['factor', 'variables', 'in', 'random', 'forest', 'xgboost']",0,"['factor', 'variable', 'in', 'random', 'forest', 'xgboost']","['factor', 'variable', 'random', 'forest', 'xgboost']",factor variable random forest xgboost,-0.5,-0.5,6,37,5.285714285714286,0,0,0,0,0,0,0,0
4594,not able to execute the following code in python version ,not able to execute the following code in python version ,"['not', 'able', 'to', 'execute', 'the', 'following', 'code', 'in', 'python', 'version']",1,"['not', 'able', 'to', 'execute', 'the', 'following', 'code', 'in', 'python', 'version']","['able', 'execute', 'following', 'code', 'python', 'version']",able execute following code python version,-0.125,0.25,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
4595,how to predict the outcome of elections in a multiparty setup,how to predict the outcome of elections in a multiparty setup,"['how', 'to', 'predict', 'the', 'outcome', 'of', 'elections', 'in', 'a', 'multiparty', 'setup']",0,"['how', 'to', 'predict', 'the', 'outcome', 'of', 'election', 'in', 'a', 'multiparty', 'setup']","['predict', 'outcome', 'election', 'multiparty', 'setup']",predict outcome election multiparty setup,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
4596,multiscale analysis and fractal arrival theories for call center forecasting,multiscale analysis and fractal arrival theories for call center forecasting,"['multiscale', 'analysis', 'and', 'fractal', 'arrival', 'theories', 'for', 'call', 'center', 'forecasting']",0,"['multiscale', 'analysis', 'and', 'fractal', 'arrival', 'theory', 'for', 'call', 'center', 'forecasting']","['multiscale', 'analysis', 'fractal', 'arrival', 'theory', 'call', 'center', 'forecasting']",multiscale analysis fractal arrival theory call center forecasting,-0.1,-0.1,10,66,6.0,0,0,0,0,0,0,0,0
4597,what is concordance index,what is concordance index,"['what', 'is', 'concordance', 'index']",0,"['what', 'is', 'concordance', 'index']","['concordance', 'index']",concordance index,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
4598,what kind of work culture does fractal analytics follow,what kind of work culture does fractal analytics follow,"['what', 'kind', 'of', 'work', 'culture', 'does', 'fractal', 'analytics', 'follow']",0,"['what', 'kind', 'of', 'work', 'culture', 'doe', 'fractal', 'analytics', 'follow']","['kind', 'work', 'culture', 'doe', 'fractal', 'analytics', 'follow']",kind work culture doe fractal analytics follow,0.6,0.6,9,46,4.6,0,0,0,0,0,0,0,0
4599,how to impute categorical missing values,how to impute categorical missing values,"['how', 'to', 'impute', 'categorical', 'missing', 'values']",0,"['how', 'to', 'impute', 'categorical', 'missing', 'value']","['impute', 'categorical', 'missing', 'value']",impute categorical missing value,-0.2,-0.2,6,32,4.571428571428571,0,0,0,0,0,0,0,0
4600,suitable forecasting techniques,suitable forecasting techniques,"['suitable', 'forecasting', 'techniques']",0,"['suitable', 'forecasting', 'technique']","['suitable', 'forecasting', 'technique']",suitable forecasting technique,0.55,0.55,3,30,7.5,0,0,0,0,0,0,0,0
4601,how to read multiple url files at one go in python,how to read multiple url files at one go in python,"['how', 'to', 'read', 'multiple', 'url', 'files', 'at', 'one', 'go', 'in', 'python']",0,"['how', 'to', 'read', 'multiple', 'url', 'file', 'at', 'one', 'go', 'in', 'python']","['read', 'multiple', 'url', 'file', 'one', 'go', 'python']",read multiple url file one go python,0.0,0.0,11,36,3.0,0,0,0,0,0,0,0,0
4602,what is bagging and boosting,what is bagging and boosting,"['what', 'is', 'bagging', 'and', 'boosting']",0,"['what', 'is', 'bagging', 'and', 'boosting']","['bagging', 'boosting']",bagging boosting,0.0,0.0,5,16,2.6666666666666665,0,0,0,0,0,0,0,0
4603,sample rfp  request for proposal  regarding data analytic and business intelligence,sample rfp  request for proposal  regarding data analytic and business intelligence,"['sample', 'rfp', 'request', 'for', 'proposal', 'regarding', 'data', 'analytic', 'and', 'business', 'intelligence']",0,"['sample', 'rfp', 'request', 'for', 'proposal', 'regarding', 'data', 'analytic', 'and', 'business', 'intelligence']","['sample', 'rfp', 'request', 'proposal', 'regarding', 'data', 'analytic', 'business', 'intelligence']",sample rfp request proposal regarding data analytic business intelligence,0.0,0.0,11,73,6.083333333333333,0,0,0,0,0,0,0,0
4604,how to find the contributing features of each tree in random forest classifier in python,how to find the contributing features of each tree in random forest classifier in python,"['how', 'to', 'find', 'the', 'contributing', 'features', 'of', 'each', 'tree', 'in', 'random', 'forest', 'classifier', 'in', 'python']",0,"['how', 'to', 'find', 'the', 'contributing', 'feature', 'of', 'each', 'tree', 'in', 'random', 'forest', 'classifier', 'in', 'python']","['find', 'contributing', 'feature', 'tree', 'random', 'forest', 'classifier', 'python']",find contributing feature tree random forest classifier python,-0.5,-0.5,15,62,3.875,0,0,0,0,0,0,0,0
4605,dataset for completed hackathons,dataset for completed hackathons,"['dataset', 'for', 'completed', 'hackathons']",0,"['dataset', 'for', 'completed', 'hackathons']","['dataset', 'completed', 'hackathons']",dataset completed hackathons,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
4606,career path for data science  cfa,career path for data science  cfa,"['career', 'path', 'for', 'data', 'science', 'cfa']",0,"['career', 'path', 'for', 'data', 'science', 'cfa']","['career', 'path', 'data', 'science', 'cfa']",career path data science cfa,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
4607,need help analysing data,need help analysing data,"['need', 'help', 'analysing', 'data']",0,"['need', 'help', 'analysing', 'data']","['need', 'help', 'analysing', 'data']",need help analysing data,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
4608,phd in data analytics,phd in data analytics,"['phd', 'in', 'data', 'analytics']",0,"['phd', 'in', 'data', 'analytics']","['phd', 'data', 'analytics']",phd data analytics,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
4609,explanation at the end of the hackathon,explanation at the end of the hackathon,"['explanation', 'at', 'the', 'end', 'of', 'the', 'hackathon']",0,"['explanation', 'at', 'the', 'end', 'of', 'the', 'hackathon']","['explanation', 'end', 'hackathon']",explanation end hackathon,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
4610,what is the purpose of doing t test z test in machine learning,what is the purpose of doing t test z test in machine learning,"['what', 'is', 'the', 'purpose', 'of', 'doing', 't', 'test', 'z', 'test', 'in', 'machine', 'learning']",0,"['what', 'is', 'the', 'purpose', 'of', 'doing', 't', 'test', 'z', 'test', 'in', 'machine', 'learning']","['purpose', 'test', 'z', 'test', 'machine', 'learning']",purpose test z test machine learning,0.0,0.0,13,36,2.5714285714285716,0,0,0,0,0,0,0,0
4611,algorithms used in shoppertrak type applications,algorithms used in shoppertrak type applications,"['algorithms', 'used', 'in', 'shoppertrak', 'type', 'applications']",0,"['algorithm', 'used', 'in', 'shoppertrak', 'type', 'application']","['algorithm', 'used', 'shoppertrak', 'type', 'application']",algorithm used shoppertrak type application,0.0,0.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
4612,which package to use in r  for sentiment analysis,which package to use in r  for sentiment analysis,"['which', 'package', 'to', 'use', 'in', 'r', 'for', 'sentiment', 'analysis']",1,"['which', 'package', 'to', 'use', 'in', 'r', 'for', 'sentiment', 'analysis']","['package', 'use', 'r', 'sentiment', 'analysis']",package use r sentiment analysis,0.0,0.0,9,32,3.2,0,0,0,0,0,0,0,0
4613,model validation techinques for r logistic regression,model validation techinques for r logistic regression,"['model', 'validation', 'techinques', 'for', 'r', 'logistic', 'regression']",0,"['model', 'validation', 'techinques', 'for', 'r', 'logistic', 'regression']","['model', 'validation', 'techinques', 'r', 'logistic', 'regression']",model validation techinques r logistic regression,0.0,0.0,7,49,6.125,0,0,0,0,0,0,0,0
4614,how are weights calculated for linear regression,how are weights calculated for linear regression,"['how', 'are', 'weights', 'calculated', 'for', 'linear', 'regression']",0,"['how', 'are', 'weight', 'calculated', 'for', 'linear', 'regression']","['weight', 'calculated', 'linear', 'regression']",weight calculated linear regression,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
4615,need help on dealing with it operational incident data,need help on dealing with it operational incident data,"['need', 'help', 'on', 'dealing', 'with', 'it', 'operational', 'incident', 'data']",0,"['need', 'help', 'on', 'dealing', 'with', 'it', 'operational', 'incident', 'data']","['need', 'help', 'dealing', 'operational', 'incident', 'data']",need help dealing operational incident data,0.0,0.0,9,43,4.3,0,0,0,0,0,0,0,0
4616,can several random forests be combined for better classification,can several random forests be combined for better classification,"['can', 'several', 'random', 'forests', 'be', 'combined', 'for', 'better', 'classification']",0,"['can', 'several', 'random', 'forest', 'be', 'combined', 'for', 'better', 'classification']","['several', 'random', 'forest', 'combined', 'better', 'classification']",several random forest combined better classification,0.0,0.0,9,52,5.2,0,0,0,0,0,0,0,0
4617,extracting data from strings in r,extracting data from strings in r,"['extracting', 'data', 'from', 'strings', 'in', 'r']",0,"['extracting', 'data', 'from', 'string', 'in', 'r']","['extracting', 'data', 'string', 'r']",extracting data string r,0.0,0.0,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
4618,what is the best way to use categorical variables in a decision tree model,what is the best way to use categorical variables in a decision tree model,"['what', 'is', 'the', 'best', 'way', 'to', 'use', 'categorical', 'variables', 'in', 'a', 'decision', 'tree', 'model']",0,"['what', 'is', 'the', 'best', 'way', 'to', 'use', 'categorical', 'variable', 'in', 'a', 'decision', 'tree', 'model']","['best', 'way', 'use', 'categorical', 'variable', 'decision', 'tree', 'model']",best way use categorical variable decision tree model,1.0,1.0,14,53,3.533333333333333,0,0,0,0,0,0,0,0
4619,python guide to start with data science and nlp,python guide to start with data science and nlp,"['python', 'guide', 'to', 'start', 'with', 'data', 'science', 'and', 'nlp']",0,"['python', 'guide', 'to', 'start', 'with', 'data', 'science', 'and', 'nlp']","['python', 'guide', 'start', 'data', 'science', 'nlp']",python guide start data science nlp,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
4620,data science jobs in pune,data science jobs in pune,"['data', 'science', 'jobs', 'in', 'pune']",0,"['data', 'science', 'job', 'in', 'pune']","['data', 'science', 'job', 'pune']",data science job pune,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
4621,can a qlikview developer be a qlik sense developer,can a qlikview developer be a qlik sense developer,"['can', 'a', 'qlikview', 'developer', 'be', 'a', 'qlik', 'sense', 'developer']",0,"['can', 'a', 'qlikview', 'developer', 'be', 'a', 'qlik', 'sense', 'developer']","['qlikview', 'developer', 'qlik', 'sense', 'developer']",qlikview developer qlik sense developer,0.0,0.0,9,39,3.9,0,0,0,0,0,0,0,0
4622,how r creates levels of a character variable,how r creates levels of a character variable,"['how', 'r', 'creates', 'levels', 'of', 'a', 'character', 'variable']",0,"['how', 'r', 'creates', 'level', 'of', 'a', 'character', 'variable']","['r', 'creates', 'level', 'character', 'variable']",r creates level character variable,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
4623,how to use pca technique to build classification model,how to use pca technique to build classification model,"['how', 'to', 'use', 'pca', 'technique', 'to', 'build', 'classification', 'model']",0,"['how', 'to', 'use', 'pca', 'technique', 'to', 'build', 'classification', 'model']","['use', 'pca', 'technique', 'build', 'classification', 'model']",use pca technique build classification model,0.0,0.0,9,44,4.4,0,0,0,0,0,0,0,0
4624,loan prediction  data conversion warning,loan prediction  data conversion warning,"['loan', 'prediction', 'data', 'conversion', 'warning']",0,"['loan', 'prediction', 'data', 'conversion', 'warning']","['loan', 'prediction', 'data', 'conversion', 'warning']",loan prediction data conversion warning,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
4625,how the number of observation and number of predictors affect the flexibility of the model,how the number of observation and number of predictors affect the flexibility of the model,"['how', 'the', 'number', 'of', 'observation', 'and', 'number', 'of', 'predictors', 'affect', 'the', 'flexibility', 'of', 'the', 'model']",0,"['how', 'the', 'number', 'of', 'observation', 'and', 'number', 'of', 'predictor', 'affect', 'the', 'flexibility', 'of', 'the', 'model']","['number', 'observation', 'number', 'predictor', 'affect', 'flexibility', 'model']",number observation number predictor affect flexibility model,0.0,0.0,15,60,3.75,0,0,0,0,0,0,0,0
4626,hypothesis testing,hypothesis testing,"['hypothesis', 'testing']",0,"['hypothesis', 'testing']","['hypothesis', 'testing']",hypothesis testing,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
4627,how to find accuracy of k means or any other clustering algorithm,how to find accuracy of k means or any other clustering algorithm,"['how', 'to', 'find', 'accuracy', 'of', 'k', 'means', 'or', 'any', 'other', 'clustering', 'algorithm']",0,"['how', 'to', 'find', 'accuracy', 'of', 'k', 'mean', 'or', 'any', 'other', 'clustering', 'algorithm']","['find', 'accuracy', 'k', 'mean', 'clustering', 'algorithm']",find accuracy k mean clustering algorithm,-0.125,-0.3125,12,41,3.1538461538461537,0,0,0,0,0,0,0,0
4628,data science in scala and spark,data science in scala and spark,"['data', 'science', 'in', 'scala', 'and', 'spark']",0,"['data', 'science', 'in', 'scala', 'and', 'spark']","['data', 'science', 'scala', 'spark']",data science scala spark,0.0,0.0,6,24,3.4285714285714284,0,0,0,0,0,0,0,0
4629,create customer persona in machine learning,create customer persona in machine learning,"['create', 'customer', 'persona', 'in', 'machine', 'learning']",0,"['create', 'customer', 'persona', 'in', 'machine', 'learning']","['create', 'customer', 'persona', 'machine', 'learning']",create customer persona machine learning,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
4630,face recognition deep learning,face recognition deep learning,"['face', 'recognition', 'deep', 'learning']",0,"['face', 'recognition', 'deep', 'learning']","['face', 'recognition', 'deep', 'learning']",face recognition deep learning,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
4631,how to work with strsplitr,how to work with strsplitr,"['how', 'to', 'work', 'with', 'strsplitr']",0,"['how', 'to', 'work', 'with', 'strsplitr']","['work', 'strsplitr']",work strsplitr,0.0,0.0,5,14,2.3333333333333335,0,0,0,0,0,0,0,0
4632,how can i stop user to enter space at the begin and end of the string in excel,how can i stop user to enter space at the begin and end of the string in excel,"['how', 'can', 'i', 'stop', 'user', 'to', 'enter', 'space', 'at', 'the', 'begin', 'and', 'end', 'of', 'the', 'string', 'in', 'excel']",0,"['how', 'can', 'i', 'stop', 'user', 'to', 'enter', 'space', 'at', 'the', 'begin', 'and', 'end', 'of', 'the', 'string', 'in', 'excel']","['stop', 'user', 'enter', 'space', 'begin', 'end', 'string', 'excel']",stop user enter space begin end string excel,0.0,0.0,18,44,2.3157894736842106,0,0,0,0,0,0,0,0
4633,files in kerasscriptpy,files in kerasscriptpy,"['files', 'in', 'kerasscriptpy']",0,"['file', 'in', 'kerasscriptpy']","['file', 'kerasscriptpy']",file kerasscriptpy,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
4634,business analyst or data science as a career,business analyst or data science as a career,"['business', 'analyst', 'or', 'data', 'science', 'as', 'a', 'career']",0,"['business', 'analyst', 'or', 'data', 'science', 'a', 'a', 'career']","['business', 'analyst', 'data', 'science', 'career']",business analyst data science career,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
4635,what does the summary of pca signifies,what does the summary of pca signifies,"['what', 'does', 'the', 'summary', 'of', 'pca', 'signifies']",0,"['what', 'doe', 'the', 'summary', 'of', 'pca', 'signifies']","['doe', 'summary', 'pca', 'signifies']",doe summary pca signifies,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
4636,how to load rolling period data in qlikview,how to load rolling period data in qlikview,"['how', 'to', 'load', 'rolling', 'period', 'data', 'in', 'qlikview']",0,"['how', 'to', 'load', 'rolling', 'period', 'data', 'in', 'qlikview']","['load', 'rolling', 'period', 'data', 'qlikview']",load rolling period data qlikview,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
4637,web scrapping using r auto updating forms,web scrapping using r auto updating forms,"['web', 'scrapping', 'using', 'r', 'auto', 'updating', 'forms']",0,"['web', 'scrapping', 'using', 'r', 'auto', 'updating', 'form']","['web', 'scrapping', 'using', 'r', 'auto', 'updating', 'form']",web scrapping using r auto updating form,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
4638,am getting nan error when working on loan prediction problem,am getting nan error when working on loan prediction problem,"['am', 'getting', 'nan', 'error', 'when', 'working', 'on', 'loan', 'prediction', 'problem']",0,"['am', 'getting', 'nan', 'error', 'when', 'working', 'on', 'loan', 'prediction', 'problem']","['getting', 'nan', 'error', 'working', 'loan', 'prediction', 'problem']",getting nan error working loan prediction problem,0.0,0.0,10,49,4.454545454545454,0,0,0,0,0,0,0,0
4639,how to become a data visualization expert,how to become a data visualization expert,"['how', 'to', 'become', 'a', 'data', 'visualization', 'expert']",0,"['how', 'to', 'become', 'a', 'data', 'visualization', 'expert']","['become', 'data', 'visualization', 'expert']",become data visualization expert,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
4640,all in one big data and analytics training,all in one big data and analytics training,"['all', 'in', 'one', 'big', 'data', 'and', 'analytics', 'training']",0,"['all', 'in', 'one', 'big', 'data', 'and', 'analytics', 'training']","['one', 'big', 'data', 'analytics', 'training']",one big data analytics training,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
4641,dealing zeros in log transformation,dealing zeros in log transformation,"['dealing', 'zeros', 'in', 'log', 'transformation']",0,"['dealing', 'zero', 'in', 'log', 'transformation']","['dealing', 'zero', 'log', 'transformation']",dealing zero log transformation,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
4642,please help me getting some good docsmaterials on pricing analytics for telecom industry,please help me getting some good docsmaterials on pricing analytics for telecom industry,"['please', 'help', 'me', 'getting', 'some', 'good', 'docsmaterials', 'on', 'pricing', 'analytics', 'for', 'telecom', 'industry']",0,"['please', 'help', 'me', 'getting', 'some', 'good', 'docsmaterials', 'on', 'pricing', 'analytics', 'for', 'telecom', 'industry']","['please', 'help', 'getting', 'good', 'docsmaterials', 'pricing', 'analytics', 'telecom', 'industry']",please help getting good docsmaterials pricing analytics telecom industry,0.7,0.7,13,73,5.214285714285714,0,0,0,0,0,0,0,0
4643,how to populate all dates between two date in sas,how to populate all dates between two date in sas,"['how', 'to', 'populate', 'all', 'dates', 'between', 'two', 'date', 'in', 'sas']",0,"['how', 'to', 'populate', 'all', 'date', 'between', 'two', 'date', 'in', 'sa']","['populate', 'date', 'two', 'date', 'sa']",populate date two date sa,0.0,0.0,10,25,2.272727272727273,0,0,0,0,0,0,0,0
4644,ltfs hackathon data set query,ltfs hackathon data set query,"['ltfs', 'hackathon', 'data', 'set', 'query']",0,"['ltfs', 'hackathon', 'data', 'set', 'query']","['ltfs', 'hackathon', 'data', 'set', 'query']",ltfs hackathon data set query,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
4645,compact prediction tree library,compact prediction tree library,"['compact', 'prediction', 'tree', 'library']",0,"['compact', 'prediction', 'tree', 'library']","['compact', 'prediction', 'tree', 'library']",compact prediction tree library,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
4646,how doe maximum likelihood estimation work in logistic regression,how doe maximum likelihood estimation work in logistic regression,"['how', 'doe', 'maximum', 'likelihood', 'estimation', 'work', 'in', 'logistic', 'regression']",0,"['how', 'doe', 'maximum', 'likelihood', 'estimation', 'work', 'in', 'logistic', 'regression']","['doe', 'maximum', 'likelihood', 'estimation', 'work', 'logistic', 'regression']",doe maximum likelihood estimation work logistic regression,0.0,0.0,9,58,5.8,0,0,0,0,0,0,0,0
4647,career path in data science  analytics,career path in data science  analytics,"['career', 'path', 'in', 'data', 'science', 'analytics']",0,"['career', 'path', 'in', 'data', 'science', 'analytics']","['career', 'path', 'data', 'science', 'analytics']",career path data science analytics,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
4648,loading csv file in python error,loading csv file in python error,"['loading', 'csv', 'file', 'in', 'python', 'error']",0,"['loading', 'csv', 'file', 'in', 'python', 'error']","['loading', 'csv', 'file', 'python', 'error']",loading csv file python error,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
4649,data engineering case interview resources,data engineering case interview resources,"['data', 'engineering', 'case', 'interview', 'resources']",0,"['data', 'engineering', 'case', 'interview', 'resource']","['data', 'engineering', 'case', 'interview', 'resource']",data engineering case interview resource,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
4650,hackathon solutions,hackathon solutions,"['hackathon', 'solutions']",0,"['hackathon', 'solution']","['hackathon', 'solution']",hackathon solution,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
4651,to predict product order quantity by regression,to predict product order quantity by regression,"['to', 'predict', 'product', 'order', 'quantity', 'by', 'regression']",0,"['to', 'predict', 'product', 'order', 'quantity', 'by', 'regression']","['predict', 'product', 'order', 'quantity', 'regression']",predict product order quantity regression,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
4652,measure two performances over time,measure two performances over time,"['measure', 'two', 'performances', 'over', 'time']",0,"['measure', 'two', 'performance', 'over', 'time']","['measure', 'two', 'performance', 'time']",measure two performance time,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
4653,abstractive algorithm for text summarizer of huge text documentlong email chain,abstractive algorithm for text summarizer of huge text documentlong email chain,"['abstractive', 'algorithm', 'for', 'text', 'summarizer', 'of', 'huge', 'text', 'documentlong', 'email', 'chain']",0,"['abstractive', 'algorithm', 'for', 'text', 'summarizer', 'of', 'huge', 'text', 'documentlong', 'email', 'chain']","['abstractive', 'algorithm', 'text', 'summarizer', 'huge', 'text', 'documentlong', 'email', 'chain']",abstractive algorithm text summarizer huge text documentlong email chain,0.4000000000000001,0.4000000000000001,11,72,6.0,0,0,0,0,0,0,0,0
4654,what do you mean by inmemory data processing when it comes to qlikview,what do you mean by inmemory data processing when it comes to qlikview,"['what', 'do', 'you', 'mean', 'by', 'inmemory', 'data', 'processing', 'when', 'it', 'comes', 'to', 'qlikview']",0,"['what', 'do', 'you', 'mean', 'by', 'inmemory', 'data', 'processing', 'when', 'it', 'come', 'to', 'qlikview']","['mean', 'inmemory', 'data', 'processing', 'come', 'qlikview']",mean inmemory data processing come qlikview,-0.3125,-0.3125,13,43,3.0714285714285716,0,0,0,0,0,0,0,0
4655,what is the attribute independence problem in naive bayes classifier,what is the attribute independence problem in naive bayes classifier,"['what', 'is', 'the', 'attribute', 'independence', 'problem', 'in', 'naive', 'bayes', 'classifier']",0,"['what', 'is', 'the', 'attribute', 'independence', 'problem', 'in', 'naive', 'bayes', 'classifier']","['attribute', 'independence', 'problem', 'naive', 'bayes', 'classifier']",attribute independence problem naive bayes classifier,-0.3,-0.3,10,53,4.818181818181818,0,0,0,0,0,0,0,0
4656,time series sales forecasting techniques and approach,time series sales forecasting techniques and approach,"['time', 'series', 'sales', 'forecasting', 'techniques', 'and', 'approach']",0,"['time', 'series', 'sale', 'forecasting', 'technique', 'and', 'approach']","['time', 'series', 'sale', 'forecasting', 'technique', 'approach']",time series sale forecasting technique approach,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
4657,computing eigenvectors for pca,computing eigenvectors for pca,"['computing', 'eigenvectors', 'for', 'pca']",0,"['computing', 'eigenvectors', 'for', 'pca']","['computing', 'eigenvectors', 'pca']",computing eigenvectors pca,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
4658,layers in a neural network,layers in a neural network,"['layers', 'in', 'a', 'neural', 'network']",0,"['layer', 'in', 'a', 'neural', 'network']","['layer', 'neural', 'network']",layer neural network,0.0,0.0,5,20,3.3333333333333335,0,0,0,0,0,0,0,0
4659,claim rejection classification problem,claim rejection classification problem,"['claim', 'rejection', 'classification', 'problem']",0,"['claim', 'rejection', 'classification', 'problem']","['claim', 'rejection', 'classification', 'problem']",claim rejection classification problem,0.0,0.0,4,38,7.6,0,0,0,0,0,0,0,0
4660,how to improve time series model arima in python,how to improve time series model arima in python,"['how', 'to', 'improve', 'time', 'series', 'model', 'arima', 'in', 'python']",0,"['how', 'to', 'improve', 'time', 'series', 'model', 'arima', 'in', 'python']","['improve', 'time', 'series', 'model', 'arima', 'python']",improve time series model arima python,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
4661,calculate entropy for decision tree,calculate entropy for decision tree,"['calculate', 'entropy', 'for', 'decision', 'tree']",0,"['calculate', 'entropy', 'for', 'decision', 'tree']","['calculate', 'entropy', 'decision', 'tree']",calculate entropy decision tree,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
4662,problem in fast rcnn,problem in fast rcnn,"['problem', 'in', 'fast', 'rcnn']",0,"['problem', 'in', 'fast', 'rcnn']","['problem', 'fast', 'rcnn']",problem fast rcnn,0.2,0.2,4,17,3.4,0,0,0,0,0,0,0,0
4663,what does the error  factor loan id has new level mean,what does the error  factor loan id has new level mean,"['what', 'does', 'the', 'error', 'factor', 'loan', 'id', 'has', 'new', 'level', 'mean']",0,"['what', 'doe', 'the', 'error', 'factor', 'loan', 'id', 'ha', 'new', 'level', 'mean']","['doe', 'error', 'factor', 'loan', 'id', 'ha', 'new', 'level', 'mean']",doe error factor loan id ha new level mean,-0.0880681818181818,-0.0880681818181818,11,42,3.5,0,0,0,0,0,0,0,0
4664,replacing missing value with mean,replacing missing value with mean,"['replacing', 'missing', 'value', 'with', 'mean']",0,"['replacing', 'missing', 'value', 'with', 'mean']","['replacing', 'missing', 'value', 'mean']",replacing missing value mean,-0.25625,-0.25625,5,28,4.666666666666667,0,0,0,0,0,0,0,0
4665,need job change in data analyst,need job change in data analyst,"['need', 'job', 'change', 'in', 'data', 'analyst']",0,"['need', 'job', 'change', 'in', 'data', 'analyst']","['need', 'job', 'change', 'data', 'analyst']",need job change data analyst,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
4666,face detection using python,face detection using python,"['face', 'detection', 'using', 'python']",0,"['face', 'detection', 'using', 'python']","['face', 'detection', 'using', 'python']",face detection using python,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
4667,how to view the slack discussion,how to view the slack discussion,"['how', 'to', 'view', 'the', 'slack', 'discussion']",0,"['how', 'to', 'view', 'the', 'slack', 'discussion']","['view', 'slack', 'discussion']",view slack discussion,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
4668,can a bad coder become a good data scientist,can a bad coder become a good data scientist,"['can', 'a', 'bad', 'coder', 'become', 'a', 'good', 'data', 'scientist']",0,"['can', 'a', 'bad', 'coder', 'become', 'a', 'good', 'data', 'scientist']","['bad', 'coder', 'become', 'good', 'data', 'scientist']",bad coder become good data scientist,5.551115123125783e-17,5.551115123125783e-17,9,36,3.6,0,0,0,0,0,0,0,0
4669,identify all feature having missing value in pandas dataframe,identify all feature having missing value in pandas dataframe,"['identify', 'all', 'feature', 'having', 'missing', 'value', 'in', 'pandas', 'dataframe']",0,"['identify', 'all', 'feature', 'having', 'missing', 'value', 'in', 'panda', 'dataframe']","['identify', 'feature', 'missing', 'value', 'panda', 'dataframe']",identify feature missing value panda dataframe,-0.2,-0.2,9,46,4.6,0,0,0,0,0,0,0,0
4670,error while reading a csv file in pandas,error while reading a csv file in pandas,"['error', 'while', 'reading', 'a', 'csv', 'file', 'in', 'pandas']",0,"['error', 'while', 'reading', 'a', 'csv', 'file', 'in', 'panda']","['error', 'reading', 'csv', 'file', 'panda']",error reading csv file panda,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
4671,file for test or training in an introduction to pytorch  a simple yet powerful deep learning library,file for test or training in an introduction to pytorch  a simple yet powerful deep learning library,"['file', 'for', 'test', 'or', 'training', 'in', 'an', 'introduction', 'to', 'pytorch', '', 'a', 'simple', 'yet', 'powerful', 'deep', 'learning', 'library']",0,"['file', 'for', 'test', 'or', 'training', 'in', 'an', 'introduction', 'to', 'pytorch', '', 'a', 'simple', 'yet', 'powerful', 'deep', 'learning', 'library']","['file', 'test', 'training', 'introduction', 'pytorch', '', 'simple', 'yet', 'powerful', 'deep', 'learning', 'library']",file test training introduction pytorch  simple yet powerful deep learning library,0.0999999999999999,0.0999999999999999,18,83,4.368421052631579,0,0,0,0,0,0,0,0
4672,why to use odd value of k in knn algorithm,why to use odd value of k in knn algorithm,"['why', 'to', 'use', 'odd', 'value', 'of', 'k', 'in', 'knn', 'algorithm']",0,"['why', 'to', 'use', 'odd', 'value', 'of', 'k', 'in', 'knn', 'algorithm']","['use', 'odd', 'value', 'k', 'knn', 'algorithm']",use odd value k knn algorithm,-0.1666666666666666,-0.1666666666666666,10,29,2.6363636363636362,0,0,0,0,0,0,0,0
4673,need help seersaccuracy,need help seersaccuracy,"['need', 'help', 'seersaccuracy']",0,"['need', 'help', 'seersaccuracy']","['need', 'help', 'seersaccuracy']",need help seersaccuracy,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
4674,kmeans clustering,kmeans clustering,"['kmeans', 'clustering']",0,"['kmeans', 'clustering']","['kmeans', 'clustering']",kmeans clustering,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
4675,how to check for stability of a model,how to check for stability of a model,"['how', 'to', 'check', 'for', 'stability', 'of', 'a', 'model']",0,"['how', 'to', 'check', 'for', 'stability', 'of', 'a', 'model']","['check', 'stability', 'model']",check stability model,0.0,0.0,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
4676,unable to do submission in blackfriday hackathon,unable to do submission in blackfriday hackathon,"['unable', 'to', 'do', 'submission', 'in', 'blackfriday', 'hackathon']",0,"['unable', 'to', 'do', 'submission', 'in', 'blackfriday', 'hackathon']","['unable', 'submission', 'blackfriday', 'hackathon']",unable submission blackfriday hackathon,-0.5,-0.5,7,39,4.875,0,0,0,0,0,0,0,0
4677,data preperation,data preperation,"['data', 'preperation']",0,"['data', 'preperation']","['data', 'preperation']",data preperation,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
4678,add comments section on meetup registration page,add comments section on meetup registration page,"['add', 'comments', 'section', 'on', 'meetup', 'registration', 'page']",0,"['add', 'comment', 'section', 'on', 'meetup', 'registration', 'page']","['add', 'comment', 'section', 'meetup', 'registration', 'page']",add comment section meetup registration page,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
4679,how can we find seasonal order for sarima,how can we find seasonal order for sarima,"['how', 'can', 'we', 'find', 'seasonal', 'order', 'for', 'sarima']",0,"['how', 'can', 'we', 'find', 'seasonal', 'order', 'for', 'sarima']","['find', 'seasonal', 'order', 'sarima']",find seasonal order sarima,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
4680,which logistic regression model should be selected among several models,which logistic regression model should be selected among several models,"['which', 'logistic', 'regression', 'model', 'should', 'be', 'selected', 'among', 'several', 'models']",0,"['which', 'logistic', 'regression', 'model', 'should', 'be', 'selected', 'among', 'several', 'model']","['logistic', 'regression', 'model', 'selected', 'among', 'several', 'model']",logistic regression model selected among several model,0.0,0.0,10,54,4.909090909090909,0,0,0,0,0,0,0,0
4681,career shift from mainframe,career shift from mainframe,"['career', 'shift', 'from', 'mainframe']",0,"['career', 'shift', 'from', 'mainframe']","['career', 'shift', 'mainframe']",career shift mainframe,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
4682,my solution  score ,my solution  score ,"['my', 'solution', 'score']",1,"['my', 'solution', 'score']","['solution', 'score']",solution score,0.0,0.0,3,14,3.5,0,0,0,0,0,0,0,0
4683,what are some unsupervised machine learning algorithms other than clustering,what are some unsupervised machine learning algorithms other than clustering,"['what', 'are', 'some', 'unsupervised', 'machine', 'learning', 'algorithms', 'other', 'than', 'clustering']",0,"['what', 'are', 'some', 'unsupervised', 'machine', 'learning', 'algorithm', 'other', 'than', 'clustering']","['unsupervised', 'machine', 'learning', 'algorithm', 'clustering']",unsupervised machine learning algorithm clustering,-0.125,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
4684,theano on windows,theano on windows,"['theano', 'on', 'windows']",0,"['theano', 'on', 'window']","['theano', 'window']",theano window,0.0,0.0,3,13,3.25,0,0,0,0,0,0,0,0
4685,analytics career for a business intelligence test lead person,analytics career for a business intelligence test lead person,"['analytics', 'career', 'for', 'a', 'business', 'intelligence', 'test', 'lead', 'person']",0,"['analytics', 'career', 'for', 'a', 'business', 'intelligence', 'test', 'lead', 'person']","['analytics', 'career', 'business', 'intelligence', 'test', 'lead', 'person']",analytics career business intelligence test lead person,0.0,0.0,9,55,5.5,0,0,0,0,0,0,0,0
4686,error while plotting overlaid histograms in r using ggplot,error while plotting overlaid histograms in r using ggplot,"['error', 'while', 'plotting', 'overlaid', 'histograms', 'in', 'r', 'using', 'ggplot']",0,"['error', 'while', 'plotting', 'overlaid', 'histogram', 'in', 'r', 'using', 'ggplot']","['error', 'plotting', 'overlaid', 'histogram', 'r', 'using', 'ggplot']",error plotting overlaid histogram r using ggplot,0.0,0.0,9,48,4.8,0,0,0,0,0,0,0,0
4687,remove leading and trailing spaces from all cells of excel,remove leading and trailing spaces from all cells of excel,"['remove', 'leading', 'and', 'trailing', 'spaces', 'from', 'all', 'cells', 'of', 'excel']",0,"['remove', 'leading', 'and', 'trailing', 'space', 'from', 'all', 'cell', 'of', 'excel']","['remove', 'leading', 'trailing', 'space', 'cell', 'excel']",remove leading trailing space cell excel,0.0,0.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
4688,what dataanalytics tools i need to use at my current ecommerce workplace,what dataanalytics tools i need to use at my current ecommerce workplace,"['what', 'dataanalytics', 'tools', 'i', 'need', 'to', 'use', 'at', 'my', 'current', 'ecommerce', 'workplace']",0,"['what', 'dataanalytics', 'tool', 'i', 'need', 'to', 'use', 'at', 'my', 'current', 'ecommerce', 'workplace']","['dataanalytics', 'tool', 'need', 'use', 'current', 'ecommerce', 'workplace']",dataanalytics tool need use current ecommerce workplace,0.0,0.0,12,55,4.230769230769231,0,0,0,0,0,0,0,0
4689,how to handle categorical variables in logistic regression,how to handle categorical variables in logistic regression,"['how', 'to', 'handle', 'categorical', 'variables', 'in', 'logistic', 'regression']",0,"['how', 'to', 'handle', 'categorical', 'variable', 'in', 'logistic', 'regression']","['handle', 'categorical', 'variable', 'logistic', 'regression']",handle categorical variable logistic regression,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
4690,data science  big data in jigsaw academy,data science  big data in jigsaw academy,"['data', 'science', 'big', 'data', 'in', 'jigsaw', 'academy']",0,"['data', 'science', 'big', 'data', 'in', 'jigsaw', 'academy']","['data', 'science', 'big', 'data', 'jigsaw', 'academy']",data science big data jigsaw academy,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
4691,missing value imputation,missing value imputation,"['missing', 'value', 'imputation']",0,"['missing', 'value', 'imputation']","['missing', 'value', 'imputation']",missing value imputation,-0.2,-0.2,3,24,6.0,0,0,0,0,0,0,0,0
4692,how can we treat missing datas in pandas dataframe through deletion in python,how can we treat missing datas in pandas dataframe through deletion in python,"['how', 'can', 'we', 'treat', 'missing', 'datas', 'in', 'pandas', 'dataframe', 'through', 'deletion', 'in', 'python']",0,"['how', 'can', 'we', 'treat', 'missing', 'data', 'in', 'panda', 'dataframe', 'through', 'deletion', 'in', 'python']","['treat', 'missing', 'data', 'panda', 'dataframe', 'deletion', 'python']",treat missing data panda dataframe deletion python,-0.2,-0.2,13,50,3.5714285714285716,0,0,0,0,0,0,0,0
4693,ho model for production deployment,ho model for production deployment,"['ho', 'model', 'for', 'production', 'deployment']",0,"['ho', 'model', 'for', 'production', 'deployment']","['ho', 'model', 'production', 'deployment']",ho model production deployment,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
4694,unsupervised learning for stocks,unsupervised learning for stocks,"['unsupervised', 'learning', 'for', 'stocks']",0,"['unsupervised', 'learning', 'for', 'stock']","['unsupervised', 'learning', 'stock']",unsupervised learning stock,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
4695,how to identify last record of sas data set,how to identify last record of sas data set,"['how', 'to', 'identify', 'last', 'record', 'of', 'sas', 'data', 'set']",0,"['how', 'to', 'identify', 'last', 'record', 'of', 'sa', 'data', 'set']","['identify', 'last', 'record', 'sa', 'data', 'set']",identify last record sa data set,0.0,0.0,9,32,3.2,0,0,0,0,0,0,0,0
4696,installation of tensorflow in docker,installation of tensorflow in docker,"['installation', 'of', 'tensorflow', 'in', 'docker']",0,"['installation', 'of', 'tensorflow', 'in', 'docker']","['installation', 'tensorflow', 'docker']",installation tensorflow docker,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
4697,is there a seperate campaign data file,is there a seperate campaign data file,"['is', 'there', 'a', 'seperate', 'campaign', 'data', 'file']",0,"['is', 'there', 'a', 'seperate', 'campaign', 'data', 'file']","['seperate', 'campaign', 'data', 'file']",seperate campaign data file,0.0,0.0,7,27,3.375,0,0,0,0,0,0,0,0
4698,weather prediction algorithm,weather prediction algorithm,"['weather', 'prediction', 'algorithm']",0,"['weather', 'prediction', 'algorithm']","['weather', 'prediction', 'algorithm']",weather prediction algorithm,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
4699,what is the research methodology of text classification project,what is the research methodology of text classification project,"['what', 'is', 'the', 'research', 'methodology', 'of', 'text', 'classification', 'project']",0,"['what', 'is', 'the', 'research', 'methodology', 'of', 'text', 'classification', 'project']","['research', 'methodology', 'text', 'classification', 'project']",research methodology text classification project,0.0,0.0,9,48,4.8,0,0,0,0,0,0,0,0
4700,how to connect to soap api using r,how to connect to soap api using r,"['how', 'to', 'connect', 'to', 'soap', 'api', 'using', 'r']",0,"['how', 'to', 'connect', 'to', 'soap', 'api', 'using', 'r']","['connect', 'soap', 'api', 'using', 'r']",connect soap api using r,0.0,0.0,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
4701,any reference for end to end process for forecastingtimeseries modelling,any reference for end to end process for forecastingtimeseries modelling,"['any', 'reference', 'for', 'end', 'to', 'end', 'process', 'for', 'forecastingtimeseries', 'modelling']",0,"['any', 'reference', 'for', 'end', 'to', 'end', 'process', 'for', 'forecastingtimeseries', 'modelling']","['reference', 'end', 'end', 'process', 'forecastingtimeseries', 'modelling']",reference end end process forecastingtimeseries modelling,0.0,0.0,10,57,5.181818181818182,0,0,0,0,0,0,0,0
4702,guidance on python learning,guidance on python learning,"['guidance', 'on', 'python', 'learning']",0,"['guidance', 'on', 'python', 'learning']","['guidance', 'python', 'learning']",guidance python learning,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
4703,best resources related to statistics for data science,best resources related to statistics for data science,"['best', 'resources', 'related', 'to', 'statistics', 'for', 'data', 'science']",0,"['best', 'resource', 'related', 'to', 'statistic', 'for', 'data', 'science']","['best', 'resource', 'related', 'statistic', 'data', 'science']",best resource related statistic data science,0.5,0.5,8,44,4.888888888888889,0,0,0,0,0,0,0,0
4704,pursuing career in data science for mechanical engineer,pursuing career in data science for mechanical engineer,"['pursuing', 'career', 'in', 'data', 'science', 'for', 'mechanical', 'engineer']",0,"['pursuing', 'career', 'in', 'data', 'science', 'for', 'mechanical', 'engineer']","['pursuing', 'career', 'data', 'science', 'mechanical', 'engineer']",pursuing career data science mechanical engineer,0.0,0.0,8,48,5.333333333333333,0,0,0,0,0,0,0,0
4705,which course to take for data science,which course to take for data science,"['which', 'course', 'to', 'take', 'for', 'data', 'science']",0,"['which', 'course', 'to', 'take', 'for', 'data', 'science']","['course', 'take', 'data', 'science']",course take data science,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
4706,switching to an analytics career  confused,switching to an analytics career  confused,"['switching', 'to', 'an', 'analytics', 'career', 'confused']",0,"['switching', 'to', 'an', 'analytics', 'career', 'confused']","['switching', 'analytics', 'career', 'confused']",switching analytics career confused,-0.4,-0.4,6,35,5.0,0,0,0,0,0,0,0,0
4707,increase sales and reduce cost,increase sales and reduce cost,"['increase', 'sales', 'and', 'reduce', 'cost']",0,"['increase', 'sale', 'and', 'reduce', 'cost']","['increase', 'sale', 'reduce', 'cost']",increase sale reduce cost,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
4708,reviews of business analytics certificate online course from edupristine,reviews of business analytics certificate online course from edupristine,"['reviews', 'of', 'business', 'analytics', 'certificate', 'online', 'course', 'from', 'edupristine']",0,"['review', 'of', 'business', 'analytics', 'certificate', 'online', 'course', 'from', 'edupristine']","['review', 'business', 'analytics', 'certificate', 'online', 'course', 'edupristine']",review business analytics certificate online course edupristine,0.0,0.0,9,63,6.3,0,0,0,0,0,0,0,0
4709,institutes for business analytics course on weekend part time basis,institutes for business analytics course on weekend part time basis,"['institutes', 'for', 'business', 'analytics', 'course', 'on', 'weekend', 'part', 'time', 'basis']",0,"['institute', 'for', 'business', 'analytics', 'course', 'on', 'weekend', 'part', 'time', 'basis']","['institute', 'business', 'analytics', 'course', 'weekend', 'part', 'time', 'basis']",institute business analytics course weekend part time basis,0.0,0.0,10,59,5.363636363636363,0,0,0,0,0,0,0,0
4710,which chart you will recommend for market research product survey,which chart you will recommend for market research product survey,"['which', 'chart', 'you', 'will', 'recommend', 'for', 'market', 'research', 'product', 'survey']",0,"['which', 'chart', 'you', 'will', 'recommend', 'for', 'market', 'research', 'product', 'survey']","['chart', 'recommend', 'market', 'research', 'product', 'survey']",chart recommend market research product survey,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
4711,seers accuracy  dependent variable,seers accuracy  dependent variable,"['seers', 'accuracy', 'dependent', 'variable']",0,"['seer', 'accuracy', 'dependent', 'variable']","['seer', 'accuracy', 'dependent', 'variable']",seer accuracy dependent variable,0.0,0.0,4,32,6.4,0,0,0,0,0,0,0,0
4712,how to avoid selffulfilling prediction in recommendation systems,how to avoid selffulfilling prediction in recommendation systems,"['how', 'to', 'avoid', 'selffulfilling', 'prediction', 'in', 'recommendation', 'systems']",0,"['how', 'to', 'avoid', 'selffulfilling', 'prediction', 'in', 'recommendation', 'system']","['avoid', 'selffulfilling', 'prediction', 'recommendation', 'system']",avoid selffulfilling prediction recommendation system,0.0,0.0,8,53,5.888888888888889,0,0,0,0,0,0,0,0
4713,usage of principle component analysis for continous and categorical variables mixed dataset,usage of principle component analysis for continous and categorical variables mixed dataset,"['usage', 'of', 'principle', 'component', 'analysis', 'for', 'continous', 'and', 'categorical', 'variables', 'mixed', 'dataset']",0,"['usage', 'of', 'principle', 'component', 'analysis', 'for', 'continous', 'and', 'categorical', 'variable', 'mixed', 'dataset']","['usage', 'principle', 'component', 'analysis', 'continous', 'categorical', 'variable', 'mixed', 'dataset']",usage principle component analysis continous categorical variable mixed dataset,0.0,0.0,12,79,6.076923076923077,0,0,0,0,0,0,0,0
4714,how to start ipython interface in inline pylab,how to start ipython interface in inline pylab,"['how', 'to', 'start', 'ipython', 'interface', 'in', 'inline', 'pylab']",0,"['how', 'to', 'start', 'ipython', 'interface', 'in', 'inline', 'pylab']","['start', 'ipython', 'interface', 'inline', 'pylab']",start ipython interface inline pylab,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
4715,machine learningpredict stock price with rnd may ,machine learningpredict stock price with rnd may ,"['machine', 'learningpredict', 'stock', 'price', 'with', 'rnd', 'may']",1,"['machine', 'learningpredict', 'stock', 'price', 'with', 'rnd', 'may']","['machine', 'learningpredict', 'stock', 'price', 'rnd', 'may']",machine learningpredict stock price rnd may,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
4716,setting the labels for columns of a data table from another table in r,setting the labels for columns of a data table from another table in r,"['setting', 'the', 'labels', 'for', 'columns', 'of', 'a', 'data', 'table', 'from', 'another', 'table', 'in', 'r']",0,"['setting', 'the', 'label', 'for', 'column', 'of', 'a', 'data', 'table', 'from', 'another', 'table', 'in', 'r']","['setting', 'label', 'column', 'data', 'table', 'another', 'table', 'r']",setting label column data table another table r,0.0,0.0,14,47,3.1333333333333333,0,0,0,0,0,0,0,0
4717,multivariate time series modelling,multivariate time series modelling,"['multivariate', 'time', 'series', 'modelling']",0,"['multivariate', 'time', 'series', 'modelling']","['multivariate', 'time', 'series', 'modelling']",multivariate time series modelling,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
4718,installing r script with nodejs,installing r script with nodejs,"['installing', 'r', 'script', 'with', 'nodejs']",0,"['installing', 'r', 'script', 'with', 'nodejs']","['installing', 'r', 'script', 'nodejs']",installing r script nodejs,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
4719,how to calculate error in rpart in r,how to calculate error in rpart in r,"['how', 'to', 'calculate', 'error', 'in', 'rpart', 'in', 'r']",0,"['how', 'to', 'calculate', 'error', 'in', 'rpart', 'in', 'r']","['calculate', 'error', 'rpart', 'r']",calculate error rpart r,0.0,0.0,8,23,2.5555555555555554,0,0,0,0,0,0,0,0
4720,residual plot for regression,residual plot for regression,"['residual', 'plot', 'for', 'regression']",0,"['residual', 'plot', 'for', 'regression']","['residual', 'plot', 'regression']",residual plot regression,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
4721,spend analytics vs biostatistics in india,spend analytics vs biostatistics in india,"['spend', 'analytics', 'vs', 'biostatistics', 'in', 'india']",0,"['spend', 'analytics', 'v', 'biostatistics', 'in', 'india']","['spend', 'analytics', 'v', 'biostatistics', 'india']",spend analytics v biostatistics india,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
4722,different train and test set data lebels for categorical data,different train and test set data lebels for categorical data,"['different', 'train', 'and', 'test', 'set', 'data', 'lebels', 'for', 'categorical', 'data']",0,"['different', 'train', 'and', 'test', 'set', 'data', 'lebels', 'for', 'categorical', 'data']","['different', 'train', 'test', 'set', 'data', 'lebels', 'categorical', 'data']",different train test set data lebels categorical data,0.0,0.0,10,53,4.818181818181818,0,0,0,0,0,0,0,0
4723,association rules to suggest new courses in elearning,association rules to suggest new courses in elearning,"['association', 'rules', 'to', 'suggest', 'new', 'courses', 'in', 'elearning']",0,"['association', 'rule', 'to', 'suggest', 'new', 'course', 'in', 'elearning']","['association', 'rule', 'suggest', 'new', 'course', 'elearning']",association rule suggest new course elearning,0.1363636363636363,0.1363636363636363,8,45,5.0,0,0,0,0,0,0,0,0
4724,assumption of same mean in pooled variance,assumption of same mean in pooled variance,"['assumption', 'of', 'same', 'mean', 'in', 'pooled', 'variance']",0,"['assumption', 'of', 'same', 'mean', 'in', 'pooled', 'variance']","['assumption', 'mean', 'pooled', 'variance']",assumption mean pooled variance,-0.15625,-0.3125,7,31,3.875,0,0,0,0,0,0,0,0
4725,how is the faculty of misb bocconis executive business analytics program,how is the faculty of misb bocconis executive business analytics program,"['how', 'is', 'the', 'faculty', 'of', 'misb', 'bocconis', 'executive', 'business', 'analytics', 'program']",0,"['how', 'is', 'the', 'faculty', 'of', 'misb', 'bocconis', 'executive', 'business', 'analytics', 'program']","['faculty', 'misb', 'bocconis', 'executive', 'business', 'analytics', 'program']",faculty misb bocconis executive business analytics program,0.0,0.0,11,58,4.833333333333333,0,0,0,0,0,0,0,0
4726,eda for bikes cristiano ronaldo and several other small datasets for beginners,eda for bikes cristiano ronaldo and several other small datasets for beginners,"['eda', 'for', 'bikes', 'cristiano', 'ronaldo', 'and', 'several', 'other', 'small', 'datasets', 'for', 'beginners']",0,"['eda', 'for', 'bike', 'cristiano', 'ronaldo', 'and', 'several', 'other', 'small', 'datasets', 'for', 'beginner']","['eda', 'bike', 'cristiano', 'ronaldo', 'several', 'small', 'datasets', 'beginner']",eda bike cristiano ronaldo several small datasets beginner,-0.125,-0.125,12,58,4.461538461538462,0,0,0,0,0,0,0,0
4727,object dtype instead of float,object dtype instead of float,"['object', 'dtype', 'instead', 'of', 'float']",0,"['object', 'dtype', 'instead', 'of', 'float']","['object', 'dtype', 'instead', 'float']",object dtype instead float,0.0,0.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
4728,can we use the z statistic when sample size is large but population variance is unknown,can we use the z statistic when sample size is large but population variance is unknown,"['can', 'we', 'use', 'the', 'z', 'statistic', 'when', 'sample', 'size', 'is', 'large', 'but', 'population', 'variance', 'is', 'unknown']",0,"['can', 'we', 'use', 'the', 'z', 'statistic', 'when', 'sample', 'size', 'is', 'large', 'but', 'population', 'variance', 'is', 'unknown']","['use', 'z', 'statistic', 'sample', 'size', 'large', 'population', 'variance', 'unknown']",use z statistic sample size large population variance unknown,0.0571428571428571,0.0571428571428571,16,61,3.588235294117647,0,0,0,0,0,0,0,0
4729,faq chatbot using python,faq chatbot using python,"['faq', 'chatbot', 'using', 'python']",0,"['faq', 'chatbot', 'using', 'python']","['faq', 'chatbot', 'using', 'python']",faq chatbot using python,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
4730,c model doesnt work in r,c model doesnt work in r,"['c', 'model', 'doesnt', 'work', 'in', 'r']",0,"['c', 'model', 'doesnt', 'work', 'in', 'r']","['c', 'model', 'doesnt', 'work', 'r']",c model doesnt work r,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
4731,need help in understanding data item mrp vs item outlet sales scatterplot is interesting,need help in understanding data item mrp vs item outlet sales scatterplot is interesting,"['need', 'help', 'in', 'understanding', 'data', 'item', 'mrp', 'vs', 'item', 'outlet', 'sales', 'scatterplot', 'is', 'interesting']",0,"['need', 'help', 'in', 'understanding', 'data', 'item', 'mrp', 'v', 'item', 'outlet', 'sale', 'scatterplot', 'is', 'interesting']","['need', 'help', 'understanding', 'data', 'item', 'mrp', 'v', 'item', 'outlet', 'sale', 'scatterplot', 'interesting']",need help understanding data item mrp v item outlet sale scatterplot interesting,0.5,0.5,14,80,5.333333333333333,0,0,0,0,0,0,0,0
4732,arma modelling of real time data,arma modelling of real time data,"['arma', 'modelling', 'of', 'real', 'time', 'data']",0,"['arma', 'modelling', 'of', 'real', 'time', 'data']","['arma', 'modelling', 'real', 'time', 'data']",arma modelling real time data,0.2,0.2,6,29,4.142857142857143,0,0,0,0,0,0,0,0
4733,non  gaussian distribution,non  gaussian distribution,"['non', 'gaussian', 'distribution']",0,"['non', 'gaussian', 'distribution']","['non', 'gaussian', 'distribution']",non gaussian distribution,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
4734,how to check concordance percentage in logistic regression while runing spss,how to check concordance percentage in logistic regression while runing spss,"['how', 'to', 'check', 'concordance', 'percentage', 'in', 'logistic', 'regression', 'while', 'runing', 'spss']",0,"['how', 'to', 'check', 'concordance', 'percentage', 'in', 'logistic', 'regression', 'while', 'runing', 'spss']","['check', 'concordance', 'percentage', 'logistic', 'regression', 'runing', 'spss']",check concordance percentage logistic regression runing spss,0.0,0.0,11,60,5.0,0,0,0,0,0,0,0,0
4735,effects of outliers on regression model,effects of outliers on regression model,"['effects', 'of', 'outliers', 'on', 'regression', 'model']",0,"['effect', 'of', 'outlier', 'on', 'regression', 'model']","['effect', 'outlier', 'regression', 'model']",effect outlier regression model,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
4736,how to produce effect of more than one variable to the output value in linear regression,how to produce effect of more than one variable to the output value in linear regression,"['how', 'to', 'produce', 'effect', 'of', 'more', 'than', 'one', 'variable', 'to', 'the', 'output', 'value', 'in', 'linear', 'regression']",0,"['how', 'to', 'produce', 'effect', 'of', 'more', 'than', 'one', 'variable', 'to', 'the', 'output', 'value', 'in', 'linear', 'regression']","['produce', 'effect', 'one', 'variable', 'output', 'value', 'linear', 'regression']",produce effect one variable output value linear regression,0.5,0.0,16,58,3.411764705882353,0,0,0,0,0,0,0,0
4737,error in using gbm in multinomial prediction,error in using gbm in multinomial prediction,"['error', 'in', 'using', 'gbm', 'in', 'multinomial', 'prediction']",0,"['error', 'in', 'using', 'gbm', 'in', 'multinomial', 'prediction']","['error', 'using', 'gbm', 'multinomial', 'prediction']",error using gbm multinomial prediction,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
4738,srindipit non personalised recommender systems,srindipit non personalised recommender systems,"['srindipit', 'non', 'personalised', 'recommender', 'systems']",0,"['srindipit', 'non', 'personalised', 'recommender', 'system']","['srindipit', 'non', 'personalised', 'recommender', 'system']",srindipit non personalised recommender system,0.0,0.0,5,47,7.833333333333333,0,0,0,0,0,0,0,0
4739,imputing missing values for stock market,imputing missing values for stock market,"['imputing', 'missing', 'values', 'for', 'stock', 'market']",0,"['imputing', 'missing', 'value', 'for', 'stock', 'market']","['imputing', 'missing', 'value', 'stock', 'market']",imputing missing value stock market,-0.2,-0.2,6,35,5.0,0,0,0,0,0,0,0,0
4740,big data machine learning and scientific computing libraries for go language,big data machine learning and scientific computing libraries for go language,"['big', 'data', 'machine', 'learning', 'and', 'scientific', 'computing', 'libraries', 'for', 'go', 'language']",0,"['big', 'data', 'machine', 'learning', 'and', 'scientific', 'computing', 'library', 'for', 'go', 'language']","['big', 'data', 'machine', 'learning', 'scientific', 'computing', 'library', 'go', 'language']",big data machine learning scientific computing library go language,0.0,0.0,11,66,5.5,0,0,0,0,0,0,0,0
4741,deep learning for invoice information extraction,deep learning for invoice information extraction,"['deep', 'learning', 'for', 'invoice', 'information', 'extraction']",0,"['deep', 'learning', 'for', 'invoice', 'information', 'extraction']","['deep', 'learning', 'invoice', 'information', 'extraction']",deep learning invoice information extraction,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
4742,features at a higher resolution than the dependant variable,features at a higher resolution than the dependant variable,"['features', 'at', 'a', 'higher', 'resolution', 'than', 'the', 'dependant', 'variable']",0,"['feature', 'at', 'a', 'higher', 'resolution', 'than', 'the', 'dependant', 'variable']","['feature', 'higher', 'resolution', 'dependant', 'variable']",feature higher resolution dependant variable,0.25,0.25,9,44,4.4,0,0,0,0,0,0,0,0
4743,regarding creating summary function,regarding creating summary function,"['regarding', 'creating', 'summary', 'function']",0,"['regarding', 'creating', 'summary', 'function']","['regarding', 'creating', 'summary', 'function']",regarding creating summary function,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
4744,object detection algorithms,object detection algorithms,"['object', 'detection', 'algorithms']",0,"['object', 'detection', 'algorithm']","['object', 'detection', 'algorithm']",object detection algorithm,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
4745,data reading error in market basket analysis,data reading error in market basket analysis,"['data', 'reading', 'error', 'in', 'market', 'basket', 'analysis']",0,"['data', 'reading', 'error', 'in', 'market', 'basket', 'analysis']","['data', 'reading', 'error', 'market', 'basket', 'analysis']",data reading error market basket analysis,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
4746,how to fill missing values for credit history in loan prediction problem,how to fill missing values for credit history in loan prediction problem,"['how', 'to', 'fill', 'missing', 'values', 'for', 'credit', 'history', 'in', 'loan', 'prediction', 'problem']",0,"['how', 'to', 'fill', 'missing', 'value', 'for', 'credit', 'history', 'in', 'loan', 'prediction', 'problem']","['fill', 'missing', 'value', 'credit', 'history', 'loan', 'prediction', 'problem']",fill missing value credit history loan prediction problem,-0.2,-0.2,12,57,4.384615384615385,0,0,0,0,0,0,0,0
4747,regarding msc in data science from chennai mathematical institute,regarding msc in data science from chennai mathematical institute,"['regarding', 'msc', 'in', 'data', 'science', 'from', 'chennai', 'mathematical', 'institute']",0,"['regarding', 'msc', 'in', 'data', 'science', 'from', 'chennai', 'mathematical', 'institute']","['regarding', 'msc', 'data', 'science', 'chennai', 'mathematical', 'institute']",regarding msc data science chennai mathematical institute,0.0,0.0,9,57,5.7,0,0,0,0,0,0,0,0
4748,what to do when my maximum ks statistic is in the th or th decile in logistic regression,what to do when my maximum ks statistic is in the th or th decile in logistic regression,"['what', 'to', 'do', 'when', 'my', 'maximum', 'ks', 'statistic', 'is', 'in', 'the', 'th', 'or', 'th', 'decile', 'in', 'logistic', 'regression']",0,"['what', 'to', 'do', 'when', 'my', 'maximum', 'k', 'statistic', 'is', 'in', 'the', 'th', 'or', 'th', 'decile', 'in', 'logistic', 'regression']","['maximum', 'k', 'statistic', 'th', 'th', 'decile', 'logistic', 'regression']",maximum k statistic th th decile logistic regression,0.0,0.0,18,52,2.736842105263158,0,0,0,0,0,0,0,0
4749,lag removal in time series,lag removal in time series,"['lag', 'removal', 'in', 'time', 'series']",0,"['lag', 'removal', 'in', 'time', 'series']","['lag', 'removal', 'time', 'series']",lag removal time series,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
4750,what does pba faw mean,what does pba faw mean,"['what', 'does', 'pba', 'faw', 'mean']",0,"['what', 'doe', 'pba', 'faw', 'mean']","['doe', 'pba', 'faw', 'mean']",doe pba faw mean,-0.3125,-0.3125,5,16,2.6666666666666665,0,0,0,0,0,0,0,0
4751,how to handle nan values in dataframe,how to handle nan values in dataframe,"['how', 'to', 'handle', 'nan', 'values', 'in', 'dataframe']",0,"['how', 'to', 'handle', 'nan', 'value', 'in', 'dataframe']","['handle', 'nan', 'value', 'dataframe']",handle nan value dataframe,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
4752,freelance jobs for analytics,freelance jobs for analytics,"['freelance', 'jobs', 'for', 'analytics']",0,"['freelance', 'job', 'for', 'analytics']","['freelance', 'job', 'analytics']",freelance job analytics,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
4753,wandering in data science,wandering in data science,"['wandering', 'in', 'data', 'science']",0,"['wandering', 'in', 'data', 'science']","['wandering', 'data', 'science']",wandering data science,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
4754,machine learning project on imbalanced data,machine learning project on imbalanced data,"['machine', 'learning', 'project', 'on', 'imbalanced', 'data']",0,"['machine', 'learning', 'project', 'on', 'imbalanced', 'data']","['machine', 'learning', 'project', 'imbalanced', 'data']",machine learning project imbalanced data,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
4755,how to model rare even population in classification problem,how to model rare even population in classification problem,"['how', 'to', 'model', 'rare', 'even', 'population', 'in', 'classification', 'problem']",0,"['how', 'to', 'model', 'rare', 'even', 'population', 'in', 'classification', 'problem']","['model', 'rare', 'even', 'population', 'classification', 'problem']",model rare even population classification problem,0.3,0.3,9,49,4.9,0,0,0,0,0,0,0,0
4756,bigdata hadoop question,bigdata hadoop question,"['bigdata', 'hadoop', 'question']",0,"['bigdata', 'hadoop', 'question']","['bigdata', 'hadoop', 'question']",bigdata hadoop question,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
4757,hands on with deep learning solution for age detection practice problem,hands on with deep learning solution for age detection practice problem,"['hands', 'on', 'with', 'deep', 'learning', 'solution', 'for', 'age', 'detection', 'practice', 'problem']",0,"['hand', 'on', 'with', 'deep', 'learning', 'solution', 'for', 'age', 'detection', 'practice', 'problem']","['hand', 'deep', 'learning', 'solution', 'age', 'detection', 'practice', 'problem']",hand deep learning solution age detection practice problem,0.0,0.0,11,58,4.833333333333333,0,0,0,0,0,0,0,0
4758,how to resolve enthought canopy userdefined module not getting updated in code,how to resolve enthought canopy userdefined module not getting updated in code,"['how', 'to', 'resolve', 'enthought', 'canopy', 'userdefined', 'module', 'not', 'getting', 'updated', 'in', 'code']",0,"['how', 'to', 'resolve', 'enthought', 'canopy', 'userdefined', 'module', 'not', 'getting', 'updated', 'in', 'code']","['resolve', 'enthought', 'canopy', 'userdefined', 'module', 'getting', 'updated', 'code']",resolve enthought canopy userdefined module getting updated code,0.0,0.0,12,64,4.923076923076923,0,0,0,0,0,0,0,0
4759,time series forecasting for irregular time series in r,time series forecasting for irregular time series in r,"['time', 'series', 'forecasting', 'for', 'irregular', 'time', 'series', 'in', 'r']",0,"['time', 'series', 'forecasting', 'for', 'irregular', 'time', 'series', 'in', 'r']","['time', 'series', 'forecasting', 'irregular', 'time', 'series', 'r']",time series forecasting irregular time series r,0.0,0.0,9,47,4.7,0,0,0,0,0,0,0,0
4760,has any one tried installing luatorch in ubuntu,has any one tried installing luatorch in ubuntu,"['has', 'any', 'one', 'tried', 'installing', 'luatorch', 'in', 'ubuntu']",0,"['ha', 'any', 'one', 'tried', 'installing', 'luatorch', 'in', 'ubuntu']","['ha', 'one', 'tried', 'installing', 'luatorch', 'ubuntu']",ha one tried installing luatorch ubuntu,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
4761,how to convert a cscmatrix or dgcmatrix into dataframe,how to convert a cscmatrix or dgcmatrix into dataframe,"['how', 'to', 'convert', 'a', 'cscmatrix', 'or', 'dgcmatrix', 'into', 'dataframe']",0,"['how', 'to', 'convert', 'a', 'cscmatrix', 'or', 'dgcmatrix', 'into', 'dataframe']","['convert', 'cscmatrix', 'dgcmatrix', 'dataframe']",convert cscmatrix dgcmatrix dataframe,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
4762,why cant the tdistribution exceed standard normal distribution,why cant the tdistribution exceed standard normal distribution,"['why', 'cant', 'the', 'tdistribution', 'exceed', 'standard', 'normal', 'distribution']",0,"['why', 'cant', 'the', 'tdistribution', 'exceed', 'standard', 'normal', 'distribution']","['cant', 'tdistribution', 'exceed', 'standard', 'normal', 'distribution']",cant tdistribution exceed standard normal distribution,0.075,0.075,8,54,6.0,0,0,0,0,0,0,0,0
4763,how to predict natural disaster using deep learning,how to predict natural disaster using deep learning,"['how', 'to', 'predict', 'natural', 'disaster', 'using', 'deep', 'learning']",0,"['how', 'to', 'predict', 'natural', 'disaster', 'using', 'deep', 'learning']","['predict', 'natural', 'disaster', 'using', 'deep', 'learning']",predict natural disaster using deep learning,0.05,0.05,8,44,4.888888888888889,0,0,0,0,0,0,0,0
4764,which algorithm is best for text classification into  categories,which algorithm is best for text classification into  categories,"['which', 'algorithm', 'is', 'best', 'for', 'text', 'classification', 'into', 'categories']",1,"['which', 'algorithm', 'is', 'best', 'for', 'text', 'classification', 'into', 'category']","['algorithm', 'best', 'text', 'classification', 'category']",algorithm best text classification category,1.0,1.0,9,43,4.3,0,0,0,0,0,0,0,0
4765,algorithm for segmentation of categorical variables,algorithm for segmentation of categorical variables,"['algorithm', 'for', 'segmentation', 'of', 'categorical', 'variables']",0,"['algorithm', 'for', 'segmentation', 'of', 'categorical', 'variable']","['algorithm', 'segmentation', 'categorical', 'variable']",algorithm segmentation categorical variable,0.0,0.0,6,43,6.142857142857143,0,0,0,0,0,0,0,0
4766,predictions for kaggle bike sharing prediction using r,predictions for kaggle bike sharing prediction using r,"['predictions', 'for', 'kaggle', 'bike', 'sharing', 'prediction', 'using', 'r']",0,"['prediction', 'for', 'kaggle', 'bike', 'sharing', 'prediction', 'using', 'r']","['prediction', 'kaggle', 'bike', 'sharing', 'prediction', 'using', 'r']",prediction kaggle bike sharing prediction using r,0.0,0.0,8,49,5.444444444444445,0,0,0,0,0,0,0,0
4767,help needed running an ipython notebook itneractively from github on uploaded train and test data there,help needed running an ipython notebook itneractively from github on uploaded train and test data there,"['help', 'needed', 'running', 'an', 'ipython', 'notebook', 'itneractively', 'from', 'github', 'on', 'uploaded', 'train', 'and', 'test', 'data', 'there']",0,"['help', 'needed', 'running', 'an', 'ipython', 'notebook', 'itneractively', 'from', 'github', 'on', 'uploaded', 'train', 'and', 'test', 'data', 'there']","['help', 'needed', 'running', 'ipython', 'notebook', 'itneractively', 'github', 'uploaded', 'train', 'test', 'data']",help needed running ipython notebook itneractively github uploaded train test data,0.0,0.0,16,82,4.823529411764706,0,0,0,0,0,0,0,0
4768,difference between rsquare and adjusted rsquare,difference between rsquare and adjusted rsquare,"['difference', 'between', 'rsquare', 'and', 'adjusted', 'rsquare']",0,"['difference', 'between', 'rsquare', 'and', 'adjusted', 'rsquare']","['difference', 'rsquare', 'adjusted', 'rsquare']",difference rsquare adjusted rsquare,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
4769,sharing the approach for minihacktime series problem,sharing the approach for minihacktime series problem,"['sharing', 'the', 'approach', 'for', 'minihacktime', 'series', 'problem']",0,"['sharing', 'the', 'approach', 'for', 'minihacktime', 'series', 'problem']","['sharing', 'approach', 'minihacktime', 'series', 'problem']",sharing approach minihacktime series problem,0.0,0.0,7,44,5.5,0,0,0,0,0,0,0,0
4770,how to learn nlp by practicing any learning path for this,how to learn nlp by practicing any learning path for this,"['how', 'to', 'learn', 'nlp', 'by', 'practicing', 'any', 'learning', 'path', 'for', 'this']",0,"['how', 'to', 'learn', 'nlp', 'by', 'practicing', 'any', 'learning', 'path', 'for', 'this']","['learn', 'nlp', 'practicing', 'learning', 'path']",learn nlp practicing learning path,0.0,0.0,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
4771,error in final submission of code and csv file,error in final submission of code and csv file,"['error', 'in', 'final', 'submission', 'of', 'code', 'and', 'csv', 'file']",0,"['error', 'in', 'final', 'submission', 'of', 'code', 'and', 'csv', 'file']","['error', 'final', 'submission', 'code', 'csv', 'file']",error final submission code csv file,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
4772,significance of biasvariance tradeoff,significance of biasvariance tradeoff,"['significance', 'of', 'biasvariance', 'tradeoff']",0,"['significance', 'of', 'biasvariance', 'tradeoff']","['significance', 'biasvariance', 'tradeoff']",significance biasvariance tradeoff,0.0,0.0,4,34,6.8,0,0,0,0,0,0,0,0
4773,what are some libraries in r similar to the beautifulsoup package in python,what are some libraries in r similar to the beautifulsoup package in python,"['what', 'are', 'some', 'libraries', 'in', 'r', 'similar', 'to', 'the', 'beautifulsoup', 'package', 'in', 'python']",0,"['what', 'are', 'some', 'library', 'in', 'r', 'similar', 'to', 'the', 'beautifulsoup', 'package', 'in', 'python']","['library', 'r', 'similar', 'beautifulsoup', 'package', 'python']",library r similar beautifulsoup package python,0.0,0.0,13,46,3.2857142857142856,0,0,0,0,0,0,0,0
4774,energy consumption and temperature,energy consumption and temperature,"['energy', 'consumption', 'and', 'temperature']",0,"['energy', 'consumption', 'and', 'temperature']","['energy', 'consumption', 'temperature']",energy consumption temperature,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
4775,should i train multiple classification models on the same data,should i train multiple classification models on the same data,"['should', 'i', 'train', 'multiple', 'classification', 'models', 'on', 'the', 'same', 'data']",0,"['should', 'i', 'train', 'multiple', 'classification', 'model', 'on', 'the', 'same', 'data']","['train', 'multiple', 'classification', 'model', 'data']",train multiple classification model data,0.0,0.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
4776,jigsaw data science with r foundation course,jigsaw data science with r foundation course,"['jigsaw', 'data', 'science', 'with', 'r', 'foundation', 'course']",0,"['jigsaw', 'data', 'science', 'with', 'r', 'foundation', 'course']","['jigsaw', 'data', 'science', 'r', 'foundation', 'course']",jigsaw data science r foundation course,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
4777,qlikview  how to associate the objects,qlikview  how to associate the objects,"['qlikview', 'how', 'to', 'associate', 'the', 'objects']",0,"['qlikview', 'how', 'to', 'associate', 'the', 'object']","['qlikview', 'associate', 'object']",qlikview associate object,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
4778,guidance for embracing deep learning,guidance for embracing deep learning,"['guidance', 'for', 'embracing', 'deep', 'learning']",0,"['guidance', 'for', 'embracing', 'deep', 'learning']","['guidance', 'embracing', 'deep', 'learning']",guidance embracing deep learning,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
4779,need help with rmongodb and date field filter criteria,need help with rmongodb and date field filter criteria,"['need', 'help', 'with', 'rmongodb', 'and', 'date', 'field', 'filter', 'criteria']",0,"['need', 'help', 'with', 'rmongodb', 'and', 'date', 'field', 'filter', 'criterion']","['need', 'help', 'rmongodb', 'date', 'field', 'filter', 'criterion']",need help rmongodb date field filter criterion,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
4780,sas data decile making,sas data decile making,"['sas', 'data', 'decile', 'making']",0,"['sa', 'data', 'decile', 'making']","['sa', 'data', 'decile', 'making']",sa data decile making,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
4781,top features are not correct as per optimization process of business,top features are not correct as per optimization process of business,"['top', 'features', 'are', 'not', 'correct', 'as', 'per', 'optimization', 'process', 'of', 'business']",0,"['top', 'feature', 'are', 'not', 'correct', 'a', 'per', 'optimization', 'process', 'of', 'business']","['top', 'feature', 'correct', 'per', 'optimization', 'process', 'business']",top feature correct per optimization process business,0.5,0.5,11,53,4.416666666666667,0,0,0,0,0,0,0,0
4782,in xgboost the next tree is trained on the residual of previous tree as independent variable or the original independent variable itself,in xgboost the next tree is trained on the residual of previous tree as independent variable or the original independent variable itself,"['in', 'xgboost', 'the', 'next', 'tree', 'is', 'trained', 'on', 'the', 'residual', 'of', 'previous', 'tree', 'as', 'independent', 'variable', 'or', 'the', 'original', 'independent', 'variable', 'itself']",0,"['in', 'xgboost', 'the', 'next', 'tree', 'is', 'trained', 'on', 'the', 'residual', 'of', 'previous', 'tree', 'a', 'independent', 'variable', 'or', 'the', 'original', 'independent', 'variable', 'itself']","['xgboost', 'next', 'tree', 'trained', 'residual', 'previous', 'tree', 'independent', 'variable', 'original', 'independent', 'variable']",xgboost next tree trained residual previous tree independent variable original independent variable,0.0416666666666666,0.0416666666666666,22,99,4.304347826086956,0,0,0,0,0,0,0,0
4783,forecasting atm dispense,forecasting atm dispense,"['forecasting', 'atm', 'dispense']",0,"['forecasting', 'atm', 'dispense']","['forecasting', 'atm', 'dispense']",forecasting atm dispense,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
4784,error while predicting data,error while predicting data,"['error', 'while', 'predicting', 'data']",0,"['error', 'while', 'predicting', 'data']","['error', 'predicting', 'data']",error predicting data,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
4785,genetic programming illustration in r,genetic programming illustration in r,"['genetic', 'programming', 'illustration', 'in', 'r']",0,"['genetic', 'programming', 'illustration', 'in', 'r']","['genetic', 'programming', 'illustration', 'r']",genetic programming illustration r,0.0,0.0,5,34,5.666666666666667,0,0,0,0,0,0,0,0
4786,laptop suggestion,laptop suggestion,"['laptop', 'suggestion']",0,"['laptop', 'suggestion']","['laptop', 'suggestion']",laptop suggestion,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
4787,text data cleaning and preprocessing steps,text data cleaning and preprocessing steps,"['text', 'data', 'cleaning', 'and', 'preprocessing', 'steps']",0,"['text', 'data', 'cleaning', 'and', 'preprocessing', 'step']","['text', 'data', 'cleaning', 'preprocessing', 'step']",text data cleaning preprocessing step,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
4788,does outlier treatment come first or missing value imputation,does outlier treatment come first or missing value imputation,"['does', 'outlier', 'treatment', 'come', 'first', 'or', 'missing', 'value', 'imputation']",0,"['doe', 'outlier', 'treatment', 'come', 'first', 'or', 'missing', 'value', 'imputation']","['doe', 'outlier', 'treatment', 'come', 'first', 'missing', 'value', 'imputation']",doe outlier treatment come first missing value imputation,0.0249999999999999,0.0249999999999999,9,57,5.7,0,0,0,0,0,0,0,0
4789,multi classification problem,multi classification problem,"['multi', 'classification', 'problem']",0,"['multi', 'classification', 'problem']","['multi', 'classification', 'problem']",multi classification problem,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
4790,cross validation from sklearn,cross validation from sklearn,"['cross', 'validation', 'from', 'sklearn']",0,"['cross', 'validation', 'from', 'sklearn']","['cross', 'validation', 'sklearn']",cross validation sklearn,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
4791,resources to learn djs,resources to learn djs,"['resources', 'to', 'learn', 'djs']",0,"['resource', 'to', 'learn', 'dj']","['resource', 'learn', 'dj']",resource learn dj,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
4792,difference between bagging  boosting and how these help,difference between bagging  boosting and how these help,"['difference', 'between', 'bagging', 'boosting', 'and', 'how', 'these', 'help']",0,"['difference', 'between', 'bagging', 'boosting', 'and', 'how', 'these', 'help']","['difference', 'bagging', 'boosting', 'help']",difference bagging boosting help,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
4793,how to study relationship between two categorical variables when number of categories is very high,how to study relationship between two categorical variables when number of categories is very high,"['how', 'to', 'study', 'relationship', 'between', 'two', 'categorical', 'variables', 'when', 'number', 'of', 'categories', 'is', 'very', 'high']",0,"['how', 'to', 'study', 'relationship', 'between', 'two', 'categorical', 'variable', 'when', 'number', 'of', 'category', 'is', 'very', 'high']","['study', 'relationship', 'two', 'categorical', 'variable', 'number', 'category', 'high']",study relationship two categorical variable number category high,0.208,0.16,15,64,4.0,0,0,0,0,0,0,0,0
4794,how to sort the data of a data frame in descending order in python,how to sort the data of a data frame in descending order in python,"['how', 'to', 'sort', 'the', 'data', 'of', 'a', 'data', 'frame', 'in', 'descending', 'order', 'in', 'python']",0,"['how', 'to', 'sort', 'the', 'data', 'of', 'a', 'data', 'frame', 'in', 'descending', 'order', 'in', 'python']","['sort', 'data', 'data', 'frame', 'descending', 'order', 'python']",sort data data frame descending order python,0.0,0.0,14,44,2.933333333333333,0,0,0,0,0,0,0,0
4795,discussions for article loan prediction using machine learning,discussions for article loan prediction using machine learning,"['discussions', 'for', 'article', '', 'loan', 'prediction', 'using', 'machine', 'learning', '']",0,"['discussion', 'for', 'article', '', 'loan', 'prediction', 'using', 'machine', 'learning', '']","['discussion', 'article', '', 'loan', 'prediction', 'using', 'machine', 'learning', '']",discussion article  loan prediction using machine learning ,0.0,0.0,10,61,5.545454545454546,0,0,0,0,0,0,0,0
4796,data hackathon online th  th july   register here,data hackathon online th  th july   register here,"['data', 'hackathon', 'online', 'th', 'th', 'july', 'register', 'here']",1,"['data', 'hackathon', 'online', 'th', 'th', 'july', 'register', 'here']","['data', 'hackathon', 'online', 'th', 'th', 'july', 'register']",data hackathon online th th july register,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
4797,getting an error valueerror bad input shape   when applying logistics regression model,getting an error valueerror bad input shape   when applying logistics regression model,"['getting', 'an', 'error', 'valueerror', 'bad', 'input', 'shape', 'when', 'applying', 'logistics', 'regression', 'model']",2,"['getting', 'an', 'error', 'valueerror', 'bad', 'input', 'shape', 'when', 'applying', 'logistics', 'regression', 'model']","['getting', 'error', 'valueerror', 'bad', 'input', 'shape', 'applying', 'logistics', 'regression', 'model']",getting error valueerror bad input shape applying logistics regression model,-0.6999999999999998,-0.6999999999999998,12,76,5.846153846153846,0,0,0,0,0,0,0,0
4798,crossvalidation,crossvalidation,['crossvalidation'],0,['crossvalidation'],['crossvalidation'],crossvalidation,0.0,0.0,1,15,7.5,0,0,0,0,0,0,0,0
4799,multivariate time series  understanding contribution of independent variables,multivariate time series  understanding contribution of independent variables,"['multivariate', 'time', 'series', 'understanding', '', 'contribution', '', 'of', 'independent', 'variables']",0,"['multivariate', 'time', 'series', 'understanding', '', 'contribution', '', 'of', 'independent', 'variable']","['multivariate', 'time', 'series', 'understanding', '', 'contribution', '', 'independent', 'variable']",multivariate time series understanding  contribution  independent variable,0.0,0.0,10,76,6.909090909090909,0,0,0,0,0,0,0,0
4800,how to recommend in this case,how to recommend in this case,"['how', 'to', 'recommend', 'in', 'this', 'case']",0,"['how', 'to', 'recommend', 'in', 'this', 'case']","['recommend', 'case']",recommend case,0.0,0.0,6,14,2.0,0,0,0,0,0,0,0,0
4801,data science probability question,data science probability question,"['data', 'science', 'probability', 'question']",0,"['data', 'science', 'probability', 'question']","['data', 'science', 'probability', 'question']",data science probability question,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
4802,shaplet mining algorithmtime series sub sequence,shaplet mining algorithmtime series sub sequence,"['shaplet', 'mining', 'algorithmtime', 'series', 'sub', 'sequence']",0,"['shaplet', 'mining', 'algorithmtime', 'series', 'sub', 'sequence']","['shaplet', 'mining', 'algorithmtime', 'series', 'sub', 'sequence']",shaplet mining algorithmtime series sub sequence,0.0,0.0,6,48,6.857142857142857,0,0,0,0,0,0,0,0
4803,customers loyalty forecast,customers loyalty forecast,"['customers', 'loyalty', 'forecast']",0,"['customer', 'loyalty', 'forecast']","['customer', 'loyalty', 'forecast']",customer loyalty forecast,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
4804,kerberos spnego authentication not working for ambari hadoop server rest api url,kerberos spnego authentication not working for ambari hadoop server rest api url,"['kerberos', 'spnego', 'authentication', 'not', 'working', 'for', 'ambari', 'hadoop', 'server', 'rest', 'api', 'url']",0,"['kerberos', 'spnego', 'authentication', 'not', 'working', 'for', 'ambari', 'hadoop', 'server', 'rest', 'api', 'url']","['kerberos', 'spnego', 'authentication', 'working', 'ambari', 'hadoop', 'server', 'rest', 'api', 'url']",kerberos spnego authentication working ambari hadoop server rest api url,0.0,0.0,12,72,5.538461538461538,0,0,0,0,0,0,0,0
4805,how to use polynomial kernel in svm using r,how to use polynomial kernel in svm using r,"['how', 'to', 'use', 'polynomial', 'kernel', 'in', 'svm', 'using', 'r']",0,"['how', 'to', 'use', 'polynomial', 'kernel', 'in', 'svm', 'using', 'r']","['use', 'polynomial', 'kernel', 'svm', 'using', 'r']",use polynomial kernel svm using r,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
4806,explain auto correlation for time series data,explain auto correlation for time series data,"['explain', 'auto', 'correlation', 'for', 'time', 'series', 'data']",0,"['explain', 'auto', 'correlation', 'for', 'time', 'series', 'data']","['explain', 'auto', 'correlation', 'time', 'series', 'data']",explain auto correlation time series data,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
4807,interpolation vs regression analysis,interpolation vs regression analysis,"['interpolation', 'vs', 'regression', 'analysis']",0,"['interpolation', 'v', 'regression', 'analysis']","['interpolation', 'v', 'regression', 'analysis']",interpolation v regression analysis,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
4808,experiments with data workshop doubts,experiments with data workshop doubts,"['experiments', 'with', 'data', 'workshop', 'doubts']",0,"['experiment', 'with', 'data', 'workshop', 'doubt']","['experiment', 'data', 'workshop', 'doubt']",experiment data workshop doubt,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
4809,missing values in target variable,missing values in target variable,"['missing', 'values', 'in', 'target', 'variable']",0,"['missing', 'value', 'in', 'target', 'variable']","['missing', 'value', 'target', 'variable']",missing value target variable,-0.2,-0.2,5,29,4.833333333333333,0,0,0,0,0,0,0,0
4810,how can i plot longitude and latitude on google map in python,how can i plot longitude and latitude on google map in python,"['how', 'can', 'i', 'plot', 'longitude', 'and', 'latitude', 'on', 'google', 'map', 'in', 'python']",0,"['how', 'can', 'i', 'plot', 'longitude', 'and', 'latitude', 'on', 'google', 'map', 'in', 'python']","['plot', 'longitude', 'latitude', 'google', 'map', 'python']",plot longitude latitude google map python,0.0,0.0,12,41,3.1538461538461537,0,0,0,0,0,0,0,0
4811,how to forecast monthly time when we have only one year data,how to forecast monthly time when we have only one year data,"['how', 'to', 'forecast', 'monthly', 'time', 'when', 'we', 'have', 'only', 'one', 'year', 'data']",0,"['how', 'to', 'forecast', 'monthly', 'time', 'when', 'we', 'have', 'only', 'one', 'year', 'data']","['forecast', 'monthly', 'time', 'one', 'year', 'data']",forecast monthly time one year data,0.0,0.0,12,35,2.6923076923076925,0,0,0,0,0,0,0,0
4812,tranformation of kurtoctic data,tranformation of kurtoctic data,"['tranformation', 'of', 'kurtoctic', 'data']",0,"['tranformation', 'of', 'kurtoctic', 'data']","['tranformation', 'kurtoctic', 'data']",tranformation kurtoctic data,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
4813,isi chennai seeking feedback on ba crash course schedule,isi chennai seeking feedback on ba crash course schedule,"['isi', 'chennai', 'seeking', 'feedback', 'on', 'ba', 'crash', 'course', 'schedule']",0,"['isi', 'chennai', 'seeking', 'feedback', 'on', 'ba', 'crash', 'course', 'schedule']","['isi', 'chennai', 'seeking', 'feedback', 'ba', 'crash', 'course', 'schedule']",isi chennai seeking feedback ba crash course schedule,0.0,0.0,9,53,5.3,0,0,0,0,0,0,0,0
4814,bookmark articles,bookmark articles,"['bookmark', 'articles']",0,"['bookmark', 'article']","['bookmark', 'article']",bookmark article,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
4815,text mining dtm,text mining dtm,"['text', 'mining', 'dtm']",0,"['text', 'mining', 'dtm']","['text', 'mining', 'dtm']",text mining dtm,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
4816,how to construct the path to file in r,how to construct the path to file in r,"['how', 'to', 'construct', 'the', 'path', 'to', 'file', 'in', 'r']",0,"['how', 'to', 'construct', 'the', 'path', 'to', 'file', 'in', 'r']","['construct', 'path', 'file', 'r']",construct path file r,0.0,0.0,9,21,2.1,0,0,0,0,0,0,0,0
4817,how to calculate population sd and variance using sas,how to calculate population sd and variance using sas,"['how', 'to', 'calculate', 'population', 'sd', 'and', 'variance', 'using', 'sas']",0,"['how', 'to', 'calculate', 'population', 'sd', 'and', 'variance', 'using', 'sa']","['calculate', 'population', 'sd', 'variance', 'using', 'sa']",calculate population sd variance using sa,0.0,0.0,9,41,4.1,0,0,0,0,0,0,0,0
4818,ho data frame error,ho data frame error,"['ho', 'data', 'frame', 'error']",0,"['ho', 'data', 'frame', 'error']","['ho', 'data', 'frame', 'error']",ho data frame error,0.0,0.0,4,19,3.8,0,0,0,0,0,0,0,0
4819,supervised principal components,supervised principal components,"['supervised', 'principal', 'components']",0,"['supervised', 'principal', 'component']","['supervised', 'principal', 'component']",supervised principal component,0.0,0.0,3,30,7.5,0,0,0,0,0,0,0,0
4820,credit risk models,credit risk models,"['credit', 'risk', 'models']",0,"['credit', 'risk', 'model']","['credit', 'risk', 'model']",credit risk model,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
4821,setting up the target variable in a classification problem,setting up the target variable in a classification problem,"['setting', 'up', 'the', 'target', 'variable', 'in', 'a', 'classification', 'problem']",0,"['setting', 'up', 'the', 'target', 'variable', 'in', 'a', 'classification', 'problem']","['setting', 'target', 'variable', 'classification', 'problem']",setting target variable classification problem,0.0,0.0,9,46,4.6,0,0,0,0,0,0,0,0
4822,should i go for data analyst profile if im good with the tools but poor in analysis,should i go for data analyst profile if im good with the tools but poor in analysis,"['should', 'i', 'go', 'for', 'data', 'analyst', 'profile', 'if', 'im', 'good', 'with', 'the', 'tools', 'but', 'poor', 'in', 'analysis']",0,"['should', 'i', 'go', 'for', 'data', 'analyst', 'profile', 'if', 'im', 'good', 'with', 'the', 'tool', 'but', 'poor', 'in', 'analysis']","['go', 'data', 'analyst', 'profile', 'im', 'good', 'tool', 'poor', 'analysis']",go data analyst profile im good tool poor analysis,0.1499999999999999,0.1499999999999999,17,50,2.7777777777777777,0,0,0,0,0,0,0,0
4823,how to improve linear regression model performance,how to improve linear regression model performance,"['how', 'to', 'improve', 'linear', 'regression', 'model', 'performance']",0,"['how', 'to', 'improve', 'linear', 'regression', 'model', 'performance']","['improve', 'linear', 'regression', 'model', 'performance']",improve linear regression model performance,0.0,0.0,7,43,5.375,0,0,0,0,0,0,0,0
4824,jigsaw academy bigdata course,jigsaw academy bigdata course,"['jigsaw', 'academy', 'bigdata', 'course']",0,"['jigsaw', 'academy', 'bigdata', 'course']","['jigsaw', 'academy', 'bigdata', 'course']",jigsaw academy bigdata course,0.0,0.0,4,29,5.8,0,0,0,0,0,0,0,0
4825,what is the value of cex signifies in biplot function during pca in r,what is the value of cex signifies in biplot function during pca in r,"['what', 'is', 'the', 'value', 'of', 'cex', 'signifies', 'in', 'biplot', 'function', 'during', 'pca', 'in', 'r']",0,"['what', 'is', 'the', 'value', 'of', 'cex', 'signifies', 'in', 'biplot', 'function', 'during', 'pca', 'in', 'r']","['value', 'cex', 'signifies', 'biplot', 'function', 'pca', 'r']",value cex signifies biplot function pca r,0.0,0.0,14,41,2.7333333333333334,0,0,0,0,0,0,0,0
4826,ensemble of ensembles,ensemble of ensembles,"['ensemble', 'of', 'ensembles']",0,"['ensemble', 'of', 'ensemble']","['ensemble', 'ensemble']",ensemble ensemble,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
4827,chi square mcnemars or cochrans q test for dependent groups,chi square mcnemars or cochrans q test for dependent groups,"['chi', 'square', 'mcnemars', 'or', 'cochrans', 'q', 'test', 'for', 'dependent', 'groups']",0,"['chi', 'square', 'mcnemars', 'or', 'cochran', 'q', 'test', 'for', 'dependent', 'group']","['chi', 'square', 'mcnemars', 'cochran', 'q', 'test', 'dependent', 'group']",chi square mcnemars cochran q test dependent group,0.0,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
4828,how to see arguments of a function in r,how to see arguments of a function in r,"['how', 'to', 'see', 'arguments', 'of', 'a', 'function', 'in', 'r']",0,"['how', 'to', 'see', 'argument', 'of', 'a', 'function', 'in', 'r']","['see', 'argument', 'function', 'r']",see argument function r,0.0,0.0,9,23,2.3,0,0,0,0,0,0,0,0
4829,require a flow diagram for the given problem,require a flow diagram for the given problem,"['require', 'a', 'flow', 'diagram', 'for', 'the', 'given', 'problem']",0,"['require', 'a', 'flow', 'diagram', 'for', 'the', 'given', 'problem']","['require', 'flow', 'diagram', 'given', 'problem']",require flow diagram given problem,0.0,0.0,8,34,3.7777777777777777,0,0,0,0,0,0,0,0
4830,random forest parameter,random forest parameter,"['random', 'forest', 'parameter']",0,"['random', 'forest', 'parameter']","['random', 'forest', 'parameter']",random forest parameter,-0.5,-0.5,3,23,5.75,0,0,0,0,0,0,0,0
4831,not able to install caret package,not able to install caret package,"['not', 'able', 'to', 'install', 'caret', 'package']",0,"['not', 'able', 'to', 'install', 'caret', 'package']","['able', 'install', 'caret', 'package']",able install caret package,-0.25,0.5,6,26,3.7142857142857144,0,0,0,0,0,0,0,0
4832,label encoding in r,label encoding in r,"['label', 'encoding', 'in', 'r']",0,"['label', 'encoding', 'in', 'r']","['label', 'encoding', 'r']",label encoding r,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
4833,predicting price of product based on historical data of other products,predicting price of product based on historical data of other products,"['predicting', 'price', 'of', 'product', 'based', 'on', 'historical', 'data', 'of', 'other', 'products']",0,"['predicting', 'price', 'of', 'product', 'based', 'on', 'historical', 'data', 'of', 'other', 'product']","['predicting', 'price', 'product', 'based', 'historical', 'data', 'product']",predicting price product based historical data product,-0.0625,0.0,11,54,4.5,0,0,0,0,0,0,0,0
4834,error while installing new package from github,error while installing new package from github,"['error', 'while', 'installing', 'new', 'package', 'from', 'github']",0,"['error', 'while', 'installing', 'new', 'package', 'from', 'github']","['error', 'installing', 'new', 'package', 'github']",error installing new package github,0.1363636363636363,0.1363636363636363,7,35,4.375,0,0,0,0,0,0,0,0
4835,select rows based on conditions of different columns in r,select rows based on conditions of different columns in r,"['select', 'rows', 'based', 'on', 'conditions', 'of', 'different', 'columns', 'in', 'r']",0,"['select', 'row', 'based', 'on', 'condition', 'of', 'different', 'column', 'in', 'r']","['select', 'row', 'based', 'condition', 'different', 'column', 'r']",select row based condition different column r,0.0,0.0,10,45,4.090909090909091,0,0,0,0,0,0,0,0
4836,why we normalize the loadings of the principal component,why we normalize the loadings of the principal component,"['why', 'we', 'normalize', 'the', 'loadings', 'of', 'the', 'principal', 'component']",0,"['why', 'we', 'normalize', 'the', 'loading', 'of', 'the', 'principal', 'component']","['normalize', 'loading', 'principal', 'component']",normalize loading principal component,0.0,0.0,9,37,3.7,0,0,0,0,0,0,0,0
4837,error installing rcurl in r,error installing rcurl in r,"['error', 'installing', 'rcurl', 'in', 'r']",0,"['error', 'installing', 'rcurl', 'in', 'r']","['error', 'installing', 'rcurl', 'r']",error installing rcurl r,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
4838,how to find similar email address using nlp,how to find similar email address using nlp,"['how', 'to', 'find', 'similar', 'email', 'address', 'using', 'nlp']",0,"['how', 'to', 'find', 'similar', 'email', 'address', 'using', 'nlp']","['find', 'similar', 'email', 'address', 'using', 'nlp']",find similar email address using nlp,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
4839,r coding in rmarkdown,r coding in rmarkdown,"['r', 'coding', 'in', 'rmarkdown']",0,"['r', 'coding', 'in', 'rmarkdown']","['r', 'coding', 'rmarkdown']",r coding rmarkdown,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
4840,clustering and r and time component,clustering and r and time component,"['clustering', 'and', 'r', 'and', 'time', 'component']",0,"['clustering', 'and', 'r', 'and', 'time', 'component']","['clustering', 'r', 'time', 'component']",clustering r time component,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
4841,courses providing real life projects to build your portfolio,courses providing real life projects to build your portfolio,"['courses', 'providing', 'real', 'life', 'projects', 'to', 'build', 'your', 'portfolio']",0,"['course', 'providing', 'real', 'life', 'project', 'to', 'build', 'your', 'portfolio']","['course', 'providing', 'real', 'life', 'project', 'build', 'portfolio']",course providing real life project build portfolio,0.2,0.2,9,50,5.0,0,0,0,0,0,0,0,0
4842,could we determine the range of the prediction scores in the content based filtering recommendation system,could we determine the range of the prediction scores in the content based filtering recommendation system,"['could', 'we', 'determine', 'the', 'range', 'of', 'the', 'prediction', 'scores', 'in', 'the', 'content', 'based', 'filtering', 'recommendation', 'system']",0,"['could', 'we', 'determine', 'the', 'range', 'of', 'the', 'prediction', 'score', 'in', 'the', 'content', 'based', 'filtering', 'recommendation', 'system']","['could', 'determine', 'range', 'prediction', 'score', 'content', 'based', 'filtering', 'recommendation', 'system']",could determine range prediction score content based filtering recommendation system,0.0,0.0,16,84,4.9411764705882355,0,0,0,0,0,0,0,0
4843,how to reduce false positive and false negative in binary classification,how to reduce false positive and false negative in binary classification,"['how', 'to', 'reduce', 'false', 'positive', 'and', 'false', 'negative', 'in', 'binary', 'classification']",0,"['how', 'to', 'reduce', 'false', 'positive', 'and', 'false', 'negative', 'in', 'binary', 'classification']","['reduce', 'false', 'positive', 'false', 'negative', 'binary', 'classification']",reduce false positive false negative binary classification,-0.2181818181818182,-0.2181818181818182,11,58,4.833333333333333,0,0,0,0,0,0,0,0
4844,multivariate forecasting,multivariate forecasting,"['multivariate', 'forecasting']",0,"['multivariate', 'forecasting']","['multivariate', 'forecasting']",multivariate forecasting,0.0,0.0,2,24,8.0,0,0,0,0,0,0,0,0
4845,extract data from another variable using r,extract data from another variable using r,"['extract', 'data', 'from', 'another', 'variable', 'using', 'r']",0,"['extract', 'data', 'from', 'another', 'variable', 'using', 'r']","['extract', 'data', 'another', 'variable', 'using', 'r']",extract data another variable using r,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
4846,scraping website with more than  pages,scraping website with more than  pages,"['scraping', 'website', 'with', 'more', 'than', 'pages']",1,"['scraping', 'website', 'with', 'more', 'than', 'page']","['scraping', 'website', 'page']",scraping website page,0.5,0.0,6,21,3.0,0,0,0,0,0,0,0,0
4847,which class the logistic regressions probabilities belong to,which class the logistic regressions probabilities belong to,"['which', 'class', 'the', 'logistic', 'regressions', 'probabilities', 'belong', 'to']",0,"['which', 'class', 'the', 'logistic', 'regression', 'probability', 'belong', 'to']","['class', 'logistic', 'regression', 'probability', 'belong']",class logistic regression probability belong,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
4848,python r vs  data science tools for people who arent so good at programming,python r vs  data science tools for people who arent so good at programming,"['python', 'r', 'vs', 'data', 'science', 'tools', 'for', 'people', 'who', 'aren', '', 't', 'so', 'good', 'at', 'programming']",1,"['python', 'r', 'v', 'data', 'science', 'tool', 'for', 'people', 'who', 'aren', '', 't', 'so', 'good', 'at', 'programming']","['python', 'r', 'v', 'data', 'science', 'tool', 'people', '', 'good', 'programming']",python r v data science tool people  good programming,0.7,0.7,16,54,3.176470588235294,0,0,0,0,0,0,0,0
4849,how to convert a table mxn to a list of lists rows of the table mentioned,how to convert a table mxn to a list of lists rows of the table mentioned,"['how', 'to', 'convert', 'a', 'table', 'mxn', 'to', 'a', 'list', 'of', 'lists', 'rows', 'of', 'the', 'table', 'mentioned']",0,"['how', 'to', 'convert', 'a', 'table', 'mxn', 'to', 'a', 'list', 'of', 'list', 'row', 'of', 'the', 'table', 'mentioned']","['convert', 'table', 'mxn', 'list', 'list', 'row', 'table', 'mentioned']",convert table mxn list list row table mentioned,0.0,0.0,16,47,2.764705882352941,0,0,0,0,0,0,0,0
4850,data analysis and correlations,data analysis and correlations,"['data', 'analysis', 'and', 'correlations']",0,"['data', 'analysis', 'and', 'correlation']","['data', 'analysis', 'correlation']",data analysis correlation,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
4851,how to start and where to start,how to start and where to start,"['how', 'to', 'start', 'and', 'where', 'to', 'start']",0,"['how', 'to', 'start', 'and', 'where', 'to', 'start']","['start', 'start']",start start,0.0,0.0,7,11,1.375,0,0,0,0,0,0,0,0
4852,maskrcnn  class car damage detection how to apply on new images similar to demoipynb,maskrcnn  class car damage detection how to apply on new images similar to demoipynb,"['maskrcnn', 'class', 'car', 'damage', 'detection', 'how', 'to', 'apply', 'on', 'new', 'images', 'similar', 'to', 'demoipynb']",1,"['maskrcnn', 'class', 'car', 'damage', 'detection', 'how', 'to', 'apply', 'on', 'new', 'image', 'similar', 'to', 'demoipynb']","['maskrcnn', 'class', 'car', 'damage', 'detection', 'apply', 'new', 'image', 'similar', 'demoipynb']",maskrcnn class car damage detection apply new image similar demoipynb,0.0681818181818181,0.0681818181818181,14,69,4.6,0,0,0,0,0,0,0,0
4853,how to analyse credit card approval rate,how to analyse credit card approval rate,"['how', 'to', 'analyse', 'credit', 'card', 'approval', 'rate']",0,"['how', 'to', 'analyse', 'credit', 'card', 'approval', 'rate']","['analyse', 'credit', 'card', 'approval', 'rate']",analyse credit card approval rate,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
4854,tutorial for sentiment analysis on twitter,tutorial for sentiment analysis on twitter,"['tutorial', 'for', 'sentiment', 'analysis', 'on', 'twitter']",0,"['tutorial', 'for', 'sentiment', 'analysis', 'on', 'twitter']","['tutorial', 'sentiment', 'analysis', 'twitter']",tutorial sentiment analysis twitter,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
4855,convert rgb images and corresponding labels into a csv file,convert rgb images and corresponding labels into a csv file,"['convert', 'rgb', 'images', 'and', 'corresponding', 'labels', 'into', 'a', 'csv', 'file']",0,"['convert', 'rgb', 'image', 'and', 'corresponding', 'label', 'into', 'a', 'csv', 'file']","['convert', 'rgb', 'image', 'corresponding', 'label', 'csv', 'file']",convert rgb image corresponding label csv file,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
4856,does having categorical dependent variables along with categorical independent variables in the dataframe make any difference in finding the correlation between independent variables,does having categorical dependent variables along with categorical independent variables in the dataframe make any difference in finding the correlation between independent variables,"['does', 'having', 'categorical', 'dependent', 'variables', 'along', 'with', 'categorical', 'independent', 'variables', 'in', 'the', 'dataframe', 'make', 'any', 'difference', 'in', 'finding', 'the', 'correlation', 'between', 'independent', 'variables']",0,"['doe', 'having', 'categorical', 'dependent', 'variable', 'along', 'with', 'categorical', 'independent', 'variable', 'in', 'the', 'dataframe', 'make', 'any', 'difference', 'in', 'finding', 'the', 'correlation', 'between', 'independent', 'variable']","['doe', 'categorical', 'dependent', 'variable', 'along', 'categorical', 'independent', 'variable', 'dataframe', 'make', 'difference', 'finding', 'correlation', 'independent', 'variable']",doe categorical dependent variable along categorical independent variable dataframe make difference finding correlation independent variable,0.0,0.0,23,140,5.833333333333333,0,0,0,0,0,0,0,0
4857,difference between wps and sas,difference between wps and sas,"['difference', 'between', 'wps', 'and', 'sas']",0,"['difference', 'between', 'wps', 'and', 'sa']","['difference', 'wps', 'sa']",difference wps sa,0.0,0.0,5,17,2.8333333333333335,0,0,0,0,0,0,0,0
4858,how to install new packages in python while using spyder ide with anaconda,how to install new packages in python while using spyder ide with anaconda,"['how', 'to', 'install', 'new', 'packages', 'in', 'python', 'while', 'using', 'spyder', 'ide', 'with', 'anaconda']",0,"['how', 'to', 'install', 'new', 'package', 'in', 'python', 'while', 'using', 'spyder', 'ide', 'with', 'anaconda']","['install', 'new', 'package', 'python', 'using', 'spyder', 'ide', 'anaconda']",install new package python using spyder ide anaconda,0.1363636363636363,0.1363636363636363,13,52,3.7142857142857144,0,0,0,0,0,0,0,0
4859,dl based face recognition model,dl based face recognition model,"['dl', 'based', 'face', 'recognition', 'model']",0,"['dl', 'based', 'face', 'recognition', 'model']","['dl', 'based', 'face', 'recognition', 'model']",dl based face recognition model,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
4860,how to decide which models to combine for ensemble methods,how to decide which models to combine for ensemble methods,"['how', 'to', 'decide', 'which', 'models', 'to', 'combine', 'for', 'ensemble', 'methods']",0,"['how', 'to', 'decide', 'which', 'model', 'to', 'combine', 'for', 'ensemble', 'method']","['decide', 'model', 'combine', 'ensemble', 'method']",decide model combine ensemble method,0.0,0.0,10,36,3.272727272727273,0,0,0,0,0,0,0,0
4861,why the regression result is having same result as of mean,why the regression result is having same result as of mean,"['why', 'the', 'regression', 'result', 'is', 'having', 'same', 'result', 'as', 'of', 'mean']",0,"['why', 'the', 'regression', 'result', 'is', 'having', 'same', 'result', 'a', 'of', 'mean']","['regression', 'result', 'result', 'mean']",regression result result mean,-0.15625,-0.3125,11,29,2.4166666666666665,0,0,0,0,0,0,0,0
4862,data science transition,data science transition,"['data', 'science', 'transition']",0,"['data', 'science', 'transition']","['data', 'science', 'transition']",data science transition,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
4863,visualization on cloud,visualization on cloud,"['visualization', 'on', 'cloud']",0,"['visualization', 'on', 'cloud']","['visualization', 'cloud']",visualization cloud,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
4864,decision tree and random forest,decision tree and random forest,"['decision', 'tree', 'and', 'random', 'forest']",0,"['decision', 'tree', 'and', 'random', 'forest']","['decision', 'tree', 'random', 'forest']",decision tree random forest,-0.5,-0.5,5,27,4.5,0,0,0,0,0,0,0,0
4865,error while running python code,error while running python code,"['error', 'while', 'running', 'python', 'code']",0,"['error', 'while', 'running', 'python', 'code']","['error', 'running', 'python', 'code']",error running python code,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
4866,how can i translate different languages in to english in r,how can i translate different languages in to english in r,"['how', 'can', 'i', 'translate', 'different', 'languages', 'in', 'to', 'english', 'in', 'r']",0,"['how', 'can', 'i', 'translate', 'different', 'language', 'in', 'to', 'english', 'in', 'r']","['translate', 'different', 'language', 'english', 'r']",translate different language english r,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
4867,need assistance in learning data science,need assistance in learning data science,"['need', 'assistance', 'in', 'learning', 'data', 'science']",0,"['need', 'assistance', 'in', 'learning', 'data', 'science']","['need', 'assistance', 'learning', 'data', 'science']",need assistance learning data science,0.0,0.0,6,37,5.285714285714286,0,0,0,0,0,0,0,0
4868,team formation for datafest  the seers accuracy,team formation for datafest  the seers accuracy,"['team', 'formation', 'for', 'datafest', 'the', 'seers', 'accuracy']",0,"['team', 'formation', 'for', 'datafest', 'the', 'seer', 'accuracy']","['team', 'formation', 'datafest', 'seer', 'accuracy']",team formation datafest seer accuracy,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
4869,overfitting and underfitting,overfitting and underfitting,"['overfitting', 'and', 'underfitting']",0,"['overfitting', 'and', 'underfitting']","['overfitting', 'underfitting']",overfitting underfitting,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
4870,fraud predictive model,fraud predictive model,"['fraud', 'predictive', 'model']",0,"['fraud', 'predictive', 'model']","['fraud', 'predictive', 'model']",fraud predictive model,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
4871,how does decision tree classifier split using continuous varaible,how does decision tree classifier split using continuous varaible,"['how', 'does', 'decision', 'tree', 'classifier', 'split', 'using', 'continuous', 'varaible']",0,"['how', 'doe', 'decision', 'tree', 'classifier', 'split', 'using', 'continuous', 'varaible']","['doe', 'decision', 'tree', 'classifier', 'split', 'using', 'continuous', 'varaible']",doe decision tree classifier split using continuous varaible,0.0,0.0,9,60,6.0,0,0,0,0,0,0,0,0
4872,predicting mobile data usage,predicting mobile data usage,"['predicting', 'mobile', 'data', 'usage']",0,"['predicting', 'mobile', 'data', 'usage']","['predicting', 'mobile', 'data', 'usage']",predicting mobile data usage,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
4873,structured equation modelsem,structured equation modelsem,"['structured', 'equation', 'modelsem']",0,"['structured', 'equation', 'modelsem']","['structured', 'equation', 'modelsem']",structured equation modelsem,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
4874,how to export data into json format using r,how to export data into json format using r,"['how', 'to', 'export', 'data', 'into', 'json', 'format', 'using', 'r']",0,"['how', 'to', 'export', 'data', 'into', 'json', 'format', 'using', 'r']","['export', 'data', 'json', 'format', 'using', 'r']",export data json format using r,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
4875,creating dummy variables in r,creating dummy variables in r,"['creating', 'dummy', 'variables', 'in', 'r']",0,"['creating', 'dummy', 'variable', 'in', 'r']","['creating', 'dummy', 'variable', 'r']",creating dummy variable r,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
4876,changes not reflected in the output while creating a shiny web app in r,changes not reflected in the output while creating a shiny web app in r,"['changes', 'not', 'reflected', 'in', 'the', 'output', 'while', 'creating', 'a', 'shiny', 'web', 'app', 'in', 'r']",0,"['change', 'not', 'reflected', 'in', 'the', 'output', 'while', 'creating', 'a', 'shiny', 'web', 'app', 'in', 'r']","['change', 'reflected', 'output', 'creating', 'shiny', 'web', 'app', 'r']",change reflected output creating shiny web app r,0.0,0.0,14,48,3.2,0,0,0,0,0,0,0,0
4877,how can i venture into data science and analytics from life sciences research,how can i venture into data science and analytics from life sciences research,"['how', 'can', 'i', 'venture', 'into', 'data', 'science', 'and', 'analytics', 'from', 'life', 'sciences', 'research']",0,"['how', 'can', 'i', 'venture', 'into', 'data', 'science', 'and', 'analytics', 'from', 'life', 'science', 'research']","['venture', 'data', 'science', 'analytics', 'life', 'science', 'research']",venture data science analytics life science research,0.0,0.0,13,52,3.7142857142857144,0,0,0,0,0,0,0,0
4878,unable to form categorical groups,unable to form categorical groups,"['unable', 'to', 'form', 'categorical', 'groups']",0,"['unable', 'to', 'form', 'categorical', 'group']","['unable', 'form', 'categorical', 'group']",unable form categorical group,-0.5,-0.5,5,29,4.833333333333333,0,0,0,0,0,0,0,0
4879,introduction to python course  plotly,introduction to python course  plotly,"['introduction', 'to', 'python', 'course', 'plotly']",0,"['introduction', 'to', 'python', 'course', 'plotly']","['introduction', 'python', 'course', 'plotly']",introduction python course plotly,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
4880,missing value treatment by using arrays in sas,missing value treatment by using arrays in sas,"['missing', 'value', 'treatment', 'by', 'using', 'arrays', 'in', 'sas']",0,"['missing', 'value', 'treatment', 'by', 'using', 'array', 'in', 'sa']","['missing', 'value', 'treatment', 'using', 'array', 'sa']",missing value treatment using array sa,-0.2,-0.2,8,38,4.222222222222222,0,0,0,0,0,0,0,0
4881,confused between sas certification and hadoop course,confused between sas certification and hadoop course,"['confused', 'between', 'sas', 'certification', 'and', 'hadoop', 'course']",0,"['confused', 'between', 'sa', 'certification', 'and', 'hadoop', 'course']","['confused', 'sa', 'certification', 'hadoop', 'course']",confused sa certification hadoop course,-0.4,-0.4,7,39,4.875,0,0,0,0,0,0,0,0
4882,solutions for hackathons,solutions for hackathons,"['solutions', 'for', 'hackathons']",0,"['solution', 'for', 'hackathons']","['solution', 'hackathons']",solution hackathons,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
4883,hackathon black friday error in uploading the file,hackathon black friday error in uploading the file,"['hackathon', 'black', 'friday', 'error', 'in', 'uploading', 'the', 'file']",0,"['hackathon', 'black', 'friday', 'error', 'in', 'uploading', 'the', 'file']","['hackathon', 'black', 'friday', 'error', 'uploading', 'file']",hackathon black friday error uploading file,-0.1666666666666666,-0.1666666666666666,8,43,4.777777777777778,0,0,0,0,0,0,0,0
4884,why i am getting log value as  in my r console can some one please assist me this might be a silly question but eager to know,why i am getting log value as  in my r console can some one please assist me this might be a silly question but eager to know,"['why', 'i', 'am', 'getting', 'log', 'value', 'as', 'in', 'my', 'r', 'console', 'can', 'some', 'one', 'please', 'assist', 'me', 'this', 'might', 'be', 'a', 'silly', 'question', 'but', 'eager', 'to', 'know']",1,"['why', 'i', 'am', 'getting', 'log', 'value', 'a', 'in', 'my', 'r', 'console', 'can', 'some', 'one', 'please', 'assist', 'me', 'this', 'might', 'be', 'a', 'silly', 'question', 'but', 'eager', 'to', 'know']","['getting', 'log', 'value', 'r', 'console', 'one', 'please', 'assist', 'might', 'silly', 'question', 'eager', 'know']",getting log value r console one please assist might silly question eager know,-0.5,-0.5,27,77,2.75,0,0,0,0,0,0,0,0
4885,help needed to predict expected sales per customer for the dec  based on past data available,help needed to predict expected sales per customer for the dec  based on past data available,"['help', 'needed', 'to', 'predict', 'expected', 'sales', 'per', 'customer', 'for', 'the', 'dec', 'based', 'on', 'past', 'data', 'available']",1,"['help', 'needed', 'to', 'predict', 'expected', 'sale', 'per', 'customer', 'for', 'the', 'dec', 'based', 'on', 'past', 'data', 'available']","['help', 'needed', 'predict', 'expected', 'sale', 'per', 'customer', 'dec', 'based', 'past', 'data', 'available']",help needed predict expected sale per customer dec based past data available,0.0166666666666666,0.0166666666666666,16,76,4.470588235294118,0,0,0,0,0,0,0,0
4886,cooksd and studentized residual statistics,cooksd and studentized residual statistics,"['cooksd', 'and', 'studentized', 'residual', 'statistics']",0,"['cooksd', 'and', 'studentized', 'residual', 'statistic']","['cooksd', 'studentized', 'residual', 'statistic']",cooksd studentized residual statistic,0.0,0.0,5,37,6.166666666666667,0,0,0,0,0,0,0,0
4887,deployment of machine learning model developed in r for production,deployment of machine learning model developed in r for production,"['deployment', 'of', 'machine', 'learning', 'model', 'developed', 'in', 'r', 'for', 'production']",0,"['deployment', 'of', 'machine', 'learning', 'model', 'developed', 'in', 'r', 'for', 'production']","['deployment', 'machine', 'learning', 'model', 'developed', 'r', 'production']",deployment machine learning model developed r production,0.1,0.1,10,56,5.090909090909091,0,0,0,0,0,0,0,0
4888,is robust regression less sensitive towards outlier and how,is robust regression less sensitive towards outlier and how,"['is', 'robust', 'regression', 'less', 'sensitive', 'towards', 'outlier', 'and', 'how']",0,"['is', 'robust', 'regression', 'le', 'sensitive', 'towards', 'outlier', 'and', 'how']","['robust', 'regression', 'le', 'sensitive', 'towards', 'outlier']",robust regression le sensitive towards outlier,-0.0333333333333333,0.1,9,46,4.6,0,0,0,0,0,0,0,0
4889,seeking your advice regarding data science courses in india,seeking your advice regarding data science courses in india,"['seeking', 'your', 'advice', 'regarding', 'data', 'science', 'courses', 'in', 'india']",0,"['seeking', 'your', 'advice', 'regarding', 'data', 'science', 'course', 'in', 'india']","['seeking', 'advice', 'regarding', 'data', 'science', 'course', 'india']",seeking advice regarding data science course india,0.0,0.0,9,50,5.0,0,0,0,0,0,0,0,0
4890,aic bic mallows cp etc,aic bic mallows cp etc,"['aic', 'bic', 'mallows', 'cp', 'etc']",0,"['aic', 'bic', 'mallow', 'cp', 'etc']","['aic', 'bic', 'mallow', 'cp', 'etc']",aic bic mallow cp etc,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
4891,what does minsamplessplit means in decision tree,what does minsamplessplit means in decision tree,"['what', 'does', 'minsamplessplit', 'means', 'in', 'decision', 'tree']",0,"['what', 'doe', 'minsamplessplit', 'mean', 'in', 'decision', 'tree']","['doe', 'minsamplessplit', 'mean', 'decision', 'tree']",doe minsamplessplit mean decision tree,0.0,-0.3125,7,38,4.75,0,0,0,0,0,0,0,0
4892,the smart recruits hackathon discussion,the smart recruits hackathon discussion,"['the', 'smart', 'recruits', 'hackathon', 'discussion']",0,"['the', 'smart', 'recruit', 'hackathon', 'discussion']","['smart', 'recruit', 'hackathon', 'discussion']",smart recruit hackathon discussion,0.2142857142857142,0.2142857142857142,5,34,5.666666666666667,0,0,0,0,0,0,0,0
4893,predicting whether the stock will go up or down,predicting whether the stock will go up or down,"['predicting', 'whether', 'the', 'stock', 'will', 'go', 'up', 'or', 'down']",0,"['predicting', 'whether', 'the', 'stock', 'will', 'go', 'up', 'or', 'down']","['predicting', 'whether', 'stock', 'go']",predicting whether stock go,-0.1555555555555555,0.0,9,27,2.7,0,0,0,0,0,0,0,0
4894,what is the difference between softprob and softmax in xgboost,what is the difference between softprob and softmax in xgboost,"['what', 'is', 'the', 'difference', 'between', 'softprob', 'and', 'softmax', 'in', 'xgboost']",0,"['what', 'is', 'the', 'difference', 'between', 'softprob', 'and', 'softmax', 'in', 'xgboost']","['difference', 'softprob', 'softmax', 'xgboost']",difference softprob softmax xgboost,0.0,0.0,10,35,3.1818181818181817,0,0,0,0,0,0,0,0
4895,what is the role of data analystbusiness analyst,what is the role of data analystbusiness analyst,"['what', 'is', 'the', 'role', 'of', 'data', 'analystbusiness', 'analyst']",0,"['what', 'is', 'the', 'role', 'of', 'data', 'analystbusiness', 'analyst']","['role', 'data', 'analystbusiness', 'analyst']",role data analystbusiness analyst,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
4896,change text color or highlight text with multiple colors in pdf using python,change text color or highlight text with multiple colors in pdf using python,"['change', 'text', 'color', 'or', 'highlight', 'text', 'with', 'multiple', 'colors', 'in', 'pdf', 'using', 'python']",0,"['change', 'text', 'color', 'or', 'highlight', 'text', 'with', 'multiple', 'color', 'in', 'pdf', 'using', 'python']","['change', 'text', 'color', 'highlight', 'text', 'multiple', 'color', 'pdf', 'using', 'python']",change text color highlight text multiple color pdf using python,0.0,0.0,13,64,4.571428571428571,0,0,0,0,0,0,0,0
4897,pg diploma in big data analytics,pg diploma in big data analytics,"['pg', 'diploma', 'in', 'big', 'data', 'analytics']",0,"['pg', 'diploma', 'in', 'big', 'data', 'analytics']","['pg', 'diploma', 'big', 'data', 'analytics']",pg diploma big data analytics,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
4898,fitting arima  should you use the original series or the transformedstationary series,fitting arima  should you use the original series or the transformedstationary series,"['fitting', 'arima', 'should', 'you', 'use', 'the', 'original', 'series', 'or', 'the', 'transformedstationary', 'series']",0,"['fitting', 'arima', 'should', 'you', 'use', 'the', 'original', 'series', 'or', 'the', 'transformedstationary', 'series']","['fitting', 'arima', 'use', 'original', 'series', 'transformedstationary', 'series']",fitting arima use original series transformedstationary series,0.4375,0.4375,12,62,4.769230769230769,0,0,0,0,0,0,0,0
4899,what are the best hackathons in deep learninig for beginners,what are the best hackathons in deep learninig for beginners,"['what', 'are', 'the', 'best', 'hackathons', 'in', 'deep', 'learninig', 'for', 'beginners']",0,"['what', 'are', 'the', 'best', 'hackathons', 'in', 'deep', 'learninig', 'for', 'beginner']","['best', 'hackathons', 'deep', 'learninig', 'beginner']",best hackathons deep learninig beginner,0.5,0.5,10,39,3.5454545454545454,0,0,0,0,0,0,0,0
4900,what are different paths in data sciences,what are different paths in data sciences,"['what', 'are', 'different', 'paths', 'in', 'data', 'sciences']",0,"['what', 'are', 'different', 'path', 'in', 'data', 'science']","['different', 'path', 'data', 'science']",different path data science,0.0,0.0,7,27,3.375,0,0,0,0,0,0,0,0
4901,data analytics or business analytics or analysis path for mba graduate with  years of it experience,data analytics or business analytics or analysis path for mba graduate with  years of it experience,"['data', 'analytics', 'or', 'business', 'analytics', 'or', 'analysis', 'path', 'for', 'mba', 'graduate', 'with', 'years', 'of', 'it', 'experience']",1,"['data', 'analytics', 'or', 'business', 'analytics', 'or', 'analysis', 'path', 'for', 'mba', 'graduate', 'with', 'year', 'of', 'it', 'experience']","['data', 'analytics', 'business', 'analytics', 'analysis', 'path', 'mba', 'graduate', 'year', 'experience']",data analytics business analytics analysis path mba graduate year experience,0.0,0.0,16,76,4.470588235294118,0,0,0,0,0,0,0,0
4902,suggestion on books and aritcles,suggestion on books and aritcles,"['suggestion', 'on', 'books', 'and', 'aritcles']",0,"['suggestion', 'on', 'book', 'and', 'aritcles']","['suggestion', 'book', 'aritcles']",suggestion book aritcles,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
4903,how can i see the weights in boosting in r,how can i see the weights in boosting in r,"['how', 'can', 'i', 'see', 'the', 'weights', 'in', 'boosting', 'in', 'r']",0,"['how', 'can', 'i', 'see', 'the', 'weight', 'in', 'boosting', 'in', 'r']","['see', 'weight', 'boosting', 'r']",see weight boosting r,0.0,0.0,10,21,1.9090909090909092,0,0,0,0,0,0,0,0
4904,how to improve accuracy of decision tree  random forest,how to improve accuracy of decision tree  random forest,"['how', 'to', 'improve', 'accuracy', 'of', 'decision', 'tree', 'random', 'forest']",0,"['how', 'to', 'improve', 'accuracy', 'of', 'decision', 'tree', 'random', 'forest']","['improve', 'accuracy', 'decision', 'tree', 'random', 'forest']",improve accuracy decision tree random forest,-0.5,-0.5,9,44,4.4,0,0,0,0,0,0,0,0
4905,what do you meant by mismatched factor levels,what do you meant by mismatched factor levels,"['what', 'do', 'you', 'meant', 'by', 'mismatched', 'factor', 'levels']",0,"['what', 'do', 'you', 'meant', 'by', 'mismatched', 'factor', 'level']","['meant', 'mismatched', 'factor', 'level']",meant mismatched factor level,0.0,0.0,8,29,3.2222222222222223,0,0,0,0,0,0,0,0
4906,what are the career opportunities for a hadoop admin,what are the career opportunities for a hadoop admin,"['what', 'are', 'the', 'career', 'opportunities', 'for', 'a', 'hadoop', 'admin']",0,"['what', 'are', 'the', 'career', 'opportunity', 'for', 'a', 'hadoop', 'admin']","['career', 'opportunity', 'hadoop', 'admin']",career opportunity hadoop admin,0.0,0.0,9,31,3.1,0,0,0,0,0,0,0,0
4907,which supervised learning system would you use,which supervised learning system would you use,"['which', 'supervised', 'learning', 'system', 'would', 'you', 'use']",0,"['which', 'supervised', 'learning', 'system', 'would', 'you', 'use']","['supervised', 'learning', 'system', 'would', 'use']",supervised learning system would use,0.0,0.0,7,36,4.5,0,0,0,0,0,0,0,0
4908,what is the boxcox transformation applied during pca in r using the caret package,what is the boxcox transformation applied during pca in r using the caret package,"['what', 'is', 'the', 'boxcox', 'transformation', 'applied', 'during', 'pca', 'in', 'r', 'using', 'the', 'caret', 'package']",0,"['what', 'is', 'the', 'boxcox', 'transformation', 'applied', 'during', 'pca', 'in', 'r', 'using', 'the', 'caret', 'package']","['boxcox', 'transformation', 'applied', 'pca', 'r', 'using', 'caret', 'package']",boxcox transformation applied pca r using caret package,0.0,0.0,14,55,3.6666666666666665,0,0,0,0,0,0,0,0
4909,what is feasible with machine learning and object detection,what is feasible with machine learning and object detection,"['what', 'is', 'feasible', 'with', 'machine', 'learning', 'and', 'object', 'detection']",0,"['what', 'is', 'feasible', 'with', 'machine', 'learning', 'and', 'object', 'detection']","['feasible', 'machine', 'learning', 'object', 'detection']",feasible machine learning object detection,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
4910,how to use break function to break the data by a specific point,how to use break function to break the data by a specific point,"['how', 'to', 'use', 'break', 'function', 'to', 'break', 'the', 'data', 'by', 'a', 'specific', 'point']",0,"['how', 'to', 'use', 'break', 'function', 'to', 'break', 'the', 'data', 'by', 'a', 'specific', 'point']","['use', 'break', 'function', 'break', 'data', 'specific', 'point']",use break function break data specific point,0.0,0.0,13,44,3.142857142857143,0,0,0,0,0,0,0,0
4911,click prediction  visualize click and convert data,click prediction  visualize click and convert data,"['click', 'prediction', 'visualize', 'click', 'and', 'convert', 'data']",0,"['click', 'prediction', 'visualize', 'click', 'and', 'convert', 'data']","['click', 'prediction', 'visualize', 'click', 'convert', 'data']",click prediction visualize click convert data,0.0,0.0,7,45,5.625,0,0,0,0,0,0,0,0
4912,how to interpret the result of a logistic regression model,how to interpret the result of a logistic regression model,"['how', 'to', 'interpret', 'the', 'result', 'of', 'a', 'logistic', 'regression', 'model']",0,"['how', 'to', 'interpret', 'the', 'result', 'of', 'a', 'logistic', 'regression', 'model']","['interpret', 'result', 'logistic', 'regression', 'model']",interpret result logistic regression model,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
4913,error in sortlisty  x must be atomic for sortlist,error in sortlisty  x must be atomic for sortlist,"['', 'error', 'in', 'sortlisty', 'x', 'must', 'be', 'atomic', 'for', 'sortlist']",0,"['', 'error', 'in', 'sortlisty', 'x', 'must', 'be', 'atomic', 'for', 'sortlist']","['', 'error', 'sortlisty', 'x', 'must', 'atomic', 'sortlist']", error sortlisty x must atomic sortlist,0.0,0.0,10,40,3.6363636363636362,0,0,0,0,0,0,0,0
4914,why the value of coefficient of variable is different when it used as single variable as compared to multivariable model,why the value of coefficient of variable is different when it used as single variable as compared to multivariable model,"['why', 'the', 'value', 'of', 'coefficient', 'of', 'variable', 'is', 'different', 'when', 'it', 'used', 'as', 'single', 'variable', 'as', 'compared', 'to', 'multivariable', 'model']",0,"['why', 'the', 'value', 'of', 'coefficient', 'of', 'variable', 'is', 'different', 'when', 'it', 'used', 'a', 'single', 'variable', 'a', 'compared', 'to', 'multivariable', 'model']","['value', 'coefficient', 'variable', 'different', 'used', 'single', 'variable', 'compared', 'multivariable', 'model']",value coefficient variable different used single variable compared multivariable model,-0.0357142857142857,-0.0357142857142857,20,86,4.095238095238095,0,0,0,0,0,0,0,0
4915,jobs in data science,jobs in data science,"['jobs', 'in', 'data', 'science']",0,"['job', 'in', 'data', 'science']","['job', 'data', 'science']",job data science,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
4916,transforming dataframe in rhow to categorize based on unique row values,transforming dataframe in rhow to categorize based on unique row values,"['transforming', 'dataframe', 'in', 'rhow', 'to', 'categorize', 'based', 'on', 'unique', 'row', 'values']",0,"['transforming', 'dataframe', 'in', 'rhow', 'to', 'categorize', 'based', 'on', 'unique', 'row', 'value']","['transforming', 'dataframe', 'rhow', 'categorize', 'based', 'unique', 'row', 'value']",transforming dataframe rhow categorize based unique row value,0.375,0.375,11,61,5.083333333333333,0,0,0,0,0,0,0,0
4917,need help for conditional enabling of expression and dimension in qlikview,need help for conditional enabling of expression and dimension in qlikview,"['need', 'help', 'for', 'conditional', 'enabling', 'of', 'expression', 'and', 'dimension', 'in', 'qlikview']",0,"['need', 'help', 'for', 'conditional', 'enabling', 'of', 'expression', 'and', 'dimension', 'in', 'qlikview']","['need', 'help', 'conditional', 'enabling', 'expression', 'dimension', 'qlikview']",need help conditional enabling expression dimension qlikview,0.0,0.0,11,60,5.0,0,0,0,0,0,0,0,0
4918,interpretation of performance of naive bayes algorithm for binary classification,interpretation of performance of naive bayes algorithm for binary classification,"['interpretation', 'of', 'performance', 'of', 'naive', 'bayes', 'algorithm', 'for', 'binary', 'classification']",0,"['interpretation', 'of', 'performance', 'of', 'naive', 'bayes', 'algorithm', 'for', 'binary', 'classification']","['interpretation', 'performance', 'naive', 'bayes', 'algorithm', 'binary', 'classification']",interpretation performance naive bayes algorithm binary classification,-0.3,-0.3,10,70,6.363636363636363,0,0,0,0,0,0,0,0
4919,trouble with reinforcement learning,trouble with reinforcement learning,"['trouble', 'with', 'reinforcement', 'learning']",0,"['trouble', 'with', 'reinforcement', 'learning']","['trouble', 'reinforcement', 'learning']",trouble reinforcement learning,-0.2,-0.2,4,30,6.0,0,0,0,0,0,0,0,0
4920,how to automate analysis in r production environment,how to automate analysis in r production environment,"['how', 'to', 'automate', 'analysis', 'in', 'r', 'production', 'environment']",0,"['how', 'to', 'automate', 'analysis', 'in', 'r', 'production', 'environment']","['automate', 'analysis', 'r', 'production', 'environment']",automate analysis r production environment,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
4921,the d hackdecode d dalai lama,the d hackdecode d dalai lama,"['the', 'd', 'hackdecode', 'd', 'dalai', 'lama']",0,"['the', 'd', 'hackdecode', 'd', 'dalai', 'lama']","['hackdecode', 'dalai', 'lama']",hackdecode dalai lama,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
4922,how do i shift from sales background to data science,how do i shift from sales background to data science,"['how', 'do', 'i', 'shift', 'from', 'sales', 'background', 'to', 'data', 'science']",0,"['how', 'do', 'i', 'shift', 'from', 'sale', 'background', 'to', 'data', 'science']","['shift', 'sale', 'background', 'data', 'science']",shift sale background data science,0.0,0.0,10,34,3.090909090909091,0,0,0,0,0,0,0,0
4923,svm for continuous variables,svm for continuous variables,"['svm', 'for', 'continuous', 'variables']",0,"['svm', 'for', 'continuous', 'variable']","['svm', 'continuous', 'variable']",svm continuous variable,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
4924,how to provide a custom stopword list in r,how to provide a custom stopword list in r,"['how', 'to', 'provide', 'a', 'custom', 'stopword', 'list', 'in', 'r']",0,"['how', 'to', 'provide', 'a', 'custom', 'stopword', 'list', 'in', 'r']","['provide', 'custom', 'stopword', 'list', 'r']",provide custom stopword list r,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
4925,giving results to the customers,giving results to the customers,"['giving', 'results', 'to', 'the', 'customers']",0,"['giving', 'result', 'to', 'the', 'customer']","['giving', 'result', 'customer']",giving result customer,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
4926,predict future valuestime series using arima,predict future valuestime series using arima,"['predict', 'future', 'valuestime', 'series', 'using', 'arima']",0,"['predict', 'future', 'valuestime', 'series', 'using', 'arima']","['predict', 'future', 'valuestime', 'series', 'using', 'arima']",predict future valuestime series using arima,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
4927,which dimentionality reduction to use for the given problem,which dimentionality reduction to use for the given problem,"['which', 'dimentionality', 'reduction', 'to', 'use', 'for', 'the', 'given', 'problem']",0,"['which', 'dimentionality', 'reduction', 'to', 'use', 'for', 'the', 'given', 'problem']","['dimentionality', 'reduction', 'use', 'given', 'problem']",dimentionality reduction use given problem,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
4928,how to tune warmstart parameter of randomforest,how to tune warmstart parameter of randomforest,"['how', 'to', 'tune', 'warmstart', 'parameter', 'of', 'randomforest']",0,"['how', 'to', 'tune', 'warmstart', 'parameter', 'of', 'randomforest']","['tune', 'warmstart', 'parameter', 'randomforest']",tune warmstart parameter randomforest,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
4929,r programming in lubuntu os,r programming in lubuntu os,"['r', 'programming', 'in', 'lubuntu', 'os']",0,"['r', 'programming', 'in', 'lubuntu', 'o']","['r', 'programming', 'lubuntu']",r programming lubuntu,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
4930,generating a multivariate time series model with some of the underlying trends,generating a multivariate time series model with some of the underlying trends,"['generating', 'a', 'multivariate', 'time', 'series', 'model', 'with', 'some', 'of', 'the', 'underlying', 'trends']",0,"['generating', 'a', 'multivariate', 'time', 'series', 'model', 'with', 'some', 'of', 'the', 'underlying', 'trend']","['generating', 'multivariate', 'time', 'series', 'model', 'underlying', 'trend']",generating multivariate time series model underlying trend,0.0,0.0,12,58,4.461538461538462,0,0,0,0,0,0,0,0
4931,rstudio crashing while help,rstudio crashing while help,"['rstudio', 'crashing', 'while', 'help']",0,"['rstudio', 'crashing', 'while', 'help']","['rstudio', 'crashing', 'help']",rstudio crashing help,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
4932,question for toppers  data hackathon  ,question for toppers  data hackathon  ,"['question', 'for', 'toppers', 'data', 'hackathon']",1,"['question', 'for', 'topper', 'data', 'hackathon']","['question', 'topper', 'data', 'hackathon']",question topper data hackathon,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
4933,how to write functions for calculating euclidean distance and mahalanobis distance,how to write functions for calculating euclidean distance and mahalanobis distance,"['how', 'to', 'write', 'functions', 'for', 'calculating', 'euclidean', 'distance', 'and', 'mahalanobis', 'distance']",0,"['how', 'to', 'write', 'function', 'for', 'calculating', 'euclidean', 'distance', 'and', 'mahalanobis', 'distance']","['write', 'function', 'calculating', 'euclidean', 'distance', 'mahalanobis', 'distance']",write function calculating euclidean distance mahalanobis distance,0.0,0.0,11,66,5.5,0,0,0,0,0,0,0,0
4934,best books for data engineering,best books for data engineering,"['best', 'books', 'for', 'data', 'engineering']",0,"['best', 'book', 'for', 'data', 'engineering']","['best', 'book', 'data', 'engineering']",best book data engineering,1.0,1.0,5,26,4.333333333333333,0,0,0,0,0,0,0,0
4935,confidence and prediction intervals using lm in r,confidence and prediction intervals using lm in r,"['confidence', 'and', 'prediction', 'intervals', 'using', 'lm', 'in', 'r']",0,"['confidence', 'and', 'prediction', 'interval', 'using', 'lm', 'in', 'r']","['confidence', 'prediction', 'interval', 'using', 'lm', 'r']",confidence prediction interval using lm r,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
4936,how to avoid overfitting in prediction,how to avoid overfitting in prediction,"['how', 'to', 'avoid', 'overfitting', 'in', 'prediction']",0,"['how', 'to', 'avoid', 'overfitting', 'in', 'prediction']","['avoid', 'overfitting', 'prediction']",avoid overfitting prediction,0.0,0.0,6,28,4.0,0,0,0,0,0,0,0,0
4937,methods to deal with zero values while performing log transformation of variable,methods to deal with zero values while performing log transformation of variable,"['methods', 'to', 'deal', 'with', 'zero', 'values', 'while', 'performing', 'log', 'transformation', 'of', 'variable']",0,"['method', 'to', 'deal', 'with', 'zero', 'value', 'while', 'performing', 'log', 'transformation', 'of', 'variable']","['method', 'deal', 'zero', 'value', 'performing', 'log', 'transformation', 'variable']",method deal zero value performing log transformation variable,0.0,0.0,12,61,4.6923076923076925,0,0,0,0,0,0,0,0
4938,finding an indian final year graduation student to team up for a university competition sponsored by sas,finding an indian final year graduation student to team up for a university competition sponsored by sas,"['finding', 'an', 'indian', 'final', 'year', 'graduation', 'student', 'to', 'team', 'up', 'for', 'a', 'university', 'competition', 'sponsored', 'by', 'sas']",0,"['finding', 'an', 'indian', 'final', 'year', 'graduation', 'student', 'to', 'team', 'up', 'for', 'a', 'university', 'competition', 'sponsored', 'by', 'sa']","['finding', 'indian', 'final', 'year', 'graduation', 'student', 'team', 'university', 'competition', 'sponsored', 'sa']",finding indian final year graduation student team university competition sponsored sa,0.0,0.0,17,85,4.722222222222222,0,0,0,0,0,0,0,0
4939,information on mapreduce hive and pig,information on mapreduce hive and pig,"['information', 'on', 'mapreduce', 'hive', 'and', 'pig']",0,"['information', 'on', 'mapreduce', 'hive', 'and', 'pig']","['information', 'mapreduce', 'hive', 'pig']",information mapreduce hive pig,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
4940,seeking career guidance to switch from oracle developer to analytics,seeking career guidance to switch from oracle developer to analytics,"['seeking', 'career', 'guidance', 'to', 'switch', 'from', 'oracle', 'developer', 'to', 'analytics']",0,"['seeking', 'career', 'guidance', 'to', 'switch', 'from', 'oracle', 'developer', 'to', 'analytics']","['seeking', 'career', 'guidance', 'switch', 'oracle', 'developer', 'analytics']",seeking career guidance switch oracle developer analytics,0.0,0.0,10,57,5.181818181818182,0,0,0,0,0,0,0,0
4941,problem while solving big mart problem using linear regression,problem while solving big mart problem using linear regression,"['problem', 'while', 'solving', 'big', 'mart', 'problem', 'using', 'linear', 'regression']",0,"['problem', 'while', 'solving', 'big', 'mart', 'problem', 'using', 'linear', 'regression']","['problem', 'solving', 'big', 'mart', 'problem', 'using', 'linear', 'regression']",problem solving big mart problem using linear regression,0.0,0.0,9,56,5.6,0,0,0,0,0,0,0,0
4942,need help with removing duplicate characters with regex,need help with removing duplicate characters with regex,"['need', 'help', 'with', 'removing', 'duplicate', 'characters', 'with', 'regex']",0,"['need', 'help', 'with', 'removing', 'duplicate', 'character', 'with', 'regex']","['need', 'help', 'removing', 'duplicate', 'character', 'regex']",need help removing duplicate character regex,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
4943,how lsf and dds techniques work,how lsf and dds techniques work,"['how', 'lsf', 'and', 'dds', 'techniques', 'work']",0,"['how', 'lsf', 'and', 'dd', 'technique', 'work']","['lsf', 'dd', 'technique', 'work']",lsf dd technique work,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
4944,interpret rfimpute output,interpret rfimpute output,"['interpret', 'rfimpute', 'output']",0,"['interpret', 'rfimpute', 'output']","['interpret', 'rfimpute', 'output']",interpret rfimpute output,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
4945,import first  records of excel to sas,import first  records of excel to sas,"['import', 'first', 'records', 'of', 'excel', 'to', 'sas']",1,"['import', 'first', 'record', 'of', 'excel', 'to', 'sa']","['import', 'first', 'record', 'excel', 'sa']",import first record excel sa,0.25,0.25,7,28,3.5,0,0,0,0,0,0,0,0
4946,populate world countries region cities in other languages beside english,populate world countries region cities in other languages beside english,"['populate', 'world', 'countries', 'region', 'cities', 'in', 'other', 'languages', 'beside', 'english']",0,"['populate', 'world', 'country', 'region', 'city', 'in', 'other', 'language', 'beside', 'english']","['populate', 'world', 'country', 'region', 'city', 'language', 'beside', 'english']",populate world country region city language beside english,-0.0625,0.0,10,58,5.2727272727272725,0,0,0,0,0,0,0,0
4947,data set for developing conversational chatbot,data set for developing conversational chatbot,"['data', 'set', 'for', 'developing', 'conversational', 'chatbot']",0,"['data', 'set', 'for', 'developing', 'conversational', 'chatbot']","['data', 'set', 'developing', 'conversational', 'chatbot']",data set developing conversational chatbot,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
4948,how to get data from twitter without a search query,how to get data from twitter without a search query,"['how', 'to', 'get', 'data', 'from', 'twitter', 'without', 'a', 'search', 'query']",0,"['how', 'to', 'get', 'data', 'from', 'twitter', 'without', 'a', 'search', 'query']","['get', 'data', 'twitter', 'without', 'search', 'query']",get data twitter without search query,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
4949,how to use datamatrix in r,how to use datamatrix in r,"['how', 'to', 'use', 'datamatrix', 'in', 'r']",0,"['how', 'to', 'use', 'datamatrix', 'in', 'r']","['use', 'datamatrix', 'r']",use datamatrix r,0.0,0.0,6,16,2.2857142857142856,0,0,0,0,0,0,0,0
4950,what is the difference between ridge and lasso regression,what is the difference between ridge and lasso regression,"['what', 'is', 'the', 'difference', 'between', 'ridge', 'and', 'lasso', 'regression']",0,"['what', 'is', 'the', 'difference', 'between', 'ridge', 'and', 'lasso', 'regression']","['difference', 'ridge', 'lasso', 'regression']",difference ridge lasso regression,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
4951,how to resolve r svm text classification error,how to resolve r svm text classification error,"['how', 'to', 'resolve', 'r', 'svm', 'text', 'classification', 'error']",0,"['how', 'to', 'resolve', 'r', 'svm', 'text', 'classification', 'error']","['resolve', 'r', 'svm', 'text', 'classification', 'error']",resolve r svm text classification error,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
4952,can we create a mobile or web based app using python,can we create a mobile or web based app using python,"['can', 'we', 'create', 'a', 'mobile', 'or', 'web', 'based', 'app', 'using', 'python']",0,"['can', 'we', 'create', 'a', 'mobile', 'or', 'web', 'based', 'app', 'using', 'python']","['create', 'mobile', 'web', 'based', 'app', 'using', 'python']",create mobile web based app using python,0.0,0.0,11,40,3.3333333333333335,0,0,0,0,0,0,0,0
4953,require cross sale data in insurancebanking domain,require cross sale data in insurancebanking domain,"['require', 'cross', 'sale', 'data', 'in', 'insurancebanking', 'domain']",0,"['require', 'cross', 'sale', 'data', 'in', 'insurancebanking', 'domain']","['require', 'cross', 'sale', 'data', 'insurancebanking', 'domain']",require cross sale data insurancebanking domain,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
4954,how kfold crossvalidation helps in improving the model,how kfold crossvalidation helps in improving the model,"['how', 'kfold', 'crossvalidation', 'helps', 'in', 'improving', 'the', 'model']",0,"['how', 'kfold', 'crossvalidation', 'help', 'in', 'improving', 'the', 'model']","['kfold', 'crossvalidation', 'help', 'improving', 'model']",kfold crossvalidation help improving model,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
4955,which machine learning model is best for this scenario,which machine learning model is best for this scenario,"['which', 'machine', 'learning', 'model', 'is', 'best', 'for', 'this', 'scenario']",0,"['which', 'machine', 'learning', 'model', 'is', 'best', 'for', 'this', 'scenario']","['machine', 'learning', 'model', 'best', 'scenario']",machine learning model best scenario,1.0,1.0,9,36,3.6,0,0,0,0,0,0,0,0
4956,modified regression tree,modified regression tree,"['modified', 'regression', 'tree']",0,"['modified', 'regression', 'tree']","['modified', 'regression', 'tree']",modified regression tree,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
4957,how to plot nomograms in r for naive bayes classifier,how to plot nomograms in r for naive bayes classifier,"['how', 'to', 'plot', 'nomograms', 'in', 'r', 'for', 'naive', 'bayes', 'classifier']",0,"['how', 'to', 'plot', 'nomogram', 'in', 'r', 'for', 'naive', 'bayes', 'classifier']","['plot', 'nomogram', 'r', 'naive', 'bayes', 'classifier']",plot nomogram r naive bayes classifier,-0.3,-0.3,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
4958,mask rcnn inference on nvidia gtx  ti,mask rcnn inference on nvidia gtx  ti,"['mask', 'rcnn', 'inference', 'on', 'nvidia', 'gtx', 'ti']",1,"['mask', 'rcnn', 'inference', 'on', 'nvidia', 'gtx', 'ti']","['mask', 'rcnn', 'inference', 'nvidia', 'gtx', 'ti']",mask rcnn inference nvidia gtx ti,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
4959,how to approach data when a given statement turns out to be false,how to approach data when a given statement turns out to be false,"['how', 'to', 'approach', 'data', 'when', 'a', 'given', 'statement', 'turns', 'out', 'to', 'be', 'false']",0,"['how', 'to', 'approach', 'data', 'when', 'a', 'given', 'statement', 'turn', 'out', 'to', 'be', 'false']","['approach', 'data', 'given', 'statement', 'turn', 'false']",approach data given statement turn false,-0.4000000000000001,-0.4000000000000001,13,40,2.857142857142857,0,0,0,0,0,0,0,0
4960,getting error error in jcallrp i fetch stride block  javalangoutofmemoryerror gc overhead limit exceeded,getting error error in jcallrp i fetch stride block  javalangoutofmemoryerror gc overhead limit exceeded,"['getting', 'error', 'error', 'in', 'jcallrp', 'i', 'fetch', 'stride', 'block', 'javalangoutofmemoryerror', 'gc', 'overhead', 'limit', 'exceeded']",0,"['getting', 'error', 'error', 'in', 'jcallrp', 'i', 'fetch', 'stride', 'block', 'javalangoutofmemoryerror', 'gc', 'overhead', 'limit', 'exceeded']","['getting', 'error', 'error', 'jcallrp', 'fetch', 'stride', 'block', 'javalangoutofmemoryerror', 'gc', 'overhead', 'limit', 'exceeded']",getting error error jcallrp fetch stride block javalangoutofmemoryerror gc overhead limit exceeded,0.0,0.0,14,98,6.533333333333333,0,0,0,0,0,0,0,0
4961,code not working and scipy version not compatible with scikitml ,code not working and scipy version not compatible with scikitml ,"['code', 'not', 'working', 'and', 'scipy', 'version', 'not', 'compatible', 'with', 'scikitml']",1,"['code', 'not', 'working', 'and', 'scipy', 'version', 'not', 'compatible', 'with', 'scikitml']","['code', 'working', 'scipy', 'version', 'compatible', 'scikitml']",code working scipy version compatible scikitml,0.0,0.0,10,46,4.181818181818182,0,0,0,0,0,0,0,0
4962,what is the difference between neural network and bunch of logistic regression put together,what is the difference between neural network and bunch of logistic regression put together,"['what', 'is', 'the', 'difference', 'between', 'neural', 'network', 'and', 'bunch', 'of', 'logistic', 'regression', 'put', 'together']",0,"['what', 'is', 'the', 'difference', 'between', 'neural', 'network', 'and', 'bunch', 'of', 'logistic', 'regression', 'put', 'together']","['difference', 'neural', 'network', 'bunch', 'logistic', 'regression', 'put', 'together']",difference neural network bunch logistic regression put together,0.0,0.0,14,64,4.266666666666667,0,0,0,0,0,0,0,0
4963,getting  score on file submission,getting  score on file submission,"['getting', 'score', 'on', 'file', 'submission']",1,"['getting', 'score', 'on', 'file', 'submission']","['getting', 'score', 'file', 'submission']",getting score file submission,0.0,0.0,5,29,4.833333333333333,0,0,0,0,0,0,0,0
4964,all in one text processing techniques,all in one text processing techniques,"['all', 'in', 'one', 'text', 'processing', 'techniques']",0,"['all', 'in', 'one', 'text', 'processing', 'technique']","['one', 'text', 'processing', 'technique']",one text processing technique,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
4965,how to print value in list in r,how to print value in list in r,"['how', 'to', 'print', 'value', 'in', 'list', 'in', 'r']",0,"['how', 'to', 'print', 'value', 'in', 'list', 'in', 'r']","['print', 'value', 'list', 'r']",print value list r,0.0,0.0,8,18,2.0,0,0,0,0,0,0,0,0
4966,typeerror on trying ulmfit and fastai tutorial,typeerror on trying ulmfit and fastai tutorial,"['typeerror', 'on', 'trying', 'ulmfit', 'and', 'fastai', 'tutorial']",0,"['typeerror', 'on', 'trying', 'ulmfit', 'and', 'fastai', 'tutorial']","['typeerror', 'trying', 'ulmfit', 'fastai', 'tutorial']",typeerror trying ulmfit fastai tutorial,0.0,0.0,7,39,4.875,0,0,0,0,0,0,0,0
4967,need of a mentorguide,need of a mentorguide,"['need', 'of', 'a', 'mentorguide']",0,"['need', 'of', 'a', 'mentorguide']","['need', 'mentorguide']",need mentorguide,0.0,0.0,4,16,3.2,0,0,0,0,0,0,0,0
4968,image classifier,image classifier,"['image', 'classifier']",0,"['image', 'classifier']","['image', 'classifier']",image classifier,0.0,0.0,2,16,5.333333333333333,0,0,0,0,0,0,0,0
4969,what does zero index signify in r,what does zero index signify in r,"['what', 'does', 'zero', 'index', 'signify', 'in', 'r']",0,"['what', 'doe', 'zero', 'index', 'signify', 'in', 'r']","['doe', 'zero', 'index', 'signify', 'r']",doe zero index signify r,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
4970,kernel svm for a classifier model,kernel svm for a classifier model,"['kernel', 'svm', 'for', 'a', 'classifier', 'model']",0,"['kernel', 'svm', 'for', 'a', 'classifier', 'model']","['kernel', 'svm', 'classifier', 'model']",kernel svm classifier model,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
4971,logistic regression techniques,logistic regression techniques,"['logistic', 'regression', 'techniques']",0,"['logistic', 'regression', 'technique']","['logistic', 'regression', 'technique']",logistic regression technique,0.0,0.0,3,29,7.25,0,0,0,0,0,0,0,0
4972,how to change the colour of the legend by using condition,how to change the colour of the legend by using condition,"['how', 'to', 'change', 'the', 'colour', 'of', 'the', 'legend', 'by', 'using', 'condition']",0,"['how', 'to', 'change', 'the', 'colour', 'of', 'the', 'legend', 'by', 'using', 'condition']","['change', 'colour', 'legend', 'using', 'condition']",change colour legend using condition,0.0,0.0,11,36,3.0,0,0,0,0,0,0,0,0
4973,how does the recursive feature eliminationrfe works and how it is different from backward elimination,how does the recursive feature eliminationrfe works and how it is different from backward elimination,"['how', 'does', 'the', 'recursive', 'feature', 'eliminationrfe', 'works', 'and', 'how', 'it', 'is', 'different', 'from', 'backward', 'elimination']",0,"['how', 'doe', 'the', 'recursive', 'feature', 'eliminationrfe', 'work', 'and', 'how', 'it', 'is', 'different', 'from', 'backward', 'elimination']","['doe', 'recursive', 'feature', 'eliminationrfe', 'work', 'different', 'backward', 'elimination']",doe recursive feature eliminationrfe work different backward elimination,0.0,0.0,15,72,4.5,0,0,0,0,0,0,0,0
4974,naive bayes loan prediction,naive bayes loan prediction,"['naive', 'bayes', 'loan', 'prediction']",0,"['naive', 'bayes', 'loan', 'prediction']","['naive', 'bayes', 'loan', 'prediction']",naive bayes loan prediction,-0.3,-0.3,4,27,5.4,0,0,0,0,0,0,0,0
4975,clustering ordinalcategorical data,clustering ordinalcategorical data,"['clustering', 'ordinalcategorical', 'data']",0,"['clustering', 'ordinalcategorical', 'data']","['clustering', 'ordinalcategorical', 'data']",clustering ordinalcategorical data,0.0,0.0,3,34,8.5,0,0,0,0,0,0,0,0
4976,finding a bottleneck using root cause algorithm,finding a bottleneck using root cause algorithm,"['finding', 'a', 'bottleneck', 'using', 'root', 'cause', 'algorithm']",0,"['finding', 'a', 'bottleneck', 'using', 'root', 'cause', 'algorithm']","['finding', 'bottleneck', 'using', 'root', 'cause', 'algorithm']",finding bottleneck using root cause algorithm,0.0,0.0,7,45,5.625,0,0,0,0,0,0,0,0
4977,how to improve the performance of a decision tree,how to improve the performance of a decision tree,"['how', 'to', 'improve', 'the', 'performance', 'of', 'a', 'decision', 'tree']",0,"['how', 'to', 'improve', 'the', 'performance', 'of', 'a', 'decision', 'tree']","['improve', 'performance', 'decision', 'tree']",improve performance decision tree,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
4978,approach and solution to break in top  of big mart sales prediction,approach and solution to break in top  of big mart sales prediction,"['approach', 'and', 'solution', 'to', 'break', 'in', 'top', 'of', 'big', 'mart', 'sales', 'prediction']",1,"['approach', 'and', 'solution', 'to', 'break', 'in', 'top', 'of', 'big', 'mart', 'sale', 'prediction']","['approach', 'solution', 'break', 'top', 'big', 'mart', 'sale', 'prediction']",approach solution break top big mart sale prediction,0.25,0.25,12,52,4.0,0,0,0,0,0,0,0,0
4979,noobie to analytics,noobie to analytics,"['noobie', 'to', 'analytics']",0,"['noobie', 'to', 'analytics']","['noobie', 'analytics']",noobie analytics,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
4980,adaboost unstable output,adaboost unstable output,"['adaboost', 'unstable', 'output']",0,"['adaboost', 'unstable', 'output']","['adaboost', 'unstable', 'output']",adaboost unstable output,0.0,0.0,3,24,6.0,0,0,0,0,0,0,0,0
4981,confusion matrix plot  x matrix,confusion matrix plot  x matrix,"['confusion', 'matrix', 'plot', 'x', 'matrix']",0,"['confusion', 'matrix', 'plot', 'x', 'matrix']","['confusion', 'matrix', 'plot', 'x', 'matrix']",confusion matrix plot x matrix,0.0,0.0,5,30,5.0,0,0,0,0,0,0,0,0
4982,casual and mechanistic statistics,casual and mechanistic statistics,"['casual', 'and', 'mechanistic', 'statistics']",0,"['casual', 'and', 'mechanistic', 'statistic']","['casual', 'mechanistic', 'statistic']",casual mechanistic statistic,-0.5000000000000001,-0.5000000000000001,4,28,5.6,0,0,0,0,0,0,0,0
4983,how to pass multiple index arrays in ipython,how to pass multiple index arrays in ipython,"['how', 'to', 'pass', 'multiple', 'index', 'arrays', 'in', 'ipython']",0,"['how', 'to', 'pas', 'multiple', 'index', 'array', 'in', 'ipython']","['pas', 'multiple', 'index', 'array', 'ipython']",pas multiple index array ipython,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
4984,how to give labels to predictions instead of probabilities in logit in r,how to give labels to predictions instead of probabilities in logit in r,"['how', 'to', 'give', 'labels', 'to', 'predictions', 'instead', 'of', 'probabilities', 'in', 'logit', 'in', 'r']",0,"['how', 'to', 'give', 'label', 'to', 'prediction', 'instead', 'of', 'probability', 'in', 'logit', 'in', 'r']","['give', 'label', 'prediction', 'instead', 'probability', 'logit', 'r']",give label prediction instead probability logit r,0.0,0.0,13,49,3.5,0,0,0,0,0,0,0,0
4985,how to specify the data type of array in ipython,how to specify the data type of array in ipython,"['how', 'to', 'specify', 'the', 'data', 'type', 'of', 'array', 'in', 'ipython']",0,"['how', 'to', 'specify', 'the', 'data', 'type', 'of', 'array', 'in', 'ipython']","['specify', 'data', 'type', 'array', 'ipython']",specify data type array ipython,0.0,0.0,10,31,2.8181818181818183,0,0,0,0,0,0,0,0
4986,how to predict values for test dataset after building an lmridge model in r,how to predict values for test dataset after building an lmridge model in r,"['how', 'to', 'predict', 'values', 'for', 'test', 'dataset', 'after', 'building', 'an', 'lmridge', 'model', 'in', 'r']",0,"['how', 'to', 'predict', 'value', 'for', 'test', 'dataset', 'after', 'building', 'an', 'lmridge', 'model', 'in', 'r']","['predict', 'value', 'test', 'dataset', 'building', 'lmridge', 'model', 'r']",predict value test dataset building lmridge model r,0.0,0.0,14,51,3.4,0,0,0,0,0,0,0,0
4987,what are acf and pacf curves why do we use them,what are acf and pacf curves why do we use them,"['what', 'are', 'acf', 'and', 'pacf', 'curves', 'why', 'do', 'we', 'use', 'them']",0,"['what', 'are', 'acf', 'and', 'pacf', 'curve', 'why', 'do', 'we', 'use', 'them']","['acf', 'pacf', 'curve', 'use']",acf pacf curve use,0.0,0.0,11,18,1.5,0,0,0,0,0,0,0,0
4988,shit from etl to public policy research and now contemplating a transition to data analytics,shit from etl to public policy research and now contemplating a transition to data analytics,"['shit', 'from', 'etl', 'to', 'public', 'policy', 'research', 'and', 'now', 'contemplating', 'a', 'transition', 'to', 'data', 'analytics']",0,"['shit', 'from', 'etl', 'to', 'public', 'policy', 'research', 'and', 'now', 'contemplating', 'a', 'transition', 'to', 'data', 'analytics']","['shit', 'etl', 'public', 'policy', 'research', 'contemplating', 'transition', 'data', 'analytics']",shit etl public policy research contemplating transition data analytics,-0.1,-0.1,15,71,4.4375,0,0,0,0,0,0,0,0
4989,how to impute or do r bind lists in for loop,how to impute or do r bind lists in for loop,"['how', 'to', 'impute', 'or', 'do', 'r', 'bind', 'lists', 'in', 'for', 'loop']",0,"['how', 'to', 'impute', 'or', 'do', 'r', 'bind', 'list', 'in', 'for', 'loop']","['impute', 'r', 'bind', 'list', 'loop']",impute r bind list loop,0.0,0.0,11,23,1.9166666666666667,0,0,0,0,0,0,0,0
4990,read a specific column from excel in python,read a specific column from excel in python,"['read', 'a', 'specific', 'column', 'from', 'excel', 'in', 'python']",0,"['read', 'a', 'specific', 'column', 'from', 'excel', 'in', 'python']","['read', 'specific', 'column', 'excel', 'python']",read specific column excel python,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
4991,time series forecasting help,time series forecasting help,"['time', 'series', 'forecasting', 'help']",0,"['time', 'series', 'forecasting', 'help']","['time', 'series', 'forecasting', 'help']",time series forecasting help,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
4992,what csv file should we submit as solution to contests,what csv file should we submit as solution to contests,"['what', 'csv', 'file', 'should', 'we', 'submit', 'as', 'solution', 'to', 'contests']",0,"['what', 'csv', 'file', 'should', 'we', 'submit', 'a', 'solution', 'to', 'contest']","['csv', 'file', 'submit', 'solution', 'contest']",csv file submit solution contest,0.0,0.0,10,32,2.909090909090909,0,0,0,0,0,0,0,0
4993,predict future attrition with survival analysis,predict future attrition with survival analysis,"['predict', 'future', 'attrition', 'with', 'survival', 'analysis']",0,"['predict', 'future', 'attrition', 'with', 'survival', 'analysis']","['predict', 'future', 'attrition', 'survival', 'analysis']",predict future attrition survival analysis,0.0,0.0,6,42,6.0,0,0,0,0,0,0,0,0
4994,how to resolve error while connecting to twitter api in r,how to resolve error while connecting to twitter api in r,"['how', 'to', 'resolve', 'error', 'while', 'connecting', 'to', 'twitter', 'api', 'in', 'r']",0,"['how', 'to', 'resolve', 'error', 'while', 'connecting', 'to', 'twitter', 'api', 'in', 'r']","['resolve', 'error', 'connecting', 'twitter', 'api', 'r']",resolve error connecting twitter api r,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
4995,how to create unique ids in sas,how to create unique ids in sas,"['how', 'to', 'create', 'unique', 'ids', 'in', 'sas']",0,"['how', 'to', 'create', 'unique', 'id', 'in', 'sa']","['create', 'unique', 'id', 'sa']",create unique id sa,0.375,0.375,7,19,2.375,0,0,0,0,0,0,0,0
4996,data science  career shift from mech engg to data science,data science  career shift from mech engg to data science,"['data', 'science', 'career', 'shift', 'from', 'mech', 'engg', 'to', 'data', 'science']",0,"['data', 'science', 'career', 'shift', 'from', 'mech', 'engg', 'to', 'data', 'science']","['data', 'science', 'career', 'shift', 'mech', 'engg', 'data', 'science']",data science career shift mech engg data science,0.0,0.0,10,48,4.363636363636363,0,0,0,0,0,0,0,0
4997,regarding game theory,regarding game theory,"['regarding', 'game', 'theory']",0,"['regarding', 'game', 'theory']","['regarding', 'game', 'theory']",regarding game theory,-0.4,-0.4,3,21,5.25,0,0,0,0,0,0,0,0
4998,score of python skill test,score of python skill test,"['score', 'of', 'python', 'skill', 'test']",0,"['score', 'of', 'python', 'skill', 'test']","['score', 'python', 'skill', 'test']",score python skill test,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
4999,how do i convert a character field to datetime format in r,how do i convert a character field to datetime format in r,"['how', 'do', 'i', 'convert', 'a', 'character', 'field', 'to', 'datetime', 'format', 'in', 'r']",0,"['how', 'do', 'i', 'convert', 'a', 'character', 'field', 'to', 'datetime', 'format', 'in', 'r']","['convert', 'character', 'field', 'datetime', 'format', 'r']",convert character field datetime format r,0.0,0.0,12,41,3.1538461538461537,0,0,0,0,0,0,0,0
5000,use of hadoop in machine learning,use of hadoop in machine learning,"['use', 'of', 'hadoop', 'in', 'machine', 'learning']",0,"['use', 'of', 'hadoop', 'in', 'machine', 'learning']","['use', 'hadoop', 'machine', 'learning']",use hadoop machine learning,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
5001,discussion business value of augmented analytics,discussion business value of augmented analytics,"['discussion', 'business', 'value', 'of', 'augmented', 'analytics']",0,"['discussion', 'business', 'value', 'of', 'augmented', 'analytics']","['discussion', 'business', 'value', 'augmented', 'analytics']",discussion business value augmented analytics,0.0,0.0,6,45,6.428571428571429,0,0,0,0,0,0,0,0
5002,frequency of a value under more than one variable in sas,frequency of a value under more than one variable in sas,"['frequency', 'of', 'a', 'value', 'under', 'more', 'than', 'one', 'variable', 'in', 'sas']",0,"['frequency', 'of', 'a', 'value', 'under', 'more', 'than', 'one', 'variable', 'in', 'sa']","['frequency', 'value', 'one', 'variable', 'sa']",frequency value one variable sa,0.5,0.0,11,31,2.5833333333333335,0,0,0,0,0,0,0,0
5003,could not find function  xgbdmatrix in r,could not find function  xgbdmatrix in r,"['could', 'not', 'find', 'function', 'xgbdmatrix', 'in', 'r']",0,"['could', 'not', 'find', 'function', 'xgbdmatrix', 'in', 'r']","['could', 'find', 'function', 'xgbdmatrix', 'r']",could find function xgbdmatrix r,0.0,0.0,7,32,4.0,0,0,0,0,0,0,0,0
5004,random forest decide variable importance,random forest decide variable importance,"['random', 'forest', 'decide', 'variable', 'importance']",0,"['random', 'forest', 'decide', 'variable', 'importance']","['random', 'forest', 'decide', 'variable', 'importance']",random forest decide variable importance,-0.5,-0.5,5,40,6.666666666666667,0,0,0,0,0,0,0,0
5005,why is xgboost predicting unseen values,why is xgboost predicting unseen values,"['why', 'is', 'xgboost', 'predicting', 'unseen', 'values']",0,"['why', 'is', 'xgboost', 'predicting', 'unseen', 'value']","['xgboost', 'predicting', 'unseen', 'value']",xgboost predicting unseen value,0.0,0.0,6,31,4.428571428571429,0,0,0,0,0,0,0,0
5006,need help criteria to create a risk score,need help criteria to create a risk score,"['need', 'help', 'criteria', 'to', 'create', 'a', 'risk', 'score']",0,"['need', 'help', 'criterion', 'to', 'create', 'a', 'risk', 'score']","['need', 'help', 'criterion', 'create', 'risk', 'score']",need help criterion create risk score,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
5007,why do we factorize variables in r  what is the benefit of doing so,why do we factorize variables in r  what is the benefit of doing so,"['why', 'do', 'we', 'factorize', 'variables', 'in', 'r', 'what', 'is', 'the', 'benefit', 'of', 'doing', 'so']",0,"['why', 'do', 'we', 'factorize', 'variable', 'in', 'r', 'what', 'is', 'the', 'benefit', 'of', 'doing', 'so']","['factorize', 'variable', 'r', 'benefit']",factorize variable r benefit,0.0,0.0,14,28,1.8666666666666667,0,0,0,0,0,0,0,0
5008,knn question questionstestknearestneighborsalgorithm,knn question questionstestknearestneighborsalgorithm,"['knn', 'question', 'questionstestknearestneighborsalgorithm']",0,"['knn', 'question', 'questionstestknearestneighborsalgorithm']","['knn', 'question', 'questionstestknearestneighborsalgorithm']",knn question questionstestknearestneighborsalgorithm,0.0,0.0,3,52,13.0,0,0,0,0,0,0,0,0
5009,can anyone help in understanding the biasvariance tradeoff for a machine learning model,can anyone help in understanding the biasvariance tradeoff for a machine learning model,"['can', 'anyone', 'help', 'in', 'understanding', 'the', 'biasvariance', 'tradeoff', 'for', 'a', 'machine', 'learning', 'model']",0,"['can', 'anyone', 'help', 'in', 'understanding', 'the', 'biasvariance', 'tradeoff', 'for', 'a', 'machine', 'learning', 'model']","['anyone', 'help', 'understanding', 'biasvariance', 'tradeoff', 'machine', 'learning', 'model']",anyone help understanding biasvariance tradeoff machine learning model,0.0,0.0,13,70,5.0,0,0,0,0,0,0,0,0
5010,how to use tfidf feature of scikitlearn,how to use tfidf feature of scikitlearn,"['how', 'to', 'use', 'tfidf', 'feature', 'of', 'scikitlearn']",0,"['how', 'to', 'use', 'tfidf', 'feature', 'of', 'scikitlearn']","['use', 'tfidf', 'feature', 'scikitlearn']",use tfidf feature scikitlearn,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
5011,finetuning gpt twice for particular style of writing on a particular topic,finetuning gpt twice for particular style of writing on a particular topic,"['finetuning', 'gpt', 'twice', 'for', 'particular', 'style', 'of', 'writing', 'on', 'a', 'particular', 'topic']",0,"['finetuning', 'gpt', 'twice', 'for', 'particular', 'style', 'of', 'writing', 'on', 'a', 'particular', 'topic']","['finetuning', 'gpt', 'twice', 'particular', 'style', 'writing', 'particular', 'topic']",finetuning gpt twice particular style writing particular topic,0.1666666666666666,0.1666666666666666,12,62,4.769230769230769,0,0,0,0,0,0,0,0
5012,data linking in r,data linking in r,"['data', 'linking', 'in', 'r']",0,"['data', 'linking', 'in', 'r']","['data', 'linking', 'r']",data linking r,0.0,0.0,4,14,2.8,0,0,0,0,0,0,0,0
5013,dealing with multiple levels in qualitative data in machine learning,dealing with multiple levels in qualitative data in machine learning,"['dealing', 'with', 'multiple', 'levels', 'in', 'qualitative', 'data', 'in', 'machine', 'learning']",0,"['dealing', 'with', 'multiple', 'level', 'in', 'qualitative', 'data', 'in', 'machine', 'learning']","['dealing', 'multiple', 'level', 'qualitative', 'data', 'machine', 'learning']",dealing multiple level qualitative data machine learning,0.0,0.0,10,56,5.090909090909091,0,0,0,0,0,0,0,0
5014,parsimony principle,parsimony principle,"['parsimony', 'principle']",0,"['parsimony', 'principle']","['parsimony', 'principle']",parsimony principle,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
5015,asymmetric costs in regression,asymmetric costs in regression,"['asymmetric', 'costs', 'in', 'regression']",0,"['asymmetric', 'cost', 'in', 'regression']","['asymmetric', 'cost', 'regression']",asymmetric cost regression,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
5016,how to find percentage of total with groupby pandas,how to find percentage of total with groupby pandas,"['how', 'to', 'find', 'percentage', 'of', 'total', 'with', 'groupby', 'pandas']",0,"['how', 'to', 'find', 'percentage', 'of', 'total', 'with', 'groupby', 'panda']","['find', 'percentage', 'total', 'groupby', 'panda']",find percentage total groupby panda,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
5017,deep learning tutorial to build your own video classification model,deep learning tutorial to build your own video classification model,"['deep', 'learning', 'tutorial', 'to', 'build', 'your', 'own', 'video', 'classification', 'model']",0,"['deep', 'learning', 'tutorial', 'to', 'build', 'your', 'own', 'video', 'classification', 'model']","['deep', 'learning', 'tutorial', 'build', 'video', 'classification', 'model']",deep learning tutorial build video classification model,0.3,0.0,10,55,5.0,0,0,0,0,0,0,0,0
5018,how to remove entire row of missing values from a data frame in python,how to remove entire row of missing values from a data frame in python,"['how', 'to', 'remove', 'entire', 'row', 'of', 'missing', 'values', 'from', 'a', 'data', 'frame', 'in', 'python']",0,"['how', 'to', 'remove', 'entire', 'row', 'of', 'missing', 'value', 'from', 'a', 'data', 'frame', 'in', 'python']","['remove', 'entire', 'row', 'missing', 'value', 'data', 'frame', 'python']",remove entire row missing value data frame python,-0.1,-0.1,14,49,3.2666666666666666,0,0,0,0,0,0,0,0
5019,how to close a file in python,how to close a file in python,"['how', 'to', 'close', 'a', 'file', 'in', 'python']",0,"['how', 'to', 'close', 'a', 'file', 'in', 'python']","['close', 'file', 'python']",close file python,0.0,0.0,7,17,2.125,0,0,0,0,0,0,0,0
5020,how to select ml model when we have  classification output variable,how to select ml model when we have  classification output variable,"['how', 'to', 'select', 'ml', 'model', 'when', 'we', 'have', 'classification', 'output', 'variable']",1,"['how', 'to', 'select', 'ml', 'model', 'when', 'we', 'have', 'classification', 'output', 'variable']","['select', 'ml', 'model', 'classification', 'output', 'variable']",select ml model classification output variable,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
5021,is there any print magazine version or sort of print media where we can find out latest data science and analyst updates etc,is there any print magazine version or sort of print media where we can find out latest data science and analyst updates etc,"['is', 'there', 'any', 'print', 'magazine', 'version', 'or', 'sort', 'of', 'print', 'media', 'where', 'we', 'can', 'find', 'out', 'latest', 'data', 'science', 'and', 'analyst', 'updates', 'etc']",0,"['is', 'there', 'any', 'print', 'magazine', 'version', 'or', 'sort', 'of', 'print', 'medium', 'where', 'we', 'can', 'find', 'out', 'latest', 'data', 'science', 'and', 'analyst', 'update', 'etc']","['print', 'magazine', 'version', 'sort', 'print', 'medium', 'find', 'latest', 'data', 'science', 'analyst', 'update', 'etc']",print magazine version sort print medium find latest data science analyst update etc,0.5,0.5,23,84,3.5,0,0,0,0,0,0,0,0
5022,how should i prepare to participate for data science hackathon,how should i prepare to participate for data science hackathon,"['how', 'should', 'i', 'prepare', 'to', 'participate', 'for', 'data', 'science', 'hackathon']",0,"['how', 'should', 'i', 'prepare', 'to', 'participate', 'for', 'data', 'science', 'hackathon']","['prepare', 'participate', 'data', 'science', 'hackathon']",prepare participate data science hackathon,0.0,0.0,10,42,3.8181818181818183,0,0,0,0,0,0,0,0
5023,downloading tweets for twitter sentiment analysis,downloading tweets for twitter sentiment analysis,"['downloading', 'tweets', 'for', 'twitter', 'sentiment', 'analysis']",0,"['downloading', 'tweet', 'for', 'twitter', 'sentiment', 'analysis']","['downloading', 'tweet', 'twitter', 'sentiment', 'analysis']",downloading tweet twitter sentiment analysis,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
5024,sas procedures and functions,sas procedures and functions,"['sas', 'procedures', 'and', 'functions']",0,"['sa', 'procedure', 'and', 'function']","['sa', 'procedure', 'function']",sa procedure function,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
5025,how to predict mobile data offloading,how to predict mobile data offloading,"['how', 'to', 'predict', 'mobile', 'data', 'offloading']",0,"['how', 'to', 'predict', 'mobile', 'data', 'offloading']","['predict', 'mobile', 'data', 'offloading']",predict mobile data offloading,0.0,0.0,6,30,4.285714285714286,0,0,0,0,0,0,0,0
5026,how to use vowpal wabbit in python,how to use vowpal wabbit in python,"['how', 'to', 'use', 'vowpal', 'wabbit', 'in', 'python']",0,"['how', 'to', 'use', 'vowpal', 'wabbit', 'in', 'python']","['use', 'vowpal', 'wabbit', 'python']",use vowpal wabbit python,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
5027,problem in making submission,problem in making submission,"['problem', 'in', 'making', 'submission']",0,"['problem', 'in', 'making', 'submission']","['problem', 'making', 'submission']",problem making submission,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
5028,how to dealwork with dates in classification problem of purchasing y over x features using r language,how to dealwork with dates in classification problem of purchasing y over x features using r language,"['how', 'to', 'dealwork', 'with', 'dates', 'in', 'classification', 'problem', 'of', 'purchasing', 'y', 'over', 'x', 'features', 'using', 'r', 'language']",0,"['how', 'to', 'dealwork', 'with', 'date', 'in', 'classification', 'problem', 'of', 'purchasing', 'y', 'over', 'x', 'feature', 'using', 'r', 'language']","['dealwork', 'date', 'classification', 'problem', 'purchasing', 'x', 'feature', 'using', 'r', 'language']",dealwork date classification problem purchasing x feature using r language,0.0,0.0,17,74,4.111111111111111,0,0,0,0,0,0,0,0
5029,not able to plot in ipython in ubuntu,not able to plot in ipython in ubuntu,"['not', 'able', 'to', 'plot', 'in', 'ipython', 'in', 'ubuntu']",0,"['not', 'able', 'to', 'plot', 'in', 'ipython', 'in', 'ubuntu']","['able', 'plot', 'ipython', 'ubuntu']",able plot ipython ubuntu,-0.25,0.5,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
5030,welcome to practice problem  time series analysis,welcome to practice problem  time series analysis,"['welcome', 'to', 'practice', 'problem', 'time', 'series', 'analysis']",0,"['welcome', 'to', 'practice', 'problem', 'time', 'series', 'analysis']","['welcome', 'practice', 'problem', 'time', 'series', 'analysis']",welcome practice problem time series analysis,0.8,0.8,7,45,5.625,0,0,0,0,0,0,0,0
5031,how to extract weights in r mclust package,how to extract weights in r mclust package,"['how', 'to', 'extract', 'weights', 'in', 'r', 'mclust', 'package']",0,"['how', 'to', 'extract', 'weight', 'in', 'r', 'mclust', 'package']","['extract', 'weight', 'r', 'mclust', 'package']",extract weight r mclust package,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
5032,may i know how to visualize the tree model generated in mlr classifrpart or is it possible to print the tree rules,may i know how to visualize the tree model generated in mlr classifrpart or is it possible to print the tree rules,"['may', 'i', 'know', 'how', 'to', 'visualize', 'the', 'tree', 'model', 'generated', 'in', 'mlr', 'classifrpart', 'or', 'is', 'it', 'possible', 'to', 'print', 'the', 'tree', 'rules']",0,"['may', 'i', 'know', 'how', 'to', 'visualize', 'the', 'tree', 'model', 'generated', 'in', 'mlr', 'classifrpart', 'or', 'is', 'it', 'possible', 'to', 'print', 'the', 'tree', 'rule']","['may', 'know', 'visualize', 'tree', 'model', 'generated', 'mlr', 'classifrpart', 'possible', 'print', 'tree', 'rule']",may know visualize tree model generated mlr classifrpart possible print tree rule,0.0,0.0,22,81,3.5217391304347827,0,0,0,0,0,0,0,0
5033,please suggest topics in statistics relevant to a data scientist,please suggest topics in statistics relevant to a data scientist,"['please', 'suggest', 'topics', 'in', 'statistics', 'relevant', 'to', 'a', 'data', 'scientist']",0,"['please', 'suggest', 'topic', 'in', 'statistic', 'relevant', 'to', 'a', 'data', 'scientist']","['please', 'suggest', 'topic', 'statistic', 'relevant', 'data', 'scientist']",please suggest topic statistic relevant data scientist,0.4,0.4,10,54,4.909090909090909,0,0,0,0,0,0,0,0
5034,what is apriori algorithm can some one explain in simple terms,what is apriori algorithm can some one explain in simple terms,"['what', 'is', 'apriori', 'algorithm', 'can', 'some', 'one', 'explain', 'in', 'simple', 'terms']",0,"['what', 'is', 'apriori', 'algorithm', 'can', 'some', 'one', 'explain', 'in', 'simple', 'term']","['apriori', 'algorithm', 'one', 'explain', 'simple', 'term']",apriori algorithm one explain simple term,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
5035,what does the dropf argument in a matrix do in r,what does the dropf argument in a matrix do in r,"['what', 'does', 'the', 'dropf', 'argument', 'in', 'a', 'matrix', 'do', 'in', 'r']",0,"['what', 'doe', 'the', 'dropf', 'argument', 'in', 'a', 'matrix', 'do', 'in', 'r']","['doe', 'dropf', 'argument', 'matrix', 'r']",doe dropf argument matrix r,0.0,0.0,11,27,2.25,0,0,0,0,0,0,0,0
5036,how can i automate the following sort an entire table based on one column and then count the values in another column,how can i automate the following sort an entire table based on one column and then count the values in another column,"['how', 'can', 'i', 'automate', 'the', 'following', 'sort', 'an', 'entire', 'table', 'based', 'on', 'one', 'column', 'and', 'then', 'count', 'the', 'values', 'in', 'another', 'column']",0,"['how', 'can', 'i', 'automate', 'the', 'following', 'sort', 'an', 'entire', 'table', 'based', 'on', 'one', 'column', 'and', 'then', 'count', 'the', 'value', 'in', 'another', 'column']","['automate', 'following', 'sort', 'entire', 'table', 'based', 'one', 'column', 'count', 'value', 'another', 'column']",automate following sort entire table based one column count value another column,0.0,0.0,22,80,3.4782608695652173,0,0,0,0,0,0,0,0
5037,inverse differencing a time series,inverse differencing a time series,"['inverse', 'differencing', 'a', 'time', 'series']",0,"['inverse', 'differencing', 'a', 'time', 'series']","['inverse', 'differencing', 'time', 'series']",inverse differencing time series,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
5038,multiclass classification in r,multiclass classification in r,"['multiclass', 'classification', 'in', 'r']",0,"['multiclass', 'classification', 'in', 'r']","['multiclass', 'classification', 'r']",multiclass classification r,0.0,0.0,4,27,5.4,0,0,0,0,0,0,0,0
5039,how to improve use of data augmentation,how to improve use of data augmentation,"['how', 'to', 'improve', 'use', 'of', 'data', 'augmentation']",0,"['how', 'to', 'improve', 'use', 'of', 'data', 'augmentation']","['improve', 'use', 'data', 'augmentation']",improve use data augmentation,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
5040,how to display top  sales person name in qlikview dashboard,how to display top  sales person name in qlikview dashboard,"['how', 'to', 'display', 'top', 'sales', 'person', 'name', 'in', 'qlikview', 'dashboard']",1,"['how', 'to', 'display', 'top', 'sale', 'person', 'name', 'in', 'qlikview', 'dashboard']","['display', 'top', 'sale', 'person', 'name', 'qlikview', 'dashboard']",display top sale person name qlikview dashboard,0.5,0.5,10,47,4.2727272727272725,0,0,0,0,0,0,0,0
5041,what does lazy means in the tm package in r,what does lazy means in the tm package in r,"['what', 'does', 'lazy', 'means', 'in', 'the', 'tm', 'package', 'in', 'r']",0,"['what', 'doe', 'lazy', 'mean', 'in', 'the', 'tm', 'package', 'in', 'r']","['doe', 'lazy', 'mean', 'tm', 'package', 'r']",doe lazy mean tm package r,-0.25,-0.28125,10,26,2.3636363636363638,0,0,0,0,0,0,0,0
5042,decision tree with continuous variables,decision tree with continuous variables,"['decision', 'tree', 'with', 'continuous', 'variables']",0,"['decision', 'tree', 'with', 'continuous', 'variable']","['decision', 'tree', 'continuous', 'variable']",decision tree continuous variable,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
5043,generating average values on dictionary of datasets,generating average values on dictionary of datasets,"['generating', 'average', 'values', 'on', 'dictionary', 'of', 'datasets']",0,"['generating', 'average', 'value', 'on', 'dictionary', 'of', 'datasets']","['generating', 'average', 'value', 'dictionary', 'datasets']",generating average value dictionary datasets,-0.15,-0.15,7,44,5.5,0,0,0,0,0,0,0,0
5044,how to display corresponding sheets in tableau dashboard,how to display corresponding sheets in tableau dashboard,"['how', 'to', 'display', 'corresponding', 'sheets', 'in', 'tableau', 'dashboard']",0,"['how', 'to', 'display', 'corresponding', 'sheet', 'in', 'tableau', 'dashboard']","['display', 'corresponding', 'sheet', 'tableau', 'dashboard']",display corresponding sheet tableau dashboard,0.0,0.0,8,45,5.0,0,0,0,0,0,0,0,0
5045,how to do inventory forecasting using r,how to do inventory forecasting using r,"['how', 'to', 'do', 'inventory', 'forecasting', 'using', 'r']",0,"['how', 'to', 'do', 'inventory', 'forecasting', 'using', 'r']","['inventory', 'forecasting', 'using', 'r']",inventory forecasting using r,0.0,0.0,7,29,3.625,0,0,0,0,0,0,0,0
5046,debugging in r function in r,debugging in r function in r,"['debugging', 'in', 'r', 'function', 'in', 'r']",0,"['debugging', 'in', 'r', 'function', 'in', 'r']","['debugging', 'r', 'function', 'r']",debugging r function r,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
5047,understanding backpropagation algorithm in neural network,understanding backpropagation algorithm in neural network,"['understanding', 'backpropagation', 'algorithm', 'in', 'neural', 'network']",0,"['understanding', 'backpropagation', 'algorithm', 'in', 'neural', 'network']","['understanding', 'backpropagation', 'algorithm', 'neural', 'network']",understanding backpropagation algorithm neural network,0.0,0.0,6,54,7.714285714285714,0,0,0,0,0,0,0,0
5048,predict st day of th week,predict st day of th week,"['predict', 'st', 'day', 'of', 'th', 'week']",0,"['predict', 'st', 'day', 'of', 'th', 'week']","['predict', 'st', 'day', 'th', 'week']",predict st day th week,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
5049,error while making predicition using a logistic regression model,error while making predicition using a logistic regression model,"['error', 'while', 'making', 'predicition', 'using', 'a', 'logistic', 'regression', 'model']",0,"['error', 'while', 'making', 'predicition', 'using', 'a', 'logistic', 'regression', 'model']","['error', 'making', 'predicition', 'using', 'logistic', 'regression', 'model']",error making predicition using logistic regression model,0.0,0.0,9,56,5.6,0,0,0,0,0,0,0,0
5050,howto use svd when matrix of very large data in r,howto use svd when matrix of very large data in r,"['howto', 'use', 'svd', 'when', 'matrix', 'of', 'very', 'large', 'data', 'in', 'r']",0,"['howto', 'use', 'svd', 'when', 'matrix', 'of', 'very', 'large', 'data', 'in', 'r']","['howto', 'use', 'svd', 'matrix', 'large', 'data', 'r']",howto use svd matrix large data r,0.2785714285714286,0.2142857142857142,11,33,2.75,0,0,0,0,0,0,0,0
5051,minimax probability machine regressionmpmr,minimax probability machine regressionmpmr,"['minimax', 'probability', 'machine', 'regressionmpmr']",0,"['minimax', 'probability', 'machine', 'regressionmpmr']","['minimax', 'probability', 'machine', 'regressionmpmr']",minimax probability machine regressionmpmr,0.0,0.0,4,42,8.4,0,0,0,0,0,0,0,0
5052,how can i test if my logistic regression model is the best one,how can i test if my logistic regression model is the best one,"['how', 'can', 'i', 'test', 'if', 'my', 'logistic', 'regression', 'model', 'is', 'the', 'best', 'one']",0,"['how', 'can', 'i', 'test', 'if', 'my', 'logistic', 'regression', 'model', 'is', 'the', 'best', 'one']","['test', 'logistic', 'regression', 'model', 'best', 'one']",test logistic regression model best one,1.0,1.0,13,39,2.7857142857142856,0,0,0,0,0,0,0,0
5053,how is pricing strategy for credit cards made effective using predictive analyticsregression analysis,how is pricing strategy for credit cards made effective using predictive analyticsregression analysis,"['how', 'is', 'pricing', 'strategy', 'for', 'credit', 'cards', 'made', 'effective', 'using', 'predictive', 'analyticsregression', 'analysis']",0,"['how', 'is', 'pricing', 'strategy', 'for', 'credit', 'card', 'made', 'effective', 'using', 'predictive', 'analyticsregression', 'analysis']","['pricing', 'strategy', 'credit', 'card', 'made', 'effective', 'using', 'predictive', 'analyticsregression', 'analysis']",pricing strategy credit card made effective using predictive analyticsregression analysis,0.6,0.6,13,89,6.357142857142857,0,0,0,0,0,0,0,0
5054,how many clusters are enough in kmeans clustering,how many clusters are enough in kmeans clustering,"['how', 'many', 'clusters', 'are', 'enough', 'in', 'kmeans', 'clustering']",0,"['how', 'many', 'cluster', 'are', 'enough', 'in', 'kmeans', 'clustering']","['many', 'cluster', 'enough', 'kmeans', 'clustering']",many cluster enough kmeans clustering,0.25,0.25,8,37,4.111111111111111,0,0,0,0,0,0,0,0
5055,change scale of a plot in seabornpython,change scale of a plot in seabornpython,"['change', 'scale', 'of', 'a', 'plot', 'in', 'seabornpython']",0,"['change', 'scale', 'of', 'a', 'plot', 'in', 'seabornpython']","['change', 'scale', 'plot', 'seabornpython']",change scale plot seabornpython,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
5056,how to present transformed factors to clients,how to present transformed factors to clients,"['how', 'to', 'present', 'transformed', 'factors', 'to', 'clients']",0,"['how', 'to', 'present', 'transformed', 'factor', 'to', 'client']","['present', 'transformed', 'factor', 'client']",present transformed factor client,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
5057,how to delete existing level of a categorical variable,how to delete existing level of a categorical variable,"['how', 'to', 'delete', 'existing', 'level', 'of', 'a', 'categorical', 'variable']",0,"['how', 'to', 'delete', 'existing', 'level', 'of', 'a', 'categorical', 'variable']","['delete', 'existing', 'level', 'categorical', 'variable']",delete existing level categorical variable,0.0,0.0,9,42,4.2,0,0,0,0,0,0,0,0
5058,how to predict class labels using xgboost in python when objective function is binarylogistic,how to predict class labels using xgboost in python when objective function is binarylogistic,"['how', 'to', 'predict', 'class', 'labels', 'using', 'xgboost', 'in', 'python', 'when', 'objective', 'function', 'is', 'binarylogistic']",0,"['how', 'to', 'predict', 'class', 'label', 'using', 'xgboost', 'in', 'python', 'when', 'objective', 'function', 'is', 'binarylogistic']","['predict', 'class', 'label', 'using', 'xgboost', 'python', 'objective', 'function', 'binarylogistic']",predict class label using xgboost python objective function binarylogistic,0.0,0.0,14,74,4.933333333333334,0,0,0,0,0,0,0,0
5059,r implementation of ftrl and vowpal wabbit,r implementation of ftrl and vowpal wabbit,"['r', 'implementation', 'of', 'ftrl', 'and', 'vowpal', 'wabbit']",0,"['r', 'implementation', 'of', 'ftrl', 'and', 'vowpal', 'wabbit']","['r', 'implementation', 'ftrl', 'vowpal', 'wabbit']",r implementation ftrl vowpal wabbit,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
5060,how to create a termdocument matrix in python,how to create a termdocument matrix in python,"['how', 'to', 'create', 'a', 'termdocument', 'matrix', 'in', 'python']",0,"['how', 'to', 'create', 'a', 'termdocument', 'matrix', 'in', 'python']","['create', 'termdocument', 'matrix', 'python']",create termdocument matrix python,0.0,0.0,8,33,3.6666666666666665,0,0,0,0,0,0,0,0
5061,which simulations are being considered for traditional data science algorithms,which simulations are being considered for traditional data science algorithms,"['which', 'simulations', 'are', 'being', 'considered', 'for', 'traditional', 'data', 'science', 'algorithms']",0,"['which', 'simulation', 'are', 'being', 'considered', 'for', 'traditional', 'data', 'science', 'algorithm']","['simulation', 'considered', 'traditional', 'data', 'science', 'algorithm']",simulation considered traditional data science algorithm,0.0,0.0,10,56,5.090909090909091,0,0,0,0,0,0,0,0
5062,how to use ml to predict the age at which rail will fail,how to use ml to predict the age at which rail will fail,"['how', 'to', 'use', 'ml', 'to', 'predict', 'the', 'age', 'at', 'which', 'rail', 'will', 'fail']",0,"['how', 'to', 'use', 'ml', 'to', 'predict', 'the', 'age', 'at', 'which', 'rail', 'will', 'fail']","['use', 'ml', 'predict', 'age', 'rail', 'fail']",use ml predict age rail fail,-0.5,-0.5,13,28,2.0,0,0,0,0,0,0,0,0
5063,why doesnt exception handling work in some cases,why doesnt exception handling work in some cases,"['why', 'doesnt', 'exception', 'handling', 'work', 'in', 'some', 'cases']",0,"['why', 'doesnt', 'exception', 'handling', 'work', 'in', 'some', 'case']","['doesnt', 'exception', 'handling', 'work', 'case']",doesnt exception handling work case,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
5064,plausible error in rmse calculation by server,plausible error in rmse calculation by server,"['plausible', 'error', 'in', 'rmse', 'calculation', 'by', 'server']",0,"['plausible', 'error', 'in', 'rmse', 'calculation', 'by', 'server']","['plausible', 'error', 'rmse', 'calculation', 'server']",plausible error rmse calculation server,0.5,0.5,7,39,4.875,0,0,0,0,0,0,0,0
5065,error  unable to read the csv file in pandas,error  unable to read the csv file in pandas,"['error', 'unable', 'to', 'read', 'the', 'csv', 'file', 'in', 'pandas']",0,"['error', 'unable', 'to', 'read', 'the', 'csv', 'file', 'in', 'panda']","['error', 'unable', 'read', 'csv', 'file', 'panda']",error unable read csv file panda,-0.5,-0.5,9,32,3.2,0,0,0,0,0,0,0,0
5066,only test specific combinations of hyperparameters keras tuner,only test specific combinations of hyperparameters keras tuner,"['only', 'test', 'specific', 'combinations', 'of', 'hyperparameters', 'keras', 'tuner']",0,"['only', 'test', 'specific', 'combination', 'of', 'hyperparameters', 'kera', 'tuner']","['test', 'specific', 'combination', 'hyperparameters', 'kera', 'tuner']",test specific combination hyperparameters kera tuner,0.0,0.0,8,52,5.777777777777778,0,0,0,0,0,0,0,0
5067,packages to impute the missing values in r other than mice,packages to impute the missing values in r other than mice,"['packages', 'to', 'impute', 'the', 'missing', 'values', 'in', 'r', 'other', 'than', 'mice']",0,"['package', 'to', 'impute', 'the', 'missing', 'value', 'in', 'r', 'other', 'than', 'mouse']","['package', 'impute', 'missing', 'value', 'r', 'mouse']",package impute missing value r mouse,-0.1625,-0.2,11,36,3.0,0,0,0,0,0,0,0,0
5068,help regarding whether to choose intern programs or fresher jobs for data scientist roles,help regarding whether to choose intern programs or fresher jobs for data scientist roles,"['help', 'regarding', 'whether', 'to', 'choose', 'intern', 'programs', 'or', 'fresher', 'jobs', 'for', 'data', 'scientist', 'roles']",0,"['help', 'regarding', 'whether', 'to', 'choose', 'intern', 'program', 'or', 'fresher', 'job', 'for', 'data', 'scientist', 'role']","['help', 'regarding', 'whether', 'choose', 'intern', 'program', 'fresher', 'job', 'data', 'scientist', 'role']",help regarding whether choose intern program fresher job data scientist role,0.0,0.0,14,76,5.066666666666666,0,0,0,0,0,0,0,0
5069,manual ordering,manual ordering,"['manual', 'ordering']",0,"['manual', 'ordering']","['manual', 'ordering']",manual ordering,0.0,0.0,2,15,5.0,0,0,0,0,0,0,0,0
5070,which algorithms are good for multiclass classification problems,which algorithms are good for multiclass classification problems,"['which', 'algorithms', 'are', 'good', 'for', 'multiclass', 'classification', 'problems']",0,"['which', 'algorithm', 'are', 'good', 'for', 'multiclass', 'classification', 'problem']","['algorithm', 'good', 'multiclass', 'classification', 'problem']",algorithm good multiclass classification problem,0.7,0.7,8,48,5.333333333333333,0,0,0,0,0,0,0,0
5071,linear regression,linear regression,"['linear', 'regression']",0,"['linear', 'regression']","['linear', 'regression']",linear regression,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
5072,parameter estimation of mcar model with r,parameter estimation of mcar model with r,"['parameter', 'estimation', 'of', 'mcar', 'model', 'with', 'r']",0,"['parameter', 'estimation', 'of', 'mcar', 'model', 'with', 'r']","['parameter', 'estimation', 'mcar', 'model', 'r']",parameter estimation mcar model r,0.0,0.0,7,33,4.125,0,0,0,0,0,0,0,0
5073,how can i show last reload time in qlikview,how can i show last reload time in qlikview,"['how', 'can', 'i', 'show', 'last', 'reload', 'time', 'in', 'qlikview']",0,"['how', 'can', 'i', 'show', 'last', 'reload', 'time', 'in', 'qlikview']","['show', 'last', 'reload', 'time', 'qlikview']",show last reload time qlikview,0.0,0.0,9,30,3.0,0,0,0,0,0,0,0,0
5074,which multi objective optimization technique is used by kmeans clustering and can someone share some information about the optimization technique,which multi objective optimization technique is used by kmeans clustering and can someone share some information about the optimization technique,"['which', 'multi', 'objective', 'optimization', 'technique', 'is', 'used', 'by', 'kmeans', 'clustering', 'and', 'can', 'someone', 'share', 'some', 'information', 'about', 'the', 'optimization', 'technique']",0,"['which', 'multi', 'objective', 'optimization', 'technique', 'is', 'used', 'by', 'kmeans', 'clustering', 'and', 'can', 'someone', 'share', 'some', 'information', 'about', 'the', 'optimization', 'technique']","['multi', 'objective', 'optimization', 'technique', 'used', 'kmeans', 'clustering', 'someone', 'share', 'information', 'optimization', 'technique']",multi objective optimization technique used kmeans clustering someone share information optimization technique,0.0,0.0,20,110,5.238095238095238,0,0,0,0,0,0,0,0
5075,test the bestfit distribution and return parameter and p values,test the bestfit distribution and return parameter and p values,"['test', 'the', 'bestfit', 'distribution', 'and', 'return', 'parameter', 'and', 'p', 'values']",0,"['test', 'the', 'bestfit', 'distribution', 'and', 'return', 'parameter', 'and', 'p', 'value']","['test', 'bestfit', 'distribution', 'return', 'parameter', 'p', 'value']",test bestfit distribution return parameter p value,0.0,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
5076,a complete list of important natural language processing frameworks you should know nlp infographic,a complete list of important natural language processing frameworks you should know nlp infographic,"['a', 'complete', 'list', 'of', 'important', 'natural', 'language', 'processing', 'frameworks', 'you', 'should', 'know', 'nlp', 'infographic']",0,"['a', 'complete', 'list', 'of', 'important', 'natural', 'language', 'processing', 'framework', 'you', 'should', 'know', 'nlp', 'infographic']","['complete', 'list', 'important', 'natural', 'language', 'processing', 'framework', 'know', 'nlp', 'infographic']",complete list important natural language processing framework know nlp infographic,0.1999999999999999,0.1999999999999999,14,82,5.466666666666667,0,0,0,0,0,0,0,0
5077,is linear regression fit for this data,is linear regression fit for this data,"['is', 'linear', 'regression', 'fit', 'for', 'this', 'data']",0,"['is', 'linear', 'regression', 'fit', 'for', 'this', 'data']","['linear', 'regression', 'fit', 'data']",linear regression fit data,0.4,0.4,7,26,3.25,0,0,0,0,0,0,0,0
5078,difference in train and test values,difference in train and test values,"['difference', 'in', 'train', 'and', 'test', 'values']",0,"['difference', 'in', 'train', 'and', 'test', 'value']","['difference', 'train', 'test', 'value']",difference train test value,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
5079,how to start project in data science,how to start project in data science,"['how', 'to', 'start', 'project', 'in', 'data', 'science']",0,"['how', 'to', 'start', 'project', 'in', 'data', 'science']","['start', 'project', 'data', 'science']",start project data science,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
5080,r studio error  error in xjjiseq  vjj  replacement has length zero,r studio error  error in xjjiseq  vjj  replacement has length zero,"['r', 'studio', 'error', 'error', 'in', 'xjjiseq', 'vjj', 'replacement', 'has', 'length', 'zero']",0,"['r', 'studio', 'error', 'error', 'in', 'xjjiseq', 'vjj', 'replacement', 'ha', 'length', 'zero']","['r', 'studio', 'error', 'error', 'xjjiseq', 'vjj', 'replacement', 'ha', 'length', 'zero']",r studio error error xjjiseq vjj replacement ha length zero,0.0,0.0,11,59,4.916666666666667,0,0,0,0,0,0,0,0
5081,private leader board ranking in mini data hack,private leader board ranking in mini data hack,"['private', 'leader', 'board', 'ranking', 'in', 'mini', 'data', 'hack']",0,"['private', 'leader', 'board', 'ranking', 'in', 'mini', 'data', 'hack']","['private', 'leader', 'board', 'ranking', 'mini', 'data', 'hack']",private leader board ranking mini data hack,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
5082,how convergence is generated in kmeans algorithm,how convergence is generated in kmeans algorithm,"['how', 'convergence', 'is', 'generated', 'in', 'kmeans', 'algorithm']",0,"['how', 'convergence', 'is', 'generated', 'in', 'kmeans', 'algorithm']","['convergence', 'generated', 'kmeans', 'algorithm']",convergence generated kmeans algorithm,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
5083,how to create pivot table from two or more sheets in excel,how to create pivot table from two or more sheets in excel,"['how', 'to', 'create', 'pivot', 'table', 'from', 'two', 'or', 'more', 'sheets', 'in', 'excel']",0,"['how', 'to', 'create', 'pivot', 'table', 'from', 'two', 'or', 'more', 'sheet', 'in', 'excel']","['create', 'pivot', 'table', 'two', 'sheet', 'excel']",create pivot table two sheet excel,0.5,0.0,12,34,2.6153846153846154,0,0,0,0,0,0,0,0
5084,what you can do to make educational technology work for you,what you can do to make educational technology work for you,"['what', 'you', 'can', 'do', 'to', 'make', 'educational', 'technology', 'work', 'for', 'you']",0,"['what', 'you', 'can', 'do', 'to', 'make', 'educational', 'technology', 'work', 'for', 'you']","['make', 'educational', 'technology', 'work']",make educational technology work,0.25,0.25,11,32,2.6666666666666665,0,0,0,0,0,0,0,0
5085,error in unitticposc mm  x and units must have length   while using the qplot function in r,error in unitticposc mm  x and units must have length   while using the qplot function in r,"['error', 'in', 'unitticposc', 'mm', 'x', 'and', 'units', 'must', 'have', 'length', 'while', 'using', 'the', 'qplot', 'function', 'in', 'r']",1,"['error', 'in', 'unitticposc', 'mm', 'x', 'and', 'unit', 'must', 'have', 'length', 'while', 'using', 'the', 'qplot', 'function', 'in', 'r']","['error', 'unitticposc', 'mm', 'x', 'unit', 'must', 'length', 'using', 'qplot', 'function', 'r']",error unitticposc mm x unit must length using qplot function r,0.0,0.0,17,62,3.4444444444444446,0,0,0,0,0,0,0,0
5086,annotation timeline chart,annotation timeline chart,"['annotation', 'timeline', 'chart']",0,"['annotation', 'timeline', 'chart']","['annotation', 'timeline', 'chart']",annotation timeline chart,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
5087,statistics for analytics,statistics for analytics,"['statistics', 'for', 'analytics']",0,"['statistic', 'for', 'analytics']","['statistic', 'analytics']",statistic analytics,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
5088,check overftting of model  validate the model,check overftting of model  validate the model,"['check', 'overftting', 'of', 'model', 'validate', 'the', 'model']",0,"['check', 'overftting', 'of', 'model', 'validate', 'the', 'model']","['check', 'overftting', 'model', 'validate', 'model']",check overftting model validate model,0.0,0.0,7,37,4.625,0,0,0,0,0,0,0,0
5089,installing r in the amazon cloud,installing r in the amazon cloud,"['installing', 'r', 'in', 'the', 'amazon', 'cloud']",0,"['installing', 'r', 'in', 'the', 'amazon', 'cloud']","['installing', 'r', 'amazon', 'cloud']",installing r amazon cloud,0.0,0.0,6,25,3.5714285714285716,0,0,0,0,0,0,0,0
5090,data analysis and visualization application,data analysis and visualization application,"['data', 'analysis', 'and', 'visualization', 'application']",0,"['data', 'analysis', 'and', 'visualization', 'application']","['data', 'analysis', 'visualization', 'application']",data analysis visualization application,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
5091,machine learning  data science interns,machine learning  data science interns,"['machine', 'learning', 'data', 'science', 'interns']",0,"['machine', 'learning', 'data', 'science', 'intern']","['machine', 'learning', 'data', 'science', 'intern']",machine learning data science intern,0.0,0.0,5,36,6.0,0,0,0,0,0,0,0,0
5092,nround parameter in xgboost,nround parameter in xgboost,"['nround', 'parameter', 'in', 'xgboost']",0,"['nround', 'parameter', 'in', 'xgboost']","['nround', 'parameter', 'xgboost']",nround parameter xgboost,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
5093,clustering questions,clustering questions,"['clustering', 'questions']",0,"['clustering', 'question']","['clustering', 'question']",clustering question,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
5094,how to use dplyr for solving these questions,how to use dplyr for solving these questions,"['how', 'to', 'use', 'dplyr', 'for', 'solving', 'these', 'questions']",0,"['how', 'to', 'use', 'dplyr', 'for', 'solving', 'these', 'question']","['use', 'dplyr', 'solving', 'question']",use dplyr solving question,0.0,0.0,8,26,2.888888888888889,0,0,0,0,0,0,0,0
5095,big mart sell key error,big mart sell key error,"['big', 'mart', 'sell', 'key', 'error']",0,"['big', 'mart', 'sell', 'key', 'error']","['big', 'mart', 'sell', 'key', 'error']",big mart sell key error,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
5096,share your approach  datahack premier league,share your approach  datahack premier league,"['share', 'your', 'approach', 'datahack', 'premier', 'league']",0,"['share', 'your', 'approach', 'datahack', 'premier', 'league']","['share', 'approach', 'datahack', 'premier', 'league']",share approach datahack premier league,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
5097,how to perform machine learning on data that has multiple rows for one response value,how to perform machine learning on data that has multiple rows for one response value,"['how', 'to', 'perform', 'machine', 'learning', 'on', 'data', 'that', 'has', 'multiple', 'rows', 'for', 'one', 'response', 'value']",0,"['how', 'to', 'perform', 'machine', 'learning', 'on', 'data', 'that', 'ha', 'multiple', 'row', 'for', 'one', 'response', 'value']","['perform', 'machine', 'learning', 'data', 'ha', 'multiple', 'row', 'one', 'response', 'value']",perform machine learning data ha multiple row one response value,0.0,0.0,15,64,4.0,0,0,0,0,0,0,0,0
5098,need help in approaching an analytics interview question,need help in approaching an analytics interview question,"['need', 'help', 'in', 'approaching', 'an', 'analytics', 'interview', 'question']",0,"['need', 'help', 'in', 'approaching', 'an', 'analytics', 'interview', 'question']","['need', 'help', 'approaching', 'analytics', 'interview', 'question']",need help approaching analytics interview question,0.0,0.0,8,50,5.555555555555555,0,0,0,0,0,0,0,0
5099,how to drop values from the column of a data frame,how to drop values from the column of a data frame,"['how', 'to', 'drop', 'values', 'from', 'the', 'column', 'of', 'a', 'data', 'frame']",0,"['how', 'to', 'drop', 'value', 'from', 'the', 'column', 'of', 'a', 'data', 'frame']","['drop', 'value', 'column', 'data', 'frame']",drop value column data frame,0.0,0.0,11,28,2.3333333333333335,0,0,0,0,0,0,0,0
5100,applying for loop to pandas dataframe in python,applying for loop to pandas dataframe in python,"['applying', 'for', 'loop', 'to', 'pandas', 'dataframe', 'in', 'python']",0,"['applying', 'for', 'loop', 'to', 'panda', 'dataframe', 'in', 'python']","['applying', 'loop', 'panda', 'dataframe', 'python']",applying loop panda dataframe python,0.0,0.0,8,36,4.0,0,0,0,0,0,0,0,0
5101,brand engagement score,brand engagement score,"['brand', 'engagement', 'score']",0,"['brand', 'engagement', 'score']","['brand', 'engagement', 'score']",brand engagement score,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
5102,help me to understand p and e functions in qlikview,help me to understand p and e functions in qlikview,"['help', 'me', 'to', 'understand', 'p', 'and', 'e', 'functions', 'in', 'qlikview']",0,"['help', 'me', 'to', 'understand', 'p', 'and', 'e', 'function', 'in', 'qlikview']","['help', 'understand', 'p', 'e', 'function', 'qlikview']",help understand p e function qlikview,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
5103,pca in regression analysis,pca in regression analysis,"['pca', 'in', 'regression', 'analysis']",0,"['pca', 'in', 'regression', 'analysis']","['pca', 'regression', 'analysis']",pca regression analysis,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
5104,use of  in place of  for assignment in r,use of  in place of  for assignment in r,"['use', 'of', 'in', 'place', 'of', 'for', 'assignment', 'in', 'r']",0,"['use', 'of', 'in', 'place', 'of', 'for', 'assignment', 'in', 'r']","['use', 'place', 'assignment', 'r']",use place assignment r,0.0,0.0,9,22,2.2,0,0,0,0,0,0,0,0
5105,how to generate repeated samples in r,how to generate repeated samples in r,"['how', 'to', 'generate', 'repeated', 'samples', 'in', 'r']",0,"['how', 'to', 'generate', 'repeated', 'sample', 'in', 'r']","['generate', 'repeated', 'sample', 'r']",generate repeated sample r,0.0,0.0,7,26,3.25,0,0,0,0,0,0,0,0
5106,no msc data science in india,no msc data science in india,"['no', 'msc', 'data', 'science', 'in', 'india']",0,"['no', 'msc', 'data', 'science', 'in', 'india']","['msc', 'data', 'science', 'india']",msc data science india,0.0,0.0,6,22,3.142857142857143,0,0,0,0,0,0,0,0
5107,sources for heathcare related data sets,sources for heathcare related data sets,"['sources', 'for', 'heathcare', 'related', 'data', 'sets']",0,"['source', 'for', 'heathcare', 'related', 'data', 'set']","['source', 'heathcare', 'related', 'data', 'set']",source heathcare related data set,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
5108,data security with h in r,data security with h in r,"['data', 'security', 'with', 'h', 'in', 'r']",0,"['data', 'security', 'with', 'h', 'in', 'r']","['data', 'security', 'h', 'r']",data security h r,0.0,0.0,6,17,2.4285714285714284,0,0,0,0,0,0,0,0
5109,how can we break link between tables in qlikview,how can we break link between tables in qlikview,"['how', 'can', 'we', 'break', 'link', 'between', 'tables', 'in', 'qlikview']",0,"['how', 'can', 'we', 'break', 'link', 'between', 'table', 'in', 'qlikview']","['break', 'link', 'table', 'qlikview']",break link table qlikview,0.0,0.0,9,25,2.5,0,0,0,0,0,0,0,0
5110,rpartcontrol to avoid overfitting,rpartcontrol to avoid overfitting,"['rpartcontrol', 'to', 'avoid', 'overfitting']",0,"['rpartcontrol', 'to', 'avoid', 'overfitting']","['rpartcontrol', 'avoid', 'overfitting']",rpartcontrol avoid overfitting,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
5111,bacp from great lakes,bacp from great lakes,"['bacp', 'from', 'great', 'lakes']",0,"['bacp', 'from', 'great', 'lake']","['bacp', 'great', 'lake']",bacp great lake,0.8,0.8,4,15,3.0,0,0,0,0,0,0,0,0
5112,eextending faster rcnn algorithm for object detection,eextending faster rcnn algorithm for object detection,"['eextending', 'faster', 'rcnn', 'algorithm', 'for', 'object', 'detection']",0,"['eextending', 'faster', 'rcnn', 'algorithm', 'for', 'object', 'detection']","['eextending', 'faster', 'rcnn', 'algorithm', 'object', 'detection']",eextending faster rcnn algorithm object detection,0.0,0.0,7,49,6.125,0,0,0,0,0,0,0,0
5113,how to do bagged logistic regression in r plz reply its urgent,how to do bagged logistic regression in r plz reply its urgent,"['how', 'to', 'do', 'bagged', 'logistic', 'regression', 'in', 'r', 'plz', 'reply', 'its', 'urgent']",0,"['how', 'to', 'do', 'bagged', 'logistic', 'regression', 'in', 'r', 'plz', 'reply', 'it', 'urgent']","['bagged', 'logistic', 'regression', 'r', 'plz', 'reply', 'urgent']",bagged logistic regression r plz reply urgent,0.0,0.0,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
5114,heatmaps correlation,heatmaps correlation,"['heatmaps', 'correlation']",0,"['heatmaps', 'correlation']","['heatmaps', 'correlation']",heatmaps correlation,0.0,0.0,2,20,6.666666666666667,0,0,0,0,0,0,0,0
5115,difference between wide and long data format,difference between wide and long data format,"['difference', 'between', 'wide', 'and', 'long', 'data', 'format']",0,"['difference', 'between', 'wide', 'and', 'long', 'data', 'format']","['difference', 'wide', 'long', 'data', 'format']",difference wide long data format,-0.075,-0.075,7,32,4.0,0,0,0,0,0,0,0,0
5116,how to deal with r code execution error,how to deal with r code execution error,"['how', 'to', 'deal', 'with', 'r', 'code', 'execution', 'error']",0,"['how', 'to', 'deal', 'with', 'r', 'code', 'execution', 'error']","['deal', 'r', 'code', 'execution', 'error']",deal r code execution error,0.0,0.0,8,27,3.0,0,0,0,0,0,0,0,0
5117,can somebody please suggest project idea combing machine learning and bioinformatics,can somebody please suggest project idea combing machine learning and bioinformatics,"['can', 'somebody', 'please', 'suggest', 'project', 'idea', 'combing', 'machine', 'learning', 'and', 'bioinformatics']",0,"['can', 'somebody', 'please', 'suggest', 'project', 'idea', 'combing', 'machine', 'learning', 'and', 'bioinformatics']","['somebody', 'please', 'suggest', 'project', 'idea', 'combing', 'machine', 'learning', 'bioinformatics']",somebody please suggest project idea combing machine learning bioinformatics,0.0,0.0,11,76,6.333333333333333,0,0,0,0,0,0,0,0
5118,business analytics question,business analytics question,"['business', 'analytics', 'question']",0,"['business', 'analytics', 'question']","['business', 'analytics', 'question']",business analytics question,0.0,0.0,3,27,6.75,0,0,0,0,0,0,0,0
5119,txt mining query,txt mining query,"['txt', 'mining', 'query']",0,"['txt', 'mining', 'query']","['txt', 'mining', 'query']",txt mining query,0.0,0.0,3,16,4.0,0,0,0,0,0,0,0,0
5120,deeplab  where to get the initial checkpoint file,deeplab  where to get the initial checkpoint file,"['deeplab', 'where', 'to', 'get', 'the', 'initial', 'checkpoint', 'file']",0,"['deeplab', 'where', 'to', 'get', 'the', 'initial', 'checkpoint', 'file']","['deeplab', 'get', 'initial', 'checkpoint', 'file']",deeplab get initial checkpoint file,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
5121,regarding the loan prediction problem,regarding the loan prediction problem,"['regarding', 'the', 'loan', 'prediction', 'problem']",0,"['regarding', 'the', 'loan', 'prediction', 'problem']","['regarding', 'loan', 'prediction', 'problem']",regarding loan prediction problem,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
5122,how do i calculate the log likelihood with variables in logistic regression in r,how do i calculate the log likelihood with variables in logistic regression in r,"['how', 'do', 'i', 'calculate', 'the', 'log', 'likelihood', 'with', 'variables', 'in', 'logistic', 'regression', 'in', 'r']",0,"['how', 'do', 'i', 'calculate', 'the', 'log', 'likelihood', 'with', 'variable', 'in', 'logistic', 'regression', 'in', 'r']","['calculate', 'log', 'likelihood', 'variable', 'logistic', 'regression', 'r']",calculate log likelihood variable logistic regression r,0.0,0.0,14,55,3.6666666666666665,0,0,0,0,0,0,0,0
5123,operations research and analytics,operations research and analytics,"['operations', 'research', 'and', 'analytics']",0,"['operation', 'research', 'and', 'analytics']","['operation', 'research', 'analytics']",operation research analytics,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
5124,how to profile a user,how to profile a user,"['how', 'to', 'profile', 'a', 'user']",0,"['how', 'to', 'profile', 'a', 'user']","['profile', 'user']",profile user,0.0,0.0,5,12,2.0,0,0,0,0,0,0,0,0
5125,python installation on windows,python installation on windows,"['python', 'installation', 'on', 'windows']",0,"['python', 'installation', 'on', 'window']","['python', 'installation', 'window']",python installation window,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
5126,replaceing missing values using fillna gives an error,replaceing missing values using fillna gives an error,"['replaceing', 'missing', 'values', 'using', 'fillna', 'gives', 'an', 'error']",0,"['replaceing', 'missing', 'value', 'using', 'fillna', 'give', 'an', 'error']","['replaceing', 'missing', 'value', 'using', 'fillna', 'give', 'error']",replaceing missing value using fillna give error,-0.2,-0.2,8,48,5.333333333333333,0,0,0,0,0,0,0,0
5127,what are some good reference materials for outlier treatment,what are some good reference materials for outlier treatment,"['what', 'are', 'some', 'good', 'reference', 'materials', 'for', 'outlier', 'treatment']",0,"['what', 'are', 'some', 'good', 'reference', 'material', 'for', 'outlier', 'treatment']","['good', 'reference', 'material', 'outlier', 'treatment']",good reference material outlier treatment,0.7,0.7,9,41,4.1,0,0,0,0,0,0,0,0
5128,stationarity  dickeyfuller test,stationarity  dickeyfuller test,"['stationarity', 'dickeyfuller', 'test']",0,"['stationarity', 'dickeyfuller', 'test']","['stationarity', 'dickeyfuller', 'test']",stationarity dickeyfuller test,0.0,0.0,3,30,7.5,0,0,0,0,0,0,0,0
5129,how to resolve this kind of problem in time series,how to resolve this kind of problem in time series,"['how', 'to', 'resolve', 'this', 'kind', 'of', 'problem', 'in', 'time', 'series']",0,"['how', 'to', 'resolve', 'this', 'kind', 'of', 'problem', 'in', 'time', 'series']","['resolve', 'kind', 'problem', 'time', 'series']",resolve kind problem time series,0.6,0.6,10,32,2.909090909090909,0,0,0,0,0,0,0,0
5130,clustering and then classification,clustering and then classification,"['clustering', 'and', 'then', 'classification']",0,"['clustering', 'and', 'then', 'classification']","['clustering', 'classification']",clustering classification,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
5131,high volatile data  time series analysis,high volatile data  time series analysis,"['high', 'volatile', 'data', 'time', 'series', 'analysis']",0,"['high', 'volatile', 'data', 'time', 'series', 'analysis']","['high', 'volatile', 'data', 'time', 'series', 'analysis']",high volatile data time series analysis,0.16,0.16,6,39,5.571428571428571,0,0,0,0,0,0,0,0
5132,sentence similarity,sentence similarity,"['sentence', 'similarity']",0,"['sentence', 'similarity']","['sentence', 'similarity']",sentence similarity,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
5133,help needed in this code while stemming,help needed in this code while stemming,"['help', 'needed', 'in', 'this', 'code', 'while', 'stemming']",0,"['help', 'needed', 'in', 'this', 'code', 'while', 'stemming']","['help', 'needed', 'code', 'stemming']",help needed code stemming,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
5134,dressify data in logestic regression,dressify data in logestic regression,"['dressify', 'data', 'in', 'logestic', 'regression']",0,"['dressify', 'data', 'in', 'logestic', 'regression']","['dressify', 'data', 'logestic', 'regression']",dressify data logestic regression,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
5135,should the train and test data be combined before running an algorithm,should the train and test data be combined before running an algorithm,"['should', 'the', 'train', 'and', 'test', 'data', 'be', 'combined', 'before', 'running', 'an', 'algorithm']",0,"['should', 'the', 'train', 'and', 'test', 'data', 'be', 'combined', 'before', 'running', 'an', 'algorithm']","['train', 'test', 'data', 'combined', 'running', 'algorithm']",train test data combined running algorithm,0.0,0.0,12,42,3.230769230769231,0,0,0,0,0,0,0,0
5136,how to populate weekday from date mmddyyyy in sas,how to populate weekday from date mmddyyyy in sas,"['how', 'to', 'populate', 'weekday', 'from', 'date', 'mmddyyyy', 'in', 'sas']",0,"['how', 'to', 'populate', 'weekday', 'from', 'date', 'mmddyyyy', 'in', 'sa']","['populate', 'weekday', 'date', 'mmddyyyy', 'sa']",populate weekday date mmddyyyy sa,0.0,0.0,9,33,3.3,0,0,0,0,0,0,0,0
5137,ideas for personal projects in r,ideas for personal projects in r,"['ideas', 'for', 'personal', 'projects', 'in', 'r']",0,"['idea', 'for', 'personal', 'project', 'in', 'r']","['idea', 'personal', 'project', 'r']",idea personal project r,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
5138,operations on train data vs the test data,operations on train data vs the test data,"['operations', 'on', 'train', 'data', 'vs', 'the', 'test', 'data']",0,"['operation', 'on', 'train', 'data', 'v', 'the', 'test', 'data']","['operation', 'train', 'data', 'v', 'test', 'data']",operation train data v test data,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
5139,valid padding in convolution neural networks,valid padding in convolution neural networks,"['valid', 'padding', 'in', 'convolution', 'neural', 'networks']",0,"['valid', 'padding', 'in', 'convolution', 'neural', 'network']","['valid', 'padding', 'convolution', 'neural', 'network']",valid padding convolution neural network,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
5140,need help on career guidance,need help on career guidance,"['need', 'help', 'on', 'career', 'guidance']",0,"['need', 'help', 'on', 'career', 'guidance']","['need', 'help', 'career', 'guidance']",need help career guidance,0.0,0.0,5,25,4.166666666666667,0,0,0,0,0,0,0,0
5141,printing the tree after applying decison tree algo for classification in sklearn,printing the tree after applying decison tree algo for classification in sklearn,"['printing', 'the', 'tree', 'after', 'applying', 'decison', 'tree', 'algo', 'for', 'classification', 'in', 'sklearn']",0,"['printing', 'the', 'tree', 'after', 'applying', 'decison', 'tree', 'algo', 'for', 'classification', 'in', 'sklearn']","['printing', 'tree', 'applying', 'decison', 'tree', 'algo', 'classification', 'sklearn']",printing tree applying decison tree algo classification sklearn,0.0,0.0,12,63,4.846153846153846,0,0,0,0,0,0,0,0
5142,from where can i get data sets to practice modelling techniques,from where can i get data sets to practice modelling techniques,"['from', 'where', 'can', 'i', 'get', 'data', 'sets', 'to', 'practice', 'modelling', 'techniques']",0,"['from', 'where', 'can', 'i', 'get', 'data', 'set', 'to', 'practice', 'modelling', 'technique']","['get', 'data', 'set', 'practice', 'modelling', 'technique']",get data set practice modelling technique,0.0,0.0,11,41,3.4166666666666665,0,0,0,0,0,0,0,0
5143,maths use in data science and ml,maths use in data science and ml,"['maths', 'use', 'in', 'data', 'science', 'and', 'ml']",0,"['math', 'use', 'in', 'data', 'science', 'and', 'ml']","['math', 'use', 'data', 'science', 'ml']",math use data science ml,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
5144,what are limitations of tree diagram,what are limitations of tree diagram,"['what', 'are', 'limitations', 'of', 'tree', 'diagram']",0,"['what', 'are', 'limitation', 'of', 'tree', 'diagram']","['limitation', 'tree', 'diagram']",limitation tree diagram,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
5145,why factor analysis are only applied to numeric data,why factor analysis are only applied to numeric data,"['why', 'factor', 'analysis', 'are', 'only', 'applied', 'to', 'numeric', 'data']",0,"['why', 'factor', 'analysis', 'are', 'only', 'applied', 'to', 'numeric', 'data']","['factor', 'analysis', 'applied', 'numeric', 'data']",factor analysis applied numeric data,0.0,0.0,9,36,3.6,0,0,0,0,0,0,0,0
5146,future of data analytics in lifescience and clinical research,future of data analytics in lifescience and clinical research,"['future', 'of', 'data', 'analytics', 'in', 'lifescience', 'and', 'clinical', 'research']",0,"['future', 'of', 'data', 'analytics', 'in', 'lifescience', 'and', 'clinical', 'research']","['future', 'data', 'analytics', 'lifescience', 'clinical', 'research']",future data analytics lifescience clinical research,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
5147,technique for modelling when number of responders are less,technique for modelling when number of responders are less,"['technique', 'for', 'modelling', 'when', 'number', 'of', 'responders', 'are', 'less']",0,"['technique', 'for', 'modelling', 'when', 'number', 'of', 'responder', 'are', 'le']","['technique', 'modelling', 'number', 'responder', 'le']",technique modelling number responder le,-0.1666666666666666,0.0,9,39,3.9,0,0,0,0,0,0,0,0
5148,interactive visuals,interactive visuals,"['interactive', 'visuals']",0,"['interactive', 'visuals']","['interactive', 'visuals']",interactive visuals,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
5149,regarding certificate course from mitmassachusetts institute of technology,regarding certificate course from mitmassachusetts institute of technology,"['regarding', 'certificate', 'course', 'from', 'mitmassachusetts', 'institute', 'of', 'technology']",0,"['regarding', 'certificate', 'course', 'from', 'mitmassachusetts', 'institute', 'of', 'technology']","['regarding', 'certificate', 'course', 'mitmassachusetts', 'institute', 'technology']",regarding certificate course mitmassachusetts institute technology,0.0,0.0,8,66,7.333333333333333,0,0,0,0,0,0,0,0
5150,how to implement svm algorithm in r,how to implement svm algorithm in r,"['how', 'to', 'implement', 'svm', 'algorithm', 'in', 'r']",0,"['how', 'to', 'implement', 'svm', 'algorithm', 'in', 'r']","['implement', 'svm', 'algorithm', 'r']",implement svm algorithm r,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
5151,different evaluation metrics for regression models,different evaluation metrics for regression models,"['different', 'evaluation', 'metrics', 'for', 'regression', 'models']",0,"['different', 'evaluation', 'metric', 'for', 'regression', 'model']","['different', 'evaluation', 'metric', 'regression', 'model']",different evaluation metric regression model,0.0,0.0,6,44,6.285714285714286,0,0,0,0,0,0,0,0
5152,error in running gbm,error in running gbm,"['error', 'in', 'running', 'gbm']",0,"['error', 'in', 'running', 'gbm']","['error', 'running', 'gbm']",error running gbm,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
5153,career in analytics post mba from iim  tier i institute,career in analytics post mba from iim  tier i institute,"['career', 'in', 'analytics', 'post', 'mba', 'from', 'iim', 'tier', 'i', 'institute']",0,"['career', 'in', 'analytics', 'post', 'mba', 'from', 'iim', 'tier', 'i', 'institute']","['career', 'analytics', 'post', 'mba', 'iim', 'tier', 'institute']",career analytics post mba iim tier institute,0.0,0.0,10,44,4.0,0,0,0,0,0,0,0,0
5154,how to ask question to the write of the specific article  k means clustering,how to ask question to the write of the specific article  k means clustering,"['how', 'to', 'ask', 'question', 'to', 'the', 'write', 'of', 'the', 'specific', 'article', 'k', 'means', 'clustering']",0,"['how', 'to', 'ask', 'question', 'to', 'the', 'write', 'of', 'the', 'specific', 'article', 'k', 'mean', 'clustering']","['ask', 'question', 'write', 'specific', 'article', 'k', 'mean', 'clustering']",ask question write specific article k mean clustering,0.0,-0.15625,14,53,3.533333333333333,0,0,0,0,0,0,0,0
5155,on what basis any algorithm is selected,on what basis any algorithm is selected,"['on', 'what', 'basis', 'any', 'algorithm', 'is', 'selected']",0,"['on', 'what', 'basis', 'any', 'algorithm', 'is', 'selected']","['basis', 'algorithm', 'selected']",basis algorithm selected,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
5156,how to connect tm rest api to r,how to connect tm rest api to r,"['how', 'to', 'connect', 'tm', 'rest', 'api', 'to', 'r']",0,"['how', 'to', 'connect', 'tm', 'rest', 'api', 'to', 'r']","['connect', 'tm', 'rest', 'api', 'r']",connect tm rest api r,0.0,0.0,8,21,2.3333333333333335,0,0,0,0,0,0,0,0
5157,loan prediction reveal your approach,loan prediction reveal your approach,"['loan', 'prediction', 'reveal', 'your', 'approach']",0,"['loan', 'prediction', 'reveal', 'your', 'approach']","['loan', 'prediction', 'reveal', 'approach']",loan prediction reveal approach,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
5158,need list of journals that give response to authors submitting their articles,need list of journals that give response to authors submitting their articles,"['need', 'list', 'of', 'journals', 'that', 'give', 'response', 'to', 'authors', 'submitting', 'their', 'articles']",0,"['need', 'list', 'of', 'journal', 'that', 'give', 'response', 'to', 'author', 'submitting', 'their', 'article']","['need', 'list', 'journal', 'give', 'response', 'author', 'submitting', 'article']",need list journal give response author submitting article,0.0,0.0,12,57,4.384615384615385,0,0,0,0,0,0,0,0
5159,predict what is the likelihood of winning a open deal this quarter in next  days or moving out to future quarters,predict what is the likelihood of winning a open deal this quarter in next  days or moving out to future quarters,"['predict', 'what', 'is', 'the', 'likelihood', 'of', 'winning', 'a', 'open', 'deal', 'this', 'quarter', 'in', 'next', 'days', 'or', 'moving', 'out', 'to', 'future', 'quarters']",1,"['predict', 'what', 'is', 'the', 'likelihood', 'of', 'winning', 'a', 'open', 'deal', 'this', 'quarter', 'in', 'next', 'day', 'or', 'moving', 'out', 'to', 'future', 'quarter']","['predict', 'likelihood', 'winning', 'open', 'deal', 'quarter', 'next', 'day', 'moving', 'future', 'quarter']",predict likelihood winning open deal quarter next day moving future quarter,0.125,0.125,21,75,3.409090909090909,0,0,0,0,0,0,0,0
5160,how to select the optimum number of dimensions after applying lsa in r,how to select the optimum number of dimensions after applying lsa in r,"['how', 'to', 'select', 'the', 'optimum', 'number', 'of', 'dimensions', 'after', 'applying', 'lsa', 'in', 'r']",0,"['how', 'to', 'select', 'the', 'optimum', 'number', 'of', 'dimension', 'after', 'applying', 'lsa', 'in', 'r']","['select', 'optimum', 'number', 'dimension', 'applying', 'lsa', 'r']",select optimum number dimension applying lsa r,0.7,0.7,13,46,3.2857142857142856,0,0,0,0,0,0,0,0
5161,importance of sas skills and certification for a career in fortune  organizationspredictive modeller enterprise miner etc,importance of sas skills and certification for a career in fortune  organizationspredictive modeller enterprise miner etc,"['importance', 'of', 'sas', 'skills', 'and', 'certification', 'for', 'a', 'career', 'in', 'fortune', 'organizationspredictive', 'modeller', 'enterprise', 'miner', 'etc']",1,"['importance', 'of', 'sa', 'skill', 'and', 'certification', 'for', 'a', 'career', 'in', 'fortune', 'organizationspredictive', 'modeller', 'enterprise', 'miner', 'etc']","['importance', 'sa', 'skill', 'certification', 'career', 'fortune', 'organizationspredictive', 'modeller', 'enterprise', 'miner', 'etc']",importance sa skill certification career fortune organizationspredictive modeller enterprise miner etc,0.0,0.0,16,102,6.0,0,0,0,0,0,0,0,0
5162,how to generate binary random normal variates in r,how to generate binary random normal variates in r,"['how', 'to', 'generate', 'binary', 'random', 'normal', 'variates', 'in', 'r']",0,"['how', 'to', 'generate', 'binary', 'random', 'normal', 'variate', 'in', 'r']","['generate', 'binary', 'random', 'normal', 'variate', 'r']",generate binary random normal variate r,-0.175,-0.175,9,39,3.9,0,0,0,0,0,0,0,0
5163,getting a warning message while reading the twitter timeline in python,getting a warning message while reading the twitter timeline in python,"['getting', 'a', 'warning', 'message', 'while', 'reading', 'the', 'twitter', 'timeline', 'in', 'python']",0,"['getting', 'a', 'warning', 'message', 'while', 'reading', 'the', 'twitter', 'timeline', 'in', 'python']","['getting', 'warning', 'message', 'reading', 'twitter', 'timeline', 'python']",getting warning message reading twitter timeline python,0.0,0.0,11,55,4.583333333333333,0,0,0,0,0,0,0,0
5164,query on blog  regression analysis and assumptions,query on blog  regression analysis and assumptions,"['query', 'on', 'blog', 'regression', 'analysis', 'and', 'assumptions']",0,"['query', 'on', 'blog', 'regression', 'analysis', 'and', 'assumption']","['query', 'blog', 'regression', 'analysis', 'assumption']",query blog regression analysis assumption,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
5165,what is bias in a machine learning algorithm,what is bias in a machine learning algorithm,"['what', 'is', 'bias', 'in', 'a', 'machine', 'learning', 'algorithm']",0,"['what', 'is', 'bias', 'in', 'a', 'machine', 'learning', 'algorithm']","['bias', 'machine', 'learning', 'algorithm']",bias machine learning algorithm,0.0,0.0,8,31,3.4444444444444446,0,0,0,0,0,0,0,0
5166,deploying predictive python model for user access,deploying predictive python model for user access,"['deploying', 'predictive', 'python', 'model', 'for', 'user', 'access']",0,"['deploying', 'predictive', 'python', 'model', 'for', 'user', 'access']","['deploying', 'predictive', 'python', 'model', 'user', 'access']",deploying predictive python model user access,0.0,0.0,7,45,5.625,0,0,0,0,0,0,0,0
5167,what is the best way for vectorizing a dataset having text features and numeric feature in it,what is the best way for vectorizing a dataset having text features and numeric feature in it,"['what', 'is', 'the', 'best', 'way', 'for', 'vectorizing', 'a', 'dataset', 'having', 'text', 'features', 'and', 'numeric', 'feature', 'in', 'it']",0,"['what', 'is', 'the', 'best', 'way', 'for', 'vectorizing', 'a', 'dataset', 'having', 'text', 'feature', 'and', 'numeric', 'feature', 'in', 'it']","['best', 'way', 'vectorizing', 'dataset', 'text', 'feature', 'numeric', 'feature']",best way vectorizing dataset text feature numeric feature,1.0,1.0,17,57,3.1666666666666665,0,0,0,0,0,0,0,0
5168,reactjs vs react native,reactjs vs react native,"['reactjs', 'vs', 'react', 'native']",0,"['reactjs', 'v', 'react', 'native']","['reactjs', 'v', 'react', 'native']",reactjs v react native,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
5169,facing problem in submission in big mart practice dataset,facing problem in submission in big mart practice dataset,"['facing', 'problem', 'in', 'submission', 'in', 'big', 'mart', 'practice', 'dataset']",0,"['facing', 'problem', 'in', 'submission', 'in', 'big', 'mart', 'practice', 'dataset']","['facing', 'problem', 'submission', 'big', 'mart', 'practice', 'dataset']",facing problem submission big mart practice dataset,0.0,0.0,9,51,5.1,0,0,0,0,0,0,0,0
5170,why merging in python using pandas is faster than datatable in r,why merging in python using pandas is faster than datatable in r,"['why', 'merging', 'in', 'python', 'using', 'pandas', 'is', 'faster', 'than', 'datatable', 'in', 'r']",0,"['why', 'merging', 'in', 'python', 'using', 'panda', 'is', 'faster', 'than', 'datatable', 'in', 'r']","['merging', 'python', 'using', 'panda', 'faster', 'datatable', 'r']",merging python using panda faster datatable r,0.0,0.0,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
5171,memory error  a comprehensive guide to understand and implement text classification in python,memory error  a comprehensive guide to understand and implement text classification in python,"['memory', 'error', 'a', 'comprehensive', 'guide', 'to', 'understand', 'and', 'implement', 'text', 'classification', 'in', 'python']",0,"['memory', 'error', 'a', 'comprehensive', 'guide', 'to', 'understand', 'and', 'implement', 'text', 'classification', 'in', 'python']","['memory', 'error', 'comprehensive', 'guide', 'understand', 'implement', 'text', 'classification', 'python']",memory error comprehensive guide understand implement text classification python,0.0,0.0,13,80,5.714285714285714,0,0,0,0,0,0,0,0
5172,transformations to convert left and right skewed distributions into normal,transformations to convert left and right skewed distributions into normal,"['transformations', 'to', 'convert', 'left', 'and', 'right', 'skewed', 'distributions', 'into', 'normal']",0,"['transformation', 'to', 'convert', 'left', 'and', 'right', 'skewed', 'distribution', 'into', 'normal']","['transformation', 'convert', 'left', 'right', 'skewed', 'distribution', 'normal']",transformation convert left right skewed distribution normal,0.1452380952380952,0.1452380952380952,10,60,5.454545454545454,0,0,0,0,0,0,0,0
5173,how to combine two list of list in python without duplicates,how to combine two list of list in python without duplicates,"['how', 'to', 'combine', 'two', 'list', 'of', 'list', 'in', 'python', 'without', 'duplicates']",0,"['how', 'to', 'combine', 'two', 'list', 'of', 'list', 'in', 'python', 'without', 'duplicate']","['combine', 'two', 'list', 'list', 'python', 'without', 'duplicate']",combine two list list python without duplicate,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
5174,error in code for time series forecast in python,error in code for time series forecast in python,"['error', 'in', 'code', 'for', 'time', 'series', 'forecast', 'in', 'python']",0,"['error', 'in', 'code', 'for', 'time', 'series', 'forecast', 'in', 'python']","['error', 'code', 'time', 'series', 'forecast', 'python']",error code time series forecast python,0.0,0.0,9,38,3.8,0,0,0,0,0,0,0,0
5175,is my profile strong enough get a data scientist role,is my profile strong enough get a data scientist role,"['is', 'my', 'profile', 'strong', 'enough', 'get', 'a', 'data', 'scientist', 'role']",0,"['is', 'my', 'profile', 'strong', 'enough', 'get', 'a', 'data', 'scientist', 'role']","['profile', 'strong', 'enough', 'get', 'data', 'scientist', 'role']",profile strong enough get data scientist role,0.2166666666666666,0.2166666666666666,10,45,4.090909090909091,0,0,0,0,0,0,0,0
5176,prediction using ridge regression,prediction using ridge regression,"['prediction', 'using', 'ridge', 'regression']",0,"['prediction', 'using', 'ridge', 'regression']","['prediction', 'using', 'ridge', 'regression']",prediction using ridge regression,0.0,0.0,4,33,6.6,0,0,0,0,0,0,0,0
5177,analysis of road accidents in new york,analysis of road accidents in new york,"['analysis', 'of', 'road', 'accidents', 'in', 'new', 'york']",0,"['analysis', 'of', 'road', 'accident', 'in', 'new', 'york']","['analysis', 'road', 'accident', 'new', 'york']",analysis road accident new york,0.1363636363636363,0.1363636363636363,7,31,3.875,0,0,0,0,0,0,0,0
5178,handling large data files in python with low ram low resource creating large datafiles at local pc from sqlserver database using python  odbc,handling large data files in python with low ram low resource creating large datafiles at local pc from sqlserver database using python  odbc,"['handling', 'large', 'data', 'files', 'in', 'python', 'with', 'low', 'ram', 'low', 'resource', 'creating', 'large', 'datafiles', 'at', 'local', 'pc', 'from', 'sqlserver', 'database', 'using', 'python', 'odbc']",0,"['handling', 'large', 'data', 'file', 'in', 'python', 'with', 'low', 'ram', 'low', 'resource', 'creating', 'large', 'datafiles', 'at', 'local', 'pc', 'from', 'sqlserver', 'database', 'using', 'python', 'odbc']","['handling', 'large', 'data', 'file', 'python', 'low', 'ram', 'low', 'resource', 'creating', 'large', 'datafiles', 'local', 'pc', 'sqlserver', 'database', 'using', 'python', 'odbc']",handling large data file python low ram low resource creating large datafiles local pc sqlserver database using python odbc,0.0857142857142857,0.0857142857142857,23,123,5.125,0,0,0,0,0,0,0,0
5179,json to r dataframe data extraction error,json to r dataframe data extraction error,"['json', 'to', 'r', 'dataframe', 'data', 'extraction', 'error']",0,"['json', 'to', 'r', 'dataframe', 'data', 'extraction', 'error']","['json', 'r', 'dataframe', 'data', 'extraction', 'error']",json r dataframe data extraction error,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
5180,xgboost feature importance,xgboost feature importance,"['xgboost', 'feature', 'importance']",0,"['xgboost', 'feature', 'importance']","['xgboost', 'feature', 'importance']",xgboost feature importance,0.0,0.0,3,26,6.5,0,0,0,0,0,0,0,0
5181,automation threat to career in analytics versus its augmentation with machine learning,automation threat to career in analytics versus its augmentation with machine learning,"['automation', 'threat', 'to', 'career', 'in', 'analytics', 'versus', 'its', 'augmentation', 'with', 'machine', 'learning']",0,"['automation', 'threat', 'to', 'career', 'in', 'analytics', 'versus', 'it', 'augmentation', 'with', 'machine', 'learning']","['automation', 'threat', 'career', 'analytics', 'versus', 'augmentation', 'machine', 'learning']",automation threat career analytics versus augmentation machine learning,0.0,0.0,12,71,5.461538461538462,0,0,0,0,0,0,0,0
5182,introduction to convolution neural networks,introduction to convolution neural networks,"['introduction', 'to', 'convolution', 'neural', 'networks']",0,"['introduction', 'to', 'convolution', 'neural', 'network']","['introduction', 'convolution', 'neural', 'network']",introduction convolution neural network,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
5183,how to regress var model with few parameters to estimate,how to regress var model with few parameters to estimate,"['how', 'to', 'regress', 'var', 'model', 'with', 'few', 'parameters', 'to', 'estimate']",0,"['how', 'to', 'regress', 'var', 'model', 'with', 'few', 'parameter', 'to', 'estimate']","['regress', 'var', 'model', 'parameter', 'estimate']",regress var model parameter estimate,-0.2,0.0,10,36,3.272727272727273,0,0,0,0,0,0,0,0
5184,data analyst in market research,data analyst in market research,"['data', 'analyst', 'in', 'market', 'research']",0,"['data', 'analyst', 'in', 'market', 'research']","['data', 'analyst', 'market', 'research']",data analyst market research,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
5185,valid events in json format,valid events in json format,"['valid', 'events', 'in', 'json', 'format']",0,"['valid', 'event', 'in', 'json', 'format']","['valid', 'event', 'json', 'format']",valid event json format,0.0,0.0,5,23,3.8333333333333335,0,0,0,0,0,0,0,0
5186,startups in data science,startups in data science,"['startups', 'in', 'data', 'science']",0,"['startup', 'in', 'data', 'science']","['startup', 'data', 'science']",startup data science,0.0,0.0,4,20,4.0,0,0,0,0,0,0,0,0
5187,how to map  unique occupationprofessions to standard occupation names,how to map  unique occupationprofessions to standard occupation names,"['how', 'to', 'map', 'unique', 'occupationprofessions', 'to', 'standard', 'occupation', 'names']",1,"['how', 'to', 'map', 'unique', 'occupationprofessions', 'to', 'standard', 'occupation', 'name']","['map', 'unique', 'occupationprofessions', 'standard', 'occupation', 'name']",map unique occupationprofessions standard occupation name,0.1875,0.1875,9,57,5.7,0,0,0,0,0,0,0,0
5188,what is the difference between prcomp and princomp for pca in r,what is the difference between prcomp and princomp for pca in r,"['what', 'is', 'the', 'difference', 'between', 'prcomp', 'and', 'princomp', 'for', 'pca', 'in', 'r']",0,"['what', 'is', 'the', 'difference', 'between', 'prcomp', 'and', 'princomp', 'for', 'pca', 'in', 'r']","['difference', 'prcomp', 'princomp', 'pca', 'r']",difference prcomp princomp pca r,0.0,0.0,12,32,2.4615384615384617,0,0,0,0,0,0,0,0
5189,conversion functions in sas,conversion functions in sas,"['conversion', 'functions', 'in', 'sas']",0,"['conversion', 'function', 'in', 'sa']","['conversion', 'function', 'sa']",conversion function sa,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
5190,why is one category predicted more accurately than the other in ada,why is one category predicted more accurately than the other in ada,"['why', 'is', 'one', 'category', 'predicted', 'more', 'accurately', 'than', 'the', 'other', 'in', 'ada']",0,"['why', 'is', 'one', 'category', 'predicted', 'more', 'accurately', 'than', 'the', 'other', 'in', 'ada']","['one', 'category', 'predicted', 'accurately', 'ada']",one category predicted accurately ada,0.2583333333333333,0.4000000000000001,12,37,2.8461538461538463,0,0,0,0,0,0,0,0
5191,how can i create bins for a numerical variable in qlikview,how can i create bins for a numerical variable in qlikview,"['how', 'can', 'i', 'create', 'bins', 'for', 'a', 'numerical', 'variable', 'in', 'qlikview']",0,"['how', 'can', 'i', 'create', 'bin', 'for', 'a', 'numerical', 'variable', 'in', 'qlikview']","['create', 'bin', 'numerical', 'variable', 'qlikview']",create bin numerical variable qlikview,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
5192,missing value imputation in r,missing value imputation in r,"['missing', 'value', 'imputation', 'in', 'r']",0,"['missing', 'value', 'imputation', 'in', 'r']","['missing', 'value', 'imputation', 'r']",missing value imputation r,-0.2,-0.2,5,26,4.333333333333333,0,0,0,0,0,0,0,0
5193,how can someone start learning about image recognition algorithms what are the best toolstechniques and research paper for it,how can someone start learning about image recognition algorithms what are the best toolstechniques and research paper for it,"['how', 'can', 'someone', 'start', 'learning', 'about', 'image', 'recognition', 'algorithms', 'what', 'are', 'the', 'best', 'toolstechniques', 'and', 'research', 'paper', 'for', 'it']",0,"['how', 'can', 'someone', 'start', 'learning', 'about', 'image', 'recognition', 'algorithm', 'what', 'are', 'the', 'best', 'toolstechniques', 'and', 'research', 'paper', 'for', 'it']","['someone', 'start', 'learning', 'image', 'recognition', 'algorithm', 'best', 'toolstechniques', 'research', 'paper']",someone start learning image recognition algorithm best toolstechniques research paper,1.0,1.0,19,86,4.3,0,0,0,0,0,0,0,0
5194,how to extract the hashtags from a tweet in r,how to extract the hashtags from a tweet in r,"['how', 'to', 'extract', 'the', 'hashtags', 'from', 'a', 'tweet', 'in', 'r']",0,"['how', 'to', 'extract', 'the', 'hashtags', 'from', 'a', 'tweet', 'in', 'r']","['extract', 'hashtags', 'tweet', 'r']",extract hashtags tweet r,0.0,0.0,10,24,2.1818181818181817,0,0,0,0,0,0,0,0
5195,image classification vs video classification,image classification vs video classification,"['image', 'classification', 'vs', 'video', 'classification']",0,"['image', 'classification', 'v', 'video', 'classification']","['image', 'classification', 'v', 'video', 'classification']",image classification v video classification,0.0,0.0,5,43,7.166666666666667,0,0,0,0,0,0,0,0
5196,data set source for sentiment analysis project,data set source for sentiment analysis project,"['data', 'set', 'source', 'for', 'sentiment', 'analysis', 'project']",0,"['data', 'set', 'source', 'for', 'sentiment', 'analysis', 'project']","['data', 'set', 'source', 'sentiment', 'analysis', 'project']",data set source sentiment analysis project,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
5197,unable to submit solution,unable to submit solution,"['unable', 'to', 'submit', 'solution']",0,"['unable', 'to', 'submit', 'solution']","['unable', 'submit', 'solution']",unable submit solution,-0.5,-0.5,4,22,4.4,0,0,0,0,0,0,0,0
5198,can svd be performed in categorical data,can svd be performed in categorical data,"['can', 'svd', 'be', 'performed', 'in', 'categorical', 'data']",0,"['can', 'svd', 'be', 'performed', 'in', 'categorical', 'data']","['svd', 'performed', 'categorical', 'data']",svd performed categorical data,0.0,0.0,7,30,3.75,0,0,0,0,0,0,0,0
5199,video anomaly detection techs,video anomaly detection techs,"['video', 'anomaly', 'detection', 'techs']",0,"['video', 'anomaly', 'detection', 'tech']","['video', 'anomaly', 'detection', 'tech']",video anomaly detection tech,0.0,0.0,4,28,5.6,0,0,0,0,0,0,0,0
5200,better way to replace expressions in regex,better way to replace expressions in regex,"['better', 'way', 'to', 'replace', 'expressions', 'in', 'regex']",0,"['better', 'way', 'to', 'replace', 'expression', 'in', 'regex']","['better', 'way', 'replace', 'expression', 'regex']",better way replace expression regex,0.5,0.5,7,35,4.375,0,0,0,0,0,0,0,0
5201,showcasing ones work,showcasing ones work,"['showcasing', 'ones', 'work']",0,"['showcasing', 'one', 'work']","['showcasing', 'one', 'work']",showcasing one work,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
5202,how to create gauge chart in excel,how to create gauge chart in excel,"['how', 'to', 'create', 'gauge', 'chart', 'in', 'excel']",0,"['how', 'to', 'create', 'gauge', 'chart', 'in', 'excel']","['create', 'gauge', 'chart', 'excel']",create gauge chart excel,0.0,0.0,7,24,3.0,0,0,0,0,0,0,0,0
5203,beginner question about how to faithfully quantify an awkward data measurement,beginner question about how to faithfully quantify an awkward data measurement,"['beginner', 'question', 'about', 'how', 'to', 'faithfully', 'quantify', 'an', 'awkward', 'data', 'measurement']",0,"['beginner', 'question', 'about', 'how', 'to', 'faithfully', 'quantify', 'an', 'awkward', 'data', 'measurement']","['beginner', 'question', 'faithfully', 'quantify', 'awkward', 'data', 'measurement']",beginner question faithfully quantify awkward data measurement,-0.6,-0.6,11,62,5.166666666666667,0,0,0,0,0,0,0,0
5204,book for learn and improve structured thinking,book for learn and improve structured thinking,"['book', 'for', 'learn', 'and', 'improve', 'structured', 'thinking']",0,"['book', 'for', 'learn', 'and', 'improve', 'structured', 'thinking']","['book', 'learn', 'improve', 'structured', 'thinking']",book learn improve structured thinking,0.0,0.0,7,38,4.75,0,0,0,0,0,0,0,0
5205,xml to csv conversion,xml to csv conversion,"['xml', 'to', 'csv', 'conversion']",0,"['xml', 'to', 'csv', 'conversion']","['xml', 'csv', 'conversion']",xml csv conversion,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
5206,excel cheat sheet,excel cheat sheet,"['excel', 'cheat', 'sheet']",0,"['excel', 'cheat', 'sheet']","['excel', 'cheat', 'sheet']",excel cheat sheet,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
5207,what are major difference between split and loop function in r,what are major difference between split and loop function in r,"['what', 'are', 'major', 'difference', 'between', 'split', 'and', 'loop', 'function', 'in', 'r']",0,"['what', 'are', 'major', 'difference', 'between', 'split', 'and', 'loop', 'function', 'in', 'r']","['major', 'difference', 'split', 'loop', 'function', 'r']",major difference split loop function r,0.0625,0.0625,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
5208,how to improve score of an binary classification model attrition with imbalanced data,how to improve score of an binary classification model attrition with imbalanced data,"['how', 'to', 'improve', 'score', 'of', 'an', 'binary', 'classification', 'model', 'attrition', 'with', 'imbalanced', 'data']",0,"['how', 'to', 'improve', 'score', 'of', 'an', 'binary', 'classification', 'model', 'attrition', 'with', 'imbalanced', 'data']","['improve', 'score', 'binary', 'classification', 'model', 'attrition', 'imbalanced', 'data']",improve score binary classification model attrition imbalanced data,0.0,0.0,13,67,4.785714285714286,0,0,0,0,0,0,0,0
5209,scope of analytics startups catering to digital india or smart city,scope of analytics startups catering to digital india or smart city,"['scope', 'of', 'analytics', 'startups', 'catering', 'to', 'digital', 'india', 'or', 'smart', 'city']",0,"['scope', 'of', 'analytics', 'startup', 'catering', 'to', 'digital', 'india', 'or', 'smart', 'city']","['scope', 'analytics', 'startup', 'catering', 'digital', 'india', 'smart', 'city']",scope analytics startup catering digital india smart city,0.1071428571428571,0.1071428571428571,11,57,4.75,0,0,0,0,0,0,0,0
5210,predict customer worth for happy customer bank techniques,predict customer worth for happy customer bank techniques,"['predict', 'customer', 'worth', 'for', 'happy', 'customer', 'bank', 'techniques']",0,"['predict', 'customer', 'worth', 'for', 'happy', 'customer', 'bank', 'technique']","['predict', 'customer', 'worth', 'happy', 'customer', 'bank', 'technique']",predict customer worth happy customer bank technique,0.55,0.55,8,52,5.777777777777778,0,0,0,0,0,0,0,0
5211,rhadoop and machine learning,rhadoop and machine learning,"['rhadoop', 'and', 'machine', 'learning']",0,"['rhadoop', 'and', 'machine', 'learning']","['rhadoop', 'machine', 'learning']",rhadoop machine learning,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
5212,extracting keywords from pdf file in python,extracting keywords from pdf file in python,"['extracting', 'keywords', 'from', 'pdf', 'file', 'in', 'python']",0,"['extracting', 'keywords', 'from', 'pdf', 'file', 'in', 'python']","['extracting', 'keywords', 'pdf', 'file', 'python']",extracting keywords pdf file python,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
5213,how we can know which variable is contributing how much to factor component in pca,how we can know which variable is contributing how much to factor component in pca,"['how', 'we', 'can', 'know', 'which', 'variable', 'is', 'contributing', 'how', 'much', 'to', 'factor', 'component', 'in', 'pca']",0,"['how', 'we', 'can', 'know', 'which', 'variable', 'is', 'contributing', 'how', 'much', 'to', 'factor', 'component', 'in', 'pca']","['know', 'variable', 'contributing', 'much', 'factor', 'component', 'pca']",know variable contributing much factor component pca,0.2,0.2,15,52,3.25,0,0,0,0,0,0,0,0
5214,a complete tutorial to learn data science in r from scratch,a complete tutorial to learn data science in r from scratch,"['a', 'complete', 'tutorial', 'to', 'learn', 'data', 'science', 'in', 'r', 'from', 'scratch']",0,"['a', 'complete', 'tutorial', 'to', 'learn', 'data', 'science', 'in', 'r', 'from', 'scratch']","['complete', 'tutorial', 'learn', 'data', 'science', 'r', 'scratch']",complete tutorial learn data science r scratch,0.1,0.1,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
5215,interactive visualization of kmeans clustering algorithm,interactive visualization of kmeans clustering algorithm,"['interactive', 'visualization', 'of', 'kmeans', 'clustering', 'algorithm']",0,"['interactive', 'visualization', 'of', 'kmeans', 'clustering', 'algorithm']","['interactive', 'visualization', 'kmeans', 'clustering', 'algorithm']",interactive visualization kmeans clustering algorithm,0.0,0.0,6,53,7.571428571428571,0,0,0,0,0,0,0,0
5216,predicting a continous output in a dataset with categories,predicting a continous output in a dataset with categories,"['predicting', 'a', 'continous', 'output', 'in', 'a', 'dataset', 'with', 'categories']",0,"['predicting', 'a', 'continous', 'output', 'in', 'a', 'dataset', 'with', 'category']","['predicting', 'continous', 'output', 'dataset', 'category']",predicting continous output dataset category,0.0,0.0,9,44,4.4,0,0,0,0,0,0,0,0
5217,how can i find number of characters within a cell in excel,how can i find number of characters within a cell in excel,"['how', 'can', 'i', 'find', 'number', 'of', 'characters', 'within', 'a', 'cell', 'in', 'excel']",0,"['how', 'can', 'i', 'find', 'number', 'of', 'character', 'within', 'a', 'cell', 'in', 'excel']","['find', 'number', 'character', 'within', 'cell', 'excel']",find number character within cell excel,0.0,0.0,12,39,3.0,0,0,0,0,0,0,0,0
5218,two different results on confusion matrix using random forest on loan prediction data,two different results on confusion matrix using random forest on loan prediction data,"['two', 'different', 'results', 'on', 'confusion', 'matrix', 'using', 'random', 'forest', 'on', 'loan', 'prediction', 'data']",0,"['two', 'different', 'result', 'on', 'confusion', 'matrix', 'using', 'random', 'forest', 'on', 'loan', 'prediction', 'data']","['two', 'different', 'result', 'confusion', 'matrix', 'using', 'random', 'forest', 'loan', 'prediction', 'data']",two different result confusion matrix using random forest loan prediction data,-0.25,-0.25,13,78,5.571428571428571,0,0,0,0,0,0,0,0
5219,looking for a career transition from system administration  devops to data scienceengineering,looking for a career transition from system administration  devops to data scienceengineering,"['looking', 'for', 'a', 'career', 'transition', 'from', 'system', 'administration', 'devops', 'to', 'data', 'scienceengineering']",0,"['looking', 'for', 'a', 'career', 'transition', 'from', 'system', 'administration', 'devops', 'to', 'data', 'scienceengineering']","['looking', 'career', 'transition', 'system', 'administration', 'devops', 'data', 'scienceengineering']",looking career transition system administration devops data scienceengineering,0.0,0.0,12,78,6.0,0,0,0,0,0,0,0,0
5220,automatic image captioning using pytorch,automatic image captioning using pytorch,"['automatic', 'image', 'captioning', 'using', 'pytorch']",0,"['automatic', 'image', 'captioning', 'using', 'pytorch']","['automatic', 'image', 'captioning', 'using', 'pytorch']",automatic image captioning using pytorch,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
5221,beginner level query regarding git and github,beginner level query regarding git and github,"['beginner', 'level', 'query', 'regarding', 'git', 'and', 'github']",0,"['beginner', 'level', 'query', 'regarding', 'git', 'and', 'github']","['beginner', 'level', 'query', 'regarding', 'git', 'github']",beginner level query regarding git github,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
5222,how to merge two csv file by a specific column using python,how to merge two csv file by a specific column using python,"['how', 'to', 'merge', 'two', 'csv', 'file', 'by', 'a', 'specific', 'column', 'using', 'python']",0,"['how', 'to', 'merge', 'two', 'csv', 'file', 'by', 'a', 'specific', 'column', 'using', 'python']","['merge', 'two', 'csv', 'file', 'specific', 'column', 'using', 'python']",merge two csv file specific column using python,0.0,0.0,12,47,3.6153846153846154,0,0,0,0,0,0,0,0
5223,imbalance class classification using random forest,imbalance class classification using random forest,"['imbalance', 'class', 'classification', 'using', 'random', 'forest']",0,"['imbalance', 'class', 'classification', 'using', 'random', 'forest']","['imbalance', 'class', 'classification', 'using', 'random', 'forest']",imbalance class classification using random forest,-0.5,-0.5,6,50,7.142857142857143,0,0,0,0,0,0,0,0
5224,learn probability,learn probability,"['learn', 'probability']",0,"['learn', 'probability']","['learn', 'probability']",learn probability,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
5225,analytics career for software development engineer,analytics career for software development engineer,"['analytics', 'career', 'for', 'software', 'development', 'engineer']",0,"['analytics', 'career', 'for', 'software', 'development', 'engineer']","['analytics', 'career', 'software', 'development', 'engineer']",analytics career software development engineer,0.0,0.0,6,46,6.571428571428571,0,0,0,0,0,0,0,0
5226,best hadoopbig data classroom course  bangalore,best hadoopbig data classroom course  bangalore,"['best', 'hadoopbig', 'data', 'classroom', 'course', 'bangalore']",0,"['best', 'hadoopbig', 'data', 'classroom', 'course', 'bangalore']","['best', 'hadoopbig', 'data', 'classroom', 'course', 'bangalore']",best hadoopbig data classroom course bangalore,1.0,1.0,6,46,6.571428571428571,0,0,0,0,0,0,0,0
5227,machine learningstratified k fold crossvalidation,machine learningstratified k fold crossvalidation,"['machine', 'learningstratified', 'k', 'fold', 'crossvalidation']",0,"['machine', 'learningstratified', 'k', 'fold', 'crossvalidation']","['machine', 'learningstratified', 'k', 'fold', 'crossvalidation']",machine learningstratified k fold crossvalidation,0.0,0.0,5,49,8.166666666666666,0,0,0,0,0,0,0,0
5228,learning from data  learning group,learning from data  learning group,"['learning', 'from', 'data', 'learning', 'group']",0,"['learning', 'from', 'data', 'learning', 'group']","['learning', 'data', 'learning', 'group']",learning data learning group,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
5229,steps after imputation,steps after imputation,"['steps', 'after', 'imputation']",0,"['step', 'after', 'imputation']","['step', 'imputation']",step imputation,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
5230,predict relative probability with the rate of  or higher,predict relative probability with the rate of  or higher,"['predict', 'relative', 'probability', 'with', 'the', 'rate', 'of', 'or', 'higher']",1,"['predict', 'relative', 'probability', 'with', 'the', 'rate', 'of', 'or', 'higher']","['predict', 'relative', 'probability', 'rate', 'higher']",predict relative probability rate higher,0.125,0.125,9,40,4.0,0,0,0,0,0,0,0,0
5231,rules for the online hackathon,rules for the online hackathon,"['rules', 'for', 'the', 'online', 'hackathon']",0,"['rule', 'for', 'the', 'online', 'hackathon']","['rule', 'online', 'hackathon']",rule online hackathon,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
5232,research paper on regression,research paper on regression,"['research', 'paper', 'on', 'regression']",0,"['research', 'paper', 'on', 'regression']","['research', 'paper', 'regression']",research paper regression,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
5233,hobby data science project ideas for a beginner,hobby data science project ideas for a beginner,"['hobby', 'data', 'science', 'project', 'ideas', 'for', 'a', 'beginner']",0,"['hobby', 'data', 'science', 'project', 'idea', 'for', 'a', 'beginner']","['hobby', 'data', 'science', 'project', 'idea', 'beginner']",hobby data science project idea beginner,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
5234,data step vs proc sql in sas,data step vs proc sql in sas,"['data', 'step', 'vs', 'proc', 'sql', 'in', 'sas']",0,"['data', 'step', 'v', 'proc', 'sql', 'in', 'sa']","['data', 'step', 'v', 'proc', 'sql', 'sa']",data step v proc sql sa,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
5235,non linear multiple regression,non linear multiple regression,"['non', 'linear', 'multiple', 'regression']",0,"['non', 'linear', 'multiple', 'regression']","['non', 'linear', 'multiple', 'regression']",non linear multiple regression,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
5236,additional factor level in test data which causes no prediction,additional factor level in test data which causes no prediction,"['additional', 'factor', 'level', 'in', 'test', 'data', 'which', 'causes', 'no', 'prediction']",0,"['additional', 'factor', 'level', 'in', 'test', 'data', 'which', 'cause', 'no', 'prediction']","['additional', 'factor', 'level', 'test', 'data', 'cause', 'prediction']",additional factor level test data cause prediction,0.0,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
5237,how to print in r without the initial ,how to print in r without the initial ,"['how', 'to', 'print', 'in', 'r', 'without', 'the', 'initial']",1,"['how', 'to', 'print', 'in', 'r', 'without', 'the', 'initial']","['print', 'r', 'without', 'initial']",print r without initial,0.0,0.0,8,23,2.5555555555555554,0,0,0,0,0,0,0,0
5238,which company is the best residential construction company in south end park hyderabad,which company is the best residential construction company in south end park hyderabad,"['which', 'company', 'is', 'the', 'best', 'residential', 'construction', 'company', 'in', 'south', 'end', 'park', 'hyderabad']",0,"['which', 'company', 'is', 'the', 'best', 'residential', 'construction', 'company', 'in', 'south', 'end', 'park', 'hyderabad']","['company', 'best', 'residential', 'construction', 'company', 'south', 'end', 'park', 'hyderabad']",company best residential construction company south end park hyderabad,1.0,1.0,13,70,5.0,0,0,0,0,0,0,0,0
5239,how the value of laplace will change the naive bayes model,how the value of laplace will change the naive bayes model,"['how', 'the', 'value', 'of', 'laplace', 'will', 'change', 'the', 'naive', 'bayes', 'model']",0,"['how', 'the', 'value', 'of', 'laplace', 'will', 'change', 'the', 'naive', 'bayes', 'model']","['value', 'laplace', 'change', 'naive', 'bayes', 'model']",value laplace change naive bayes model,-0.3,-0.3,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
5240,cant open jupyter notebook with anaconda even after successfully installing it,cant open jupyter notebook with anaconda even after successfully installing it,"['cant', 'open', 'jupyter', 'notebook', 'with', 'anaconda', 'even', 'after', 'successfully', 'installing', 'it']",0,"['cant', 'open', 'jupyter', 'notebook', 'with', 'anaconda', 'even', 'after', 'successfully', 'installing', 'it']","['cant', 'open', 'jupyter', 'notebook', 'anaconda', 'even', 'successfully', 'installing']",cant open jupyter notebook anaconda even successfully installing,0.375,0.375,11,64,5.333333333333333,0,0,0,0,0,0,0,0
5241,what does the error requires complex weights in neural nets mean,what does the error requires complex weights in neural nets mean,"['what', 'does', 'the', 'error', 'requires', 'complex', 'weights', 'in', 'neural', 'nets', 'mean']",0,"['what', 'doe', 'the', 'error', 'requires', 'complex', 'weight', 'in', 'neural', 'net', 'mean']","['doe', 'error', 'requires', 'complex', 'weight', 'neural', 'net', 'mean']",doe error requires complex weight neural net mean,-0.30625,-0.2041666666666667,11,49,4.083333333333333,0,0,0,0,0,0,0,0
5242,how to draw spider chart in r,how to draw spider chart in r,"['how', 'to', 'draw', 'spider', 'chart', 'in', 'r']",0,"['how', 'to', 'draw', 'spider', 'chart', 'in', 'r']","['draw', 'spider', 'chart', 'r']",draw spider chart r,0.0,0.0,7,19,2.375,0,0,0,0,0,0,0,0
5243,how to calculate the accuracy score of a model in python,how to calculate the accuracy score of a model in python,"['how', 'to', 'calculate', 'the', 'accuracy', 'score', 'of', 'a', 'model', 'in', 'python']",0,"['how', 'to', 'calculate', 'the', 'accuracy', 'score', 'of', 'a', 'model', 'in', 'python']","['calculate', 'accuracy', 'score', 'model', 'python']",calculate accuracy score model python,0.0,0.0,11,37,3.0833333333333335,0,0,0,0,0,0,0,0
5244,portfolio optimization,portfolio optimization,"['portfolio', 'optimization']",0,"['portfolio', 'optimization']","['portfolio', 'optimization']",portfolio optimization,0.0,0.0,2,22,7.333333333333333,0,0,0,0,0,0,0,0
5245,can anybody please help me to convert the date variable in seers accuracy competition,can anybody please help me to convert the date variable in seers accuracy competition,"['can', 'anybody', 'please', 'help', 'me', 'to', 'convert', 'the', 'date', 'variable', 'in', 'seers', 'accuracy', 'competition']",0,"['can', 'anybody', 'please', 'help', 'me', 'to', 'convert', 'the', 'date', 'variable', 'in', 'seer', 'accuracy', 'competition']","['anybody', 'please', 'help', 'convert', 'date', 'variable', 'seer', 'accuracy', 'competition']",anybody please help convert date variable seer accuracy competition,0.0,0.0,14,67,4.466666666666667,0,0,0,0,0,0,0,0
5246,why we use  to impute for missing values,why we use  to impute for missing values,"['why', 'we', 'use', 'to', 'impute', 'for', 'missing', 'values']",1,"['why', 'we', 'use', 'to', 'impute', 'for', 'missing', 'value']","['use', 'impute', 'missing', 'value']",use impute missing value,-0.2,-0.2,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
5247,how clustering helps in improving the performance of the model,how clustering helps in improving the performance of the model,"['how', 'clustering', 'helps', 'in', 'improving', 'the', 'performance', 'of', 'the', 'model']",0,"['how', 'clustering', 'help', 'in', 'improving', 'the', 'performance', 'of', 'the', 'model']","['clustering', 'help', 'improving', 'performance', 'model']",clustering help improving performance model,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
5248,why does the rare words have more weight in inverse document frequency representation,why does the rare words have more weight in inverse document frequency representation,"['why', 'does', 'the', 'rare', 'words', 'have', 'more', 'weight', 'in', 'inverse', 'document', 'frequency', 'representation']",0,"['why', 'doe', 'the', 'rare', 'word', 'have', 'more', 'weight', 'in', 'inverse', 'document', 'frequency', 'representation']","['doe', 'rare', 'word', 'weight', 'inverse', 'document', 'frequency', 'representation']",doe rare word weight inverse document frequency representation,0.4,0.3,13,62,4.428571428571429,0,0,0,0,0,0,0,0
5249,looking for sample business datasets,looking for sample business datasets,"['looking', 'for', 'sample', 'business', 'datasets']",0,"['looking', 'for', 'sample', 'business', 'datasets']","['looking', 'sample', 'business', 'datasets']",looking sample business datasets,0.0,0.0,5,32,5.333333333333333,0,0,0,0,0,0,0,0
5250,getting error while installing pattern package in python,getting error while installing pattern package in python,"['getting', 'error', 'while', 'installing', 'pattern', 'package', 'in', 'python']",0,"['getting', 'error', 'while', 'installing', 'pattern', 'package', 'in', 'python']","['getting', 'error', 'installing', 'pattern', 'package', 'python']",getting error installing pattern package python,0.0,0.0,8,47,5.222222222222222,0,0,0,0,0,0,0,0
5251,difference between ols  mle,difference between ols  mle,"['difference', 'between', 'ols', 'mle']",0,"['difference', 'between', 'ols', 'mle']","['difference', 'ols', 'mle']",difference ols mle,0.0,0.0,4,18,3.6,0,0,0,0,0,0,0,0
5252,datasets of grammatically uncommon sentences,datasets of grammatically uncommon sentences,"['datasets', 'of', 'grammatically', 'uncommon', 'sentences']",0,"['datasets', 'of', 'grammatically', 'uncommon', 'sentence']","['datasets', 'grammatically', 'uncommon', 'sentence']",datasets grammatically uncommon sentence,0.8,0.8,5,40,6.666666666666667,0,0,0,0,0,0,0,0
5253,error could not convert string to float while running randomforest model in python,error could not convert string to float while running randomforest model in python,"['error', 'could', 'not', 'convert', 'string', 'to', 'float', 'while', 'running', 'randomforest', 'model', 'in', 'python']",0,"['error', 'could', 'not', 'convert', 'string', 'to', 'float', 'while', 'running', 'randomforest', 'model', 'in', 'python']","['error', 'could', 'convert', 'string', 'float', 'running', 'randomforest', 'model', 'python']",error could convert string float running randomforest model python,0.0,0.0,13,66,4.714285714285714,0,0,0,0,0,0,0,0
5254,missing values treatment in model building steps in r,missing values treatment in model building steps in r,"['missing', 'values', 'treatment', 'in', 'model', 'building', 'steps', 'in', 'r']",0,"['missing', 'value', 'treatment', 'in', 'model', 'building', 'step', 'in', 'r']","['missing', 'value', 'treatment', 'model', 'building', 'step', 'r']",missing value treatment model building step r,-0.2,-0.2,9,45,4.5,0,0,0,0,0,0,0,0
5255,datafest  experiments with data  importing issues in the data in r,datafest  experiments with data  importing issues in the data in r,"['datafest', 'experiments', 'with', 'data', 'importing', 'issues', 'in', 'the', 'data', 'in', 'r']",0,"['datafest', 'experiment', 'with', 'data', 'importing', 'issue', 'in', 'the', 'data', 'in', 'r']","['datafest', 'experiment', 'data', 'importing', 'issue', 'data', 'r']",datafest experiment data importing issue data r,0.0,0.0,11,47,3.9166666666666665,0,0,0,0,0,0,0,0
5256,bridge school of managements pgdba program,bridge school of managements pgdba program,"['bridge', 'school', 'of', 'managements', 'pgdba', 'program']",0,"['bridge', 'school', 'of', 'management', 'pgdba', 'program']","['bridge', 'school', 'management', 'pgdba', 'program']",bridge school management pgdba program,0.0,0.0,6,38,5.428571428571429,0,0,0,0,0,0,0,0
5257,date variables in prediction,date variables in prediction,"['date', 'variables', 'in', 'prediction']",0,"['date', 'variable', 'in', 'prediction']","['date', 'variable', 'prediction']",date variable prediction,0.0,0.0,4,24,4.8,0,0,0,0,0,0,0,0
5258,article publishing,article publishing,"['article', 'publishing']",0,"['article', 'publishing']","['article', 'publishing']",article publishing,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
5259,plot two graphs on the same plot in r,plot two graphs on the same plot in r,"['plot', 'two', 'graphs', 'on', 'the', 'same', 'plot', 'in', 'r']",0,"['plot', 'two', 'graph', 'on', 'the', 'same', 'plot', 'in', 'r']","['plot', 'two', 'graph', 'plot', 'r']",plot two graph plot r,0.0,0.0,9,21,2.1,0,0,0,0,0,0,0,0
5260,data visualization in python and r,data visualization in python and r,"['data', 'visualization', 'in', 'python', 'and', 'r']",0,"['data', 'visualization', 'in', 'python', 'and', 'r']","['data', 'visualization', 'python', 'r']",data visualization python r,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
5261,residual plot to validate linear model,residual plot to validate linear model,"['residual', 'plot', 'to', 'validate', 'linear', 'model']",0,"['residual', 'plot', 'to', 'validate', 'linear', 'model']","['residual', 'plot', 'validate', 'linear', 'model']",residual plot validate linear model,0.0,0.0,6,35,5.0,0,0,0,0,0,0,0,0
5262,test for this func,test for this func,"['test', 'for', 'this', 'func']",0,"['test', 'for', 'this', 'func']","['test', 'func']",test func,0.0,0.0,4,9,1.8,0,0,0,0,0,0,0,0
5263,create frequency table in r,create frequency table in r,"['create', 'frequency', 'table', 'in', 'r']",0,"['create', 'frequency', 'table', 'in', 'r']","['create', 'frequency', 'table', 'r']",create frequency table r,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
5264,any quick way to classify large dataset into smaller buckets to get better linear regression model for each bucket,any quick way to classify large dataset into smaller buckets to get better linear regression model for each bucket,"['any', 'quick', 'way', 'to', 'classify', 'large', 'dataset', 'into', 'smaller', 'buckets', 'to', 'get', 'better', 'linear', 'regression', 'model', 'for', 'each', 'bucket']",0,"['any', 'quick', 'way', 'to', 'classify', 'large', 'dataset', 'into', 'smaller', 'bucket', 'to', 'get', 'better', 'linear', 'regression', 'model', 'for', 'each', 'bucket']","['quick', 'way', 'classify', 'large', 'dataset', 'smaller', 'bucket', 'get', 'better', 'linear', 'regression', 'model', 'bucket']",quick way classify large dataset smaller bucket get better linear regression model bucket,0.2619047619047618,0.2619047619047618,19,89,4.45,0,0,0,0,0,0,0,0
5265,how to solve a route optimization problem in r,how to solve a route optimization problem in r,"['how', 'to', 'solve', 'a', 'route', 'optimization', 'problem', 'in', 'r']",0,"['how', 'to', 'solve', 'a', 'route', 'optimization', 'problem', 'in', 'r']","['solve', 'route', 'optimization', 'problem', 'r']",solve route optimization problem r,0.0,0.0,9,34,3.4,0,0,0,0,0,0,0,0
5266,how to add a new column in a existing data in r,how to add a new column in a existing data in r,"['how', 'to', 'add', 'a', 'new', 'column', 'in', 'a', 'existing', 'data', 'in', 'r']",0,"['how', 'to', 'add', 'a', 'new', 'column', 'in', 'a', 'existing', 'data', 'in', 'r']","['add', 'new', 'column', 'existing', 'data', 'r']",add new column existing data r,0.1363636363636363,0.1363636363636363,12,30,2.3076923076923075,0,0,0,0,0,0,0,0
5267,svm algorithm performance,svm algorithm performance,"['svm', 'algorithm', 'performance']",0,"['svm', 'algorithm', 'performance']","['svm', 'algorithm', 'performance']",svm algorithm performance,0.0,0.0,3,25,6.25,0,0,0,0,0,0,0,0
5268,institute in pune for r and python,institute in pune for r and python,"['institute', 'in', 'pune', 'for', 'r', 'and', 'python']",0,"['institute', 'in', 'pune', 'for', 'r', 'and', 'python']","['institute', 'pune', 'r', 'python']",institute pune r python,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
5269,wns  niit university joint mba program in business analytics  thoughts  feedback from experts required,wns  niit university joint mba program in business analytics  thoughts  feedback from experts required,"['wns', 'niit', 'university', 'joint', 'mba', 'program', 'in', 'business', 'analytics', 'thoughts', 'feedback', 'from', 'experts', 'required']",0,"['wns', 'niit', 'university', 'joint', 'mba', 'program', 'in', 'business', 'analytics', 'thought', 'feedback', 'from', 'expert', 'required']","['wns', 'niit', 'university', 'joint', 'mba', 'program', 'business', 'analytics', 'thought', 'feedback', 'expert', 'required']",wns niit university joint mba program business analytics thought feedback expert required,0.0,0.0,14,89,5.933333333333334,0,0,0,0,0,0,0,0
5270,how to fill the element in matrix by row wise in r,how to fill the element in matrix by row wise in r,"['how', 'to', 'fill', 'the', 'element', 'in', 'matrix', 'by', 'row', 'wise', 'in', 'r']",0,"['how', 'to', 'fill', 'the', 'element', 'in', 'matrix', 'by', 'row', 'wise', 'in', 'r']","['fill', 'element', 'matrix', 'row', 'wise', 'r']",fill element matrix row wise r,0.7,0.7,12,30,2.3076923076923075,0,0,0,0,0,0,0,0
5271,web scraping with r using rvest for financial website,web scraping with r using rvest for financial website,"['web', 'scraping', 'with', 'r', 'using', 'rvest', 'for', 'financial', 'website']",0,"['web', 'scraping', 'with', 'r', 'using', 'rvest', 'for', 'financial', 'website']","['web', 'scraping', 'r', 'using', 'rvest', 'financial', 'website']",web scraping r using rvest financial website,0.0,0.0,9,44,4.4,0,0,0,0,0,0,0,0
5272,how do you exploit the social media data,how do you exploit the social media data,"['how', 'do', 'you', 'exploit', 'the', 'social', 'media', 'data']",0,"['how', 'do', 'you', 'exploit', 'the', 'social', 'medium', 'data']","['exploit', 'social', 'medium', 'data']",exploit social medium data,0.0333333333333333,0.0333333333333333,8,26,2.888888888888889,0,0,0,0,0,0,0,0
5273,how to find internship in data science,how to find internship in data science,"['how', 'to', 'find', 'internship', 'in', 'data', 'science']",0,"['how', 'to', 'find', 'internship', 'in', 'data', 'science']","['find', 'internship', 'data', 'science']",find internship data science,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
5274,xgboost bank data,xgboost bank data,"['xgboost', 'bank', 'data']",0,"['xgboost', 'bank', 'data']","['xgboost', 'bank', 'data']",xgboost bank data,0.0,0.0,3,17,4.25,0,0,0,0,0,0,0,0
5275,how is data collected for analysis,how is data collected for analysis,"['how', 'is', 'data', 'collected', 'for', 'analysis']",0,"['how', 'is', 'data', 'collected', 'for', 'analysis']","['data', 'collected', 'analysis']",data collected analysis,0.0,0.0,6,23,3.2857142857142856,0,0,0,0,0,0,0,0
5276,what is the difference between bagging of decision trees and random forest,what is the difference between bagging of decision trees and random forest,"['what', 'is', 'the', 'difference', 'between', 'bagging', 'of', 'decision', 'trees', 'and', 'random', 'forest']",0,"['what', 'is', 'the', 'difference', 'between', 'bagging', 'of', 'decision', 'tree', 'and', 'random', 'forest']","['difference', 'bagging', 'decision', 'tree', 'random', 'forest']",difference bagging decision tree random forest,-0.5,-0.5,12,46,3.5384615384615383,0,0,0,0,0,0,0,0
5277,data mining concept tenchnique,data mining concept tenchnique,"['data', 'mining', 'concept', 'tenchnique']",0,"['data', 'mining', 'concept', 'tenchnique']","['data', 'mining', 'concept', 'tenchnique']",data mining concept tenchnique,0.0,0.0,4,30,6.0,0,0,0,0,0,0,0,0
5278,transition to data science,transition to data science,"['transition', 'to', 'data', 'science']",0,"['transition', 'to', 'data', 'science']","['transition', 'data', 'science']",transition data science,0.0,0.0,4,23,4.6,0,0,0,0,0,0,0,0
5279,errors while executing codes after importing pygraphviz,errors while executing codes after importing pygraphviz,"['errors', 'while', 'executing', 'codes', 'after', 'importing', 'pygraphviz']",0,"['error', 'while', 'executing', 'code', 'after', 'importing', 'pygraphviz']","['error', 'executing', 'code', 'importing', 'pygraphviz']",error executing code importing pygraphviz,0.0,0.0,7,41,5.125,0,0,0,0,0,0,0,0
5280,displaying alphabets with help of property,displaying alphabets with help of property,"['displaying', 'alphabets', 'with', 'help', 'of', 'property']",0,"['displaying', 'alphabet', 'with', 'help', 'of', 'property']","['displaying', 'alphabet', 'help', 'property']",displaying alphabet help property,0.0,0.0,6,33,4.714285714285714,0,0,0,0,0,0,0,0
5281,join volunteer club be our data science torchbearers,join volunteer club be our data science torchbearers,"['join', 'volunteer', 'club', 'be', 'our', 'data', 'science', 'torchbearers']",0,"['join', 'volunteer', 'club', 'be', 'our', 'data', 'science', 'torchbearer']","['join', 'volunteer', 'club', 'data', 'science', 'torchbearer']",join volunteer club data science torchbearer,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
5282,data reading with r,data reading with r,"['data', 'reading', 'with', 'r']",0,"['data', 'reading', 'with', 'r']","['data', 'reading', 'r']",data reading r,0.0,0.0,4,14,2.8,0,0,0,0,0,0,0,0
5283,two graphs together on the same plot in r using ggplot,two graphs together on the same plot in r using ggplot,"['two', 'graphs', 'together', 'on', 'the', 'same', 'plot', 'in', 'r', 'using', 'ggplot']",0,"['two', 'graph', 'together', 'on', 'the', 'same', 'plot', 'in', 'r', 'using', 'ggplot']","['two', 'graph', 'together', 'plot', 'r', 'using', 'ggplot']",two graph together plot r using ggplot,0.0,0.0,11,38,3.1666666666666665,0,0,0,0,0,0,0,0
5284,ms in analytics from us or pgdba from iim cisi kolkata  iit kharagpur,ms in analytics from us or pgdba from iim cisi kolkata  iit kharagpur,"['ms', 'in', 'analytics', 'from', 'us', 'or', 'pgdba', 'from', 'iim', 'cisi', 'kolkata', 'iit', 'kharagpur']",0,"['m', 'in', 'analytics', 'from', 'u', 'or', 'pgdba', 'from', 'iim', 'cisi', 'kolkata', 'iit', 'kharagpur']","['analytics', 'u', 'pgdba', 'iim', 'cisi', 'kolkata', 'iit', 'kharagpur']",analytics u pgdba iim cisi kolkata iit kharagpur,0.0,0.0,13,48,3.4285714285714284,0,0,0,0,0,0,0,0
5285,how can i convert a groupby dataframe to dataframe in python,how can i convert a groupby dataframe to dataframe in python,"['how', 'can', 'i', 'convert', 'a', 'groupby', 'dataframe', 'to', 'dataframe', 'in', 'python']",0,"['how', 'can', 'i', 'convert', 'a', 'groupby', 'dataframe', 'to', 'dataframe', 'in', 'python']","['convert', 'groupby', 'dataframe', 'dataframe', 'python']",convert groupby dataframe dataframe python,0.0,0.0,11,42,3.5,0,0,0,0,0,0,0,0
5286,spell error mapping,spell error mapping,"['spell', 'error', 'mapping']",0,"['spell', 'error', 'mapping']","['spell', 'error', 'mapping']",spell error mapping,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
5287,structured thinking resource,structured thinking resource,"['structured', 'thinking', 'resource']",0,"['structured', 'thinking', 'resource']","['structured', 'thinking', 'resource']",structured thinking resource,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
5288,importing dataset,importing dataset,"['importing', 'dataset']",0,"['importing', 'dataset']","['importing', 'dataset']",importing dataset,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
5289,rstudio v released,rstudio v released,"['rstudio', 'v', 'released']",0,"['rstudio', 'v', 'released']","['rstudio', 'v', 'released']",rstudio v released,0.0,0.0,3,18,4.5,0,0,0,0,0,0,0,0
5290,xgboost package in r,xgboost package in r,"['xgboost', 'package', 'in', 'r']",0,"['xgboost', 'package', 'in', 'r']","['xgboost', 'package', 'r']",xgboost package r,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
5291,how to decide the kernal type in svm,how to decide the kernal type in svm,"['how', 'to', 'decide', 'the', 'kernal', 'type', 'in', 'svm']",0,"['how', 'to', 'decide', 'the', 'kernal', 'type', 'in', 'svm']","['decide', 'kernal', 'type', 'svm']",decide kernal type svm,0.0,0.0,8,22,2.4444444444444446,0,0,0,0,0,0,0,0
5292,collinearity versus correlation,collinearity versus correlation,"['collinearity', 'versus', 'correlation']",0,"['collinearity', 'versus', 'correlation']","['collinearity', 'versus', 'correlation']",collinearity versus correlation,0.0,0.0,3,31,7.75,0,0,0,0,0,0,0,0
5293,framework to build survival analysis model on r,framework to build survival analysis model on r,"['framework', 'to', 'build', 'survival', 'analysis', 'model', 'on', 'r']",0,"['framework', 'to', 'build', 'survival', 'analysis', 'model', 'on', 'r']","['framework', 'build', 'survival', 'analysis', 'model', 'r']",framework build survival analysis model r,0.0,0.0,8,41,4.555555555555555,0,0,0,0,0,0,0,0
5294,export a file into json format in r,export a file into json format in r,"['export', 'a', 'file', 'into', 'json', 'format', 'in', 'r']",0,"['export', 'a', 'file', 'into', 'json', 'format', 'in', 'r']","['export', 'file', 'json', 'format', 'r']",export file json format r,0.0,0.0,8,25,2.7777777777777777,0,0,0,0,0,0,0,0
5295,hadoop projects for big data analysis,hadoop projects for big data analysis,"['hadoop', 'projects', 'for', 'big', 'data', 'analysis']",0,"['hadoop', 'project', 'for', 'big', 'data', 'analysis']","['hadoop', 'project', 'big', 'data', 'analysis']",hadoop project big data analysis,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
5296,how use gridsearchcv and pipelines to crossvalidate best categorical encoding,how use gridsearchcv and pipelines to crossvalidate best categorical encoding,"['how', 'use', 'gridsearchcv', 'and', 'pipelines', 'to', 'crossvalidate', 'best', 'categorical', 'encoding']",0,"['how', 'use', 'gridsearchcv', 'and', 'pipeline', 'to', 'crossvalidate', 'best', 'categorical', 'encoding']","['use', 'gridsearchcv', 'pipeline', 'crossvalidate', 'best', 'categorical', 'encoding']",use gridsearchcv pipeline crossvalidate best categorical encoding,1.0,1.0,10,65,5.909090909090909,0,0,0,0,0,0,0,0
5297,linear regression doubt,linear regression doubt,"['linear', 'regression', 'doubt']",0,"['linear', 'regression', 'doubt']","['linear', 'regression', 'doubt']",linear regression doubt,0.0,0.0,3,23,5.75,0,0,0,0,0,0,0,0
5298,what is the errorevol output from boosting in r,what is the errorevol output from boosting in r,"['what', 'is', 'the', 'errorevol', 'output', 'from', 'boosting', 'in', 'r']",0,"['what', 'is', 'the', 'errorevol', 'output', 'from', 'boosting', 'in', 'r']","['errorevol', 'output', 'boosting', 'r']",errorevol output boosting r,0.0,0.0,9,27,2.7,0,0,0,0,0,0,0,0
5299,download hd infographic   essential data science books,download hd infographic   essential data science books,"['download', 'hd', 'infographic', 'essential', 'data', 'science', 'books']",1,"['download', 'hd', 'infographic', 'essential', 'data', 'science', 'book']","['download', 'hd', 'infographic', 'essential', 'data', 'science', 'book']",download hd infographic essential data science book,0.0,0.0,7,51,6.375,0,0,0,0,0,0,0,0
5300,hackathon crosssell target the right customer  issue with submission data,hackathon crosssell target the right customer  issue with submission data,"['hackathon', 'crosssell', 'target', 'the', 'right', 'customer', 'issue', 'with', 'submission', 'data']",0,"['hackathon', 'crosssell', 'target', 'the', 'right', 'customer', 'issue', 'with', 'submission', 'data']","['hackathon', 'crosssell', 'target', 'right', 'customer', 'issue', 'submission', 'data']",hackathon crosssell target right customer issue submission data,0.2857142857142857,0.2857142857142857,10,63,5.7272727272727275,0,0,0,0,0,0,0,0
5301,best database for short  months analyticsadvanced analytics engagements,best database for short  months analyticsadvanced analytics engagements,"['best', 'database', 'for', 'short', 'months', 'analyticsadvanced', 'analytics', 'engagements']",1,"['best', 'database', 'for', 'short', 'month', 'analyticsadvanced', 'analytics', 'engagement']","['best', 'database', 'short', 'month', 'analyticsadvanced', 'analytics', 'engagement']",best database short month analyticsadvanced analytics engagement,0.5,0.5,8,64,7.111111111111111,0,0,0,0,0,0,0,0
5302,classification of association rules,classification of association rules,"['classification', 'of', 'association', 'rules']",0,"['classification', 'of', 'association', 'rule']","['classification', 'association', 'rule']",classification association rule,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
5303,grid search related to machine learning knn algorithm,grid search related to machine learning knn algorithm,"['grid', 'search', 'related', 'to', 'machine', 'learning', 'knn', 'algorithm']",0,"['grid', 'search', 'related', 'to', 'machine', 'learning', 'knn', 'algorithm']","['grid', 'search', 'related', 'machine', 'learning', 'knn', 'algorithm']",grid search related machine learning knn algorithm,0.0,0.0,8,50,5.555555555555555,0,0,0,0,0,0,0,0
5304,question on artificial intelligence,question on artificial intelligence,"['question', 'on', 'artificial', 'intelligence']",0,"['question', 'on', 'artificial', 'intelligence']","['question', 'artificial', 'intelligence']",question artificial intelligence,-0.6,-0.6,4,32,6.4,0,0,0,0,0,0,0,0
5305,apply function with multiple parameters in r,apply function with multiple parameters in r,"['apply', 'function', 'with', 'multiple', 'parameters', 'in', 'r']",0,"['apply', 'function', 'with', 'multiple', 'parameter', 'in', 'r']","['apply', 'function', 'multiple', 'parameter', 'r']",apply function multiple parameter r,0.0,0.0,7,35,4.375,0,0,0,0,0,0,0,0
5306, useful pandas techniques in python for data manipulation, useful pandas techniques in python for data manipulation,"['useful', 'pandas', 'techniques', 'in', 'python', 'for', 'data', 'manipulation']",1,"['useful', 'panda', 'technique', 'in', 'python', 'for', 'data', 'manipulation']","['useful', 'panda', 'technique', 'python', 'data', 'manipulation']",useful panda technique python data manipulation,0.3,0.3,8,47,5.222222222222222,0,0,0,0,0,0,0,0
5307,what is varimax rotation in pca,what is varimax rotation in pca,"['what', 'is', 'varimax', 'rotation', 'in', 'pca']",0,"['what', 'is', 'varimax', 'rotation', 'in', 'pca']","['varimax', 'rotation', 'pca']",varimax rotation pca,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
5308,stl for non seasonal time series data in r,stl for non seasonal time series data in r,"['stl', 'for', 'non', 'seasonal', 'time', 'series', 'data', 'in', 'r']",0,"['stl', 'for', 'non', 'seasonal', 'time', 'series', 'data', 'in', 'r']","['stl', 'non', 'seasonal', 'time', 'series', 'data', 'r']",stl non seasonal time series data r,0.0,0.0,9,35,3.5,0,0,0,0,0,0,0,0
5309,dataset for natural language processing project,dataset for natural language processing project,"['dataset', 'for', 'natural', 'language', 'processing', 'project']",0,"['dataset', 'for', 'natural', 'language', 'processing', 'project']","['dataset', 'natural', 'language', 'processing', 'project']",dataset natural language processing project,0.1,0.1,6,43,6.142857142857143,0,0,0,0,0,0,0,0
5310,how to clean the test set,how to clean the test set,"['how', 'to', 'clean', 'the', 'test', 'set']",0,"['how', 'to', 'clean', 'the', 'test', 'set']","['clean', 'test', 'set']",clean test set,0.3666666666666667,0.3666666666666667,6,14,2.0,0,0,0,0,0,0,0,0
5311,binning and encoding for cat and numerical variables in r,binning and encoding for cat and numerical variables in r,"['binning', 'and', 'encoding', 'for', 'cat', 'and', 'numerical', 'variables', 'in', 'r']",0,"['binning', 'and', 'encoding', 'for', 'cat', 'and', 'numerical', 'variable', 'in', 'r']","['binning', 'encoding', 'cat', 'numerical', 'variable', 'r']",binning encoding cat numerical variable r,0.0,0.0,10,41,3.727272727272727,0,0,0,0,0,0,0,0
5312,which algorithm fits best for predicting continuous outcome from continuous and categorical inputs,which algorithm fits best for predicting continuous outcome from continuous and categorical inputs,"['which', 'algorithm', 'fits', 'best', 'for', 'predicting', 'continuous', 'outcome', 'from', 'continuous', 'and', 'categorical', 'inputs']",0,"['which', 'algorithm', 'fit', 'best', 'for', 'predicting', 'continuous', 'outcome', 'from', 'continuous', 'and', 'categorical', 'input']","['algorithm', 'fit', 'best', 'predicting', 'continuous', 'outcome', 'continuous', 'categorical', 'input']",algorithm fit best predicting continuous outcome continuous categorical input,1.0,0.7,13,77,5.5,0,0,0,0,0,0,0,0
5313,nlp reading materials,nlp reading materials,"['nlp', 'reading', 'materials']",0,"['nlp', 'reading', 'material']","['nlp', 'reading', 'material']",nlp reading material,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
5314,too many false postives with unbalanced data,too many false postives with unbalanced data,"['too', 'many', 'false', 'postives', 'with', 'unbalanced', 'data']",0,"['too', 'many', 'false', 'postives', 'with', 'unbalanced', 'data']","['many', 'false', 'postives', 'unbalanced', 'data']",many false postives unbalanced data,0.0499999999999999,0.0499999999999999,7,35,4.375,0,0,0,0,0,0,0,0
5315,meaning of the statement  formataccuracy in print accuracy  s  formataccuracy,meaning of the statement  formataccuracy in print accuracy  s  formataccuracy,"['meaning', 'of', 'the', 'statement', 'formataccuracy', 'in', 'print', 'accuracy', 's', 'formataccuracy']",0,"['meaning', 'of', 'the', 'statement', 'formataccuracy', 'in', 'print', 'accuracy', 's', 'formataccuracy']","['meaning', 'statement', 'formataccuracy', 'print', 'accuracy', 'formataccuracy']",meaning statement formataccuracy print accuracy formataccuracy,0.0,0.0,10,62,5.636363636363637,0,0,0,0,0,0,0,0
5316,pgpm or pgdm full time from great lakes,pgpm or pgdm full time from great lakes,"['pgpm', 'or', 'pgdm', 'full', 'time', 'from', 'great', 'lakes']",0,"['pgpm', 'or', 'pgdm', 'full', 'time', 'from', 'great', 'lake']","['pgpm', 'pgdm', 'full', 'time', 'great', 'lake']",pgpm pgdm full time great lake,0.575,0.575,8,30,3.3333333333333335,0,0,0,0,0,0,0,0
5317,join volunteer club be our data science torchbearers,join volunteer club be our data science torchbearers,"['join', 'volunteer', 'club', 'be', 'our', 'data', 'science', 'torchbearers']",0,"['join', 'volunteer', 'club', 'be', 'our', 'data', 'science', 'torchbearer']","['join', 'volunteer', 'club', 'data', 'science', 'torchbearer']",join volunteer club data science torchbearer,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
5318,career opportunities in analytics for mba freshers,career opportunities in analytics for mba freshers,"['career', 'opportunities', 'in', 'analytics', 'for', 'mba', 'freshers']",0,"['career', 'opportunity', 'in', 'analytics', 'for', 'mba', 'fresher']","['career', 'opportunity', 'analytics', 'mba', 'fresher']",career opportunity analytics mba fresher,0.0,0.0,7,40,5.0,0,0,0,0,0,0,0,0
5319,aggregations using spark data frames in java for large data,aggregations using spark data frames in java for large data,"['aggregations', 'using', 'spark', 'data', 'frames', 'in', 'java', 'for', 'large', 'data']",0,"['aggregation', 'using', 'spark', 'data', 'frame', 'in', 'java', 'for', 'large', 'data']","['aggregation', 'using', 'spark', 'data', 'frame', 'java', 'large', 'data']",aggregation using spark data frame java large data,0.2142857142857142,0.2142857142857142,10,50,4.545454545454546,0,0,0,0,0,0,0,0
5320,infographic  a complete guide on getting started with deep learning in python,infographic  a complete guide on getting started with deep learning in python,"['infographic', 'a', 'complete', 'guide', 'on', 'getting', 'started', 'with', 'deep', 'learning', 'in', 'python']",0,"['infographic', 'a', 'complete', 'guide', 'on', 'getting', 'started', 'with', 'deep', 'learning', 'in', 'python']","['infographic', 'complete', 'guide', 'getting', 'started', 'deep', 'learning', 'python']",infographic complete guide getting started deep learning python,0.05,0.05,12,63,4.846153846153846,0,0,0,0,0,0,0,0
5321,hackathon process,hackathon process,"['hackathon', 'process']",0,"['hackathon', 'process']","['hackathon', 'process']",hackathon process,0.0,0.0,2,17,5.666666666666667,0,0,0,0,0,0,0,0
5322,how to remove error while creating list in python using spyder,how to remove error while creating list in python using spyder,"['how', 'to', 'remove', 'error', 'while', 'creating', 'list', 'in', 'python', 'using', 'spyder']",0,"['how', 'to', 'remove', 'error', 'while', 'creating', 'list', 'in', 'python', 'using', 'spyder']","['remove', 'error', 'creating', 'list', 'python', 'using', 'spyder']",remove error creating list python using spyder,0.0,0.0,11,46,3.8333333333333335,0,0,0,0,0,0,0,0
5323,help needed for sequence problem,help needed for sequence problem,"['help', 'needed', 'for', 'sequence', 'problem']",0,"['help', 'needed', 'for', 'sequence', 'problem']","['help', 'needed', 'sequence', 'problem']",help needed sequence problem,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
5324,how to deal with mixed objects in r,how to deal with mixed objects in r,"['how', 'to', 'deal', 'with', 'mixed', 'objects', 'in', 'r']",0,"['how', 'to', 'deal', 'with', 'mixed', 'object', 'in', 'r']","['deal', 'mixed', 'object', 'r']",deal mixed object r,0.0,0.0,8,19,2.111111111111111,0,0,0,0,0,0,0,0
5325,best resources to break into data science,best resources to break into data science,"['best', 'resources', 'to', 'break', 'into', 'data', 'science']",0,"['best', 'resource', 'to', 'break', 'into', 'data', 'science']","['best', 'resource', 'break', 'data', 'science']",best resource break data science,1.0,1.0,7,32,4.0,0,0,0,0,0,0,0,0
5326,are precision and recall interdependant,are precision and recall interdependant,"['are', 'precision', 'and', 'recall', 'interdependant']",0,"['are', 'precision', 'and', 'recall', 'interdependant']","['precision', 'recall', 'interdependant']",precision recall interdependant,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
5327,logisticregression,logisticregression,['logisticregression'],0,['logisticregression'],['logisticregression'],logisticregression,0.0,0.0,1,18,9.0,0,0,0,0,0,0,0,0
5328,statistics for data science,statistics for data science,"['statistics', 'for', 'data', 'science']",0,"['statistic', 'for', 'data', 'science']","['statistic', 'data', 'science']",statistic data science,0.0,0.0,4,22,4.4,0,0,0,0,0,0,0,0
5329,internship after certification course,internship after certification course,"['internship', 'after', 'certification', 'course']",0,"['internship', 'after', 'certification', 'course']","['internship', 'certification', 'course']",internship certification course,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
5330,replacing punctuation by space in text analytics,replacing punctuation by space in text analytics,"['replacing', 'punctuation', 'by', 'space', 'in', 'text', 'analytics']",0,"['replacing', 'punctuation', 'by', 'space', 'in', 'text', 'analytics']","['replacing', 'punctuation', 'space', 'text', 'analytics']",replacing punctuation space text analytics,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
5331,how to input multiple indices on pdcrosstab,how to input multiple indices on pdcrosstab,"['how', 'to', 'input', 'multiple', 'indices', 'on', 'pdcrosstab']",0,"['how', 'to', 'input', 'multiple', 'index', 'on', 'pdcrosstab']","['input', 'multiple', 'index', 'pdcrosstab']",input multiple index pdcrosstab,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
5332,how to extract important variables from random forest model using varimpplot in r,how to extract important variables from random forest model using varimpplot in r,"['how', 'to', 'extract', 'important', 'variables', 'from', 'random', 'forest', 'model', 'using', 'varimpplot', 'in', 'r']",0,"['how', 'to', 'extract', 'important', 'variable', 'from', 'random', 'forest', 'model', 'using', 'varimpplot', 'in', 'r']","['extract', 'important', 'variable', 'random', 'forest', 'model', 'using', 'varimpplot', 'r']",extract important variable random forest model using varimpplot r,-0.0499999999999999,-0.0499999999999999,13,65,4.642857142857143,0,0,0,0,0,0,0,0
5333,deep learning setup requirements,deep learning setup requirements,"['deep', 'learning', 'setup', 'requirements']",0,"['deep', 'learning', 'setup', 'requirement']","['deep', 'learning', 'setup', 'requirement']",deep learning setup requirement,0.0,0.0,4,31,6.2,0,0,0,0,0,0,0,0
5334,companies hiring for business analyst,companies hiring for business analyst,"['companies', 'hiring', 'for', 'business', 'analyst']",0,"['company', 'hiring', 'for', 'business', 'analyst']","['company', 'hiring', 'business', 'analyst']",company hiring business analyst,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
5335,calculating information gain in decision trees while choosing which attribute to split on,calculating information gain in decision trees while choosing which attribute to split on,"['calculating', 'information', 'gain', 'in', 'decision', 'trees', 'while', 'choosing', 'which', 'attribute', 'to', 'split', 'on']",0,"['calculating', 'information', 'gain', 'in', 'decision', 'tree', 'while', 'choosing', 'which', 'attribute', 'to', 'split', 'on']","['calculating', 'information', 'gain', 'decision', 'tree', 'choosing', 'attribute', 'split']",calculating information gain decision tree choosing attribute split,0.0,0.0,13,67,4.785714285714286,0,0,0,0,0,0,0,0
5336,how to plot a proper decision tree using fancyrpartplot in r,how to plot a proper decision tree using fancyrpartplot in r,"['how', 'to', 'plot', 'a', 'proper', 'decision', 'tree', 'using', 'fancyrpartplot', 'in', 'r']",0,"['how', 'to', 'plot', 'a', 'proper', 'decision', 'tree', 'using', 'fancyrpartplot', 'in', 'r']","['plot', 'proper', 'decision', 'tree', 'using', 'fancyrpartplot', 'r']",plot proper decision tree using fancyrpartplot r,0.0,0.0,11,48,4.0,0,0,0,0,0,0,0,0
5337,why scaling matters in in lasso regression,why scaling matters in in lasso regression,"['why', 'scaling', 'matters', 'in', 'in', 'lasso', 'regression']",0,"['why', 'scaling', 'matter', 'in', 'in', 'lasso', 'regression']","['scaling', 'matter', 'lasso', 'regression']",scaling matter lasso regression,0.0,0.0,7,31,3.875,0,0,0,0,0,0,0,0
5338,how to replace the missing values with mean in a sas dataset,how to replace the missing values with mean in a sas dataset,"['how', 'to', 'replace', 'the', 'missing', 'values', 'with', 'mean', 'in', 'a', 'sas', 'dataset']",0,"['how', 'to', 'replace', 'the', 'missing', 'value', 'with', 'mean', 'in', 'a', 'sa', 'dataset']","['replace', 'missing', 'value', 'mean', 'sa', 'dataset']",replace missing value mean sa dataset,-0.25625,-0.25625,12,37,2.8461538461538463,0,0,0,0,0,0,0,0
5339,importing sql server data into r,importing sql server data into r,"['importing', 'sql', 'server', 'data', 'into', 'r']",0,"['importing', 'sql', 'server', 'data', 'into', 'r']","['importing', 'sql', 'server', 'data', 'r']",importing sql server data r,0.0,0.0,6,27,3.857142857142857,0,0,0,0,0,0,0,0
5340,submission file error,submission file error,"['submission', 'file', 'error']",0,"['submission', 'file', 'error']","['submission', 'file', 'error']",submission file error,0.0,0.0,3,21,5.25,0,0,0,0,0,0,0,0
5341,hackathon resource guide for tomorrow,hackathon resource guide for tomorrow,"['hackathon', 'resource', 'guide', 'for', 'tomorrow']",0,"['hackathon', 'resource', 'guide', 'for', 'tomorrow']","['hackathon', 'resource', 'guide', 'tomorrow']",hackathon resource guide tomorrow,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
5342,career shift from it to big data  hadoop,career shift from it to big data  hadoop,"['career', 'shift', 'from', 'it', 'to', 'big', 'data', 'hadoop']",0,"['career', 'shift', 'from', 'it', 'to', 'big', 'data', 'hadoop']","['career', 'shift', 'big', 'data', 'hadoop']",career shift big data hadoop,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
5343,want to make an innovativecreativeattractive deep learning project which make my resume better,want to make an innovativecreativeattractive deep learning project which make my resume better,"['want', 'to', 'make', 'an', 'innovativecreativeattractive', 'deep', 'learning', 'project', 'which', 'make', 'my', 'resume', 'better']",0,"['want', 'to', 'make', 'an', 'innovativecreativeattractive', 'deep', 'learning', 'project', 'which', 'make', 'my', 'resume', 'better']","['want', 'make', 'innovativecreativeattractive', 'deep', 'learning', 'project', 'make', 'resume', 'better']",want make innovativecreativeattractive deep learning project make resume better,0.25,0.25,13,79,5.642857142857143,0,0,0,0,0,0,0,0
5344,colinearity and corelation,colinearity and corelation,"['colinearity', 'and', 'corelation']",0,"['colinearity', 'and', 'corelation']","['colinearity', 'corelation']",colinearity corelation,0.0,0.0,3,22,5.5,0,0,0,0,0,0,0,0
5345,machine learning using sas vs python,machine learning using sas vs python,"['machine', 'learning', 'using', 'sas', 'vs', 'python']",0,"['machine', 'learning', 'using', 'sa', 'v', 'python']","['machine', 'learning', 'using', 'sa', 'v', 'python']",machine learning using sa v python,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
5346,what are additive models,what are additive models,"['what', 'are', 'additive', 'models']",0,"['what', 'are', 'additive', 'model']","['additive', 'model']",additive model,0.0,0.0,4,14,2.8,0,0,0,0,0,0,0,0
5347,variable selection in r similar to proc varclus in sas,variable selection in r similar to proc varclus in sas,"['variable', 'selection', 'in', 'r', 'similar', 'to', 'proc', 'varclus', 'in', 'sas']",0,"['variable', 'selection', 'in', 'r', 'similar', 'to', 'proc', 'varclus', 'in', 'sa']","['variable', 'selection', 'r', 'similar', 'proc', 'varclus', 'sa']",variable selection r similar proc varclus sa,0.0,0.0,10,44,4.0,0,0,0,0,0,0,0,0
5348,i could not download the file with the data,i could not download the file with the data,"['i', 'could', 'not', 'download', 'the', 'file', 'with', 'the', 'data']",0,"['i', 'could', 'not', 'download', 'the', 'file', 'with', 'the', 'data']","['could', 'download', 'file', 'data']",could download file data,0.0,0.0,9,24,2.4,0,0,0,0,0,0,0,0
5349,imbalanced classification,imbalanced classification,"['imbalanced', 'classification']",0,"['imbalanced', 'classification']","['imbalanced', 'classification']",imbalanced classification,0.0,0.0,2,25,8.333333333333334,0,0,0,0,0,0,0,0
5350,how to save compact prediction tree cpt model,how to save compact prediction tree cpt model,"['how', 'to', 'save', 'compact', 'prediction', 'tree', 'cpt', 'model']",0,"['how', 'to', 'save', 'compact', 'prediction', 'tree', 'cpt', 'model']","['save', 'compact', 'prediction', 'tree', 'cpt', 'model']",save compact prediction tree cpt model,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
5351,how to calculate baseline prediction of a linear regression model,how to calculate baseline prediction of a linear regression model,"['how', 'to', 'calculate', 'baseline', 'prediction', 'of', 'a', 'linear', 'regression', 'model']",0,"['how', 'to', 'calculate', 'baseline', 'prediction', 'of', 'a', 'linear', 'regression', 'model']","['calculate', 'baseline', 'prediction', 'linear', 'regression', 'model']",calculate baseline prediction linear regression model,0.0,0.0,10,53,4.818181818181818,0,0,0,0,0,0,0,0
5352,predicting customer rechargetopup value for prepaid customer,predicting customer rechargetopup value for prepaid customer,"['predicting', 'customer', 'rechargetopup', 'value', 'for', 'prepaid', 'customer']",0,"['predicting', 'customer', 'rechargetopup', 'value', 'for', 'prepaid', 'customer']","['predicting', 'customer', 'rechargetopup', 'value', 'prepaid', 'customer']",predicting customer rechargetopup value prepaid customer,0.0,0.0,7,56,7.0,0,0,0,0,0,0,0,0
5353,a sr statistician needs guidance to build data science skills,a sr statistician needs guidance to build data science skills,"['a', 'sr', 'statistician', 'needs', 'guidance', 'to', 'build', 'data', 'science', 'skills']",0,"['a', 'sr', 'statistician', 'need', 'guidance', 'to', 'build', 'data', 'science', 'skill']","['sr', 'statistician', 'need', 'guidance', 'build', 'data', 'science', 'skill']",sr statistician need guidance build data science skill,0.0,0.0,10,54,4.909090909090909,0,0,0,0,0,0,0,0
5354,how well do we need to be skilled for getting an internship in data science,how well do we need to be skilled for getting an internship in data science,"['how', 'well', 'do', 'we', 'need', 'to', 'be', 'skilled', 'for', 'getting', 'an', 'internship', 'in', 'data', 'science']",0,"['how', 'well', 'do', 'we', 'need', 'to', 'be', 'skilled', 'for', 'getting', 'an', 'internship', 'in', 'data', 'science']","['well', 'need', 'skilled', 'getting', 'internship', 'data', 'science']",well need skilled getting internship data science,0.5,0.5,15,49,3.0625,0,0,0,0,0,0,0,0
5355,magnitude of coefficient values and its interpretation,magnitude of coefficient values and its interpretation,"['magnitude', 'of', 'coefficient', 'values', 'and', 'its', 'interpretation']",0,"['magnitude', 'of', 'coefficient', 'value', 'and', 'it', 'interpretation']","['magnitude', 'coefficient', 'value', 'interpretation']",magnitude coefficient value interpretation,0.0,0.0,7,42,5.25,0,0,0,0,0,0,0,0
5356,how to call a function in python,how to call a function in python,"['how', 'to', 'call', 'a', 'function', 'in', 'python']",0,"['how', 'to', 'call', 'a', 'function', 'in', 'python']","['call', 'function', 'python']",call function python,0.0,0.0,7,20,2.5,0,0,0,0,0,0,0,0
5357,why are there multiple hypotheses in ensemble methods,why are there multiple hypotheses in ensemble methods,"['why', 'are', 'there', 'multiple', 'hypotheses', 'in', 'ensemble', 'methods']",0,"['why', 'are', 'there', 'multiple', 'hypothesis', 'in', 'ensemble', 'method']","['multiple', 'hypothesis', 'ensemble', 'method']",multiple hypothesis ensemble method,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
5358,valueerror could not convert string to float when running model,valueerror could not convert string to float when running model,"['valueerror', 'could', 'not', 'convert', 'string', 'to', 'float', 'when', 'running', 'model']",0,"['valueerror', 'could', 'not', 'convert', 'string', 'to', 'float', 'when', 'running', 'model']","['valueerror', 'could', 'convert', 'string', 'float', 'running', 'model']",valueerror could convert string float running model,0.0,0.0,10,51,4.636363636363637,0,0,0,0,0,0,0,0
5359,how to connect sql table with kafka,how to connect sql table with kafka,"['how', 'to', 'connect', 'sql', 'table', 'with', 'kafka']",0,"['how', 'to', 'connect', 'sql', 'table', 'with', 'kafka']","['connect', 'sql', 'table', 'kafka']",connect sql table kafka,0.0,0.0,7,23,2.875,0,0,0,0,0,0,0,0
5360,how can i generate twoway table in python,how can i generate twoway table in python,"['how', 'can', 'i', 'generate', 'twoway', 'table', 'in', 'python']",0,"['how', 'can', 'i', 'generate', 'twoway', 'table', 'in', 'python']","['generate', 'twoway', 'table', 'python']",generate twoway table python,0.0,0.0,8,28,3.111111111111111,0,0,0,0,0,0,0,0
5361,to replace sas by python in companies,to replace sas by python in companies,"['to', 'replace', 'sas', 'by', 'python', 'in', 'companies']",0,"['to', 'replace', 'sa', 'by', 'python', 'in', 'company']","['replace', 'sa', 'python', 'company']",replace sa python company,0.0,0.0,7,25,3.125,0,0,0,0,0,0,0,0
5362,how to identify top and bottom performer in qlikview,how to identify top and bottom performer in qlikview,"['how', 'to', 'identify', 'top', 'and', 'bottom', 'performer', 'in', 'qlikview']",0,"['how', 'to', 'identify', 'top', 'and', 'bottom', 'performer', 'in', 'qlikview']","['identify', 'top', 'bottom', 'performer', 'qlikview']",identify top bottom performer qlikview,0.5,0.5,9,38,3.8,0,0,0,0,0,0,0,0
5363,exporting modified corpus with r,exporting modified corpus with r,"['exporting', 'modified', 'corpus', 'with', 'r']",0,"['exporting', 'modified', 'corpus', 'with', 'r']","['exporting', 'modified', 'corpus', 'r']",exporting modified corpus r,0.0,0.0,5,27,4.5,0,0,0,0,0,0,0,0
5364,choosing online ms in data science or analytics,choosing online ms in data science or analytics,"['choosing', 'online', 'ms', 'in', 'data', 'science', 'or', 'analytics']",0,"['choosing', 'online', 'm', 'in', 'data', 'science', 'or', 'analytics']","['choosing', 'online', 'data', 'science', 'analytics']",choosing online data science analytics,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
5365,shift from software data analysis to data analytics,shift from software data analysis to data analytics,"['shift', 'from', 'software', 'data', 'analysis', 'to', 'data', 'analytics']",0,"['shift', 'from', 'software', 'data', 'analysis', 'to', 'data', 'analytics']","['shift', 'software', 'data', 'analysis', 'data', 'analytics']",shift software data analysis data analytics,0.0,0.0,8,43,4.777777777777778,0,0,0,0,0,0,0,0
5366,how to select the value of extra in rplot,how to select the value of extra in rplot,"['how', 'to', 'select', 'the', 'value', 'of', 'extra', 'in', 'rplot']",0,"['how', 'to', 'select', 'the', 'value', 'of', 'extra', 'in', 'rplot']","['select', 'value', 'extra', 'rplot']",select value extra rplot,0.0,0.0,9,24,2.4,0,0,0,0,0,0,0,0
5367,looking for an active bigdatahadoop forum,looking for an active bigdatahadoop forum,"['looking', 'for', 'an', 'active', 'bigdatahadoop', 'forum']",0,"['looking', 'for', 'an', 'active', 'bigdatahadoop', 'forum']","['looking', 'active', 'bigdatahadoop', 'forum']",looking active bigdatahadoop forum,-0.1333333333333333,-0.1333333333333333,6,34,4.857142857142857,0,0,0,0,0,0,0,0
5368,unexpected http status code  bad request in hgbm,unexpected http status code  bad request in hgbm,"['unexpected', 'http', 'status', 'code', 'bad', 'request', 'in', 'hgbm']",1,"['unexpected', 'http', 'status', 'code', 'bad', 'request', 'in', 'hgbm']","['unexpected', 'http', 'status', 'code', 'bad', 'request', 'hgbm']",unexpected http status code bad request hgbm,-0.2999999999999999,-0.2999999999999999,8,44,4.888888888888889,0,0,0,0,0,0,0,0
5369,prediction technique for a new product launch in pharma,prediction technique for a new product launch in pharma,"['prediction', 'technique', 'for', 'a', 'new', 'product', 'launch', 'in', 'pharma']",0,"['prediction', 'technique', 'for', 'a', 'new', 'product', 'launch', 'in', 'pharma']","['prediction', 'technique', 'new', 'product', 'launch', 'pharma']",prediction technique new product launch pharma,0.1363636363636363,0.1363636363636363,9,46,4.6,0,0,0,0,0,0,0,0
5370,how to populate subtotal and grand total in pivot table of qlikview,how to populate subtotal and grand total in pivot table of qlikview,"['how', 'to', 'populate', 'subtotal', 'and', 'grand', 'total', 'in', 'pivot', 'table', 'of', 'qlikview']",0,"['how', 'to', 'populate', 'subtotal', 'and', 'grand', 'total', 'in', 'pivot', 'table', 'of', 'qlikview']","['populate', 'subtotal', 'grand', 'total', 'pivot', 'table', 'qlikview']",populate subtotal grand total pivot table qlikview,0.25,0.25,12,50,3.8461538461538463,0,0,0,0,0,0,0,0
5371,error in function in python,error in function in python,"['error', 'in', 'function', 'in', 'python']",0,"['error', 'in', 'function', 'in', 'python']","['error', 'function', 'python']",error function python,0.0,0.0,5,21,3.5,0,0,0,0,0,0,0,0
5372,black friday data hack  reveal your approach,black friday data hack  reveal your approach,"['black', 'friday', 'data', 'hack', 'reveal', 'your', 'approach']",0,"['black', 'friday', 'data', 'hack', 'reveal', 'your', 'approach']","['black', 'friday', 'data', 'hack', 'reveal', 'approach']",black friday data hack reveal approach,-0.1666666666666666,-0.1666666666666666,7,38,4.75,0,0,0,0,0,0,0,0
5373,how can we show the cumulative total of total sales using line chart in qlikview,how can we show the cumulative total of total sales using line chart in qlikview,"['how', 'can', 'we', 'show', 'the', 'cumulative', 'total', 'of', 'total', 'sales', 'using', 'line', 'chart', 'in', 'qlikview']",0,"['how', 'can', 'we', 'show', 'the', 'cumulative', 'total', 'of', 'total', 'sale', 'using', 'line', 'chart', 'in', 'qlikview']","['show', 'cumulative', 'total', 'total', 'sale', 'using', 'line', 'chart', 'qlikview']",show cumulative total total sale using line chart qlikview,0.0,0.0,15,58,3.625,0,0,0,0,0,0,0,0
5374,practical implementation of predictive models,practical implementation of predictive models,"['practical', 'implementation', 'of', 'predictive', 'models']",0,"['practical', 'implementation', 'of', 'predictive', 'model']","['practical', 'implementation', 'predictive', 'model']",practical implementation predictive model,0.0,0.0,5,41,6.833333333333333,0,0,0,0,0,0,0,0
5375,predicting inflow and outflow from bank account of customer,predicting inflow and outflow from bank account of customer,"['predicting', 'inflow', 'and', 'outflow', 'from', 'bank', 'account', 'of', 'customer']",0,"['predicting', 'inflow', 'and', 'outflow', 'from', 'bank', 'account', 'of', 'customer']","['predicting', 'inflow', 'outflow', 'bank', 'account', 'customer']",predicting inflow outflow bank account customer,0.0,0.0,9,47,4.7,0,0,0,0,0,0,0,0
5376,career tips  python or r,career tips  python or r,"['career', 'tips', 'python', 'or', 'r']",0,"['career', 'tip', 'python', 'or', 'r']","['career', 'tip', 'python', 'r']",career tip python r,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
5377,a comprehensive guide to understand and implement text classification in python,a comprehensive guide to understand and implement text classification in python,"['a', 'comprehensive', 'guide', 'to', 'understand', 'and', 'implement', 'text', 'classification', 'in', 'python']",0,"['a', 'comprehensive', 'guide', 'to', 'understand', 'and', 'implement', 'text', 'classification', 'in', 'python']","['comprehensive', 'guide', 'understand', 'implement', 'text', 'classification', 'python']",comprehensive guide understand implement text classification python,0.0,0.0,11,67,5.583333333333333,0,0,0,0,0,0,0,0
5378,why should a data scientist know cc,why should a data scientist know cc,"['why', 'should', 'a', 'data', 'scientist', 'know', 'cc']",0,"['why', 'should', 'a', 'data', 'scientist', 'know', 'cc']","['data', 'scientist', 'know', 'cc']",data scientist know cc,0.0,0.0,7,22,2.75,0,0,0,0,0,0,0,0
5379,same function in different libraries in r,same function in different libraries in r,"['same', 'function', 'in', 'different', 'libraries', 'in', 'r']",0,"['same', 'function', 'in', 'different', 'library', 'in', 'r']","['function', 'different', 'library', 'r']",function different library r,0.0,0.0,7,28,3.5,0,0,0,0,0,0,0,0
5380,time series classification in python,time series classification in python,"['time', 'series', 'classification', 'in', 'python']",0,"['time', 'series', 'classification', 'in', 'python']","['time', 'series', 'classification', 'python']",time series classification python,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
5381,abinbev data science talent hunt hackathon submission format,abinbev data science talent hunt hackathon submission format,"['abinbev', 'data', 'science', 'talent', 'hunt', 'hackathon', 'submission', 'format']",0,"['abinbev', 'data', 'science', 'talent', 'hunt', 'hackathon', 'submission', 'format']","['abinbev', 'data', 'science', 'talent', 'hunt', 'hackathon', 'submission', 'format']",abinbev data science talent hunt hackathon submission format,0.0,0.0,8,60,6.666666666666667,0,0,0,0,0,0,0,0
5382,starting at kaggle,starting at kaggle,"['starting', 'at', 'kaggle']",0,"['starting', 'at', 'kaggle']","['starting', 'kaggle']",starting kaggle,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
5383,career decision before proceeding with a specific data analysis tool or joining a business analytics course instead,career decision before proceeding with a specific data analysis tool or joining a business analytics course instead,"['career', 'decision', 'before', 'proceeding', 'with', 'a', 'specific', 'data', 'analysis', 'tool', 'or', 'joining', 'a', 'business', 'analytics', 'course', 'instead']",0,"['career', 'decision', 'before', 'proceeding', 'with', 'a', 'specific', 'data', 'analysis', 'tool', 'or', 'joining', 'a', 'business', 'analytics', 'course', 'instead']","['career', 'decision', 'proceeding', 'specific', 'data', 'analysis', 'tool', 'joining', 'business', 'analytics', 'course', 'instead']",career decision proceeding specific data analysis tool joining business analytics course instead,0.0,0.0,17,96,5.333333333333333,0,0,0,0,0,0,0,0
5384,regression with categorical variables working,regression with categorical variables working,"['regression', 'with', 'categorical', 'variables', 'working']",0,"['regression', 'with', 'categorical', 'variable', 'working']","['regression', 'categorical', 'variable', 'working']",regression categorical variable working,0.0,0.0,5,39,6.5,0,0,0,0,0,0,0,0
5385,is boosting algorithm only applied to rpart tree,is boosting algorithm only applied to rpart tree,"['is', 'boosting', 'algorithm', 'only', 'applied', 'to', 'rpart', 'tree']",0,"['is', 'boosting', 'algorithm', 'only', 'applied', 'to', 'rpart', 'tree']","['boosting', 'algorithm', 'applied', 'rpart', 'tree']",boosting algorithm applied rpart tree,0.0,0.0,8,37,4.111111111111111,0,0,0,0,0,0,0,0
5386,tutorials for matlab,tutorials for matlab,"['tutorials', 'for', 'matlab']",0,"['tutorial', 'for', 'matlab']","['tutorial', 'matlab']",tutorial matlab,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
5387,categorical variable with large level,categorical variable with large level,"['categorical', 'variable', 'with', 'large', 'level']",0,"['categorical', 'variable', 'with', 'large', 'level']","['categorical', 'variable', 'large', 'level']",categorical variable large level,0.2142857142857142,0.2142857142857142,5,32,5.333333333333333,0,0,0,0,0,0,0,0
5388,building team for computer vision and machine learning expert,building team for computer vision and machine learning expert,"['building', 'team', 'for', 'computer', 'vision', 'and', 'machine', 'learning', 'expert']",0,"['building', 'team', 'for', 'computer', 'vision', 'and', 'machine', 'learning', 'expert']","['building', 'team', 'computer', 'vision', 'machine', 'learning', 'expert']",building team computer vision machine learning expert,0.0,0.0,9,53,5.3,0,0,0,0,0,0,0,0
5389,machine learning project on imbalanced data  test dataset query,machine learning project on imbalanced data  test dataset query,"['machine', 'learning', 'project', 'on', 'imbalanced', 'data', 'test', 'dataset', 'query']",0,"['machine', 'learning', 'project', 'on', 'imbalanced', 'data', 'test', 'dataset', 'query']","['machine', 'learning', 'project', 'imbalanced', 'data', 'test', 'dataset', 'query']",machine learning project imbalanced data test dataset query,0.0,0.0,9,59,5.9,0,0,0,0,0,0,0,0
5390,warehouse productivity analysis  approach,warehouse productivity analysis  approach,"['warehouse', 'productivity', 'analysis', 'approach']",0,"['warehouse', 'productivity', 'analysis', 'approach']","['warehouse', 'productivity', 'analysis', 'approach']",warehouse productivity analysis approach,0.0,0.0,4,40,8.0,0,0,0,0,0,0,0,0
5391,why does the image structure show different content,why does the image structure show different content,"['why', 'does', 'the', 'image', 'structure', 'show', 'different', 'content']",0,"['why', 'doe', 'the', 'image', 'structure', 'show', 'different', 'content']","['doe', 'image', 'structure', 'show', 'different', 'content']",doe image structure show different content,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
5392,assistance on where to start for analyzing employee engagement data,assistance on where to start for analyzing employee engagement data,"['assistance', 'on', 'where', 'to', 'start', 'for', 'analyzing', 'employee', 'engagement', 'data']",0,"['assistance', 'on', 'where', 'to', 'start', 'for', 'analyzing', 'employee', 'engagement', 'data']","['assistance', 'start', 'analyzing', 'employee', 'engagement', 'data']",assistance start analyzing employee engagement data,0.0,0.0,10,51,4.636363636363637,0,0,0,0,0,0,0,0
5393,suggest some cool ml applications in computer vision  image processing,suggest some cool ml applications in computer vision  image processing,"['suggest', 'some', 'cool', 'ml', 'applications', 'in', 'computer', 'vision', 'image', 'processing']",0,"['suggest', 'some', 'cool', 'ml', 'application', 'in', 'computer', 'vision', 'image', 'processing']","['suggest', 'cool', 'ml', 'application', 'computer', 'vision', 'image', 'processing']",suggest cool ml application computer vision image processing,0.35,0.35,10,60,5.454545454545454,0,0,0,0,0,0,0,0
5394,lexical scoping in r,lexical scoping in r,"['lexical', 'scoping', 'in', 'r']",0,"['lexical', 'scoping', 'in', 'r']","['lexical', 'scoping', 'r']",lexical scoping r,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
5395,need an algorithm or direction in order to classify time series data,need an algorithm or direction in order to classify time series data,"['need', 'an', 'algorithm', 'or', 'direction', 'in', 'order', 'to', 'classify', 'time', 'series', 'data']",0,"['need', 'an', 'algorithm', 'or', 'direction', 'in', 'order', 'to', 'classify', 'time', 'series', 'data']","['need', 'algorithm', 'direction', 'order', 'classify', 'time', 'series', 'data']",need algorithm direction order classify time series data,0.0,0.0,12,56,4.3076923076923075,0,0,0,0,0,0,0,0
5396,r code for eclat algorithm,r code for eclat algorithm,"['r', 'code', 'for', 'eclat', 'algorithm']",0,"['r', 'code', 'for', 'eclat', 'algorithm']","['r', 'code', 'eclat', 'algorithm']",r code eclat algorithm,0.0,0.0,5,22,3.6666666666666665,0,0,0,0,0,0,0,0
5397,misb bocconis program online course content how good is it,misb bocconis program online course content how good is it,"['misb', 'bocconis', 'program', 'online', 'course', 'content', 'how', 'good', 'is', 'it']",0,"['misb', 'bocconis', 'program', 'online', 'course', 'content', 'how', 'good', 'is', 'it']","['misb', 'bocconis', 'program', 'online', 'course', 'content', 'good']",misb bocconis program online course content good,0.7,0.7,10,48,4.363636363636363,0,0,0,0,0,0,0,0
5398,need tool for extracting data from online graph,need tool for extracting data from online graph,"['need', 'tool', 'for', 'extracting', 'data', 'from', 'online', 'graph']",0,"['need', 'tool', 'for', 'extracting', 'data', 'from', 'online', 'graph']","['need', 'tool', 'extracting', 'data', 'online', 'graph']",need tool extracting data online graph,0.0,0.0,8,38,4.222222222222222,0,0,0,0,0,0,0,0
5399,latent markov model,latent markov model,"['latent', 'markov', 'model']",0,"['latent', 'markov', 'model']","['latent', 'markov', 'model']",latent markov model,0.0,0.0,3,19,4.75,0,0,0,0,0,0,0,0
5400,time series in r,time series in r,"['time', 'series', 'in', 'r']",0,"['time', 'series', 'in', 'r']","['time', 'series', 'r']",time series r,0.0,0.0,4,13,2.6,0,0,0,0,0,0,0,0
5401,books  websites which provide steps to solve various data science projects,books  websites which provide steps to solve various data science projects,"['books', 'websites', 'which', 'provide', 'steps', 'to', 'solve', 'various', 'data', 'science', 'projects']",0,"['book', 'website', 'which', 'provide', 'step', 'to', 'solve', 'various', 'data', 'science', 'project']","['book', 'website', 'provide', 'step', 'solve', 'various', 'data', 'science', 'project']",book website provide step solve various data science project,0.0,0.0,11,60,5.0,0,0,0,0,0,0,0,0
5402,how to find out influential and unusual observation and how to capping it in r,how to find out influential and unusual observation and how to capping it in r,"['how', 'to', 'find', 'out', 'influential', 'and', 'unusual', 'observation', 'and', 'how', 'to', 'capping', 'it', 'in', 'r']",0,"['how', 'to', 'find', 'out', 'influential', 'and', 'unusual', 'observation', 'and', 'how', 'to', 'capping', 'it', 'in', 'r']","['find', 'influential', 'unusual', 'observation', 'capping', 'r']",find influential unusual observation capping r,0.2,0.2,15,46,2.875,0,0,0,0,0,0,0,0
5403,potential customer for targeted marketing  machine learning models,potential customer for targeted marketing  machine learning models,"['potential', 'customer', 'for', 'targeted', 'marketing', 'machine', 'learning', 'models']",0,"['potential', 'customer', 'for', 'targeted', 'marketing', 'machine', 'learning', 'model']","['potential', 'customer', 'targeted', 'marketing', 'machine', 'learning', 'model']",potential customer targeted marketing machine learning model,0.0,0.0,8,60,6.666666666666667,0,0,0,0,0,0,0,0
5404,sales prediction based on multiple attributes,sales prediction based on multiple attributes,"['sales', 'prediction', 'based', 'on', 'multiple', 'attributes']",0,"['sale', 'prediction', 'based', 'on', 'multiple', 'attribute']","['sale', 'prediction', 'based', 'multiple', 'attribute']",sale prediction based multiple attribute,0.0,0.0,6,40,5.714285714285714,0,0,0,0,0,0,0,0
5405,what is pca and how is it different from svd,what is pca and how is it different from svd,"['what', 'is', 'pca', 'and', 'how', 'is', 'it', 'different', 'from', 'svd']",0,"['what', 'is', 'pca', 'and', 'how', 'is', 'it', 'different', 'from', 'svd']","['pca', 'different', 'svd']",pca different svd,0.0,0.0,10,17,1.5454545454545454,0,0,0,0,0,0,0,0
5406,transactional patterns,transactional patterns,"['transactional', 'patterns']",0,"['transactional', 'pattern']","['transactional', 'pattern']",transactional pattern,0.0,0.0,2,21,7.0,0,0,0,0,0,0,0,0
5407,the analytics edge on edx,the analytics edge on edx,"['the', 'analytics', 'edge', 'on', 'edx']",0,"['the', 'analytics', 'edge', 'on', 'edx']","['analytics', 'edge', 'edx']",analytics edge edx,0.0,0.0,5,18,3.0,0,0,0,0,0,0,0,0
5408,what is the singularity error in linear regression,what is the singularity error in linear regression,"['what', 'is', 'the', 'singularity', 'error', 'in', 'linear', 'regression']",0,"['what', 'is', 'the', 'singularity', 'error', 'in', 'linear', 'regression']","['singularity', 'error', 'linear', 'regression']",singularity error linear regression,0.0,0.0,8,35,3.888888888888889,0,0,0,0,0,0,0,0
5409,how to write r code similar to sas proc summary or spss data audit  is there any such r package available,how to write r code similar to sas proc summary or spss data audit  is there any such r package available,"['how', 'to', 'write', 'r', 'code', 'similar', 'to', 'sas', 'proc', 'summary', 'or', 'spss', 'data', 'audit', 'is', 'there', 'any', 'such', 'r', 'package', 'available']",0,"['how', 'to', 'write', 'r', 'code', 'similar', 'to', 'sa', 'proc', 'summary', 'or', 'spss', 'data', 'audit', 'is', 'there', 'any', 'such', 'r', 'package', 'available']","['write', 'r', 'code', 'similar', 'sa', 'proc', 'summary', 'spss', 'data', 'audit', 'r', 'package', 'available']",write r code similar sa proc summary spss data audit r package available,0.1333333333333333,0.2,21,72,3.272727272727273,0,0,0,0,0,0,0,0
5410,r programming resources for a newbie,r programming resources for a newbie,"['r', 'programming', 'resources', 'for', 'a', 'newbie']",0,"['r', 'programming', 'resource', 'for', 'a', 'newbie']","['r', 'programming', 'resource', 'newbie']",r programming resource newbie,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
5411,how to resolve cannot compute oob estimate or the oob curve error in gbm using r,how to resolve cannot compute oob estimate or the oob curve error in gbm using r,"['how', 'to', 'resolve', 'can', 'not', 'compute', 'oob', 'estimate', 'or', 'the', 'oob', 'curve', 'error', 'in', 'gbm', 'using', 'r']",0,"['how', 'to', 'resolve', 'can', 'not', 'compute', 'oob', 'estimate', 'or', 'the', 'oob', 'curve', 'error', 'in', 'gbm', 'using', 'r']","['resolve', 'compute', 'oob', 'estimate', 'oob', 'curve', 'error', 'gbm', 'using', 'r']",resolve compute oob estimate oob curve error gbm using r,0.0,0.0,17,56,3.111111111111111,0,0,0,0,0,0,0,0
5412,handwritten text recognition python,handwritten text recognition python,"['handwritten', 'text', 'recognition', 'python']",0,"['handwritten', 'text', 'recognition', 'python']","['handwritten', 'text', 'recognition', 'python']",handwritten text recognition python,0.0,0.0,4,35,7.0,0,0,0,0,0,0,0,0
5413,pgdba iit isi iim,pgdba iit isi iim,"['pgdba', 'iit', 'isi', 'iim']",0,"['pgdba', 'iit', 'isi', 'iim']","['pgdba', 'iit', 'isi', 'iim']",pgdba iit isi iim,0.0,0.0,4,17,3.4,0,0,0,0,0,0,0,0
5414,irregular market or trading behavior,irregular market or trading behavior,"['irregular', 'market', 'or', 'trading', 'behavior']",0,"['irregular', 'market', 'or', 'trading', 'behavior']","['irregular', 'market', 'trading', 'behavior']",irregular market trading behavior,0.0,0.0,5,33,5.5,0,0,0,0,0,0,0,0
5415,what is the scenario where we need to use weighted mean,what is the scenario where we need to use weighted mean,"['what', 'is', 'the', 'scenario', 'where', 'we', 'need', 'to', 'use', 'weighted', 'mean']",0,"['what', 'is', 'the', 'scenario', 'where', 'we', 'need', 'to', 'use', 'weighted', 'mean']","['scenario', 'need', 'use', 'weighted', 'mean']",scenario need use weighted mean,-0.3125,-0.3125,11,31,2.5833333333333335,0,0,0,0,0,0,0,0
5416,kaggle walkthrough on data science,kaggle walkthrough on data science,"['kaggle', 'walkthrough', 'on', 'data', 'science']",0,"['kaggle', 'walkthrough', 'on', 'data', 'science']","['kaggle', 'walkthrough', 'data', 'science']",kaggle walkthrough data science,0.0,0.0,5,31,5.166666666666667,0,0,0,0,0,0,0,0
5417,megastar prediction share your maximum accuracy  the method adopted,megastar prediction share your maximum accuracy  the method adopted,"['megastar', 'prediction', 'share', 'your', 'maximum', 'accuracy', 'the', 'method', 'adopted']",0,"['megastar', 'prediction', 'share', 'your', 'maximum', 'accuracy', 'the', 'method', 'adopted']","['megastar', 'prediction', 'share', 'maximum', 'accuracy', 'method', 'adopted']",megastar prediction share maximum accuracy method adopted,0.0,0.0,9,57,5.7,0,0,0,0,0,0,0,0
5418,book recommendation scalable machine learning for bigger data,book recommendation scalable machine learning for bigger data,"['book', 'recommendation', 'scalable', 'machine', 'learning', 'for', 'bigger', 'data']",0,"['book', 'recommendation', 'scalable', 'machine', 'learning', 'for', 'bigger', 'data']","['book', 'recommendation', 'scalable', 'machine', 'learning', 'bigger', 'data']",book recommendation scalable machine learning bigger data,0.0,0.0,8,57,6.333333333333333,0,0,0,0,0,0,0,0
5419,how to use principal components for further analysis,how to use principal components for further analysis,"['how', 'to', 'use', 'principal', 'components', 'for', 'further', 'analysis']",0,"['how', 'to', 'use', 'principal', 'component', 'for', 'further', 'analysis']","['use', 'principal', 'component', 'analysis']",use principal component analysis,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
5420,who are top analytics companies,who are top analytics companies,"['who', 'are', 'top', 'analytics', 'companies']",0,"['who', 'are', 'top', 'analytics', 'company']","['top', 'analytics', 'company']",top analytics company,0.5,0.5,5,21,3.5,0,0,0,0,0,0,0,0
5421,data analytics or business analytics after mba and experience in hr,data analytics or business analytics after mba and experience in hr,"['data', 'analytics', 'or', 'business', 'analytics', 'after', 'mba', 'and', 'experience', 'in', 'hr']",0,"['data', 'analytics', 'or', 'business', 'analytics', 'after', 'mba', 'and', 'experience', 'in', 'hr']","['data', 'analytics', 'business', 'analytics', 'mba', 'experience', 'hr']",data analytics business analytics mba experience hr,0.0,0.0,11,51,4.25,0,0,0,0,0,0,0,0
5422,case studies using analytics,case studies using analytics,"['case', 'studies', 'using', 'analytics']",0,"['case', 'study', 'using', 'analytics']","['case', 'study', 'using', 'analytics']",case study using analytics,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
5423,how can we access the elements of dfdescribe for any dataframe df,how can we access the elements of dfdescribe for any dataframe df,"['how', 'can', 'we', 'access', 'the', 'elements', 'of', 'dfdescribe', 'for', 'any', 'dataframe', 'df']",0,"['how', 'can', 'we', 'access', 'the', 'element', 'of', 'dfdescribe', 'for', 'any', 'dataframe', 'df']","['access', 'element', 'dfdescribe', 'dataframe', 'df']",access element dfdescribe dataframe df,0.0,0.0,12,38,2.923076923076923,0,0,0,0,0,0,0,0
5424,r  memory issue on allocating large size data to a vector,r  memory issue on allocating large size data to a vector,"['r', 'memory', 'issue', 'on', 'allocating', 'large', 'size', 'data', 'to', 'a', 'vector']",0,"['r', 'memory', 'issue', 'on', 'allocating', 'large', 'size', 'data', 'to', 'a', 'vector']","['r', 'memory', 'issue', 'allocating', 'large', 'size', 'data', 'vector']",r memory issue allocating large size data vector,0.2142857142857142,0.2142857142857142,11,48,4.0,0,0,0,0,0,0,0,0
5425,difference between ridge regression and lasso and its effect,difference between ridge regression and lasso and its effect,"['difference', 'between', 'ridge', 'regression', 'and', 'lasso', 'and', 'its', 'effect']",0,"['difference', 'between', 'ridge', 'regression', 'and', 'lasso', 'and', 'it', 'effect']","['difference', 'ridge', 'regression', 'lasso', 'effect']",difference ridge regression lasso effect,0.0,0.0,9,40,4.0,0,0,0,0,0,0,0,0
5426,what are the ways of treatment of na in time series and cross sectional data,what are the ways of treatment of na in time series and cross sectional data,"['what', 'are', 'the', 'ways', 'of', 'treatment', 'of', 'na', 'in', 'time', 'series', 'and', 'cross', 'sectional', 'data']",0,"['what', 'are', 'the', 'way', 'of', 'treatment', 'of', 'na', 'in', 'time', 'series', 'and', 'cross', 'sectional', 'data']","['way', 'treatment', 'na', 'time', 'series', 'cross', 'sectional', 'data']",way treatment na time series cross sectional data,0.0,0.0,15,49,3.0625,0,0,0,0,0,0,0,0
5427,what is the best sas certification for an aspiring data scientist,what is the best sas certification for an aspiring data scientist,"['what', 'is', 'the', 'best', 'sas', 'certification', 'for', 'an', 'aspiring', 'data', 'scientist']",0,"['what', 'is', 'the', 'best', 'sa', 'certification', 'for', 'an', 'aspiring', 'data', 'scientist']","['best', 'sa', 'certification', 'aspiring', 'data', 'scientist']",best sa certification aspiring data scientist,1.0,1.0,11,45,3.75,0,0,0,0,0,0,0,0
5428,career change from c developer to data scientist,career change from c developer to data scientist,"['career', 'change', 'from', 'c', 'developer', 'to', 'data', 'scientist']",0,"['career', 'change', 'from', 'c', 'developer', 'to', 'data', 'scientist']","['career', 'change', 'c', 'developer', 'data', 'scientist']",career change c developer data scientist,0.0,0.0,8,40,4.444444444444445,0,0,0,0,0,0,0,0
5429,how to open the json file in r,how to open the json file in r,"['how', 'to', 'open', 'the', 'json', 'file', 'in', 'r']",0,"['how', 'to', 'open', 'the', 'json', 'file', 'in', 'r']","['open', 'json', 'file', 'r']",open json file r,0.0,0.0,8,16,1.7777777777777777,0,0,0,0,0,0,0,0
5430,simple machine learning projects to learn machine learning,simple machine learning projects to learn machine learning,"['simple', 'machine', 'learning', 'projects', 'to', 'learn', 'machine', 'learning']",0,"['simple', 'machine', 'learning', 'project', 'to', 'learn', 'machine', 'learning']","['simple', 'machine', 'learning', 'project', 'learn', 'machine', 'learning']",simple machine learning project learn machine learning,0.0,0.0,8,54,6.0,0,0,0,0,0,0,0,0
5431,pages and filters in tableau,pages and filters in tableau,"['pages', 'and', 'filters', 'in', 'tableau']",0,"['page', 'and', 'filter', 'in', 'tableau']","['page', 'filter', 'tableau']",page filter tableau,0.0,0.0,5,19,3.1666666666666665,0,0,0,0,0,0,0,0
5432,how to mix rows in r,how to mix rows in r,"['how', 'to', 'mix', 'rows', 'in', 'r']",0,"['how', 'to', 'mix', 'row', 'in', 'r']","['mix', 'row', 'r']",mix row r,0.0,0.0,6,9,1.2857142857142858,0,0,0,0,0,0,0,0
5433,how to split the data in random forest,how to split the data in random forest,"['how', 'to', 'split', 'the', 'data', 'in', 'random', 'forest']",0,"['how', 'to', 'split', 'the', 'data', 'in', 'random', 'forest']","['split', 'data', 'random', 'forest']",split data random forest,-0.5,-0.5,8,24,2.6666666666666665,0,0,0,0,0,0,0,0
5434,forecasting using arima after series has been transformed,forecasting using arima after series has been transformed,"['forecasting', 'using', 'arima', 'after', 'series', 'has', 'been', 'transformed']",0,"['forecasting', 'using', 'arima', 'after', 'series', 'ha', 'been', 'transformed']","['forecasting', 'using', 'arima', 'series', 'ha', 'transformed']",forecasting using arima series ha transformed,0.0,0.0,8,45,5.0,0,0,0,0,0,0,0,0
5435,review on analytixslab course,review on analytixslab course,"['review', 'on', 'analytixslab', 'course']",0,"['review', 'on', 'analytixslab', 'course']","['review', 'analytixslab', 'course']",review analytixslab course,0.0,0.0,4,26,5.2,0,0,0,0,0,0,0,0
5436,understanding and coding neural networks from scratch in python and r,understanding and coding neural networks from scratch in python and r,"['understanding', 'and', 'coding', 'neural', 'networks', 'from', 'scratch', 'in', 'python', 'and', 'r']",0,"['understanding', 'and', 'coding', 'neural', 'network', 'from', 'scratch', 'in', 'python', 'and', 'r']","['understanding', 'coding', 'neural', 'network', 'scratch', 'python', 'r']",understanding coding neural network scratch python r,0.0,0.0,11,52,4.333333333333333,0,0,0,0,0,0,0,0
5437,download new year resolutions checklist ,download new year resolutions checklist ,"['download', 'new', 'year', 'resolutions', 'checklist']",1,"['download', 'new', 'year', 'resolution', 'checklist']","['download', 'new', 'year', 'resolution', 'checklist']",download new year resolution checklist,0.1363636363636363,0.1363636363636363,5,38,6.333333333333333,0,0,0,0,0,0,0,0
5438,how to change my career from digital marketing to data science,how to change my career from digital marketing to data science,"['how', 'to', 'change', 'my', 'career', 'from', 'digital', 'marketing', 'to', 'data', 'science']",0,"['how', 'to', 'change', 'my', 'career', 'from', 'digital', 'marketing', 'to', 'data', 'science']","['change', 'career', 'digital', 'marketing', 'data', 'science']",change career digital marketing data science,0.0,0.0,11,44,3.6666666666666665,0,0,0,0,0,0,0,0
5439,is there a  chance if null hypothesis is true then parameter must be true,is there a  chance if null hypothesis is true then parameter must be true,"['is', 'there', 'a', 'chance', 'if', 'null', 'hypothesis', 'is', 'true', 'then', 'parameter', 'must', 'be', 'true']",1,"['is', 'there', 'a', 'chance', 'if', 'null', 'hypothesis', 'is', 'true', 'then', 'parameter', 'must', 'be', 'true']","['chance', 'null', 'hypothesis', 'true', 'parameter', 'must', 'true']",chance null hypothesis true parameter must true,0.35,0.35,14,47,3.1333333333333333,0,0,0,0,0,0,0,0
5440,how to use genetic algorithm to shift time for peak loads to non peak hours,how to use genetic algorithm to shift time for peak loads to non peak hours,"['how', 'to', 'use', 'genetic', 'algorithm', 'to', 'shift', 'time', 'for', 'peak', 'loads', 'to', 'non', 'peak', 'hours']",0,"['how', 'to', 'use', 'genetic', 'algorithm', 'to', 'shift', 'time', 'for', 'peak', 'load', 'to', 'non', 'peak', 'hour']","['use', 'genetic', 'algorithm', 'shift', 'time', 'peak', 'load', 'non', 'peak', 'hour']",use genetic algorithm shift time peak load non peak hour,0.0,0.0,15,56,3.5,0,0,0,0,0,0,0,0
5441,classification problem with m rows in training set,classification problem with m rows in training set,"['classification', 'problem', 'with', 'm', 'rows', 'in', 'training', 'set']",0,"['classification', 'problem', 'with', 'm', 'row', 'in', 'training', 'set']","['classification', 'problem', 'row', 'training', 'set']",classification problem row training set,0.0,0.0,8,39,4.333333333333333,0,0,0,0,0,0,0,0
5442,how do i create a data frame with all possible combinations of three other data frames of  column each in r,how do i create a data frame with all possible combinations of three other data frames of  column each in r,"['how', 'do', 'i', 'create', 'a', 'data', 'frame', 'with', 'all', 'possible', 'combinations', 'of', 'three', 'other', 'data', 'frames', 'of', 'column', 'each', 'in', 'r']",1,"['how', 'do', 'i', 'create', 'a', 'data', 'frame', 'with', 'all', 'possible', 'combination', 'of', 'three', 'other', 'data', 'frame', 'of', 'column', 'each', 'in', 'r']","['create', 'data', 'frame', 'possible', 'combination', 'three', 'data', 'frame', 'column', 'r']",create data frame possible combination three data frame column r,-0.0625,0.0,21,64,2.909090909090909,0,0,0,0,0,0,0,0
5443,what are the disadvantages of boosting,what are the disadvantages of boosting,"['what', 'are', 'the', 'disadvantages', 'of', 'boosting']",0,"['what', 'are', 'the', 'disadvantage', 'of', 'boosting']","['disadvantage', 'boosting']",disadvantage boosting,0.0,0.0,6,21,3.0,0,0,0,0,0,0,0,0
5444,which type of regression to use,which type of regression to use,"['which', 'type', 'of', 'regression', 'to', 'use']",0,"['which', 'type', 'of', 'regression', 'to', 'use']","['type', 'regression', 'use']",type regression use,0.0,0.0,6,19,2.7142857142857144,0,0,0,0,0,0,0,0
5445,is there any difference in ridge regression performed using glmnet function and lmridge function,is there any difference in ridge regression performed using glmnet function and lmridge function,"['is', 'there', 'any', 'difference', 'in', 'ridge', 'regression', 'performed', 'using', 'glmnet', 'function', 'and', 'lmridge', 'function']",0,"['is', 'there', 'any', 'difference', 'in', 'ridge', 'regression', 'performed', 'using', 'glmnet', 'function', 'and', 'lmridge', 'function']","['difference', 'ridge', 'regression', 'performed', 'using', 'glmnet', 'function', 'lmridge', 'function']",difference ridge regression performed using glmnet function lmridge function,0.0,0.0,14,76,5.066666666666666,0,0,0,0,0,0,0,0
5446,labelencoder throws type error in sort,labelencoder throws type error in sort,"['labelencoder', 'throws', 'type', 'error', 'in', 'sort']",0,"['labelencoder', 'throw', 'type', 'error', 'in', 'sort']","['labelencoder', 'throw', 'type', 'error', 'sort']",labelencoder throw type error sort,0.0,0.0,6,34,4.857142857142857,0,0,0,0,0,0,0,0
5447,dataframe arguments,dataframe arguments,"['dataframe', 'arguments']",0,"['dataframe', 'argument']","['dataframe', 'argument']",dataframe argument,0.0,0.0,2,18,6.0,0,0,0,0,0,0,0,0
5448,handling the axis range and intervals for a bar plot,handling the axis range and intervals for a bar plot,"['handling', 'the', 'axis', 'range', 'and', 'intervals', 'for', 'a', 'bar', 'plot']",0,"['handling', 'the', 'axis', 'range', 'and', 'interval', 'for', 'a', 'bar', 'plot']","['handling', 'axis', 'range', 'interval', 'bar', 'plot']",handling axis range interval bar plot,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
5449,help with prediction,help with prediction,"['help', 'with', 'prediction']",0,"['help', 'with', 'prediction']","['help', 'prediction']",help prediction,0.0,0.0,3,15,3.75,0,0,0,0,0,0,0,0
5450,using mean to guess availality on boolean data before munging,using mean to guess availality on boolean data before munging,"['using', 'mean', 'to', 'guess', 'availality', 'on', 'boolean', 'data', 'before', 'munging']",0,"['using', 'mean', 'to', 'guess', 'availality', 'on', 'boolean', 'data', 'before', 'munging']","['using', 'mean', 'guess', 'availality', 'boolean', 'data', 'munging']",using mean guess availality boolean data munging,-0.3125,-0.3125,10,48,4.363636363636363,0,0,0,0,0,0,0,0
5451,join volunteer club be our data science torchbearers,join volunteer club be our data science torchbearers,"['join', 'volunteer', 'club', 'be', 'our', 'data', 'science', 'torchbearers']",0,"['join', 'volunteer', 'club', 'be', 'our', 'data', 'science', 'torchbearer']","['join', 'volunteer', 'club', 'data', 'science', 'torchbearer']",join volunteer club data science torchbearer,0.0,0.0,8,44,4.888888888888889,0,0,0,0,0,0,0,0
5452,microsoft certified solutions expert mcse,microsoft certified solutions expert mcse,"['microsoft', 'certified', 'solutions', 'expert', 'mcse']",0,"['microsoft', 'certified', 'solution', 'expert', 'mcse']","['microsoft', 'certified', 'solution', 'expert', 'mcse']",microsoft certified solution expert mcse,0.0,0.0,5,40,6.666666666666667,0,0,0,0,0,0,0,0
5453,which machine learning technique can be used for network downtime prediction in telecom,which machine learning technique can be used for network downtime prediction in telecom,"['which', 'machine', 'learning', 'technique', 'can', 'be', 'used', 'for', 'network', 'downtime', 'prediction', 'in', 'telecom']",0,"['which', 'machine', 'learning', 'technique', 'can', 'be', 'used', 'for', 'network', 'downtime', 'prediction', 'in', 'telecom']","['machine', 'learning', 'technique', 'used', 'network', 'downtime', 'prediction', 'telecom']",machine learning technique used network downtime prediction telecom,0.0,0.0,13,67,4.785714285714286,0,0,0,0,0,0,0,0
5454,loading arff type files in python,loading arff type files in python,"['loading', 'arff', 'type', 'files', 'in', 'python']",0,"['loading', 'arff', 'type', 'file', 'in', 'python']","['loading', 'arff', 'type', 'file', 'python']",loading arff type file python,0.0,0.0,6,29,4.142857142857143,0,0,0,0,0,0,0,0
5455,how to create a cooccurence matrix in python,how to create a cooccurence matrix in python,"['how', 'to', 'create', 'a', 'cooccurence', 'matrix', 'in', 'python']",0,"['how', 'to', 'create', 'a', 'cooccurence', 'matrix', 'in', 'python']","['create', 'cooccurence', 'matrix', 'python']",create cooccurence matrix python,0.0,0.0,8,32,3.5555555555555554,0,0,0,0,0,0,0,0
5456,is mu sigma still a good company,is mu sigma still a good company,"['is', 'mu', 'sigma', 'still', 'a', 'good', 'company']",0,"['is', 'mu', 'sigma', 'still', 'a', 'good', 'company']","['mu', 'sigma', 'still', 'good', 'company']",mu sigma still good company,0.7,0.7,7,27,3.375,0,0,0,0,0,0,0,0
5457,what are some techniques of hypothesis testing for model building,what are some techniques of hypothesis testing for model building,"['what', 'are', 'some', 'techniques', 'of', 'hypothesis', 'testing', 'for', 'model', 'building']",0,"['what', 'are', 'some', 'technique', 'of', 'hypothesis', 'testing', 'for', 'model', 'building']","['technique', 'hypothesis', 'testing', 'model', 'building']",technique hypothesis testing model building,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
5458,devise a single metric to measure retention of listeners using the service on a daily basis for the last month,devise a single metric to measure retention of listeners using the service on a daily basis for the last month,"['devise', 'a', 'single', 'metric', 'to', 'measure', 'retention', 'of', 'listeners', 'using', 'the', 'service', 'on', 'a', 'daily', 'basis', 'for', 'the', 'last', 'month']",0,"['devise', 'a', 'single', 'metric', 'to', 'measure', 'retention', 'of', 'listener', 'using', 'the', 'service', 'on', 'a', 'daily', 'basis', 'for', 'the', 'last', 'month']","['devise', 'single', 'metric', 'measure', 'retention', 'listener', 'using', 'service', 'daily', 'basis', 'last', 'month']",devise single metric measure retention listener using service daily basis last month,-0.0238095238095238,-0.0238095238095238,20,84,4.0,0,0,0,0,0,0,0,0
5459,can you suggest some good tutorial on ga package in r,can you suggest some good tutorial on ga package in r,"['can', 'you', 'suggest', 'some', 'good', 'tutorial', 'on', 'ga', 'package', 'in', 'r']",0,"['can', 'you', 'suggest', 'some', 'good', 'tutorial', 'on', 'ga', 'package', 'in', 'r']","['suggest', 'good', 'tutorial', 'ga', 'package', 'r']",suggest good tutorial ga package r,0.7,0.7,11,34,2.8333333333333335,0,0,0,0,0,0,0,0
5460,mysql  sql cheat sheet,mysql  sql cheat sheet,"['mysql', 'sql', 'cheat', 'sheet']",0,"['mysql', 'sql', 'cheat', 'sheet']","['mysql', 'sql', 'cheat', 'sheet']",mysql sql cheat sheet,0.0,0.0,4,21,4.2,0,0,0,0,0,0,0,0
5461,interview question asked from a project,interview question asked from a project,"['interview', 'question', 'asked', 'from', 'a', 'project']",0,"['interview', 'question', 'asked', 'from', 'a', 'project']","['interview', 'question', 'asked', 'project']",interview question asked project,0.0,0.0,6,32,4.571428571428571,0,0,0,0,0,0,0,0
5462,when should use the  operator in r,when should use the  operator in r,"['when', 'should', 'use', 'the', 'operator', 'in', 'r']",0,"['when', 'should', 'use', 'the', 'operator', 'in', 'r']","['use', 'operator', 'r']",use operator r,0.0,0.0,7,14,1.75,0,0,0,0,0,0,0,0
5463,trainee  entry level jobs in data science  machine learning in india,trainee  entry level jobs in data science  machine learning in india,"['trainee', 'entry', 'level', 'jobs', 'in', 'data', 'science', 'machine', 'learning', 'in', 'india']",0,"['trainee', 'entry', 'level', 'job', 'in', 'data', 'science', 'machine', 'learning', 'in', 'india']","['trainee', 'entry', 'level', 'job', 'data', 'science', 'machine', 'learning', 'india']",trainee entry level job data science machine learning india,0.0,0.0,11,59,4.916666666666667,0,0,0,0,0,0,0,0
5464,time series analysis,time series analysis,"['time', 'series', 'analysis']",0,"['time', 'series', 'analysis']","['time', 'series', 'analysis']",time series analysis,0.0,0.0,3,20,5.0,0,0,0,0,0,0,0,0
5465,is m tech in data science good for market resarch field,is m tech in data science good for market resarch field,"['is', 'm', 'tech', 'in', 'data', 'science', 'good', 'for', 'market', 'resarch', 'field']",0,"['is', 'm', 'tech', 'in', 'data', 'science', 'good', 'for', 'market', 'resarch', 'field']","['tech', 'data', 'science', 'good', 'market', 'resarch', 'field']",tech data science good market resarch field,0.7,0.7,11,43,3.5833333333333335,0,0,0,0,0,0,0,0
5466,difference between tier and tier architectures in qlikview,difference between tier and tier architectures in qlikview,"['difference', 'between', 'tier', 'and', 'tier', 'architectures', 'in', 'qlikview']",0,"['difference', 'between', 'tier', 'and', 'tier', 'architecture', 'in', 'qlikview']","['difference', 'tier', 'tier', 'architecture', 'qlikview']",difference tier tier architecture qlikview,0.0,0.0,8,42,4.666666666666667,0,0,0,0,0,0,0,0
5467,trying to replicate sachin dashboardbar chart not showing correctly,trying to replicate sachin dashboardbar chart not showing correctly,"['trying', 'to', 'replicate', 'sachin', 'dashboardbar', 'chart', 'not', 'showing', 'correctly']",0,"['trying', 'to', 'replicate', 'sachin', 'dashboardbar', 'chart', 'not', 'showing', 'correctly']","['trying', 'replicate', 'sachin', 'dashboardbar', 'chart', 'showing', 'correctly']",trying replicate sachin dashboardbar chart showing correctly,0.0,0.0,9,60,6.0,0,0,0,0,0,0,0,0
5468,is it required to remove correlated variables before performing pca,is it required to remove correlated variables before performing pca,"['is', 'it', 'required', 'to', 'remove', 'correlated', 'variables', 'before', 'performing', 'pca']",0,"['is', 'it', 'required', 'to', 'remove', 'correlated', 'variable', 'before', 'performing', 'pca']","['required', 'remove', 'correlated', 'variable', 'performing', 'pca']",required remove correlated variable performing pca,0.0,0.0,10,50,4.545454545454546,0,0,0,0,0,0,0,0
5469,reactions to gartner advanced analytics quadrants  ,reactions to gartner advanced analytics quadrants  ,"['reactions', 'to', 'gartner', 'advanced', 'analytics', 'quadrants']",1,"['reaction', 'to', 'gartner', 'advanced', 'analytics', 'quadrant']","['reaction', 'gartner', 'advanced', 'analytics', 'quadrant']",reaction gartner advanced analytics quadrant,0.4,0.4,6,44,6.285714285714286,0,0,0,0,0,0,0,0
5470,deployment of naive bayes model,deployment of naive bayes model,"['deployment', 'of', 'naive', 'bayes', 'model']",0,"['deployment', 'of', 'naive', 'bayes', 'model']","['deployment', 'naive', 'bayes', 'model']",deployment naive bayes model,-0.3,-0.3,5,28,4.666666666666667,0,0,0,0,0,0,0,0
5471,career shift to data science after working in plsql for  years will it be a good choice,career shift to data science after working in plsql for  years will it be a good choice,"['career', 'shift', 'to', 'data', 'science', 'after', 'working', 'in', 'plsql', 'for', 'years', 'will', 'it', 'be', 'a', 'good', 'choice']",1,"['career', 'shift', 'to', 'data', 'science', 'after', 'working', 'in', 'plsql', 'for', 'year', 'will', 'it', 'be', 'a', 'good', 'choice']","['career', 'shift', 'data', 'science', 'working', 'plsql', 'year', 'good', 'choice']",career shift data science working plsql year good choice,0.7,0.7,17,56,3.111111111111111,0,0,0,0,0,0,0,0
5472,how can get the actionable insights faster from data set,how can get the actionable insights faster from data set,"['how', 'can', 'get', 'the', 'actionable', 'insights', 'faster', 'from', 'data', 'set']",0,"['how', 'can', 'get', 'the', 'actionable', 'insight', 'faster', 'from', 'data', 'set']","['get', 'actionable', 'insight', 'faster', 'data', 'set']",get actionable insight faster data set,0.0,0.0,10,38,3.4545454545454546,0,0,0,0,0,0,0,0
5473,to work on weather forecasting,to work on weather forecasting,"['to', 'work', 'on', 'weather', 'forecasting']",0,"['to', 'work', 'on', 'weather', 'forecasting']","['work', 'weather', 'forecasting']",work weather forecasting,0.0,0.0,5,24,4.0,0,0,0,0,0,0,0,0
5474,decision tree  sklearn  python spyder ide,decision tree  sklearn  python spyder ide,"['decision', 'tree', 'sklearn', 'python', 'spyder', 'ide']",0,"['decision', 'tree', 'sklearn', 'python', 'spyder', 'ide']","['decision', 'tree', 'sklearn', 'python', 'spyder', 'ide']",decision tree sklearn python spyder ide,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
5475,how is svd different from other matrix factorization techniques like non negative matrix factorization,how is svd different from other matrix factorization techniques like non negative matrix factorization,"['how', 'is', 'svd', 'different', 'from', 'other', 'matrix', 'factorization', 'techniques', 'like', 'non', 'negative', 'matrix', 'factorization']",0,"['how', 'is', 'svd', 'different', 'from', 'other', 'matrix', 'factorization', 'technique', 'like', 'non', 'negative', 'matrix', 'factorization']","['svd', 'different', 'matrix', 'factorization', 'technique', 'like', 'non', 'negative', 'matrix', 'factorization']",svd different matrix factorization technique like non negative matrix factorization,-0.1416666666666666,-0.15,14,83,5.533333333333333,0,0,0,0,0,0,0,0
5476,cognitive computing,cognitive computing,"['cognitive', 'computing']",0,"['cognitive', 'computing']","['cognitive', 'computing']",cognitive computing,0.0,0.0,2,19,6.333333333333333,0,0,0,0,0,0,0,0
5477,combined probability of n events,combined probability of n events,"['combined', 'probability', 'of', 'n', 'events']",0,"['combined', 'probability', 'of', 'n', 'event']","['combined', 'probability', 'n', 'event']",combined probability n event,0.0,0.0,5,28,4.666666666666667,0,0,0,0,0,0,0,0
5478,novice how do pupils acquire real world data for research academic projects in business analytics domain,novice how do pupils acquire real world data for research academic projects in business analytics domain,"['novice', 'how', 'do', 'pupils', 'acquire', 'real', 'world', 'data', 'for', 'research', 'academic', 'projects', 'in', 'business', 'analytics', 'domain']",0,"['novice', 'how', 'do', 'pupil', 'acquire', 'real', 'world', 'data', 'for', 'research', 'academic', 'project', 'in', 'business', 'analytics', 'domain']","['novice', 'pupil', 'acquire', 'real', 'world', 'data', 'research', 'academic', 'project', 'business', 'analytics', 'domain']",novice pupil acquire real world data research academic project business analytics domain,0.1,0.1,16,88,5.176470588235294,0,0,0,0,0,0,0,0
5479,why is plot function behaving like hist function in r,why is plot function behaving like hist function in r,"['why', 'is', 'plot', 'function', 'behaving', 'like', 'hist', 'function', 'in', 'r']",0,"['why', 'is', 'plot', 'function', 'behaving', 'like', 'hist', 'function', 'in', 'r']","['plot', 'function', 'behaving', 'like', 'hist', 'function', 'r']",plot function behaving like hist function r,0.0,0.0,10,43,3.909090909090909,0,0,0,0,0,0,0,0
5480,what is text analytics,what is text analytics,"['what', 'is', 'text', 'analytics']",0,"['what', 'is', 'text', 'analytics']","['text', 'analytics']",text analytics,0.0,0.0,4,14,2.8,0,0,0,0,0,0,0,0
5481,wanted to join a group to execute projects using r and git,wanted to join a group to execute projects using r and git,"['wanted', 'to', 'join', 'a', 'group', 'to', 'execute', 'projects', 'using', 'r', 'and', 'git']",0,"['wanted', 'to', 'join', 'a', 'group', 'to', 'execute', 'project', 'using', 'r', 'and', 'git']","['wanted', 'join', 'group', 'execute', 'project', 'using', 'r', 'git']",wanted join group execute project using r git,0.0,0.0,12,45,3.4615384615384617,0,0,0,0,0,0,0,0
5482,executive program in business analytics offered by jigsaw academy in collaboration with misb bocconi university,executive program in business analytics offered by jigsaw academy in collaboration with misb bocconi university,"['executive', 'program', 'in', 'business', 'analytics', 'offered', 'by', 'jigsaw', 'academy', 'in', 'collaboration', 'with', 'misb', 'bocconi', 'university']",0,"['executive', 'program', 'in', 'business', 'analytics', 'offered', 'by', 'jigsaw', 'academy', 'in', 'collaboration', 'with', 'misb', 'bocconi', 'university']","['executive', 'program', 'business', 'analytics', 'offered', 'jigsaw', 'academy', 'collaboration', 'misb', 'bocconi', 'university']",executive program business analytics offered jigsaw academy collaboration misb bocconi university,0.0,0.0,15,97,6.0625,0,0,0,0,0,0,0,0
5483,train  test data partition,train  test data partition,"['train', 'test', 'data', 'partition']",0,"['train', 'test', 'data', 'partition']","['train', 'test', 'data', 'partition']",train test data partition,0.0,0.0,4,25,5.0,0,0,0,0,0,0,0,0
5484,logistic results inconsistent,logistic results inconsistent,"['logistic', 'results', 'inconsistent']",0,"['logistic', 'result', 'inconsistent']","['logistic', 'result', 'inconsistent']",logistic result inconsistent,0.0,0.0,3,28,7.0,0,0,0,0,0,0,0,0
5485,how to remove nan value while calculating the information value of the variable,how to remove nan value while calculating the information value of the variable,"['how', 'to', 'remove', 'nan', 'value', 'while', 'calculating', 'the', 'information', 'value', 'of', 'the', 'variable']",0,"['how', 'to', 'remove', 'nan', 'value', 'while', 'calculating', 'the', 'information', 'value', 'of', 'the', 'variable']","['remove', 'nan', 'value', 'calculating', 'information', 'value', 'variable']",remove nan value calculating information value variable,0.0,0.0,13,55,3.9285714285714284,0,0,0,0,0,0,0,0
5486,please help me in joining the datafest online from us,please help me in joining the datafest online from us,"['please', 'help', 'me', 'in', 'joining', 'the', 'datafest', 'online', 'from', 'us']",0,"['please', 'help', 'me', 'in', 'joining', 'the', 'datafest', 'online', 'from', 'u']","['please', 'help', 'joining', 'datafest', 'online', 'u']",please help joining datafest online u,0.0,0.0,10,37,3.3636363636363638,0,0,0,0,0,0,0,0
5487,what algorithms are suitable for the following recommender healthcare system,what algorithms are suitable for the following recommender healthcare system,"['what', 'algorithms', 'are', 'suitable', 'for', 'the', 'following', 'recommender', 'healthcare', 'system']",0,"['what', 'algorithm', 'are', 'suitable', 'for', 'the', 'following', 'recommender', 'healthcare', 'system']","['algorithm', 'suitable', 'following', 'recommender', 'healthcare', 'system']",algorithm suitable following recommender healthcare system,0.275,0.275,10,58,5.2727272727272725,0,0,0,0,0,0,0,0
5488,certifications suggestion,certifications suggestion,"['certifications', 'suggestion']",0,"['certification', 'suggestion']","['certification', 'suggestion']",certification suggestion,0.0,0.0,2,24,8.0,0,0,0,0,0,0,0,0
5489,what are anonymous function in r,what are anonymous function in r,"['what', 'are', 'anonymous', 'function', 'in', 'r']",0,"['what', 'are', 'anonymous', 'function', 'in', 'r']","['anonymous', 'function', 'r']",anonymous function r,0.0,0.0,6,20,2.857142857142857,0,0,0,0,0,0,0,0
5490,should we take all the variables from the training data in a randomforest model,should we take all the variables from the training data in a randomforest model,"['should', 'we', 'take', 'all', 'the', 'variables', 'from', 'the', 'training', 'data', 'in', 'a', 'randomforest', 'model']",0,"['should', 'we', 'take', 'all', 'the', 'variable', 'from', 'the', 'training', 'data', 'in', 'a', 'randomforest', 'model']","['take', 'variable', 'training', 'data', 'randomforest', 'model']",take variable training data randomforest model,0.0,0.0,14,46,3.066666666666667,0,0,0,0,0,0,0,0
5491,time series forecasting and reducing it to stationary series,time series forecasting and reducing it to stationary series,"['time', 'series', 'forecasting', 'and', 'reducing', 'it', 'to', 'stationary', 'series']",0,"['time', 'series', 'forecasting', 'and', 'reducing', 'it', 'to', 'stationary', 'series']","['time', 'series', 'forecasting', 'reducing', 'stationary', 'series']",time series forecasting reducing stationary series,0.0,0.0,9,50,5.0,0,0,0,0,0,0,0,0
5492,data visualization and text analysis twitter mining,data visualization and text analysis twitter mining,"['data', 'visualization', 'and', 'text', 'analysis', 'twitter', 'mining']",0,"['data', 'visualization', 'and', 'text', 'analysis', 'twitter', 'mining']","['data', 'visualization', 'text', 'analysis', 'twitter', 'mining']",data visualization text analysis twitter mining,0.0,0.0,7,47,5.875,0,0,0,0,0,0,0,0
5493,cross validation strategy for stacked models,cross validation strategy for stacked models,"['cross', 'validation', 'strategy', 'for', 'stacked', 'models']",0,"['cross', 'validation', 'strategy', 'for', 'stacked', 'model']","['cross', 'validation', 'strategy', 'stacked', 'model']",cross validation strategy stacked model,0.0,0.0,6,39,5.571428571428571,0,0,0,0,0,0,0,0
5494,how to convert cross table into straight table in qlikview,how to convert cross table into straight table in qlikview,"['how', 'to', 'convert', 'cross', 'table', 'into', 'straight', 'table', 'in', 'qlikview']",0,"['how', 'to', 'convert', 'cross', 'table', 'into', 'straight', 'table', 'in', 'qlikview']","['convert', 'cross', 'table', 'straight', 'table', 'qlikview']",convert cross table straight table qlikview,0.1,0.1,10,43,3.909090909090909,0,0,0,0,0,0,0,0
